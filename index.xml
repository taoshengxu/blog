<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Homepage on My Lives</title>
    <link>/blog/</link>
    <description>Recent content in Homepage on My Lives</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 27 Aug 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="/blog/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>python学习</title>
      <link>/blog/cn/2017/12/python_study/</link>
      <pubDate>Thu, 21 Dec 2017 11:17:39 +0000</pubDate>
      
      <guid>/blog/cn/2017/12/python_study/</guid>
      <description>
        

&lt;p&gt;&lt;a href=&#34;http://www.runoob.com/python/python-tutorial.html&#34;&gt;入门教程&lt;/a&gt;
&lt;a href=&#34;http://study.163.com/course/courseMain.htm?courseId=378003&#34;&gt;视频教程&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;认识python&#34;&gt;认识python&lt;/h1&gt;

&lt;h4 id=&#34;实例-python-2-0&#34;&gt;实例(Python 2.0+)&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/python
print &amp;quot;Hello, World!&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;实例-python-3-0&#34;&gt;实例(Python 3.0+)&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/python3
print(&amp;quot;Hello, World!&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;python-脚本&#34;&gt;python 脚本&lt;/h1&gt;

&lt;p&gt;所有 Python 文件将以 .py 为扩展名。用 $ python *.py 执行脚本。&lt;/p&gt;

&lt;h1 id=&#34;python语法&#34;&gt;python语法&lt;/h1&gt;

&lt;p&gt;1.Python 的代码块不使用大括号 {} 来控制类，函数以及其他逻辑判断。&lt;/p&gt;

&lt;p&gt;python 最具特色的就是用缩进来写模块。缩进的空白数量是可变的，但是所有代码块语句必须包含相同的缩进空白数量，这个必须严格执行。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;if True:
  print &amp;quot;True&amp;quot;
else:
  print &amp;quot;False&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.xx&lt;/p&gt;

&lt;h1 id=&#34;python函数&#34;&gt;python函数&lt;/h1&gt;

&lt;p&gt;语法&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def functionname( parameters ):
   &amp;quot;函数_文档字符串&amp;quot;
   function_suite
   return [expression]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;示例&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/python
# -*- coding: UTF-8 -*-
 
# 定义函数
def printme( str ):
   &amp;quot;打印任何传入的字符串&amp;quot;
   print str;
   return;
# 调用函数
printme(&amp;quot;我要调用用户自定义函数!&amp;quot;);
printme(&amp;quot;再次调用同一函数&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;python-模块&#34;&gt;Python 模块&lt;/h1&gt;

&lt;p&gt;Python 模块(Module)，是一个 Python 文件，以 .py 结尾，包含了 Python 对象定义和Python语句。&lt;/p&gt;

&lt;p&gt;定义support.py 模块：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def print_func( par ):
   print &amp;quot;Hello : &amp;quot;, par
   return
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;模块的引入&#34;&gt;模块的引入&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/python
# -*- coding: UTF-8 -*-
# 导入模块
import support
# 现在可以调用模块里包含的函数了
# 调用方法：模块名.函数名
support.print_func(&amp;quot;Runoob&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;from-import-语句&#34;&gt;From…import 语句&lt;/h3&gt;

&lt;p&gt;Python 的 from 语句让你从模块中导入一个指定的部分到当前命名空间中。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from fib import fibonacci

&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;常用语句&#34;&gt;常用语句&lt;/h1&gt;

&lt;h3 id=&#34;读文件&#34;&gt;读文件&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;try:
    f = open(&#39;/path/to/file&#39;, &#39;r&#39;)
    print(f.read())
finally:
    if f:
        f.close()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#with语句来自动帮我们调用close()方法
with open(&#39;/path/to/file&#39;, &#39;r&#39;) as f:
    print(f.read())
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;for line in f.readlines():
    print(line.strip()) # 把末尾的&#39;\n&#39;删掉
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;写文件&#34;&gt;写文件&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;with open(&#39;/Users/michael/test.txt&#39;, &#39;w&#39;) as f:
    f.write(&#39;Hello, world!&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;常规语法&#34;&gt;常规语法&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;import&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from...import
如 from A import b,相当于
import A
b=A.b
在此过程中有一个隐含的赋值的过程

import A as B,给予A库一个B的别称，帮助记忆
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;原始字符串&lt;/strong&gt;
在单引号或者双引号 前面加一个字符 &lt;strong&gt;r&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;运算符&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;a=10
a+=1  等价于 a=a+1=11

/  除法
// 除法取整
% 取余
** 幂运算  3**2=9
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;三元操作符&lt;/strong&gt;  small =x if x &amp;lt;y else y 条件真为x, 假为y&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;断言&lt;/strong&gt;   assert 3&amp;gt;4&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;循环&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1. for 
for i in range(1,8):  注意冒号

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;break&lt;/strong&gt;跳出当前循环&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;continue&lt;/strong&gt; 终止本轮循环，开启下一轮循环（如果循环条件为真）&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;range()函数&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;range([start,]stop[,step=1])&lt;/p&gt;

&lt;p&gt;list(range(5))&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;列表&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;menber=[&amp;quot;a&amp;quot;,&amp;quot;b&amp;quot;,&amp;quot;c&amp;quot;] 单一类型列表
mix=[1,&amp;quot;a&amp;quot;,3.14,[a,b,c]] 混合类型列表

empty=[]    创建空列表
empty.append(&amp;quot;小甲鱼&amp;quot;)  向列表添加单一元素
empty.extend([a,b])     向列表添加另外一个列表
empty.insert(0,&amp;quot;牡丹&amp;quot;)
empty.remove(&amp;quot;牡丹&amp;quot;)
del empty 删除
pop()从列表中删除最后一个元素并弹出
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;操作符&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;列表比较大小 只比较第一个元素
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;dir(list)&lt;/strong&gt; 列出list的所有内置函数&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;numpy moudle&lt;/strong&gt; API&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy-1.13.0/genindex.html&#34;&gt;https://docs.scipy.org/doc/numpy-1.13.0/genindex.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;strong&gt;call&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;变量:
1.  前带_的变量:  标明是一个私有变量, 只用于标明, 外部类还是可以访问到这个变量
2.  前带两个_ ,后带两个_ 的变量:  标明是内置变量,
3.  大写加下划线的变量:  标明是 不会发生改变的全局变量
函数:
1. 前带_的变量: 标明是一个私有函数, 只用于标明,
2.  前带两个_ ,后带两个_ 的函数:  标明是特殊函数
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Python特殊语法：filter、map、reduce、lambda [转]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Python内置了一些非常有趣但非常有用的函数，充分体现了Python的语言魅力！&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;filter(function, sequence)&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;对sequence中的item依次执行function(item)，将执行结果为True的item组成一个List/String/Tuple（取决于sequence的类型）返回：
&amp;gt;&amp;gt;&amp;gt; def f(x): return x % 2 != 0 and x % 3 != 0 
&amp;gt;&amp;gt;&amp;gt; filter(f, range(2, 25)) 
[5, 7, 11, 13, 17, 19, 23]
&amp;gt;&amp;gt;&amp;gt; def f(x): return x != &#39;a&#39; 
&amp;gt;&amp;gt;&amp;gt; filter(f, &amp;quot;abcdef&amp;quot;) 
&#39;bcdef&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;map(function, sequence)&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;对sequence中的item依次执行function(item)，见执行结果组成一个List返回：
&amp;gt;&amp;gt;&amp;gt; def cube(x): return x*x*x 
&amp;gt;&amp;gt;&amp;gt; map(cube, range(1, 11)) 
[1, 8, 27, 64, 125, 216, 343, 512, 729, 1000]
&amp;gt;&amp;gt;&amp;gt; def cube(x) : return x + x 
... 
&amp;gt;&amp;gt;&amp;gt; map(cube , &amp;quot;abcde&amp;quot;) 
[&#39;aa&#39;, &#39;bb&#39;, &#39;cc&#39;, &#39;dd&#39;, &#39;ee&#39;]
另外map也支持多个sequence，这就要求function也支持相应数量的参数输入：
&amp;gt;&amp;gt;&amp;gt; def add(x, y): return x+y 
&amp;gt;&amp;gt;&amp;gt; map(add, range(8), range(8)) 
[0, 2, 4, 6, 8, 10, 12, 14]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;reduce(function, sequence, starting_value)&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;对sequence中的item顺序迭代调用function，如果有starting_value，
还可以作为初始值调用，例如可以用来对List求和：
&amp;gt;&amp;gt;&amp;gt; def add(x,y): return x + y 
&amp;gt;&amp;gt;&amp;gt; reduce(add, range(1, 11)) 
55 （注：1+2+3+4+5+6+7+8+9+10）
&amp;gt;&amp;gt;&amp;gt; reduce(add, range(1, 11), 20) 
75 （注：1+2+3+4+5+6+7+8+9+10+20）
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;lambda&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;：这是Python支持一种有趣的语法，它允许你快速定义单行的最小函数，
类似与C语言中的宏，这些叫做lambda的函数，
是从LISP借用来的，可以用在任何需要函数的地方： 
&amp;gt;&amp;gt;&amp;gt; g = lambda x: x * 2 
&amp;gt;&amp;gt;&amp;gt; g(3) 
6 
&amp;gt;&amp;gt;&amp;gt; (lambda x: x * 2)(3) 
6
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;我们也可以把filter map reduce 和lambda结合起来用，函数就可以简单的写成一行。
例如
kmpathes = filter(lambda kmpath: kmpath,                  
map(lambda kmpath: string.strip(kmpath),
string.split(l, &#39;:&#39;)))              
看起来麻烦，其实就像用语言来描述问题一样，非常优雅。
对 l 中的所有元素以&#39;:&#39;做分割，得出一个列表。对这个列表的每一个元素做字符串strip，形成一个列表。对这个列表的每一个元素做直接返回操作(这个地方可以加上过滤条件限制)，最终获得一个字符串被&#39;:&#39;分割的列表，列表中的每一个字符串都做了strip，并可以对特殊字符串过滤。

--
lambda表达式返回一个函数对象
例子：
func = lambda x,y:x+y
func相当于下面这个函数
def func(x,y):
    return x+y
 
注意def是语句而lambda是表达式
下面这种情况下就只能用lambda而不能用def
[(lambda x:x*x)(x) for x in range(1,11)]
 
map，reduce，filter中的function都可以用lambda表达式来生成！
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;map(function,sequence)&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;把sequence中的值当参数逐个传给function，返回一个包含函数执行结果的list。
如果function有两个参数，即map(function,sequence1,sequence2)。
例子：
求1*1,2*2,3*3,4*4
map(lambda x:x*x,range(1,5))
返回值是[1,4,9,16]
 
reduce(function,sequence)
function接收的参数个数只能为2
先把sequence中第一个值和第二个值当参数传给function，再把function的返回值和第三个值当参数传给
function，然后只返回一个结果。
 
例子：
求1到10的累加
reduce(lambda x,y:x+y,range(1,11))
返回值是55。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;filter(function,sequence)&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;function的返回值只能是True或False
把sequence中的值逐个当参数传给function，如果function(x)的返回值是True，
就把x加到filter的返回值里面。一般来说filter的返回值是list，
特殊情况如sequence是string或tuple，则返回值按照sequence的类型。
 
例子：
找出1到10之间的奇数
filter(lambda x:x%2!=0,range(1,11))
返回值
[1,3,5,7,9]
 
如果sequence是一个string
filter(lambda x:len(x)!=0,&#39;hello&#39;)返回&#39;hello&#39;
filter(lambda x:len(x)==0,&#39;hello&#39;)返回&#39;&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;定义：zip([iterable, &amp;hellip;])&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;zip()是Python的一个内建函数，它接受一系列可迭代的对象作为参数，将对象中对应的元素打包成一个个tuple（元组），然后返回由这些tuples组成的list（列表）。若传入参数的长度不等，则返回list的长度和参数中长度最短的对象相同。利用*号操作符，可以将list unzip（解压），看下面的例子就明白了：

&amp;gt;&amp;gt;&amp;gt; a = [1,2,3]
&amp;gt;&amp;gt;&amp;gt; b = [4,5,6]
&amp;gt;&amp;gt;&amp;gt; c = [4,5,6,7,8]
&amp;gt;&amp;gt;&amp;gt; zipped = zip(a,b)
[(1, 4), (2, 5), (3, 6)]
&amp;gt;&amp;gt;&amp;gt; zip(a,c)
[(1, 4), (2, 5), (3, 6)]
&amp;gt;&amp;gt;&amp;gt; zip(*zipped)
[(1, 2, 3), (4, 5, 6)]
&lt;/code&gt;&lt;/pre&gt;

        
      </description>
    </item>
    
    <item>
      <title>深度学习Tensorflow</title>
      <link>/blog/cn/2017/12/deeplearning/</link>
      <pubDate>Wed, 20 Dec 2017 21:04:42 +0000</pubDate>
      
      <guid>/blog/cn/2017/12/deeplearning/</guid>
      <description>
        &lt;p&gt;&lt;a href=&#34;https://jizhi.im/blog/post/gpu-p6&#34;&gt;学习教程&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://study.163.com/course/courseMain.htm?courseId=1003223001&#34;&gt;斯坦福李飞飞&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.tensorfly.cn/&#34;&gt;TensorFlow中文社区&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy-1.13.0/genindex.html&#34;&gt;numpy API&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.csdn.net/yunpiao123456/article/details/52437794&#34;&gt;卷积神经网络1&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.csdn.net/hjimce/article/details/47323463&#34;&gt;卷积神经网络2&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap&#34;&gt;Roadmap&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/exacity/deeplearningbook-chinese&#34;&gt;AI圣经&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.zybuluo.com/hanbingtao/note/433855&#34;&gt;零基础入门深度学习&lt;/a&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>决策树</title>
      <link>/blog/cn/2017/11/decision_tree/</link>
      <pubDate>Tue, 21 Nov 2017 09:26:01 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/decision_tree/</guid>
      <description>
        

&lt;h1 id=&#34;特征选择问题&#34;&gt;特征选择问题&lt;/h1&gt;

&lt;p&gt;选择信息增益和信息增益比大的特征&lt;/p&gt;

&lt;h1 id=&#34;信息增益-互信息&#34;&gt;信息增益（互信息）&lt;/h1&gt;

&lt;p&gt;表示得知特征X的信息而使得类Y的信息的不确定性减少的程度。&lt;/p&gt;

&lt;h4 id=&#34;信息熵&#34;&gt;信息熵&lt;/h4&gt;

&lt;p&gt;熵越大，随机变量的不确定性就越大。&lt;/p&gt;

&lt;h4 id=&#34;条件熵&#34;&gt;条件熵&lt;/h4&gt;

&lt;p&gt;随机变量X给定条件下随机变量Y的条件熵 H(Y|X)定义为X给定条件下Y的条件概率分布的熵对X的数学期望。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;信息熵和条件熵中概率由数据估计得到，所对应的熵与条件熵分别称为经验熵和经验条件熵&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&#34;信息增益比&#34;&gt;信息增益比&lt;/h1&gt;

&lt;p&gt;信息增益与训练数据集经验熵的比值&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>基因组版本对应关系</title>
      <link>/blog/cn/2017/11/genome_version/</link>
      <pubDate>Mon, 13 Nov 2017 08:52:07 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/genome_version/</guid>
      <description>
        

&lt;p&gt;&lt;a href=&#34;http://www.bio-info-trainee.com/1469.html&#34;&gt;原文&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;hg19(UCSC)，GRCH37(NCBI)和Ensembl75(ENSEMBL)是三种国际生物信息学数据库资源收集存储单各自发布的基因组信息。&lt;/p&gt;

&lt;p&gt;hg系列，hg18/19/38是目前使用频率最高的基因组。hg38是目前的最新版本。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;基因组各种版本对应关系&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;GRCh36 (hg18): ENSEMBL release_52.&lt;/li&gt;
&lt;li&gt;GRCh37 (hg19): ENSEMBL release_59/61/64/68/69/75.&lt;/li&gt;
&lt;li&gt;GRCh38 (hg38): ENSEMBL release_76/77/78/80/81/82.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;ucsc基因组下载&#34;&gt;UCSC基因组下载&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;http://hgdownload.cse.ucsc.edu/goldenPath/mm10/bigZips/chromFa.tar.gz
http://hgdownload.cse.ucsc.edu/goldenPath/mm9/bigZips/chromFa.tar.gz
http://hgdownload.cse.ucsc.edu/goldenPath/hg19/bigZips/chromFa.tar.gz
http://hgdownload.cse.ucsc.edu/goldenPath/hg38/bigZips/chromFa.tar.gz
# 或者用shell脚本指定下载的染色体号
for i in $(seq 1 22) X Y M;
do echo $i;
  wget http://hgdownload.cse.ucsc.edu/goldenPath/hg19/chromosomes/chr${i}.fa.gz;done
  gunzip *.gz
  for i in $(seq 1 22) X Y M;
  do cat chr${i}.fa &amp;gt;&amp;gt; hg19.fasta;
done
rm -fr chr*.fasta
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;gtf注释文件&#34;&gt;GTF注释文件&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;NCBI&lt;/strong&gt;：最新版（hg38）&lt;/p&gt;

&lt;p&gt;● &lt;a href=&#34;ftp://ftp.ncbi.nih.gov/genomes/H_sapiens/GFF/&#34;&gt;ftp://ftp.ncbi.nih.gov/genomes/H_sapiens/GFF/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;其它版本&lt;/p&gt;

&lt;p&gt;● &lt;a href=&#34;ftp://ftp.ncbi.nlm.nih.gov/genomes/Homo_sapiens/ARCHIVE/&#34;&gt;ftp://ftp.ncbi.nlm.nih.gov/genomes/Homo_sapiens/ARCHIVE/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ensembl&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;● &lt;a href=&#34;ftp://ftp.ensembl.org/pub/release-75/gtf/homosapiens/Homosapiens.GRCh37.75.gtf.gz&#34;&gt;ftp://ftp.ensembl.org/pub/release-75/gtf/homosapiens/Homosapiens.GRCh37.75.gtf.gz&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;变化上面链接中的release就可以拿到所有版本信息&lt;/p&gt;

&lt;p&gt;● &lt;a href=&#34;ftp://ftp.ensembl.org/pub/&#34;&gt;ftp://ftp.ensembl.org/pub/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;UCSC&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;本身需要一系列参数：
  1. Navigate to http://genome.ucsc.edu/cgi-bin/hgTables
  2. Select the following options:
  3. clade: Mammal
  4. genome: Human
  5. assembly: Feb. 2009 (GRCh37/hg19)
  6. group: Genes and Gene Predictions
  7. track: UCSC Genes
  8. table: knownGene
  9. region: Select &amp;quot;genome&amp;quot; for the entire genome.
  10. output format: GTF - gene transfer format
  11. output file: enter a file name to save your results to a file, or leave blank to display results in the browser
  12. Click &#39;get output&#39;.
&lt;/code&gt;&lt;/pre&gt;

        
      </description>
    </item>
    
    <item>
      <title>SAM文件与SAMtools</title>
      <link>/blog/cn/2017/11/sam_samtools/</link>
      <pubDate>Sun, 12 Nov 2017 09:32:54 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/sam_samtools/</guid>
      <description>
        

&lt;h1 id=&#34;sam&#34;&gt;SAM&lt;/h1&gt;

&lt;p&gt;SAM输出的结果中每一行都包括十二项通过Tab分隔&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FCC0YG3ACXX:2:1103:1572:139769#GCTTAATG 99  chr10   60001   0   90M =   60390   479 GAATTCCTTGAGGCCTAAATGCATCGGGGTGCTCTGGTTTTGTTGTTGTTATTTCTGAATGACATTTACTTTGGTGCTCTTTATTTTGCG  CCCFFFFFHHHHHJJJJJJJJIJJJJJJJ?HHGIJJJBFHIJIJIDHIHIEHJJIJJIJJJHHGHHHFFFFFFEDCEEECCDDDDEECDD  XT:A:R  NM:i:0  SM:i:0  AM:i:0  X0:i:2  X1:i:0  XM:i:0  XO:i:0  XG:i:0  MD:Z:90 XA:Z:chr18,+14415,90M,0;    RG:Z:120618_I245_FCC0YG3ACXX_L2_SZAXPI010030-30
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;(1)FCC0YG3ACXX:2:1103:1572:139769#GCTTAATG
(2)99
(3)chr10
(4)60001
(5)0
(6)90M
(7)=
(8)60390
(9)479
(10)GAATTCCTTGAGGCCTAAATGCATCGGGGTGCTCTGGTTTTGTTGTTGTTATTTCTGAATGACATTTACTTTGGTGCTCTTTATTTTGCG
(11)CCCFFFFFHHHHHJJJJJJJJIJJJJJJJ?HHGIJJJBFHIJIJIDHIHIEHJJIJJIJJJHHGHHHFFFFFFEDCEEECCDDDDEECDD
(12)XT:A:R  NM:i:0  SM:i:0  AM:i:0  X0:i:2  X1:i:0  XM:i:0  XO:i:0  XG:i:0  MD:Z:90 XA:Z:chr18,+14415,90M,0;    RG:Z:120618_I245_FCC0YG3ACXX_L2_SZAXPI010030-30


(1)read的名字
(2)Flag 为各个标志的和
(3)比对到的染色体号
(4)第一个比对上的碱基所在位置
(5)质量值 
6. CIGAR  如果CIGAR是*，这个才是判断左右端是否匹配失败的标准
7. mate比对上的染色体号，如果是“=”，则表示在同一条染色体上，*表示没有比对上
8. mate第一个比对上的碱基所在位置 
9. 该read和mate的距离(估计出的片段的长度，当mate 序列位于本序列上游时该值为负值)
10. 序列 
11. 序列对应的质量值 (ASCII码格式)
12. 标记
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(1)如果PE reads的左右两端均没有比对成功，那么第3,6,7列都是*，4，5，8，9都是0，第2列flag只有77,141这两种情况。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;77代表PE,而且PE的两条reads都是unmanned的，&lt;/li&gt;
&lt;li&gt;141跟77一样，只是它们分别指代unmanned的PE的reads的两端,&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(2) 如果是左右两端reads只有一个比对成功，另一个reads没有比对上.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;不管是左端还是右端，第3列都是有染色体的，(第7列是=号[好像不对])，但这并不能说明左端跟右端有着同样的比对结果。而第6列CIGAR是*，这个才是判断左右端是否匹配失败的标准。An unmapped segment without coordinate has a * at this field. However, an unmapped segment may also have an ordinary coordinate such that it can be placed at a desired position after sorting. If RNAME is *, no assumptions can be made about POS and CIGAR. (&lt;a href=&#34;https://samtools.github.io/hts-specs/SAMv1.pdf&#34;&gt;https://samtools.github.io/hts-specs/SAMv1.pdf&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;这也就是我为什么没有发现第7列有染色体，第3列是*号的reads。即使PE reads的右端匹配，左端未匹配，它只会把这个read比对的染色体写在第3列，而不是第7列！所以说要想探究它是左端还是右端未比对成功，得看flag。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;flag-标志&#34;&gt;Flag 标志&lt;/h4&gt;

&lt;p&gt;Flag值解析 &lt;a href=&#34;https://broadinstitute.github.io/picard/explain-flags.html&#34;&gt;https://broadinstitute.github.io/picard/explain-flags.html&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1  序列是一对序列中的一个&lt;/li&gt;
&lt;li&gt;2  比对结果是一个pair-end比对的末端&lt;/li&gt;
&lt;li&gt;4  没有找到位点&lt;/li&gt;
&lt;li&gt;8  这个序列是pair中的一个但是没有找到位点&lt;/li&gt;
&lt;li&gt;16  在这个比对上的位点，序列与参考序列反向互补&lt;/li&gt;
&lt;li&gt;32  这个序列在pair-end中的mate序列与参考序列反向互补&lt;/li&gt;
&lt;li&gt;64 序列是 mate 1&lt;/li&gt;
&lt;li&gt;128 序列是 mate 2&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;质量值&#34;&gt;质量值&lt;/h4&gt;

&lt;p&gt;因工具而异。质量值越高这个比对越可信，如果质量值为0，可能是该序列在参考基因组有多种定位的可能性。&lt;/p&gt;

&lt;h4 id=&#34;cigar&#34;&gt;CIGAR&lt;/h4&gt;

&lt;p&gt;如37M1D2M1I，这段字符的意思是37个匹配，1个参考序列上的删除，2个匹配，1个参考序列上的插入。M代表的是alignment match(可以是错配)&lt;/p&gt;

&lt;h1 id=&#34;samtools&#34;&gt;SAMtools&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://taoshengxu.github.io/DocumentGit/pdf/samtools常用命令详解.pdf&#34;&gt;SAMtools使用手册&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;SAM（sequence Alignment/mapping)数据格式是目前高通量测序中存放比对数据的标准格式，当然他可以用于存放未比对的数据。&lt;/p&gt;

&lt;p&gt;主要功能有：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;samtools view : BAM-SAM/SAM-BAM 转换和提取部分比对&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;samtools sort : 比对排序&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;samtools index: 索引排序比对&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;samtools merge: 聚合多个排序比对&lt;/li&gt;
&lt;li&gt;samtools faidx: 建立FASTA索引，提取部分序列&lt;/li&gt;
&lt;li&gt;samtools tview: 文本格式查看序列&lt;/li&gt;
&lt;li&gt;samtools pileup: 产生基于位置的结果和 consensus/indel calling&lt;/li&gt;
&lt;/ul&gt;

        
      </description>
    </item>
    
    <item>
      <title>Jimmy 直播基因组学习笔记</title>
      <link>/blog/cn/2017/11/genomic_live_streaming/</link>
      <pubDate>Fri, 10 Nov 2017 20:34:59 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/genomic_live_streaming/</guid>
      <description>
        

&lt;p&gt;&lt;strong&gt;教程&lt;/strong&gt; &lt;a href=&#34;http://www.biotrainee.com/thread-1376-1-1.html&#34;&gt;Jimmy直播我的基因组分析 - 目录&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/RNASeq_WES.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;下载hg19基因组&#34;&gt;下载hg19基因组&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;cd /data/reference
mkdir -p genome/hg19  &amp;amp;&amp;amp; cd genome/hg19
nohup wget http://hgdownload.cse.ucsc.edu/goldenPath/hg19/bigZips/chromFa.tar.gz &amp;amp;
tar zvfx chromFa.tar.gz
cat *.fa &amp;gt; hg19.fa
rm chr*.fa
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;fastq-sam-bam&#34;&gt;fastq-sam-bam&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;ls *gz |xargs ~/biosoft/fastqc/FastQC/fastqc -t 10

for i in $(seq 1 6) ;do (nohup bwa  mem -t 5 -M /data/reference/index/bwa/hg19  KPGP-00001_L${i}_R1.fq.gz KPGP-00001_L${i}_R2.fq.gz 1&amp;gt;KPGP-00001_L${i}.sam 2&amp;gt;KPGP-00001_L${i}.bwa.align.log &amp;amp;);done

for i in $(seq 1 6) ;do (nohup samtools sort -@ 5 -o KPGP-00001_L${i}.sorted.bam  KPGP-00001_L${i}.sam &amp;amp;);done

for i in $(seq 1 6) ;do (nohup samtools index KPGP-00001_L${i}.sorted.bam &amp;amp;);done
samtools merge KPGP-00001.merge.bam *.sorted.bam
samtools sort -@ 10 -O bam -o KPGP-00001.sorted.merge.bam  KPGP-00001.merge.bam
samtools index  KPGP-00001.sorted.merge.bam
for i in $(seq 1 6) ;do ( samtools flagstat KPGP-00001_L${i}.sorted.bam &amp;gt;KPGP-00001_L${i}.flagstat.txt );done
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;根据gtf格式的基因注释文件得到人所有基因的染色体坐标&#34;&gt;根据gtf格式的基因注释文件得到人所有基因的染色体坐标&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.biotrainee.com/thread-472-1-1.html&#34;&gt;原文&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir -p ~/reference/gtf/gencode
cd  ~/reference/gtf/gencode
## https://www.gencodegenes.org/releases/current.html
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/gencode.v25.2wayconspseudos.gtf.gz
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/gencode.v25.long_noncoding_RNAs.gtf.gz 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/gencode.v25.polyAs.gtf.gz 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/gencode.v25.annotation.gtf.gz 

## https://www.gencodegenes.org/releases/25lift37.html 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/GRCh37_mapping/gencode.v25lift37.annotation.gtf.gz 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/GRCh37_mapping/gencode.v25lift37.metadata.HGNC.gz 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/GRCh37_mapping/gencode.v25lift37.metadata.EntrezGene.gz 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/GRCh37_mapping/gencode.v25lift37.metadata.RefSeq.gz 
 
zcat  gencode.v25.long_noncoding_RNAs.gtf.gz |perl -alne &#39;{next unless $F[2] eq &amp;quot;gene&amp;quot; ;/gene_name \&amp;quot;(.*?)\&amp;quot;;/; print &amp;quot;$F[0]\t$F[3]\t$F[4]\t$1&amp;quot; }&#39; &amp;gt;lncRNA.hg38.position
zcat  gencode.v25.2wayconspseudos.gtf.gz     |perl -alne &#39;{next unless $F[2] eq &amp;quot;transcript&amp;quot; ;/gene_name \&amp;quot;(.*?)\&amp;quot;;/; print &amp;quot;$F[0]\t$F[3]\t$F[4]\t$1&amp;quot; }&#39; &amp;gt;pseudos.hg38.position
zcat  gencode.v25.annotation.gtf.gz| grep   protein_coding |perl -alne &#39;{next unless $F[2] eq &amp;quot;gene&amp;quot; ;/gene_name \&amp;quot;(.*?)\&amp;quot;;/; print &amp;quot;$F[0]\t$F[3]\t$F[4]\t$1&amp;quot; }&#39; &amp;gt;protein_coding.hg38.position
zcat  gencode.v25.annotation.gtf.gz|perl -alne &#39;{next unless $F[2] eq &amp;quot;gene&amp;quot; ;/gene_name \&amp;quot;(.*?)\&amp;quot;;/; print &amp;quot;$F[0]\t$F[3]\t$F[4]\t$1&amp;quot; }&#39; &amp;gt;allGene.hg38.position
 
zcat  gencode.v25lift37.annotation.gtf.gz | grep   protein_coding |perl -alne &#39;{next unless $F[2] eq &amp;quot;gene&amp;quot; ;/gene_name \&amp;quot;(.*?)\&amp;quot;;/; print &amp;quot;$F[0]\t$F[3]\t$F[4]\t$1&amp;quot; }&#39; &amp;gt;protein_coding.hg19.position
zcat  gencode.v25lift37.annotation.gtf.gz | perl -alne &#39;{next unless $F[2] eq &amp;quot;gene&amp;quot; ;/gene_name \&amp;quot;(.*?)\&amp;quot;;/; print &amp;quot;$F[0]\t$F[3]\t$F[4]\t$1&amp;quot; }&#39; &amp;gt;allGene.hg19.position
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;有个很严重的问题，gencode里面的数据有着HAVANA和ENSEMBL的区别，尤其是在hg38里面，需要区别对待！具体见：&lt;a href=&#34;http://www.bio-info-trainee.com/1991.html&#34;&gt;http://www.bio-info-trainee.com/1991.html&lt;/a&gt; 的解释.&lt;/p&gt;

&lt;h1 id=&#34;call-感兴趣的基因-variation&#34;&gt;Call 感兴趣的基因 variation&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.bio-info-trainee.com/2013.html&#34;&gt;原文&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;grep H3F3A /data/reference/gtf/gencode/protein_coding.hg19.position
samtools mpileup -r chr1:226249552-226259702  -ugf /data/reference/genome/hg19/hg19.fa *sorted.bam | bcftools call -vmO z -o H3F3A.vcf.gz
gunzip H3F3A.vcf.gz

/data/biosoft/annovar/convert2annovar.pl -format vcf4old H3F3A.vcf &amp;gt;H3F3A.annovar
/data/biosoft/annovar/annotate_variation.pl -buildver hg19 --geneanno --outfile H3F3A.anno H3F3A.annovar /data/biosoft/annovar/humandb/

#/data/biosoft/annovar/annotate_variation.pl --downdb refGene /data/biosoft/annovar/humandb

/data/biosoft/annovar/annotate_variation.pl -buildver hg19 --dbtype refGene --geneanno --outfile H3F3A.anno H3F3A.annovar /data/biosoft/annovar/humandb/
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;获取感兴趣的基因坐标&#34;&gt;获取感兴趣的基因坐标&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;grep H3F3A /data/reference/gtf/gencode/protein_coding.hg19.position &amp;gt;&amp;gt; key.list.txt
grep HLA-DQ /data/reference/gtf/gencode/protein_coding.hg19.position &amp;gt;&amp;gt; key.list.txt
grep AVPR1 /data/reference/gtf/gencode/protein_coding.hg19.position &amp;gt;&amp;gt; key.list.txt
grep IRX3 /data/reference/gtf/gencode/protein_coding.hg19.position &amp;gt;&amp;gt; key.list.txt
grep IRX5 /data/reference/gtf/gencode/protein_coding.hg19.position &amp;gt;&amp;gt; key.list.txt
grep GLI3 /data/reference/gtf/gencode/protein_coding.hg19.position &amp;gt;&amp;gt; key.list.txt
grep PAX1 /data/reference/gtf/gencode/protein_coding.hg19.position &amp;gt;&amp;gt; key.list.txt
grep RUNX2 /data/reference/gtf/gencode/protein_coding.hg19.position &amp;gt;&amp;gt; key.list.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;批量提取我们感兴趣的基因的变异情况&#34;&gt;批量提取我们感兴趣的基因的变异情况&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cat key.list.txt |while read id;
do
chr=$(echo $id |cut -d&amp;quot; &amp;quot; -f 1|sed &#39;s/chr//&#39; )
start=$(echo $id |cut -d&amp;quot; &amp;quot; -f 2 )
end=$(echo $id |cut -d&amp;quot; &amp;quot; -f 3 )
gene=$(echo $id |cut -d&amp;quot; &amp;quot; -f 4 )
echo $chr:$start-$end  $gene
samtools mpileup -r  $chr:$start-$end   -ugf /data/reference/genome/hg19/hg19.fa KPGP-00001.sorted.merge.bam | bcftools call -vmO z -o $gene.vcf.gz
done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;前面我们说到有研究表明STAT4上的rs7574865和HLA-DQ的rs9275319是国人群中乙型肝炎病毒（HBV）相关肝细胞癌（HCC）遗传易感基因，那么我们很容易去dbSNP数据库或者我最近强烈推荐 的&lt;a href=&#34;https://www.snpedia.com/index.php/Rs7574865&#34;&gt;Snpedia&lt;/a&gt;数据库&lt;a href=&#34;http://www.bio-info-trainee.com/2100.html&#34;&gt;吐血推荐snpedia数据库，非常丰富的snp信息记录&lt;/a&gt;里面找到它的坐标。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;6   32666295 :Rs9275319--HLA-DQ
2   191964633 :Rs7574865--STAT4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后我检查了我刚才call到的variation文件，&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;zcat STAT4.vcf.gz |grep -w 191964633 显示为空。
zcat HLA-DQ* |grep 32666295  也是空。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;哈哈，我完美的错过了这两个易感位点！！！！谢天谢地！！！&lt;/p&gt;

&lt;h1 id=&#34;bam文件给按照染色体给分割&#34;&gt;bam文件给按照染色体给分割&lt;/h1&gt;

&lt;p&gt;按照染色体（chr1-chr22,chrX,chrY,chrMT）&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bamtools split -in KPGP-00001.sorted.merge.bam -reference  
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;提取未比对的测序数据&#34;&gt;提取未比对的测序数据&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;samtools view -f4 KPGP-00001.sorted.merge.bam &amp;gt; KPGP-00001.sorted.merge.unmapped.sam #more fast,  or
# samtools view sample.bam |perl -alne &#39;{print if $F[2] eq &amp;quot;*&amp;quot; or $F[5] eq &amp;quot;*&amp;quot; }&#39; &amp;gt; sample.unmapped.sam

#提前未比对成功的测序数据(可以分成3类，仅reads1，仅reads2，和两端reads都没有比对成功)
#小写的f是提取，大写的F是过滤
samtools view -u -f 4 -F 264 alignments.bam  &amp;gt; tmps1.bam #仅reads1
samtools view -u -f 8 -F 260 alignments.bam  &amp;gt; tmps2.bam #仅reads2
samtools view -u -f 12 -F 256 alignments.bam &amp;gt; tmps3.bam #两端reads都没有比对成功
samtools merge -u - tmps[123].bam | samtools sort -n - unmapped
bamToFastq -bam unmapped.bam -fq1 unmapped_reads1.fastq -fq2 unmapped_reads2.fastq

#统计一下未比对成功的reads有多少
cut -f 3,6 KPGP-00001.sorted.merge.unmapped.sam |sort |uniq -c &amp;gt;KPGP-00001.sorted.merge.unmapped.counts 

&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;提取左右端测序数据比对到不同染色体的pe-reads&#34;&gt;提取左右端测序数据比对到不同染色体的PE reads&lt;/h1&gt;

&lt;p&gt;左右端测序数据比对到不同染色体的情况，比较有意义，可能是融合基因，也可能是基因之间本来就相似性很大。
三种具有代表性的肿瘤融合基因BCR-ABL、SLC45A3-ELK4 和PAX3-FOXO1&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;融合基因&lt;/strong&gt;（英语：Fusion gene）是指两个基因的全部或一部分的序列相互融合为一个新的基因的过程。其有可能是染色体易位、中间缺失或染色体倒置所致的结果.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;samtools view KPGP-00001.sorted.merge.bam | perl -alne &#39;{print if $F[6] ne &amp;quot;=&amp;quot;}&#39;  &amp;gt;unpaired.sam 
cut -f 3,7 unpaired.sam |sort |uniq -c
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;pcr-duplication&#34;&gt;PCR duplication&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.sina.com.cn/s/blog_69e75efd0102wu57.html&#34;&gt;http://blog.sina.com.cn/s/blog_69e75efd0102wu57.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;设一个基因组有A、B两个片段，PCR后得到无论多少条reads，比如nA+mB条，在数据分析的时候，都只保留1条A和1条B（unique reads）用于组装，而去掉(n-1)条A和(m-1)条B。共有(n-1)条A和(m-1)条B被当成duplicatedreads看待，尽管它们是正常PCR的正常产物。&lt;/p&gt;

&lt;p&gt;那么为什么要去除这个duplication呢？主要是因为在call snp的时候，如果某个变异位点的变异碱基都是来自于PCR重复，而我们却认为它深度足够判断是真的变异位点，这个结论其实有很大可能是假阳性。&lt;/p&gt;

&lt;h1 id=&#34;覆盖度详细探究&#34;&gt;覆盖度详细探究&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;samtools flagstat KPGP-00001.sorted.merge.bam

#全基因组
samtools mpileup KPGP-00001.sorted.merge.bam |perl -alne &#39;{if($F[3]&amp;gt;100){$depth{&amp;quot;over100&amp;quot;}++}else{$depth{$F[3]}++}}END{print &amp;quot;$_\t$depth{$_}&amp;quot; foreach sort{$a &amp;lt;=&amp;gt; $b}keys %depth}&#39; 

#每一条染色体
ls KPGP-00001.sorted.merge.REF*.bam |while read id 
do 
echo $id
samtools mpileup $id |perl -alne &#39;{if($F[3]&amp;gt;100){$depth{&amp;quot;over100&amp;quot;}++}else{$depth{$F[3]}++}} END {print &amp;quot;$_\t$depth{$_}&amp;quot; foreach sort{$a &amp;lt;=&amp;gt; $b}keys %depth}&#39; &amp;gt;$id.depth.txt
done 

&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;对比对结果文件进行过滤&#34;&gt;对比对结果文件进行过滤&lt;/h1&gt;

&lt;p&gt;这个地方有问题&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;samtools view -h -F4  -q 5 KPGP-00001.sorted.merge.bam |samtools view -bS |samtools rmdup - KPGP-00001.filter.rmdup.bam
samtools index KPGP-00001.filter.rmdup.bam

bam文件是二进制文件，我们需要samtools view的命令进行格式转换。
这个管道的意思分开来说就是运行第一步时过滤的时候已将bam文件转成我们能看的sam格式。
其中h是在输出的结果中包含头header，F和q是过滤掉没有mapped上的reads（也就是multiple mapping的情况）和低质量的reads。
第二步是将上一步得出的sam文件再转成bam，
第三步就是用samtools rmdup过滤掉PCR duplication的情况了，最后得到了过滤了multiple mapping、PCR duplication及低质量比对的bam文件。
最后利用samtools index对过滤后的bam文件建立索引。
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;用gatk对sam格式的文件进行重排&#34;&gt;用GATK对SAM格式的文件进行重排&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.bio-info-trainee.com/838.html&#34;&gt;GATK使用注意事项&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/snewhouse/ngs_nextflow/wiki/GATK-Bundle&#34;&gt;https://github.com/snewhouse/ngs_nextflow/wiki/GATK-Bundle&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/ddcap/halvade/wiki&#34;&gt;https://github.com/ddcap/halvade/wiki&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# ftp://ftp.broadinstitute.org/bundle/hg19

axel ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz
wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz
gunzip ucsc.hg19.fasta.gz
bwa index ucsc.hg19.fasta
# ucsc.hg19.fasta.amb
# ucsc.hg19.fasta.ann
# ucsc.hg19.fasta.bwt
# ucsc.hg19.fasta.pac
# ucsc.hg19.fasta.sa
axel ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/1000G_phase1.indels.hg19.sites.vcf.gz
axel ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/1000G_phase1.indels.hg19.sites.vcf.idx.gz
axel ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/Mills_and_1000G_gold_standard.indels.hg19.sites.vcf.gz
axel ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/Mills_and_1000G_gold_standard.indels.hg19.sites.vcf.idx.gz
axel ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.dict.gz
axel ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/dbsnp_138.hg19.vcf.gz

ls *.gz |while read id;
do
gunzip $id
done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;按染色体下载hg19基因组&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for i in $(seq 1 22) X Y M;
do echo $i;
wget http://hgdownload.cse.ucsc.edu/goldenPath/hg19/chromosomes/chr${i}.fa.gz;
done
gunzip *.gz
for i in $(seq 1 22) X Y M;
do cat chr${i}.fa &amp;gt;&amp;gt; hg19.fasta;
done
rm -fr chr*.fasta

bwa index ucsc.hg19.fasta

bwa index -a bwtsw hg19.fasta
samtools faidx hg19.fasta
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;首先用RealignerTargetCreator找到需要重新比对的区域，输出文件intervals，然后用输出的 tmp.intervals 做输入文件来进行重新比对，也就是用IndelRealigner在这些区域内进行重新比对.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;nohup java -Xmx60g -jar /data/biosoft/GATK/GenomeAnalysisTK.jar -R \
/data/reference/annotation/GATK/ucsc.hg19.fasta -T RealignerTargetCreator \
-I KPGP-00001.filter.rmdup.bam -o KPGP-00001.filter.rmdup.intervals \
-known /data/reference/annotation/GATK/1000G_phase1.indels.hg19.sites.vcf \
1&amp;gt; KPGP-00001.filter.rmdup.RealignerTargetCreator.log

nohup java -Xmx60g -jar /data/biosoft/GATK/GenomeAnalysisTK.jar  -R \
/data/reference/annotation/GATK/ucsc.hg19.fasta  -T IndelRealigner  \
-I KPGP-00001.filter.rmdup.bam  -targetIntervals KPGP-00001.filter.rmdup.intervals \
-o KPGP-00001.filter.rmdup.realgn.bam  1&amp;gt;KPGP-00001.filter.rmdup.IndelRealigner.log
&lt;/code&gt;&lt;/pre&gt;

        
      </description>
    </item>
    
    <item>
      <title>根据gtf格式的基因注释文件得到人所有基因的染色体坐标</title>
      <link>/blog/cn/2017/11/gtf_gene_position/</link>
      <pubDate>Fri, 10 Nov 2017 11:00:13 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/gtf_gene_position/</guid>
      <description>
        &lt;p&gt;&lt;strong&gt;原文&lt;/strong&gt; ：&lt;a href=&#34;http://www.biotrainee.com/thread-472-1-1.html&#34;&gt;http://www.biotrainee.com/thread-472-1-1.html&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir -p ~/reference/gtf/gencode
cd  ~/reference/gtf/gencode
## https://www.gencodegenes.org/releases/current.html
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/gencode.v25.2wayconspseudos.gtf.gz
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/gencode.v25.long_noncoding_RNAs.gtf.gz 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/gencode.v25.polyAs.gtf.gz 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/gencode.v25.annotation.gtf.gz 
## https://www.gencodegenes.org/releases/25lift37.html 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/GRCh37_mapping/gencode.v25lift37.annotation.gtf.gz 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/GRCh37_mapping/gencode.v25lift37.metadata.HGNC.gz 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/GRCh37_mapping/gencode.v25lift37.metadata.EntrezGene.gz 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/GRCh37_mapping/gencode.v25lift37.metadata.RefSeq.gz 

zcat  gencode.v25.long_noncoding_RNAs.gtf.gz |perl -alne &#39;{next unless $F[2] eq &amp;quot;gene&amp;quot; ;/gene_name \&amp;quot;(.*?)\&amp;quot;;/; print &amp;quot;$F[0]\t$F[3]\t$F[4]\t$1&amp;quot; }&#39; &amp;gt;lncRNA.hg38.position
zcat  gencode.v25.2wayconspseudos.gtf.gz     |perl -alne &#39;{next unless $F[2] eq &amp;quot;transcript&amp;quot; ;/gene_name \&amp;quot;(.*?)\&amp;quot;;/; print &amp;quot;$F[0]\t$F[3]\t$F[4]\t$1&amp;quot; }&#39; &amp;gt;pseudos.hg38.position
zcat  gencode.v25.annotation.gtf.gz| grep   protein_coding |perl -alne &#39;{next unless $F[2] eq &amp;quot;gene&amp;quot; ;/gene_name \&amp;quot;(.*?)\&amp;quot;;/; print &amp;quot;$F[0]\t$F[3]\t$F[4]\t$1&amp;quot; }&#39; &amp;gt;protein_coding.hg38.position
zcat  gencode.v25.annotation.gtf.gz|perl -alne &#39;{next unless $F[2] eq &amp;quot;gene&amp;quot; ;/gene_name \&amp;quot;(.*?)\&amp;quot;;/; print &amp;quot;$F[0]\t$F[3]\t$F[4]\t$1&amp;quot; }&#39; &amp;gt;allGene.hg38.position

zcat  gencode.v25lift37.annotation.gtf.gz | grep   protein_coding |perl -alne &#39;{next unless $F[2] eq &amp;quot;gene&amp;quot; ;/gene_name \&amp;quot;(.*?)\&amp;quot;;/; print &amp;quot;$F[0]\t$F[3]\t$F[4]\t$1&amp;quot; }&#39; &amp;gt;protein_coding.hg19.position
zcat  gencode.v25lift37.annotation.gtf.gz | perl -alne &#39;{next unless $F[2] eq &amp;quot;gene&amp;quot; ;/gene_name \&amp;quot;(.*?)\&amp;quot;;/; print &amp;quot;$F[0]\t$F[3]\t$F[4]\t$1&amp;quot; }&#39; &amp;gt;allGene.hg19.position
&lt;/code&gt;&lt;/pre&gt;

        
      </description>
    </item>
    
    <item>
      <title>外显子测序数据分析学习笔记</title>
      <link>/blog/cn/2017/11/whole_exon_sequencing_study/</link>
      <pubDate>Thu, 09 Nov 2017 18:01:02 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/whole_exon_sequencing_study/</guid>
      <description>
        

&lt;p&gt;&lt;strong&gt;学习提纲&lt;/strong&gt;：&lt;/p&gt;

&lt;p&gt;（1）&lt;a href=&#34;http://www.bio-info-trainee.com/2735.html&#34;&gt;肿瘤全外显子测序数据分析流程&lt;/a&gt; &lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=MzAxMDkxODM1Ng==&amp;amp;mid=2247485033&amp;amp;idx=1&amp;amp;sn=eb9865b92879e20c4afe285aeb8dc73c&amp;amp;chksm=9b4846d2ac3fcfc4e3f90c6ec8ff533494f3a43c502e3c8e842dafb7496db137c11434fccea4&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=0922Ls8z5WWLuNh7ml25V20r#rd&#34;&gt;微信连接&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(2) &lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=MzAxMDkxODM1Ng==&amp;amp;mid=2247484873&amp;amp;idx=1&amp;amp;sn=e455578dfac51afece7adb21cb315a17&amp;amp;chksm=9b484572ac3fcc6460b6b9bbb88306f73c399d8e7a96ad8bb472a179a8de518bc70e21a72b0b&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=0819fvKioudGMT1TYHXwnXoG#rd&#34;&gt;WES分析七步走&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(3) &lt;a href=&#34;http://www.bio-info-trainee.com/1108.html&#34;&gt;WES 测序质量控制&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(4) &lt;a href=&#34;http://www.bio-info-trainee.com/1114.html&#34;&gt;WES（二）snp-calling&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(5) &lt;a href=&#34;http://www.bio-info-trainee.com/1137.html&#34;&gt;WES（三）snp-filter&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(6) &lt;a href=&#34;http://www.bio-info-trainee.com/1138.html&#34;&gt;WES（四）不同个体的比较&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(7) &lt;a href=&#34;http://www.bio-info-trainee.com/1150.html&#34;&gt;WES（五）不同软件比较&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(8) &lt;a href=&#34;http://www.bio-info-trainee.com/1158.html&#34;&gt;WES（六）用annovar注释&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(9) &lt;a href=&#34;http://www.bio-info-trainee.com/1159.html&#34;&gt;WES（七）看de novo变异情况&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(10) &lt;a href=&#34;http://blog.csdn.net/zhu_si_tao/article/details/53321374&#34;&gt;GATK流程&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(11) &lt;a href=&#34;http://www.bio-info-trainee.com/838.html&#34;&gt;GATK使用注意事项&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;WES数据分析步骤：A Survey of Computational Tools to Analyze and Interpret Whole Exome Sequencing Data(2016)&lt;/p&gt;

&lt;h1 id=&#34;数据下载&#34;&gt;数据下载&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4812767/&#34;&gt;Whole-exome sequencing identifies MST1R as a genetic susceptibility gene in nasopharyngeal carcinoma&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We sequenced the blood samples from 161 NPC cases, including 39 EAO cases, 63 FH+ cases from 52 independent families, and 59 sporadic cases by WES and achieved an average coverage of 49-fold on target (range of 32- to 76-fold). An additional 2,160 NPC cases and 2,433 healthy controls from Hong Kong were further examined for the selected candidate variants. &lt;strong&gt;GEO Accession ID SRA291701&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;挑选5个样本进行分析 npc.sra.txt&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SRX445405    MALE    NPC15   SRR1139956  NPC15F  NO  SRS540548   NPC15F-T
SRX445406    MALE    NPC15   SRR1139958  NPC15F  NO  SRS540549   NPC15F-N
SRX445407    MALE    NPC29   SRR1139966  NPC29F  YES SRS540550   NPC29F-T
SRX445408    MALE    NPC29   SRR1139973  NPC29F  YES SRS540551   NPC29F-N
SRX445409    FEMALE  NPC10   SRR1139999  NPC10F  NO  SRS540552   NPC10F-T
SRX445410    FEMALE  NPC10   SRR1140007  NPC10F  NO  SRS540553   NPC10F-N
SRX445411    FEMALE  NPC34   SRR1140015  NPC34F  NO  SRS540554   NPC34F-T
SRX445412    FEMALE  NPC34   SRR1140023  NPC34F  NO  SRS540555   NPC34F-N
SRX445413    MALE    NPC37   SRR1140044  NPC37F  YES SRS540556   NPC37F-T
SRX445414    MALE    NPC37   SRR1140045  NPC37F  YES SRS540557   NPC37F-N
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cat npc.sra.txt | cut -f 4| while read id
# or cut -f 4 npc.sra.txt | while read id
do echo $id
axel ftp://ftp-trace.ncbi.nlm.nih.gov/sra/sra-instant/reads/ByStudy/sra/SRP/SRP035/SRP035573/$id/$id.sra &amp;amp;
done
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cat npc.sra.txt | while read id
do
array=($id)
echo  ${array[3]}.sra  ${array[7]} fastq-dump --gzip --split-3 -A \  
   ${array[7]}  ${array[3]}.sra 
done 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;刚刚开始没搞清楚，这个太难了，学了好像暂时也没啥好用的，数据、资料收集到这里，以后有空再学习吧，数据太大了，浪费空间和电费了。&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>DNA Methylation甲基化450k,850k芯片</title>
      <link>/blog/cn/2017/11/humanmethylation450_850k/</link>
      <pubDate>Tue, 07 Nov 2017 23:39:50 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/humanmethylation450_850k/</guid>
      <description>
        

&lt;h1 id=&#34;illumina-humanmethylation-beadchip简介&#34;&gt;Illumina HumanMethylation BeadChip简介&lt;/h1&gt;

&lt;p&gt;Illumina最早的甲基化芯片是27K（K代表1000，表示大概可以测到的CpG位点数）的数据，后来增加到了450K（主流的甲基化芯片），而目前illumina已经出了新一代产品EPIC（我习惯称之为850K），但是技术核心在450K已经成熟了，所以分析流程这里以450K为主（也是目前数据库主流的甲基化芯片数据）。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;芯片&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;一张芯片包括12个array，也就是一张芯片可以做12个sample，一台机子一次可以跑8张芯片，也就是一共96个sample，每个样本可以测到超过450，000个CpG位点的甲基化信息（大概人所有甲基化位点的1%，但是覆盖了多数CpG岛和启动子区），芯片本身包含一些控制探针可以做质控。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;原理&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;简而言之，基于亚硫酸盐处理后的DNA序列杂交的信号探测。亚硫酸盐是甲基化探测的“金标准”，不管是芯片或者甲基化测序，都要先对DNA样品进行亚硫酸盐处理，使非甲基化的C变成U，而甲基化的C保持不变，从而在后续的测序或者杂交后区分出来。450K采用了两种探针对甲基化进行测定，Infinium I采用了两种bead（甲基化M和非甲基化U，如图显示），而II只有一种bead（即甲基化和非甲基化在一起），这也导致了它们在后续荧光探测的不同，450K采用了两种荧光探测信号（红光和绿光）。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/DNA_methylation1.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;DNA甲基化指的是包裹在DNA上CG碱基（又叫CpG）的外周的一些蛋白发生变化，进而导致基因或者一些调控因子的表达出现变化，进而导致那些基因或者调控因子控制的表型出现变化，进而导致疾病或者差异的发生。DNA甲基化被认为是表观遗传调控的一种方式，如Cytosine methylation (5-mC)是研究最多的，被认为是哺乳动物中常见的甲基化方式, 最近有一些研究也发现了其他形式的甲基化，如2016年Nature上发表了一篇关于鼠的胚胎干细胞的m6A（N6-methyladenine）形式的甲基化。DAN甲基化被认为对基因表达，染色质重塑，细胞分化，疾病等都有重要影响。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/DNA_methylation2.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;甲基化的检测方法&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;目前甲基化检测的方法可以概括为三种：芯片、测序、免疫沉淀。具体选择何种方法主要还是根据实验目的和实验室条件了。但目前来说，甲基化芯片技术从覆盖度，检测灵敏度和价格综合考虑，还是性价比相对高。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/DNA_methylation3.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;甲基化芯片常见的Glossary&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;CpG island: Defned as regions 500 bp, 55% GC and expected/observed CpG ratio of 0.65. 40% of gene promoters contain islands.&lt;/li&gt;
&lt;li&gt;CpG shelves: ~4Kb from islands.&lt;/li&gt;
&lt;li&gt;CpG shores: ~2Kb from islands, 75% of tissuespecifc differentially methylated regions found in shores. Methylation in shores shows higher correlation with gene expression than CpG islands.&lt;/li&gt;
&lt;li&gt;Differentially methylated regions (DMR): Cell-, tissue-, and condition- specifc differences in methylation.&lt;/li&gt;
&lt;li&gt;Enhancer: A short region of DNA that can activate transcription and is often regulated by methylation.&lt;/li&gt;
&lt;li&gt;Hypermethylation: Most cytosines are methylated. Hypomethylation: Most cytosines do not have 5-mC. Euchromatin and active gene promoters are hypomethylated.&lt;/li&gt;
&lt;li&gt;Beta value:通常的甲基化衡量方法被称为“Beta”值; 等于甲基化百分比，并定义为“Meth”除以“Meth + Unmeth”。&lt;/li&gt;
&lt;li&gt;CGI: CpG island 即甲基化岛。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;分析需要考虑的问题&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;背景校正&lt;/li&gt;
&lt;li&gt;红光和绿光的校正&lt;/li&gt;
&lt;li&gt;控制芯片的使用（illumina450K本身有一些控制芯片，可以用来做质控，如亚硫酸盐处理效率）&lt;/li&gt;
&lt;li&gt;探针类型（I型和II型）的校正（不同探针类型产生的数据不同）
这个问题我们之前关注很多，这里附上两篇文献供大家参考，最终我们选择BMIQ的方法（基于ebayes的原理将II型探针的甲基化水平拉伸到I型水平，如下图显示）来做矫正。(图片来源于第1篇文献)&lt;br /&gt;
文献1： &lt;a href=&#34;http://bioinformatics.oxfordjournals.org/content/29/2/189.short&#34;&gt;http://bioinformatics.oxfordjournals.org/content/29/2/189.short&lt;/a&gt;&lt;br /&gt;
文献2： &lt;a href=&#34;http://www.tandfonline.com/doi/abs/10.4161/epi.24008&#34;&gt;http://www.tandfonline.com/doi/abs/10.4161/epi.24008&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;位置的校正（芯片上的不同位置产生的数据可能会有偏差）&lt;/li&gt;
&lt;li&gt;批次的校正（不同的批次做的数据会有偏差）&lt;/li&gt;
&lt;li&gt;探针序列本身是否可靠（有些探针本身位于repeat区或者包含snp等就会影响杂交及最后的结果，应该去除，附上一片参考文献，里边有list可以用来去除不好的探针）&lt;br /&gt;
文献：&lt;a href=&#34;http://bmcgenomics.biomedcentral.com/articles/10.1186/1471-2164-15-51&#34;&gt;http://bmcgenomics.biomedcentral.com/articles/10.1186/1471-2164-15-51&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;数据处理&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;GenomeStudio
GS是illumina开发的软件，基于图形界面的操作处理，适合于没有R及编程基础的人使用，但是使用GS需要权限，本人试过挺难破解的，如果有人可以破解，可以提供给论坛小伙伴使用。&lt;/li&gt;
&lt;li&gt;基于R和bioconductor的pipeline&lt;br /&gt;
bioconductor里开发了很多package供大家使用，如果你会R，那么处理这个甲基化芯片的数据将变得简单。
可以处理450K芯片的package有lumi、minfi、wateRmelon、ChAMP等，没有哪一种就特别好，大家都在不断改进，所以只要你知道大概的流程和需要注意的问题，那么你也可以自己写代码处理，只是package可以帮你省很多事情。下边我会附上我的处理流程图和详解，还有我的代码，我的代码是基于minfi的，我再次强调，代码只是手段，你可以用其他的package（例如我的同事很多使用ChAMP），也许会更好。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/DNA_methylation4.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;流程图详解：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;蓝色部分代表的是有关于数据的准备部分&lt;/li&gt;
&lt;li&gt;红色部分代表的是数据分析部分&lt;/li&gt;
&lt;li&gt;黄色部门代表数据可视化部分&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;箭头指示了分析流程，首先是load数据，然后是QC（quality control），然后是normalization，然后是SVD分析（看有没有batch effect）。准备完毕之后，黑点代表了一批质量有保证，经过处理，可以直接上马进行数据分析的数据了。之后的分析，DMP代表找出Differential Methylation Probe（差异化CpG位点），DMR代表找出Differential Methylation Region（差异化CpG区域），Block代表Differential Methylation Block（更大范围的差异化region区域），RefFree代表细胞差异被修正过后再找的DMP，EpiMod是基于基因作用网络的差异化分析。&lt;/p&gt;

&lt;p&gt;我们一般下载或者iscan后的原始数据格式为Idat，首先可以得到每个sample的每个probe的p值和bead数，根据p值和bead数可以进行样本和探针的过滤，过滤之后需要用BMIQ的方法进行I和II型探针的校正，矫正之后去掉那些包含snp之类的不好的探针，最后对数据做batch的校正。校正之后的数据就是预处理后的数据了，可以用于更下游的分析，如差异甲基化和甲基化与表达的关联分析等。
我的代码： &lt;a href=&#34;https://github.com/wkl1990/illumina-450K-analysis&#34;&gt;https://github.com/wkl1990/illumina-450K-analysis&lt;/a&gt; 。&lt;/p&gt;

&lt;h1 id=&#34;数据分析&#34;&gt;数据分析&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://www.biotrainee.com/thread-237-1-1.html&#34;&gt;Illumina HumanMethylation450 BeadChip甲基化450k芯片预处理初探&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.bio-info-trainee.com/2823.html&#34;&gt;850K甲基化芯片数据的分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://bioconductor.org/packages/release/bioc/vignettes/ChAMP/inst/doc/ChAMP.html&#34;&gt;Bioconductor ChAMP包&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.csdn.net/joshua_hit/article/details/54982018&#34;&gt;Shiny和Plotly实现可交互DNA甲基化分析包ChAMP&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

        
      </description>
    </item>
    
    <item>
      <title>Chip-seq 分析学习笔记</title>
      <link>/blog/cn/2017/11/chip_seq_study/</link>
      <pubDate>Tue, 07 Nov 2017 16:52:20 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/chip_seq_study/</guid>
      <description>
        

&lt;script type=&#34;text/javascript&#34; src=&#34;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&#34;&gt;&lt;/script&gt;

&lt;p&gt;这是一个学习笔记，跟随生信技能树的学习笔记重复,把几个优秀笔记的内容重复摘录在此。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.biotrainee.com/thread-2013-1-1.html&#34;&gt;学习提纲&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=MzAxMDkxODM1Ng==&amp;amp;mid=2247485198&amp;amp;idx=1&amp;amp;sn=bfb419c568723c5c121e017b2e265d2f&amp;amp;chksm=9b4847b5ac3fcea303e986c17e19b3750dc145f23a8e18daa74c5de704d4a203f8ba08bed651&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=1103lRh7ZlI9oD2bGJJhvqlh#rd&#34;&gt;优秀学习笔记&lt;/a&gt; &lt;a href=&#34;http://www.bio-info-trainee.com/2773.html&#34;&gt;链接2&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;chip-seq介绍&#34;&gt;ChIP-Seq介绍&lt;/h1&gt;

&lt;h2 id=&#34;1-了解基础知识&#34;&gt;1.了解基础知识&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;peak calling的统计学原理 &lt;a href=&#34;http://www.plob.org/2014/05/08/7227.html&#34;&gt;http://www.plob.org/2014/05/08/7227.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;根据比对的bam文件来对peaks区域可视化 &lt;a href=&#34;http://www.bio-info-trainee.com/1843.html&#34;&gt;http://www.bio-info-trainee.com/1843.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;wig、bigWig和bedgraph文件详解 &lt;a href=&#34;http://www.bio-info-trainee.com/1815.html&#34;&gt;http://www.bio-info-trainee.com/1815.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;2-文章综述&#34;&gt;2.文章综述&lt;/h2&gt;

&lt;p&gt;ChIP-seq guidelines and practices of the ENCODE and modENCODE consortia. &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pubmed/22955991&#34;&gt;https://www.ncbi.nlm.nih.gov/pubmed/22955991&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;3-chip-seq测序的统计学原理&#34;&gt;3.Chip-Seq测序的统计学原理&lt;/h2&gt;

&lt;p&gt;TF在基因组上的结合其实是一个随机过程，基因组的每个位置其实都有机会结合某个TF，只是概率不一样，说白了，peak出现的位置，是TF结合的热点，而peak-calling就是为了找到这些热点。&lt;/p&gt;

&lt;p&gt;如何定义热点呢？通俗地讲，热点是这样一些位置，这些位置多次被测得的read所覆盖（我们测的是一个细胞群体，read出现次数多，说明该位置被TF结合的几率大）。那么，read数达到多少才叫多？这就要用到统计检验喽。假设TF在基因组上的分布是没有任何规律的，那么，测序得到的read在基因组上的分布也必然是随机的，某个碱基上覆盖的read的数目应该服从二项分布。这其实和高中大学课本上抽小球的过程是类似的。当n很大，p很小时，二项分布可以近似用泊松分布替代。&lt;/p&gt;

&lt;p&gt;$$\lambda=n \ast p, p=\frac{l}{s}$$&lt;/p&gt;

&lt;p&gt;\(\lambda\)是泊松分布唯一的参数，n是测序得到的read总数目，l是单个read的长度，s是基因组的大小。有了分布，我们可以算出在某个置信概率（如0.00001）下，随机情况下，某个碱基上可以覆盖的read的数目的最小值，当实际观察到的read数目超过这个值（单侧检验）时，我们认为该碱基是TF的一个结合热点。反过来，针对每一个read数目，我们也可以算出对应的置信概率P。
但是，这只是一个简化的模型，实际情况要复杂好多。比如，由于测序、mapping过程内在的偏好性，以及不同染色质间的差异性，相比全基因组，某些碱基可能内在地会被更多的read所覆盖，这种情况得到的很多peak可能都是假的。MACS考虑到了这一点，当对某个碱基进行假设检验时，MACS只考虑该碱基附近的染色质区段（如10k），此时，上述公式中n表示附近10k区间内的read数目，s被置为10k。当有对照组实验（Control，相比实验组，没有用抗体捕获TF，或用了一个通用抗体）存在时，利用Control组的数据构建泊松分布，当没有Control时，利用实验组，稍大一点的局部区间（比如50k）的数据构建泊松分布。
这儿还有一个问题，read只是跟随着TF一起沉淀下来的DNA fragment的末端，read的位置并不是真实的TF结合的位置。所以在peak-calling之前，延伸read是必须的。不同TF大小不一样，对read延伸的长度也理应不同。我们知道，测得的read最终其实会近似地平均分配到正负链上，这样，对于一个TF结合热点而言，read在附近正负链上会近似地形成“双峰”。MACS会以某个window size扫描基因组，统计每个window里面read的富集程度，然后抽取（比如1000个）合适的（read富集程度适中，过少，无法建立模型，过大，可能反映的只是某种偏好性）window作样本，建立“双峰模型”。最后，两个峰之间的距离就被认为是TF的长度D，每个read将延伸D/2的长度。见下图：&lt;/p&gt;

&lt;h2 id=&#34;4-chip-seq实验&#34;&gt;4.Chip-seq实验&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;数据获取&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;将蛋白交联到DNA上。 也就是保证蛋白和DNA能够结合，找到互作位点。&lt;/li&gt;
&lt;li&gt;通过超声波剪切DNA链。&lt;/li&gt;
&lt;li&gt;加上附上抗体的磁珠用于免疫沉淀靶蛋白。抗体很重要&lt;/li&gt;
&lt;li&gt;接触蛋白交联；纯化DNA&lt;/li&gt;
&lt;li&gt;测序。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;分析流程&lt;/strong&gt;：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;质量控制, 用到的是FastQC&lt;/li&gt;
&lt;li&gt;序列比对, Bowtie2或这BWA&lt;/li&gt;
&lt;li&gt;peak calling，此处用的MACS&lt;/li&gt;
&lt;li&gt;peak注释, 这里用的Y叔的ChIPseeker&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/ChIP-Seq.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;数据下载&#34;&gt;数据下载&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pubmed/23273917&#34;&gt;RYBP and Cbx7 define specific biological functions of polycomb complexes in mouse embryonic stem cells&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE42466&#34;&gt;https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE42466&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;for ((i=204;i&amp;lt;=209;i++))
do
 axel ftp://ftp-trace.ncbi.nlm.nih.gov/sra/sra-instant/reads/ByStudy/sra/SRP/SRP017/SRP017311/SRR620$i/SRR620$i.sra &amp;amp;
done
ls *sra |while read id; do fastq-dump –split-3 $id &amp;amp; done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意文件： 这里要注意是双端测序还是单端测序。&lt;/p&gt;

&lt;p&gt;fastq-dump 转换sra文件成fastq/fasta 文件。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;pair-end: fastq-dump &amp;ndash;split-3 *.sra&lt;/li&gt;
&lt;li&gt;single-end: fastq-dump *.sra 或者 fastq-dump &amp;ndash;fasta *sra&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;下载参考基因组-建立bowtie2索引&#34;&gt;下载参考基因组,建立bowtie2索引&lt;/h1&gt;

&lt;p&gt;索引可以自己build，也可以下载 &lt;a href=&#34;ftp://ftp.ccb.jhu.edu/pub/data/bowtie2_indexes/mm10.zip&#34;&gt;ftp://ftp.ccb.jhu.edu/pub/data/bowtie2_indexes/mm10.zip&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir -p  /data/reference/genome/mm10
cd /data/reference/genome/mm10
axel http://hgdownload.cse.ucsc.edu/goldenPath/mm10/bigZips/chromFa.tar.gz
tar zvxf chromFa.tar.gz 
cat *.fa &amp;gt; mm10.fa
rm chr*.fa 

mkdir -p /data/reference/index/bowtie
cd /data/reference/index/bowtie
nohup time bowtie2-build  /data/reference/genome/mm10/mm10.fa  /data/reference/index/bowtie/mm10 1&amp;gt;mm10.bowtie_index.log 2&amp;gt;&amp;amp;1 &amp;amp;

&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;下载注释文件&#34;&gt;下载注释文件&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://genome.ucsc.edu/cgi-bin/hgTables&#34;&gt;https://genome.ucsc.edu/cgi-bin/hgTables&lt;/a&gt;&lt;br /&gt;
（参阅&lt;a href=&#34;http://www.bio-info-trainee.com/2136.html）&#34;&gt;http://www.bio-info-trainee.com/2136.html）&lt;/a&gt;
&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/mm10_ucsc_refseq_bed.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;软件安装&#34;&gt;软件安装&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;conda install -c bioconda bowtie2
conda install -c bioconda deeptools 
pip install MACS2
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;数据处理与分析&#34;&gt;数据处理与分析&lt;/h1&gt;

&lt;h2 id=&#34;质控&#34;&gt;质控&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;ls *fastq |xargs fastqc -t 10
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;发现3端质量有点问题，我就用了-3 5&amp;ndash;local参数，&lt;/p&gt;

&lt;h2 id=&#34;序列拼接&#34;&gt;序列拼接&lt;/h2&gt;

&lt;p&gt;bowtie 短序列比对工具，用bowtie2软件把测序得到的fastq文件比对到mm10参考基因组上面&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd /data/ChIPSeq
bowtie2 -p 6 -3 5 --local -x /data/reference/index/bowtie/mm10 -U SRR620204.fastq | samtools sort -O bam -o ring1B.bam
bowtie2 -p 6 -3 5 --local -x /data/reference/index/bowtie/mm10 -U SRR620205.fastq | samtools sort -O bam -o cbx7.bam
bowtie2 -p 6 -3 5 --local -x /data/reference/index/bowtie/mm10 -U SRR620206.fastq | samtools sort -O bam -o suz12.bam
bowtie2 -p 6 -3 5 --local -x /data/reference/index/bowtie/mm10 -U SRR620207.fastq | samtools sort -O bam -o RYBP.bam
bowtie2 -p 6 -3 5 --local -x /data/reference/index/bowtie/mm10 -U SRR620208.fastq | samtools sort -O bam -o IgGold.bam
bowtie2 -p 6 -3 5 --local -x /data/reference/index/bowtie/mm10 -U SRR620209.fastq | samtools sort -O bam -o IgG.bam
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;call-peaks&#34;&gt;call peaks&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;##参数解释
##-m 建立“双峰模型”用到，默认就算10 30，-p p-value 大于 1e-5，
##-f 文件来源是bam格式，-g 基因组大小是小鼠的（代号mm），-n 起名字的话叫 cbx7 
nohup macs2 callpeak -c IgGold.bam -t suz12.bam -m 10 30 -p 1e-5 -f BAM -g mm -n suz12 2&amp;gt;suz12.masc2.log &amp;amp;
nohup macs2 callpeak -c IgGold.bam -t ring1B.bam -m 10 30 -p 1e-5 -f BAM -g mm -n ring1B 2&amp;gt;ring1B.masc2.log &amp;amp;
nohup macs2 callpeak -c IgG.bam -t cbx7.bam -m 10 30 -p 1e-5 -f BAM -g mm -n cbx7 2&amp;gt;cbx7.masc2.log &amp;amp;
nohup macs2 callpeak -c IgG.bam -t RYBP.bam -m 10 30 -p 1e-5 -f BAM -g mm -n RYBP 2&amp;gt;RYBP.masc2.log &amp;amp;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;bam转换成bw文件&#34;&gt;bam转换成bw文件&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ls *.bam |while read id; do samtools index $id $id.bai; done
ls *bam |while read id
do 
  file=$(basename $id )
  sample=${file%%.*}
  echo $sample
  bamCoverage -b $id -o $sample.bw ## 这里有个参数，-p 10 --normalizeUsingRPKM
  computeMatrix reference-point --referencePoint TSS -b 10000 -a 10000 -R /data/reference/annotation/ChIPSeq/mm10/ucsc.refseq.bed -S $sample.bw --skipZeros -o matrix1_${sample}_TSS.gz --outFileSortedRegions regions1_${sample}_genes.bed
  plotHeatmap -m matrix1_${sample}_TSS.gz -out ${sample}.png
done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果文件不只是上述提到的一类，还有如下格式：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;NAMEpeaks.xls: 以表格形式存放peak信息，虽然后缀是xls，但其实能用文本编辑器打开，和bed格式类似，但是以1为基，而bed文件是以0为基.也就是说xls的坐标都要减一才是bed文件的坐标&lt;/li&gt;
&lt;li&gt;NAMEpeaks.narrowPeak NAMEpeaks.broadPeak 类似。后面4列表示为， integer score for display， fold-change，-log10pvalue，-log10qvalue，relative summit position to peak start。内容和NAMEpeaks.xls基本一致，适合用于导入R进行分析。&lt;/li&gt;
&lt;li&gt;NAMEsummits.bed：记录每个peak的peak summits，话句话说就是记录极值点的位置。MACS建议用该文件寻找结合位点的motif。&lt;/li&gt;
&lt;li&gt;NAMEmodel.r，能通过$ Rscript NAME_model.r作图，得到是基于你提供数据的peak模型&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;计算peak数&#34;&gt;计算peak数&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;wc -l *summits.bed
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;下载原作者的peak数据,可以用于分析结果比较&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;wget ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE42nnn/GSE42466/suppl/GSE42466_RYBP_peaks_5.txt.gz
gzip -d GSE42466_RYBP_peaks_5.txt.gz
mv GSE42466_RYBP_peaks_5.txt RYBP2_summits.bed
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;整合所有的chipseq的bam文件-画基因的tss附近的profile和heatmap图&#34;&gt;整合所有的chipseq的bam文件，画基因的TSS附近的profile和heatmap图&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;computeMatrix reference-point -p 10 --referencePoint TSS -b 2000 -a 2000 -S *bw -R /data/reference/annotation/ChIPSeq/mm10/ucsc.refseq.bed --skipZeros -o tmp4.mat.gz
plotHeatmap -m tmp4.mat.gz -out tmp4.merge.png
plotProfile --dpi 720 -m tmp4.mat.gz -out tmp4.profile.pdf --plotFileFormat pdf --perGroup
plotHeatmap --dpi 720 -m tmp4.mat.gz -out tmp4.merge.pdf --plotFileFormat pdf
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;整合所有的chipseq的bam文件-画基因的genebody附近的profile和heatmap图&#34;&gt;整合所有的chipseq的bam文件，画基因的genebody附近的profile和heatmap图&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;computeMatrix scale-regions -p 10 -S *bw -R /data/reference/annotation/ChIPSeq/mm10/ucsc.refseq.bed -b 3000 -a 3000 -m 5000 --skipZeros -o tmp5.mat.gz
plotHeatmap -m tmp5.mat.gz -out tmp5.merge.png
plotProfile --dpi 720 -m tmp5.mat.gz -out tmp5.profile.pdf --plotFileFormat pdf --perGroup
plotHeatmap --dpi 720 -m tmp5.mat.gz -out tmp5.merge.pdf --plotFileFormat pdf
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;结果注释与可视化&#34;&gt;结果注释与可视化&lt;/h1&gt;

&lt;p&gt;ChIPseeker R package的功能分为三类:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;注释：提取peak附近最近的基因， 注释peak所在区域&lt;/li&gt;
&lt;li&gt;比较：估计ChIP peak数据集中重叠部分的显著性；整合GEO数据集，以便于将当前结果和已知结果比较&lt;/li&gt;
&lt;li&gt;可视化： peak的覆盖情况；TSS区域结合的peak的平均表达谱和热图；基因组注释；TSS距离；peak和基因的重叠。&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;source (&amp;quot;https://bioconductor.org/biocLite.R&amp;quot;)
biocLite(&amp;quot;ChIPseeker&amp;quot;)
biocLite(&amp;quot;org.Mm.eg.db&amp;quot;)
biocLite(&amp;quot;TxDb.Mmusculus.UCSC.mm10.knownGene&amp;quot;)
biocLite(&amp;quot;clusterProfiler&amp;quot;)
biocLite(&amp;quot;ReactomePA&amp;quot;)
biocLite(&amp;quot;DOSE&amp;quot;)

library(&amp;quot;ChIPseeker&amp;quot;)
library(&amp;quot;org.Mm.eg.db&amp;quot;)
library(&amp;quot;TxDb.Mmusculus.UCSC.mm10.knownGene&amp;quot;)
txdb &amp;lt;- TxDb.Mmusculus.UCSC.mm10.knownGene
library(&amp;quot;clusterProfiler&amp;quot;)

#读入bed文件
ring1B &amp;lt;- readPeakFile(&amp;quot;F:/Chip-seq_exercise/ring1B_peaks.narrowPeak&amp;quot;)
#查看peak在全基因组的位置
covplot(ring1B)##全基因组
covplot(ring1B,chrs=c(&amp;quot;chr17&amp;quot;, &amp;quot;chr18&amp;quot;))   #指定染色体

#Average Profile of ChIP peaks binding to TSS region
#(Confidence interval estimated by bootstrap method)
plotAvgProf(tagMatrix, xlim=c(-3000, 3000), conf = 0.95, resample = 1000)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;peak的注释&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;peak的注释用annotatePeak()函数，&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;TSS (transcription start site) region 可以自己设定，默认是（-3000，3000），&lt;/li&gt;
&lt;li&gt;TxDb 是指某个物种的基因组，例如TxDb.Hsapiens.UCSC.hg38.knownGene, TxDb.Hsapiens.UCSC.hg19.knownGene for human genome hg38 and hg19, TxDb.Mmusculus.UCSC.mm10.knownGene and TxDb.Mmusculus.UCSC.mm9.knownGene for mouse mm10 and mm9.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;peakAnno &amp;lt;- annotatePeak(ring1B, tssRegion=c(-3000, 3000),
TxDb=txdb, annoDb=&amp;quot;org.Mm.eg.db&amp;quot;)
#可视化 Pie and Bar plot
plotAnnoBar(peakAnno)
vennpie(peakAnno)
upsetplot(peakAnno)

#可视化TSS区域的TF binding loci
plotDistToTSS(peakAnno,
title=&amp;quot;Distribution of transcription factor-binding loci\nrelative to TSS&amp;quot;)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;多个peak的比较&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;多个peak set注释时，先构建list,然后用lapply.list(name1=bed&lt;em&gt;file1,name2=bed&lt;/em&gt;file2) RYBP的数据有问题，这里加上去，会一直报错。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;peaks &amp;lt;- list(cbx7=cbx7,ring1B=ring1B,suz12=suz12)
promoter &amp;lt;- getPromoters(TxDb=txdb, upstream=3000, downstream=3000)
tagMatrixList &amp;lt;- lapply(peaks, getTagMatrix, windows=promoter)
plotAvgProf(tagMatrixList, xlim=c(-3000, 3000))
plotAvgProf(tagMatrixList, xlim=c(-3000, 3000), conf=0.95,resample=500, facet=&amp;quot;row&amp;quot;)
tagHeatmap(tagMatrixList, xlim=c(-3000, 3000), color=NULL)

#ChIP peak annotation comparision
peakAnnoList &amp;lt;- lapply(peaks, annotatePeak, TxDb=txdb,
tssRegion=c(-3000, 3000), verbose=FALSE)
plotAnnoBar(peakAnnoList)
plotDistToTSS(peakAnnoList)

#Overlap of peaks and annotated genes
genes= lapply(peakAnnoList, function(i) as.data.frame(i)$geneId)
vennplot(genes)
&lt;/code&gt;&lt;/pre&gt;

        
      </description>
    </item>
    
    <item>
      <title>Markdown&#43;Rmarkdown&#43;Shiny手册</title>
      <link>/blog/cn/2017/11/markdown_rmarkdown_shiny/</link>
      <pubDate>Mon, 06 Nov 2017 23:13:24 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/markdown_rmarkdown_shiny/</guid>
      <description>
        &lt;p&gt;&lt;a href=&#34;https://taoshengxu.github.io/DocumentGit/pdf/Markdown+RMarkdown+Shiny.pdf&#34;&gt;Markdown+Rmarkdown+Shiny手册&lt;/a&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>常用生物信息学格式介绍</title>
      <link>/blog/cn/2017/11/data_format/</link>
      <pubDate>Mon, 06 Nov 2017 22:59:05 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/data_format/</guid>
      <description>
        &lt;p&gt;&lt;a href=&#34;http://ju.outofmemory.cn/entry/193943&#34;&gt;原文&lt;/a&gt; &lt;a href=&#34;https://taoshengxu.github.io/DocumentGit/pdf/常用生物信息学格式介绍.pdf&#34;&gt;PDF&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;fasta&lt;/li&gt;
&lt;li&gt;fastq&lt;/li&gt;
&lt;li&gt;gff2&lt;/li&gt;
&lt;li&gt;gtf(gff2.5)&lt;/li&gt;
&lt;li&gt;gff3&lt;/li&gt;
&lt;li&gt;bed&lt;/li&gt;
&lt;li&gt;sam、bam&lt;/li&gt;
&lt;li&gt;vcf&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;另外，有wig、bigWig和bedgraph文件详解，仅仅是为了追踪参考基因组的各个区域的覆盖度，测序深度！而且这些定义好的文件，可以无缝连接到UCSC的Genome Browser工具里面进行可视化！
&lt;a href=&#34;http://www.bio-info-trainee.com/1815.html&#34;&gt;http://www.bio-info-trainee.com/1815.html&lt;/a&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>ENCODE计划数据,千人基因组计划数据,Roadmap计划数据</title>
      <link>/blog/cn/2017/11/encode_data/</link>
      <pubDate>Mon, 06 Nov 2017 16:44:54 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/encode_data/</guid>
      <description>
        

&lt;p&gt;&lt;a href=&#34;http://www.bio-info-trainee.com/1825.html&#34;&gt;From Jimmy 原文1&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.bio-info-trainee.com/1841.html&#34;&gt;From Jimmy 原文2&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.bio-info-trainee.com/1339.html&#34;&gt;From Jimmy 原文3&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;DNA元件百科全书(Encyclopedia of DNA Elements, ENCODE)ENCODE计划的重要性我就不多说了，如果大家还不是很了解，可以直接跳到本文末尾去下载一下ENCODE教程，好好学习。该计划采用以下几种高通量测序技术来刻画了超过100种不同的细胞系或者组织内的全基因组范围内的基因调控元件信息。本来只是针对人类的，后来对mouse以及fly等模式生物也开始测这些数据并进行分析了， 叫做 modENCODE.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;chromatin structure (5C)&lt;/li&gt;
&lt;li&gt;open chromatin (DNase-seq and FAIRE-seq)&lt;/li&gt;
&lt;li&gt;histone modifications and DNA-binding of over 100 transcription factors (ChIP-seq)&lt;/li&gt;
&lt;li&gt;RNA transcription (RNAseq and CAGE)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;目前所有数据均全部公开(&lt;a href=&#34;http://genome.ucsc.edu/ENCODE/&#34;&gt;http://genome.ucsc.edu/ENCODE/&lt;/a&gt; )，ENCODE results from 2007 and later are available from the ENCODE Project Portal, encodeproject.org. 并以30篇论文在Nature、Science、Cell、JBC、Genome Biol、Genome Research同时发表(&lt;a href=&#34;http://www.nature.com/encode&#34;&gt;http://www.nature.com/encode&lt;/a&gt; )。
&lt;strong&gt;所有数据从raw data形式的原始测序数据到比对后的信号文件以及分析好的有意的peaks文件都可以下载&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;我这里根据自己的学习情况，简单介绍一些ENCODE计划数据下载方式，包括ENCODE官网下载,UCSC下载，ENSEMBL下载，broad研究所数据，IHEC存放的数据，还有GEO下载这6种形式！！！&lt;/p&gt;

&lt;h1 id=&#34;ucsc&#34;&gt;UCSC&lt;/h1&gt;

&lt;p&gt;直接浏览文件，根据文件夹分类及文件名就可以任意方式下载自己感兴趣的数据&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://hgdownload.cse.ucsc.edu/goldenPath/hg19/encodeDCC/&#34;&gt;http://hgdownload.cse.ucsc.edu/goldenPath/hg19/encodeDCC/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;大家可能会比较习惯用UCSC提供的Genome Browser工具来可视化CHIP-seq的结果，而且Genome Browser里面非常多的选项可以控制各种在线资料是否跟你的数据一起显示来做对比，所以它必然有ftp服务器存放这些数据，其中比较出名的就是ENCODE计划的相关数据啦.&lt;/p&gt;

&lt;h1 id=&#34;encode计划的官网下载&#34;&gt;ENCODE计划的官网下载&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.encodeproject.org/pipelines/&#34;&gt;https://www.encodeproject.org/pipelines/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;官网的数据下载，做得像是一个购物网站，大家可以根据自己的需求把数据添加到购物篮，然后统一下载。&lt;/p&gt;

&lt;p&gt;This document describes what data are available at the ENCODE Portal, ways to get started searching and downloading data, and an overview to how the metadata describing the assays and reagents are organized. ENCODE data can be visualized and accessed from other resources, including the UCSC Genome Browser and ENSEMBL.
进入 &lt;a href=&#34;https://www.encodeproject.org/matrix/?type=Experiment&#34;&gt;https://www.encodeproject.org/matrix/?type=Experiment&lt;/a&gt; 可以看到里面列出了173种细胞系，148种组织，还有一堆癌症样本的，包括CHIP-seq，DNase-seq等在内的十几种高通量测序数据。&lt;/p&gt;

&lt;h1 id=&#34;geo&#34;&gt;GEO&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.ncbi.nlm.nih.gov/geo/info/ENCODE.html&#34;&gt;http://www.ncbi.nlm.nih.gov/geo/info/ENCODE.html&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;broad-研究所托管的encode计划数据&#34;&gt;Broad 研究所托管的ENCODE计划数据&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.broadinstitute.org/~anshul/projects/encode&#34;&gt;http://www.broadinstitute.org/~anshul/projects/encode&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;原始数据在：&lt;a href=&#34;http://www.broadinstitute.org/~anshul/projects/encode/rawdata/&#34;&gt;http://www.broadinstitute.org/~anshul/projects/encode/rawdata/&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;ihec&#34;&gt;iHEC&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://epigenomesportal.ca/ihec/download.html&#34;&gt;http://epigenomesportal.ca/ihec/download.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;以文件夹文件的形式直接浏览，根据自己的需求下载即可,除了ENCODE计划的数据，还有Blueprint计划和roadmap计划的数据都可以下载&lt;/p&gt;

&lt;h1 id=&#34;ensembl&#34;&gt;ENSEMBL&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://asia.ensembl.org/info/website/tutorials/encode.html&#34;&gt;http://asia.ensembl.org/info/website/tutorials/encode.html&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;结尾&#34;&gt;结尾&lt;/h1&gt;

&lt;p&gt;如果你对ENCODE计划不是很了解，可以先看看一些教程：
NIH提供的ENCODE计划相关教程： &lt;a href=&#34;https://www.genome.gov/27553900/encode-tutorials/&#34;&gt;https://www.genome.gov/27553900/encode-tutorials/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.genome.gov/27562350/encode-workshop-april-2015-keystone-symposia/&#34;&gt;https://www.genome.gov/27562350/encode-workshop-april-2015-keystone-symposia/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.genome.gov/27561253/encode-workshop-tutorial-october-2014-ashg/&#34;&gt;https://www.genome.gov/27561253/encode-workshop-tutorial-october-2014-ashg/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.genome.gov/27553901/encode-tutorial-may-2013-biology-of-genomes-cshl/&#34;&gt;https://www.genome.gov/27553901/encode-tutorial-may-2013-biology-of-genomes-cshl/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.genome.gov/27563006/encoderoadmap-epigenomics-tutorial-october-2015-ashg/&#34;&gt;https://www.genome.gov/27563006/encoderoadmap-epigenomics-tutorial-october-2015-ashg/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.genome.gov/27555330/encoderoadmap-epigenomics-tutorial-october-2013-ashg/&#34;&gt;https://www.genome.gov/27555330/encoderoadmap-epigenomics-tutorial-october-2013-ashg/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.genome.gov/27551933/encoderoadmap-epigenomics-tutorial-nov-2012-ashg/&#34;&gt;https://www.genome.gov/27551933/encoderoadmap-epigenomics-tutorial-nov-2012-ashg/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://useast.ensembl.org/info/website/tutorials/encode.html&#34;&gt;http://useast.ensembl.org/info/website/tutorials/encode.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.encodeproject.org/tutorials/&#34;&gt;https://www.encodeproject.org/tutorials/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.encodeproject.org/tutorials/encode-meeting-2016/&#34;&gt;https://www.encodeproject.org/tutorials/encode-meeting-2016/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.encodeproject.org/tutorials/encode-users-meeting-2015/&#34;&gt;https://www.encodeproject.org/tutorials/encode-users-meeting-2015/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;DNA元件百科全书(Encyclopedia of DNA Elements, ENCODE)项目旨在描述人类基因组中所编码的全部功能性序列元件。ENCODE计划于2003年9月正式启动，吸引了来自美国、英国、西班牙、日本和新加坡五国32个研究机构的440多名研究人员的参与，经过了9年的努力，研究了147个组织类型，进行了1478次实验，获得并分析了超过15万亿字节的原始数据，确定了400万个基因开关，明确了哪些DNA片段能打开或关闭特定的基因，以及不同类型细胞之间的“开关”存在的差异。证明所谓“垃圾DNA”都是十分有用的基因成分，担任着基因调控重任。证明人体内没有一个DNA片段是无用的。&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;千人基因组计划&#34;&gt;千人基因组计划&lt;/h1&gt;

&lt;p&gt;由于时间跨度比较长，最终的数据不只是一千人，最新版共有NA编号开头的1182个人，HG开头的1768个人！它的官方网站是：有一个ppt讲得很清楚如何通过官网做的data portal来下载数据：&lt;a href=&#34;https://www.genome.gov/pages/research/der/ichg-1000genomestutorial/how_to_access_the_data.pdf&#34;&gt;https://www.genome.gov/pages/research/der/ichg-1000genomestutorial/how_to_access_the_data.pdf&lt;/a&gt; 我不喜欢可视化的界面，我比较喜欢直接进入ftp自己翻需要的数据，千人基因组计划不仅仅有自己的ftp站点，而且在NCBI，EBI和sanger研究所里面也有数据源可以下载， 是非常丰富的生信入门资源！&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;ftp://ftp-trace.ncbi.nih.gov/1000genomes/ftp/&#34;&gt;ftp://ftp-trace.ncbi.nih.gov/1000genomes/ftp/&lt;/a&gt;
&lt;a href=&#34;ftp://ftp.sanger.ac.uk/pub/1000genomes/&#34;&gt;ftp://ftp.sanger.ac.uk/pub/1000genomes/&lt;/a&gt;
&lt;a href=&#34;ftp://ftp.ebi.ac.uk/pub/databases/1000genomes/&#34;&gt;ftp://ftp.ebi.ac.uk/pub/databases/1000genomes/&lt;/a&gt;
 &lt;a href=&#34;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp&#34;&gt;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;千人基因组计划测了5个大的人种，25个亚人种，具体介绍如下：
09/08/2014 12:00AM          1,663 20131219.populations.tsv
09/09/2014 12:00AM             97 20131219.superpopulations.tsv
其实对大部分人来说，除非你想下载千人基因组计划的原始数据来学习生物信息学分析流程，不然用不着这个ftp站点的，它自己在EBI里面的有一个非常好用的可视化界面来浏览千人基因组计划的variation结果&lt;/p&gt;

&lt;p&gt;千人基因组计划 &amp;ndash; 基因组浏览器： &lt;a href=&#34;http://www.ncbi.nlm.nih.gov/variation/tools/1000genomes/&#34;&gt;http://www.ncbi.nlm.nih.gov/variation/tools/1000genomes/&lt;/a&gt;
&lt;a href=&#34;http://www.ncbi.nlm.nih.gov/projects/SNP/snp_ref.cgi?rs=rs35761398&#34;&gt;http://www.ncbi.nlm.nih.gov/projects/SNP/snp_ref.cgi?rs=rs35761398&lt;/a&gt;  chr1:24201919:24201920
&lt;a href=&#34;http://www.ncbi.nlm.nih.gov/SNP/snp_ref.cgi?rs=2501432&#34;&gt;http://www.ncbi.nlm.nih.gov/SNP/snp_ref.cgi?rs=2501432&lt;/a&gt;  chr1:24201920
&lt;a href=&#34;http://www.ncbi.nlm.nih.gov/SNP/snp_ref.cgi?rs=2502992&#34;&gt;http://www.ncbi.nlm.nih.gov/SNP/snp_ref.cgi?rs=2502992&lt;/a&gt;  chr1:24201919
在千人基因组计划里面看一个rs就能看到各种人群信息：
&lt;a href=&#34;http://browser.1000genomes.org/Homo_sapiens/Variation/Population?r=1:24201420-24202420;v=rs2501432;vdb=variation;vf=1849472&#34;&gt;http://browser.1000genomes.org/Homo_sapiens/Variation/Population?r=1:24201420-24202420;v=rs2501432;vdb=variation;vf=1849472&lt;/a&gt;
这些人群信息，可以画一个网路图！ 只需要变化rs ID号即可，当然并不是所有的rs ID号都在千人基因组计划里面有显示的。
还有一个java软件-可视化检测千人基因组数据&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://bioinformatics.oxfordjournals.org/content/early/2016/03/17/bioinformatics.btw147.short?rss=1&#34;&gt;http://bioinformatics.oxfordjournals.org/content/early/2016/03/17/bioinformatics.btw147.short?rss=1&lt;/a&gt;
&lt;a href=&#34;http://limousophie35.github.io/Ferret/&#34;&gt;http://limousophie35.github.io/Ferret/&lt;/a&gt;
但是好像不是很好用！&lt;/p&gt;

&lt;p&gt;在千人基因组计划的ftp主站点里面可以下载所有数据。
&lt;a href=&#34;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/&#34;&gt;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/&lt;/a&gt;
&lt;a href=&#34;ftp://ftp.ncbi.nlm.nih.gov/1000genomes/ftp/&#34;&gt;ftp://ftp.ncbi.nlm.nih.gov/1000genomes/ftp/&lt;/a&gt;
直接看最新版的数据，共有NA编号开头的1182个人，HG开头的1768个人！
&lt;a href=&#34;ftp://ftp.ncbi.nlm.nih.gov/1000genomes/ftp/phase3/data/&#34;&gt;ftp://ftp.ncbi.nlm.nih.gov/1000genomes/ftp/phase3/data/&lt;/a&gt;
也可以按照人种来查看这些数据：&lt;a href=&#34;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/data/&#34;&gt;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/data/&lt;/a&gt;
每个人的目录下面都有 四个数据文件夹
Oct 01 2014 00:00    Directory alignment
Oct 01 2014 00:00    Directory exome&lt;em&gt;alignment
Oct 01 2014 00:00    Directory high&lt;/em&gt;coverage&lt;em&gt;alignment
Oct 01 2014 00:00    Directory sequence&lt;/em&gt;read
这些数据实在是太丰富了！
也可以直接看最新版的vcf文件，记录了这两千多人的所有变异位点信息！
可以直接看到所有的位点，具体到每个人在该位点是否变异！
&lt;a href=&#34;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/&#34;&gt;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/&lt;/a&gt;
不过它的基因型信息是通过MVNcall+SHAPEIT这个程序call出来的，具体原理见：&lt;a href=&#34;http://www.ncbi.nlm.nih.gov/pubmed/23093610&#34;&gt;http://www.ncbi.nlm.nih.gov/pubmed/23093610&lt;/a&gt;
而且网站还提供一些教程：&lt;a href=&#34;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/working/&#34;&gt;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/working/&lt;/a&gt;
我们肯定可以在千人基因计划的官网下载测序数据，主要是vcf格式的突变！
Coriell Catalog website: 1000 Genomes Project
1000 Genomes website: browser.1000genomes.org/index.html (by SNP ID)
1000 Genomes website: www.1000genomes.org/data (bulk data)
但是关于它的表达数据，就不是那么简单了！
The most important available existing expression datasets involving 1000g individuals are probably the following:&lt;/p&gt;

&lt;p&gt;RNAseq (mRNA &amp;amp; miRNA) on 465 individuals (CEU, TSI, GBR, FIN, YRI)&lt;/p&gt;

&lt;p&gt;Pre-publication RNA-sequencing data from the Geuvadis project is available through &lt;a href=&#34;http://www.geuvadis.org&#34;&gt;http://www.geuvadis.org&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.ebi.ac.uk/arrayexpress/experiments/E-GEUV-1/samples.html&#34;&gt;http://www.ebi.ac.uk/arrayexpress/experiments/E-GEUV-1/samples.html&lt;/a&gt;
&lt;a href=&#34;http://www.ebi.ac.uk/arrayexpress/experiments/E-GEUV-2/samples.html&#34;&gt;http://www.ebi.ac.uk/arrayexpress/experiments/E-GEUV-2/samples.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;RNAseq on 60 CEU individual [1]&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.ebi.ac.uk/arrayexpress/experiments/E-MTAB-197&#34;&gt;http://www.ebi.ac.uk/arrayexpress/experiments/E-MTAB-197&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Expression arrays on about 800 HapMap 3 individuals with a lot of overlap with 1000g data [1,2]&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.ebi.ac.uk/arrayexpress/experiments/E-MTAB-198&#34;&gt;http://www.ebi.ac.uk/arrayexpress/experiments/E-MTAB-198&lt;/a&gt;
&lt;a href=&#34;http://www.ebi.ac.uk/arrayexpress/experiments/E-MTAB-264&#34;&gt;http://www.ebi.ac.uk/arrayexpress/experiments/E-MTAB-264&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;RNAseq for 69 YRI individuals [3]&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.ebi.ac.uk/arrayexpress/experiments/E-GEOD-19480&#34;&gt;http://www.ebi.ac.uk/arrayexpress/experiments/E-GEOD-19480&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;居然可以下载千人基因组计划的所有数据bam-vcf数据&#34;&gt;居然可以下载千人基因组计划的所有数据bam，vcf数据&lt;/h1&gt;

&lt;p&gt;它有两个ftp站点存储所有的数据！
&lt;a href=&#34;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/&#34;&gt;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/&lt;/a&gt;
&lt;a href=&#34;ftp://ftp.ncbi.nlm.nih.gov/1000genomes/ftp/&#34;&gt;ftp://ftp.ncbi.nlm.nih.gov/1000genomes/ftp/&lt;/a&gt;
直接看最新版的数据，共有NA编号开头的1182个人，HG开头的1768个人！
&lt;a href=&#34;ftp://ftp.ncbi.nlm.nih.gov/1000genomes/ftp/phase3/data/&#34;&gt;ftp://ftp.ncbi.nlm.nih.gov/1000genomes/ftp/phase3/data/&lt;/a&gt;
也可以按照人种来查看这些数据：&lt;a href=&#34;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/data/&#34;&gt;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/data/&lt;/a&gt;
每个人的目录下面都有 四个数据文件夹&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Oct 01 2014 00:00    Directory alignment
Oct 01 2014 00:00    Directory exome_alignment
Oct 01 2014 00:00    Directory high_coverage_alignment
Oct 01 2014 00:00    Directory sequence_read
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这些数据实在是太丰富了！
也可以直接看最新版的vcf文件，记录了这两千多人的所有变异位点信息！
可以直接看到所有的位点，具体到每个人在该位点是否变异！
&lt;a href=&#34;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/&#34;&gt;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/&lt;/a&gt;
不过它的基因型信息是通过MVNcall+SHAPEIT这个程序call出来的，具体原理见：&lt;a href=&#34;http://www.ncbi.nlm.nih.gov/pubmed/23093610&#34;&gt;http://www.ncbi.nlm.nih.gov/pubmed/23093610&lt;/a&gt;
而且网站还提供一些教程：&lt;a href=&#34;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/working/&#34;&gt;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/working/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;还有Illumina的450K甲基化芯片数据：&lt;a href=&#34;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/hgsv_sv_discovery/working/20151214_450k_methylation/&#34;&gt;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/hgsv_sv_discovery/working/20151214_450k_methylation/&lt;/a&gt;
还有一个小程序，&lt;a href=&#34;ftp://ftp.ncbi.nlm.nih.gov/1000genomes/ftp/technical/browser/vcf_to_ped_converter/version_1.1/&#34;&gt;ftp://ftp.ncbi.nlm.nih.gov/1000genomes/ftp/technical/browser/vcf_to_ped_converter/version_1.1/&lt;/a&gt;
还有Illumina的450K甲基化芯片数据：&lt;a href=&#34;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/hgsv_sv_discovery/working/20151214_450k_methylation/&#34;&gt;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/hgsv_sv_discovery/working/20151214_450k_methylation/&lt;/a&gt;
还有一个小程序，&lt;a href=&#34;ftp://ftp.ncbi.nlm.nih.gov/1000genomes/ftp/technical/browser/vcf_to_ped_converter/version_1.1/&#34;&gt;ftp://ftp.ncbi.nlm.nih.gov/1000genomes/ftp/technical/browser/vcf_to_ped_converter/version_1.1/&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;roadmap&#34;&gt;roadmap&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.roadmapepigenomics.org/&#34;&gt;http://www.roadmapepigenomics.org/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;精选的129个细胞系，细胞系的介绍如下：&lt;a href=&#34;http://www.broadinstitute.org/~anshul/projects/roadmap/metadata/EID_metadata.tab&#34;&gt;http://www.broadinstitute.org/~anshul/projects/roadmap/metadata/EID_metadata.tab&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;对每个细胞系，都至少处理了5个核心组蛋白修饰数据，还有其它若干转录因子数据。
官网介绍的很详细，我就不翻译了：&lt;/p&gt;

&lt;p&gt;The NIH Roadmap Epigenomics Mapping Consortium was launched with the goal of producing a public resource of human epigenomic data to catalyze basic biology and disease-oriented research. The Consortium leverages experimental pipelines built around next-generation sequencing technologies to map DNA methylation, histone modifications, chromatin accessibility and small RNA transcripts in stem cells and primary ex vivo tissues selected to represent the normal counterparts of tissues and organ systems frequently involved in human disease. The Consortium expects to deliver a collection of normal epigenomes that will provide a framework or reference for comparison and integration within a broad array of future studies. The Consortium also aims to close the gap between data generation and its public dissemination by rapid release of raw sequence data, profiles of epigenomics features and higher-level integrated maps to the scientific community. The Consortium is also committed to the development, standardization and dissemination of protocols, reagents and analytical tools to enable the research community to utilize, integrate and expand upon this body of data.&lt;/p&gt;

&lt;p&gt;首先是这个网站：
&lt;a href=&#34;http://www.encode-roadmap.org/&#34;&gt;http://www.encode-roadmap.org/&lt;/a&gt;
矩阵很容易看懂roadmap处理了哪些细胞系，进行了什么样的处理，数据可以直接下载。&lt;/p&gt;

&lt;p&gt;然后我比较首先推崇broad研究所的下载方式&lt;/p&gt;

&lt;p&gt;里面还列出了他们用过的peaks caller 工具：
&lt;a href=&#34;http://www.broadinstitute.org/~anshul/projects/encode/preprocessing/peakcalling/&#34;&gt;http://www.broadinstitute.org/~anshul/projects/encode/preprocessing/peakcalling/&lt;/a&gt;  可以看到，主要有MACS，peakranger，quest，sicer，peakseq，hotspot等等
直接进入broad分析好的peaks结果：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[DIR]   Parent Directory    
-   
[DIR]   broadPeak/  08-Feb-2015 21:00   -   
[DIR]   gappedPeak/ 08-Feb-2015 21:00   -   
[DIR]   lowq/   31-Aug-2014 20:42   -   
[DIR]   narrowPeak/ 08-Feb-2015 20:59   -   
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里面有3种peaks，我现在还没有搞懂是什么意思。&lt;/p&gt;

&lt;p&gt;接着是 iHEC存放的数据：&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://epigenomesportal.ca/ihec/download.html&#34;&gt;http://epigenomesportal.ca/ihec/download.html&lt;/a&gt;
我还是第一次看到这个数据接口，也是以文件夹文件的形式直接浏览，根据自己的需求下载即可：
除了ENCODE计划的数据，还有Blueprint计划和roadmap计划的数据都可以下载。
NIH Roadmap 2014-05-29  Click here for policies
最后可以从圣路易斯华盛顿大学里面下载&lt;/p&gt;

&lt;p&gt;圣路易斯华盛顿大学Washington University in St. Louis，简称（Wash U，WU）以美国国父乔治·华盛顿命名，始建于1853年2月22日，位于美国密苏里州圣路易斯市，是美国历史上建校最早也是最负盛名的“华盛顿大学”，该校在美国新闻和世界报道（US News &amp;amp; World Report）2014大学综合排名中名列14位。
里面有一个非常详细的页面来介绍roadmap的各种数据:&lt;a href=&#34;http://egg2.wustl.edu/roadmap/web_portal/processed_data.html&#34;&gt;http://egg2.wustl.edu/roadmap/web_portal/processed_data.html&lt;/a&gt;
如果你已经了解了roadmap计划，就很容易找到自己的数据，从而直接浏览器或者wget下载即可。
首先是序列比对结果下载。
onsolidated Epigenomes:36 bp mappability filtered, pooled and subsampled read alignment files:
&lt;a href=&#34;http://egg2.wustl.edu/roadmap/data/byFileType/alignments/consolidated/&#34;&gt;http://egg2.wustl.edu/roadmap/data/byFileType/alignments/consolidated/&lt;/a&gt;
Unconsolidated Epigenomes (Uniform mappability): 36 bp mappability filtered primary alignment files:
&lt;a href=&#34;http://egg2.wustl.edu/roadmap/data/byFileType/alignments/unconsolidated/&#34;&gt;http://egg2.wustl.edu/roadmap/data/byFileType/alignments/unconsolidated/&lt;/a&gt;
包括各种peaks记录文件下载
Narrow contiguous regions of enrichment (peaks) for histone ChIP-seq and DNase-seq
Data format: NarrowPeak
&lt;a href=&#34;http://egg2.wustl.edu/roadmap/data/byFileType/peaks/consolidated/narrowPeak/&#34;&gt;http://egg2.wustl.edu/roadmap/data/byFileType/peaks/consolidated/narrowPeak/&lt;/a&gt;
Broad domains on enrichment for histone ChIP-seq and DNase-seq)
Data format: BroadPeak
&lt;a href=&#34;http://egg2.wustl.edu/roadmap/data/byFileType/peaks/consolidated/broadPeak/&#34;&gt;http://egg2.wustl.edu/roadmap/data/byFileType/peaks/consolidated/broadPeak/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Data format: GappedPeak (subset of domains containing at least one narrow peaks)
&lt;a href=&#34;http://egg2.wustl.edu/roadmap/data/byFileType/peaks/consolidated/gappedPeak/&#34;&gt;http://egg2.wustl.edu/roadmap/data/byFileType/peaks/consolidated/gappedPeak/&lt;/a&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>nat123</title>
      <link>/blog/cn/2017/11/nat123/</link>
      <pubDate>Sun, 05 Nov 2017 22:02:28 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/nat123/</guid>
      <description>
        

&lt;h1 id=&#34;启动&#34;&gt;启动&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.nat123.com/Pages_17_619.jsp&#34;&gt;教程&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;#cd  /soft/nat123    --进入自己本地实际安装目录
#mono  nat123linux.sh     --根据提示手动输入帐号密码 
#mono  nat123linux.sh  service  &amp;amp;     --自动读取上一次成功登录帐号以后台服务启动
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;开机自动登录&#34;&gt;开机自动登录&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;（1）本地必须先手动输入帐号密码成功登录一次；
（2）执行“chmod +x /etc/rc.local”命令确保有权限；
（3）把启动程序的命令添加到/etc/rc.local文件中，此文件内容如下，
#!/bin/sh -e
# rc.local
# This script is executed at the end of each multiuser runlevel.
# Make sure that the script will &amp;quot;exit 0&amp;quot; on success or any other
# value on error.
# In order to enable or disable this script just change the execution
# bits.
# By default this script does nothing.

cd  /soft/nat123    --本地实际安装目录
mono  nat123linux.sh  service  &amp;amp;      ---自动读取上次成功登录帐号并以后台服务启动

exit 0
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;linux环境开机自动启动防掉线脚本&#34;&gt;LINUX环境开机自动启动防掉线脚本&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.nat123.com/Pages_17_682.jsp&#34;&gt;教程&lt;/a&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>转录组分析笔记（2）</title>
      <link>/blog/cn/2017/11/transcriptome_analysis1/</link>
      <pubDate>Sun, 05 Nov 2017 09:34:40 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/transcriptome_analysis1/</guid>
      <description>
        

&lt;p&gt;这是一个生信技能树的优秀作业，一字未改。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.biotrainee.com/thread-1931-1-1.html&#34;&gt;原文&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;转录组差异表达分析小实战-一&#34;&gt;转录组差异表达分析小实战（一）&lt;/h2&gt;

&lt;h5 id=&#34;读文献获取数据&#34;&gt;读文献获取数据&lt;/h5&gt;

&lt;p&gt;文献名称：AKAP95 regulates splicing through scaffolding
RNAs and RNA processing factors&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;查找数据：Data availability&lt;br /&gt;
The RIP-seq an RNA-seq data have been deposited in the Gene
Expression Omnibus database, with accession code GSE81916. All other data is
available from the author upon reasonable request.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;获得GSE号：GSE81916&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&#34;下载测序数据&#34;&gt;下载测序数据&lt;/h5&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE81916&#34;&gt;https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE81916&lt;/a&gt;获取数据信息，并点击网址下方的ftp，下载测序数据&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;从&lt;a href=&#34;https://trace.ncbi.nlm.nih.gov/Traces/study/?acc=PRJNA323422&#34;&gt;https://trace.ncbi.nlm.nih.gov/Traces/study/?acc=PRJNA323422&lt;/a&gt;可知我们需要的mRNA测序编号为SRR3589956到SRR3589962&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;通过Apera下载SRR数据，这里以SRR3589956为例：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ascp -T -i /home/anlan/.aspera/connect/etc/asperaweb_id_dsa.openssh anonftp@ftp-private.ncbi.nlm.nih.gov:sra/sra-instant/reads/ByRun/sra/SRR/SRR358/SRR3589956/SRR3589956.sra ./
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&#34;转化fastq测序数据&#34;&gt;转化fastq测序数据&lt;/h5&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;通过sratoolkit工具将SRR文件转化为fastq格式的测序数据（写了个shell循环）&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for i in $(seq 56 62);do nohup fastq-dump --split-3  SRR35899${i} &amp;amp;;done
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;通过fastqc对每个fastq文件进行质检，用multiqc查看整体质检报告（对当前目录下的fastq测序结果进行质检，生成每个fq文件的质检报告总multiqc整合后统计查看）&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fastqc *.fastq
multiqc ./
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;点击这个url可以查看我这个multiqc报告：&lt;a href=&#34;http://www.bioinfo-scrounger.com/data/multiqc_report.html&#34;&gt;http://www.bioinfo-scrounger.com/data/multiqc_report.html&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如果有接头或者质量值不达标的需要进行过滤，这次的数据质量都不错，因此直接进行比对即可&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&#34;序列比对&#34;&gt;序列比对&lt;/h5&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;安装hisat2软件，下载人类的hiast2索引文件&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;hisat2下载并安装：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ftp://ftp.ccb.jhu.edu/pub/infphilo/hisat2/downloads/hisat2-2.1.0-Linux_x86_64.zip
unzip hisat2-2.1.0-Linux_x86_64.zip
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;下载hisat2的human索引&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ftp://ftp.ccb.jhu.edu/pub/infphilo/hisat2/data/hg19.tar.gz
tar zxvf hg19.tar.gz
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;用hisat2进行比对，测序数据放在data目录下，索引文件放在reference/index/hisat2/hg19目录下，SRR3589956-SRR3589958为人的测序数据&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for i in $(seq 56 58);do hisat2 -p 4 \
-x ~/reference/index/hisat2/hg19/genome \
-1 ./data/SRR35899${i}_1.fastq -2 ./data/SRR35899${i}_2.fastq \
-S SRR35899$i.sam &amp;gt;SRR35899${i}.log;done
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;用samtools将sam文件转化为bam文件，并使用默认排序&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for i in $(seq 56 58);do samtools sort -@ 5 -o SRR35899${i}.bam SRR35899${i}.sam;done
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&#34;reads计数&#34;&gt;reads计数&lt;/h5&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;用htseq对比对产生的bam进行count计数&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;htseq安装，使用miniconda，省事！唯一的问题是htseq版本不是最新的，是0.7.2。想要最新版还是要正常安装，可参考&lt;a href=&#34;http://www.biotrainee.com/thread-1847-1-2.html&#34;&gt;http://www.biotrainee.com/thread-1847-1-2.html&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;conda install -c bioconda htseq
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;用htseq将对比后的结果进行计数&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for i in $(seq 56 58);do htseq-count -f bam -r pos -s no \
SRR35899${i}.bam ~/reference/genome/hg19/gencode.v26lift37.annotation.gtf \
1&amp;gt;SRR35899${i}.count 2&amp;gt;SRR35899${i}_htseq.log;done
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;将3个count文件（SRR3589956.count，SRR3589957.count，SRR3589958.count）合并成一个count矩阵，这是就需要脚本来解决这个问题，不然其他方法会稍微麻烦点&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!/usr/bin/perl -w
use strict;

my $path = shift @ARGV;
opendir DIR, $path or die;
my @dir = readdir DIR;

my $header;
my @sample;
my %hash;
foreach my $file (@dir) {
    if ($file =~ /^\w+.*\.count/) {
        push @sample, $file;
        $header .= &amp;quot;\t$file&amp;quot;;
        open my $fh, $file or die;
        while (&amp;lt;$fh&amp;gt;) {
            chomp;
            next if ($_ =~ /^\W+/);
            my @array = split /\t/, $_;
            $hash{$array[0]} -&amp;gt; {$file} = $array[1];
        }
        close $fh;
    }
}
print &amp;quot;$header\n&amp;quot;;
map{
    my $gene = $_;
    print &amp;quot;$gene&amp;quot;;
    foreach my $file (@sample) {
        print &amp;quot;\t&amp;quot;.$hash{$gene} -&amp;gt; {$file};
    }
    print &amp;quot;\n&amp;quot;;
}keys %hash;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;按照接下来的剧本，应该讲count&lt;em&gt;matrix文件导入DESeq进行差异表达分析。但是从这篇文章的Bioinformatic analyses部分可以发现，作者的control组的2组数据是来自2个不同的批次（一个是SRR3589956，另外一个来源GSM1095127 in GSE44976），treat组倒是同一个批次（SRR3589957和SRR3589958）。但是对于Mouse cells来说，倒是满足2个control和2个treat都正常来自同个批次，因此打算重新用SRR3589959-SRR3589962重新做个一个count&lt;/em&gt;matrix进行后续差异分析&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

        
      </description>
    </item>
    
    <item>
      <title>转录组分析笔记</title>
      <link>/blog/cn/2017/11/transcriptome_analysis/</link>
      <pubDate>Sun, 05 Nov 2017 09:34:39 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/transcriptome_analysis/</guid>
      <description>
        

&lt;p&gt;这是一个学习笔记，跟随生信技能树的学习笔记重复,把几个优秀笔记的内容重复摘录在此。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;学习提纲&lt;/strong&gt;：&lt;a href=&#34;http://www.biotrainee.com/thread-1750-1-1.html&#34;&gt;RNA-seq基础入门传送门&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;文章链接&lt;/strong&gt;：&lt;a href=&#34;https://www.nature.com/articles/ncomms13347&#34;&gt;https://www.nature.com/articles/ncomms13347&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;非常棒的学习笔记1&lt;/strong&gt;：&lt;a href=&#34;https://taoshengxu.github.io/DocumentGit/pdf/沈梦圆2017年转录组入门合辑0-6.pdf&#34;&gt;PANDA姐的转录组入门（0-6）合辑&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;非常棒的学习笔记2&lt;/strong&gt;:&lt;a href=&#34;https://taoshengxu.github.io/DocumentGit/pdf/浙大植物学小白的转录组笔记.pdf&#34;&gt;浙大植物学小白的转录组笔记&lt;/a&gt; &lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=MzAxMDkxODM1Ng==&amp;amp;mid=2247484895&amp;amp;idx=1&amp;amp;sn=678da702fa929789b177d214070dd39a&amp;amp;chksm=9b484564ac3fcc72914b0ae2c1b71adb63fb359cf7e73221be1ddfd3040efa2944c91bee8e3b&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=0824NWlPEoAgwVKtIWnkEDd9#rd&#34;&gt;Link2&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;非常棒的学习笔记3&lt;/strong&gt;:&lt;a href=&#34;./post/transcriptome_analysis1.html&#34;&gt;下一篇&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;分析软件安装&#34;&gt;分析软件安装&lt;/h1&gt;

&lt;p&gt;最方便的安装方式就是 Anaconda&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;wget https://repo.continuum.io/archive/Anaconda3-4.4.0-Linux-x86_64.sh

 conda install -c bioconda samtools=1.5
 conda install -c bioconda htseq=0.7.2
 conda install -c bioconda hisat2=2.1.0
 conda install -c bioconda fastqc=0.11.5
 conda install -c jfear sratoolkit=2.8.1
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;数据下载&#34;&gt;数据下载&lt;/h1&gt;

&lt;p&gt;From NCBI GEO ftp&lt;/p&gt;

&lt;p&gt;The RIP-seq an RNA-seq data have been deposited in the Gene Expression Omnibus database, with accession code &lt;strong&gt;GSE81916&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&#34;数据分析&#34;&gt;数据分析&lt;/h1&gt;

&lt;h2 id=&#34;质控&#34;&gt;质控&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;for id in `seq 56 62`
do fastq-dump --gzip --split-3 -O /data/RNASeq -A SRR35899${id}
done ##很慢，建议后台多线程

##查看fastq文件
zcat SRR3589956_1.fastq.gz | head -n 4
##安装集成分析工具
conda install -c bioconda multiqc

# 先获取QC结果
ls *gz | while read id; do fastqc -t 4 $id; done
# multiqc
multiqc *fastqc.zip --pdf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Python质控脚本&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import re
import zipfile
# read the zip file
def zipReader(file):
    qcfile =  zipfile.ZipFile(file)
    data_txt = [file for file in qcfile.namelist() if re.match(&amp;quot;.*?_data\.txt&amp;quot;, file)][0]
    data = [bytes.decode(line) for line in qcfile.open(data_txt)]
    return data
 
def fastqc_summary(data):
    module_num = 0
    bases = 0
    Q20 = 0
    Q30 = 0
    for line in data:
        if re.match(&#39;Filename&#39;, line):
            filename = line.split(sep=&amp;quot;\t&amp;quot;)[1].strip()
        if re.match(&#39;Total Sequence&#39;, line):
            read = line.split(sep=&amp;quot;\t&amp;quot;)[1].strip()
        if re.match(&#39;%GC&#39;, line):
            GC = line.split(sep=&amp;quot;\t&amp;quot;)[1].strip()
        if re.match(&amp;quot;[^#](.*?\t){6}&amp;quot;,line):
            bases = bases + 1
            if float(line.split(&amp;quot;\t&amp;quot;)[1]) &amp;gt; 30:
                Q20 = Q20 + 1
                Q30 = Q30 + 1
            elif float(line.split(&amp;quot;\t&amp;quot;)[1]) &amp;gt; 20:
                Q20 = Q20 + 1
 
        if re.match(&amp;quot;&amp;gt;&amp;gt;END&amp;quot;, line) :
            module_num = module_num + 1
            if module_num &amp;gt;= 2:
                break
    Q20 = Q20 / bases
    Q30 = Q30 / bases
    summary = [filename, read, GC, str(Q20), str(Q30)]
    return summary
 
if __name__ == &#39;__main__&#39;:
    import sys
    for arg in range(1, len(sys.argv)):
        data = zipReader(sys.argv[arg])
        summary = fastqc_summary(data)
        with open(&#39;summary.txt&#39;, &#39;a&#39;) as f:
            f.write(&#39;\t&#39;.join(summary) + &#39;\n&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;grep -w &#39;gene&#39; gencode.v26lift37.annotation.gtf |grep -w &#39;TP53&#39;|cut -f 1,4,5 &amp;gt;&amp;gt;gene.bed
grep -w &#39;gene&#39; gencode.v26lift37.annotation.gtf |grep -w &#39;KRAS&#39;|cut -f 1,4,5 &amp;gt;&amp;gt;gene.bed
grep -w &#39;gene&#39; gencode.v26lift37.annotation.gtf |grep -w &#39;EGFR&#39;|cut -f 1,4,5 &amp;gt;&amp;gt;gene.bed
bedtools igv -i gene.bed &amp;gt;Bach_sanpshot.txt
perl -alne &#39;{print &amp;quot;goto $F[0]:$F[1]-$F[2]\nsnapshot $F[3].png&amp;quot;} &#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;hisat2比对&#34;&gt;Hisat2比对&lt;/h2&gt;

&lt;p&gt;HISAT2是TopHat2/Bowti2的继任者，使用改进的BWT算法，实现了更快的速度和更少的资源占用，作者推荐TopHat2/Bowti2和HISAT的用户转换到HISAT2。
官网：&lt;a href=&#34;https://ccb.jhu.edu/software/hisat2/index.shtml&#34;&gt;https://ccb.jhu.edu/software/hisat2/index.shtml&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;1.建立基因组索引or index 下载&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;#建立基因组索引
#hisat2-build –p 4 genome.fa genome

#下载索引
cd ~/reference
mkdir -p index/hisat &amp;amp;&amp;amp; cd index/hisat
wget -c ftp://ftp.ccb.jhu.edu/pub/infphilo/hisat2/data/hg19.tar.gz
wget -c ftp://ftp.ccb.jhu.edu/pub/infphilo/hisat2/data/mm10.tar.gz
tar zxvf hg19.tar.gz
tar xvzf mm10.tar.gz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.比对&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;for i in `seq 56 58`
do
    hisat2 -t -p 24 -x /data/Reference/index/hisat2/hg19/genome \
    -1 /data/RNASeq/fastq/SRR35899${i}_1.fastq.gz \
    -2 SRR35899${i}_2.fastq.gz \
    -S /data/RNASeq/fastq/SRR35899${i}.sam &amp;gt; SRR35899${i}.log &amp;amp;
done


##比对结果
xts@R710:/data/RNASeq/fastq$ for i in `seq 56 58`
&amp;gt; do
&amp;gt;     hisat2 -t -p 24 -x /data/Reference/index/hisat2/hg19/genome \
&amp;gt;     -1 /data/RNASeq/fastq/SRR35899${i}_1.fastq.gz \
&amp;gt;     -2 SRR35899${i}_2.fastq.gz \
&amp;gt;     -S /data/RNASeq/fastq/SRR35899${i}.sam &amp;gt; SRR35899${i}.log &amp;amp;
&amp;gt; done
[1] 11177
[2] 11178
[3] 11179
xts@R710:/data/RNASeq/fastq$ tipTime loading forward index: 00:00:24
Time loading forward index: 00:00:24
Time loading forward index: 00:00:24
Time loading reference: 00:00:04
Time loading reference: 00:00:04
Time loading reference: 00:00:04
Multiseed full-index search: 00:13:22
28856780 reads; of these:
  28856780 (100.00%) were paired; of these:
    1838981 (6.37%) aligned concordantly 0 times
    24732654 (85.71%) aligned concordantly exactly 1 time
    2285145 (7.92%) aligned concordantly &amp;gt;1 times
    ----
    1838981 pairs aligned concordantly 0 times; of these:
      90927 (4.94%) aligned discordantly 1 time
    ----
    1748054 pairs aligned 0 times concordantly or discordantly; of these:
      3496108 mates make up the pairs; of these:
        2034939 (58.21%) aligned 0 times
        1221462 (34.94%) aligned exactly 1 time
        239707 (6.86%) aligned &amp;gt;1 times
96.47% overall alignment rate
Time searching: 00:13:26
Overall time: 00:13:50

Multiseed full-index search: 00:14:42
25914821 reads; of these:
  25914821 (100.00%) were paired; of these:
    1785160 (6.89%) aligned concordantly 0 times
    21786672 (84.07%) aligned concordantly exactly 1 time
    2342989 (9.04%) aligned concordantly &amp;gt;1 times
    ----
    1785160 pairs aligned concordantly 0 times; of these:
      53455 (2.99%) aligned discordantly 1 time
    ----
    1731705 pairs aligned 0 times concordantly or discordantly; of these:
      3463410 mates make up the pairs; of these:
        2187330 (63.16%) aligned 0 times
        1050929 (30.34%) aligned exactly 1 time
        225151 (6.50%) aligned &amp;gt;1 times
95.78% overall alignment rate
Time searching: 00:14:46
Overall time: 00:15:10
[1]   已完成               hisat2 -t -p 24 -x /data/Reference/index/hisat2/hg19/genome -1 /data/RNASeq/fastq/SRR35899${i}_1.fastq.gz -2 SRR35899${i}_2.fastq.gz -S /data/RNASeq/fastq/SRR35899${i}.sam &amp;gt; SRR35899${i}.log
[3]+  已完成               hisat2 -t -p 24 -x /data/Reference/index/hisat2/hg19/genome -1 /data/RNASeq/fastq/SRR35899${i}_1.fastq.gz -2 SRR35899${i}_2.fastq.gz -S /data/RNASeq/fastq/SRR35899${i}.sam &amp;gt; SRR35899${i}.log
xts@R710:/data/RNASeq/fastq$ Multiseed full-index search: 00:16:08
29720636 reads; of these:
  29720636 (100.00%) were paired; of these:
    1920019 (6.46%) aligned concordantly 0 times
    25503958 (85.81%) aligned concordantly exactly 1 time
    2296659 (7.73%) aligned concordantly &amp;gt;1 times
    ----
    1920019 pairs aligned concordantly 0 times; of these:
      61683 (3.21%) aligned discordantly 1 time
    ----
    1858336 pairs aligned 0 times concordantly or discordantly; of these:
      3716672 mates make up the pairs; of these:
        2292272 (61.68%) aligned 0 times
        1196099 (32.18%) aligned exactly 1 time
        228301 (6.14%) aligned &amp;gt;1 times
96.14% overall alignment rate
Time searching: 00:16:12
Overall time: 00:16:36

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;数据转换sam-bam-sorted bam&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for i in `seq 56 58`
do
    samtools view -S SRR35899${i}.sam -b &amp;gt; SRR35899${i}.bam
    samtools sort SRR35899${i}.bam -o SRR35899${i}_sorted.bam
    samtools index SRR35899${i}_sorted.bam
done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;SAMtools其他操作&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;head -1000 SRR3589957.sam &amp;gt; test.sam
samtools view -b  test.sam &amp;gt; test.bam
samtools view test.bam | head

samtools sort test.bam -o default.bam
samtools view default.bam | head
 
# Sort alignments by leftmost coordinates, or by read name when -n is used
samtools sort test.bam default
samtools view default.bam | head


#提取1号染色体1234-123456区域的比对read
samtools view SRR3589957_sorted.bam chr1:1234-123456 | head

#在比如搭配flag(0.1.19版本没有）和flagstat，使用-f或-F参数提取不同匹配情况的read。

# 可以先用flagstat看下总体情况
samtools flagstat SRR3589957_sorted.bam

#筛选恰好配对的read,就需要用0x10
samtools view -b -f 0x10 SRR3589957_sorted.bam chr1:1234-123456  &amp;gt; flag.bam
samtools flagstat flag.bam
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;比对质控&#34;&gt;比对质控&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;RSeQC——&lt;a href=&#34;http://rseqc.sourceforge.net/&#34;&gt;http://rseqc.sourceforge.net/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Qualimap——&lt;a href=&#34;http://qualimap.bioinfo.cipf.es/&#34;&gt;http://qualimap.bioinfo.cipf.es/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Picard——&lt;a href=&#34;http://broadinstitute.github.io/picard/&#34;&gt;http://broadinstitute.github.io/picard/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;使用RSeQC来对我们的比对结果进行质控,RSeQC包括了十多个Python脚本，实现很多功能，具体每个脚本的参数用法，都可以在官网学习.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# RSeQC的安装，需要先安装gcc；numpy；R；Python2.7
$ pip install RSeQC
# 对bam文件进行质控，其余都同样的进行
$ bam_stat.py  -i SRR3589956_sorted.bam

基因组覆盖率的QC需要提供bed文件，可以直接RSeQC的网站下载，或者可以用gtf转换
read_distribution.py -i RNA-Seq/aligned/SRR3589956_sorted.bam -r reference/hg19_RefSeq.bed
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;reads-计数-from-hoptop&#34;&gt;Reads 计数 (From hoptop)&lt;/h1&gt;

&lt;p&gt;定量分为三个水平
- 基因水平(gene-level)
- 转录本水平(transcript-level)
- 外显子使用水平(exon-usage-level)。&lt;/p&gt;

&lt;p&gt;1.在&lt;strong&gt;基因水平&lt;/strong&gt;上，常用的软件为HTSeq-count，featureCounts，BEDTools, Qualimap, Rsubread, GenomicRanges等。以常用的HTSeq-count为例，这些工具要解决的问题就是&lt;strong&gt;根据read和基因位置的overlap判断这个read到底是谁家的孩子&lt;/strong&gt;。值得注意的是不同工具对multimapping reads处理方式也是不同的，例如HTSeq-count就直接当它们不存在。而Qualimpa则是一人一份，平均分配。&lt;/p&gt;

&lt;p&gt;对每个基因计数之后得到的count matrix再后续的分析中，要注意标准化的问题。如果你要比较同一个样本(within-sample)不同基因之间的表达情况，你就需要考虑到&lt;strong&gt;转录本长度&lt;/strong&gt;，因为转录本越长，那么检测的片段也会更多，直接比较等于让小孩和大人进行赛跑。如果你是比较不同样本（across sample）同一个基因的表达情况，虽然不必在意转录本长度，但是你要考虑到&lt;strong&gt;测序深度&lt;/strong&gt;（sequence depth)，毕竟测序深度越高，检测到的概率越大。除了这两个因素外，你还需要考虑GC%所导致的偏差，以及测序仪器的系统偏差。目前对read count标准化的算法有RPKM（SE）, FPKM（PE），TPM, TMM等，不同算法之间的差异与换算方法已经有文章进行整理和吐槽了。但是，有一些下游分析的软件会要求是输入的count matrix是原始数据，未经标准化，比如说DESeq2，这个时候你需要注意你上一步所用软件会不会进行标准化。&lt;/p&gt;

&lt;p&gt;2.在&lt;strong&gt;转录本水平&lt;/strong&gt;上，一般常用工具为Cufflinks和它的继任者StringTie， eXpress。这些软件要处理的难题就时转录本亚型（isoforms）之间通常是有重叠的，当二代测序读长低于转录本长度时，如何进行区分？这些工具大多采用的都是expectation maximization（EM）。好在我们有三代测序。
上述软件都是alignment-based，目前许多alignment-free软件，如kallisto, silfish, salmon，能够省去比对这一步，直接得到read count，在运行效率上更高。不过最近一篇文献[1]指出这类方法在估计丰度时存在样本特异性和读长偏差。&lt;/p&gt;

&lt;p&gt;3.在&lt;strong&gt;外显子使用水平&lt;/strong&gt;上，其实和基因水平的统计类似。但是值得注意的是为了更好的计数，我们需要提供无重叠的外显子区域的gtf文件。用于分析差异外显子使用的DEXSeq提供了一个Python脚本（dexseq&lt;em&gt;prepare&lt;/em&gt;annotation.py）执行这个任务。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mkdir -p /data/RNASeq/fastq/matrix/
for i in $(seq 56 58); 
do htseq-count -f bam -r pos -s no \
/data/RNASeq/fastq/SRR35899${i}_sorted.bam /data/Reference/gtf/gencode/gencode.v26lift37.annotation.sorted.gtf \
1&amp;gt;matrix/SRR35899${i}.count 2&amp;gt;matrix/SRR35899${i}_htseq.log &amp;amp;; done
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;表达矩阵&#34;&gt;表达矩阵&lt;/h2&gt;

&lt;p&gt;在RNA-Seq分析中，每一个基因就是一个feature（特征？），而基因被认为是它的所有外显子的和集。在可变剪切分析中，可以单独把每个外显子当作一个feature。而在ChIP-Seq分析中，feature则是预先定义的结合域。但是确定一个read到底属于哪一个feature有时会非常棘手。&lt;/p&gt;

&lt;h4 id=&#34;这段描述很有意思-信息量也很多-from-hoptop&#34;&gt;这段描述很有意思，信息量也很多(From hoptop)&lt;/h4&gt;

&lt;p&gt;我们这次分析是人类mRNA-Seq测序的结果，但是我们其实只下载了3个sra文件。一般而言RNA-Seq数据分析都至少要有2个重复，所以必须要有4个sra文件才行。我在仔细读完文章的方法这一段以后，发现他们有一批数据用的是其他课题组的： For 293 cells, the mRNA-seq results of the control samples include (1) those from the doxycycline-treated parental Flp-In T-REx 293 cells by us and (2) those from the doxycycline-treated control Flp-In T-REx 293 cells performed by another group unrelated to us (sample GSM1095127 in GSE44976)。 然后和Jimmy交流之后，他也承认自己只分析了小鼠的数据，而没有分析人类的数据。所以我们需要根据文章提供的线索下载另外一份数据，才能进行下一步的分析。
这个时候就有一个经常被问到的问题：不同来源的RNA-Seq数据能够直接比较吗？甚至说如果不同来源的RNA-seq数据的构建文库都不一样该如何比较?不同来源的RNA-Seq结果之间比较需要考虑 批次效应（batch effect) 的影响。
处理批次效应，根据我搜索的结果，是不能使用FPKM/RPKM，关于这个标准化的吐槽，我在biostars上找到了如下观点：
FPKM/RPKM 不是标准化的方法，它会引入文库特异的协变量
FPKM/RPKM has never been peer-reviewed, it has been introduced as an ad-hoc measure in a supplementary 没有同行评审
One of the authors of this paper states, that it should not be used because of faulty arithmetic 作者说算法有问题
All reviews so far have shown it to be an inferior scale for DE analysis of genes Length normalization is mostly dispensable imo in DE analysis because gene length is constant
有人建议使用一个Bioconductor包&lt;a href=&#34;http://www.bioconductor.org/packages/devel/bioc/html/sva.html&#34;&gt;http://www.bioconductor.org/packages/devel/bioc/html/sva.html&lt;/a&gt; 我没有具体了解，有生之年去了解补充。
还有人引用了一篇文献 IVT-seq reveals extreme bias in RNA-sequencing 证明不同文库的RNA-Seq结果会存在很大差异。
结论： 可以问下原作者他们是如何处理数据的，居然有一个居然没有重复的分析也能过审。改用小鼠数据进行分析。或者使用无重复的分析方法，或者模拟一份数据出来，先把流程走完。&lt;/p&gt;

&lt;h1 id=&#34;panda实践完整代码&#34;&gt;PANDA实践完整代码&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;##1.SRA to fastq

perl -F&#39;\t&#39; -alne &#39;if($F[7]=~/SRR/){$F[6]=~s/\s/_/g;$F[13]=~ s/\s|#/_/g;$F[13]=~s/\(|\)//g;print &amp;quot;$F[7]\t$F[6]_$F[13]&amp;quot;}&#39; SraRunTable.txt &amp;gt; Rename.txt

perl -F&#39;\t&#39; -alne &#39;print &amp;quot;fastq-dump --split-3 --gzip -A $F[1] $F[0].sra &amp;amp;&amp;quot; &#39; Rename.txt &amp;gt;sratofq.sh

sh sratofq.sh 

md5sum *.fastq.gz &amp;gt;md5sum.txt

##2.QC
cd MYShen
mkdir 1_FastQC_Raw_Data
ls *.gz|while read id;do(fastqc $id -o 1_FastQC_Raw_Data -t 8);done
# 质控统计
cd 1_FastQC_Raw_Data
for i in *.zip; do unzip $i; done
perl /data/RNASeq/MYShen/fastqc_table.pl
csvtk tab2csv fastqc_table.txt | csvtk csv2md
------------------------------------------------------------------------------------------------
                                                  |total_reads|GC |Q20              |Q30
:-------------------------------------------------|:----------|:--|:----------------|:----------------
Homo_sapiens_AKAP95_KD_miR_12_293_cell_1_fastqc   |25914821   |50 |0.999810031487387|0.972201583024633
Homo_sapiens_AKAP95_KD_miR_12_293_cell_2_fastqc   |25914821   |50 |0.977900484051192|0.934933990090072
Homo_sapiens_AKAP95_KD_miR_8_293_cell_1_fastqc    |29720636   |50 |0.992602101445318|0.966831930304341
Homo_sapiens_AKAP95_KD_miR_8_293_cell_2_fastqc    |29720636   |50 |0.978714654693123|0.93782410982053
Homo_sapiens_Control_293_cell_1_fastqc            |28856780   |50 |0.989872946867992|0.966726176148248
Homo_sapiens_Control_293_cell_2_fastqc            |28856780   |50 |0.977797280223227|0.940547004897982
Mus_musculus_E14_cells_Akap95_shRNA_rep1_1_fastqc |52972617   |50 |0.99966391028307 |0.987561698545491
Mus_musculus_E14_cells_Akap95_shRNA_rep1_2_fastqc |52972617   |50 |0.991854774481748|0.968082091276275
Mus_musculus_E14_cells_Akap95_shRNA_rep2_1_fastqc |43802631   |49 |0.999679725428068|0.972184686419785
Mus_musculus_E14_cells_Akap95_shRNA_rep2_2_fastqc |43802631   |49 |0.986887120253892|0.937616464383233
Mus_musculus_E14_cells_control_shRNA_rep1_1_fastqc|30468155   |50 |0.99960200376177 |0.987110860654561
Mus_musculus_E14_cells_control_shRNA_rep1_2_fastqc|30468155   |50 |0.991083449869222|0.966506018600785
Mus_musculus_E14_cells_control_shRNA_rep2_1_fastqc|36763726   |50 |0.999694316126568|0.979622471169646
Mus_musculus_E14_cells_control_shRNA_rep2_2_fastqc|36763726   |50 |0.990428680495556|0.951578715079022
-------------------------------------------------------------------------------------------------------
#截图几个基因的 IGV 可视化结构
grep -w &#39;gene&#39; gencode.v26lift37.annotation.gtf |grep -w &#39;TP53&#39;|cut -f 1,4,5 &amp;gt;&amp;gt;gene.bed
grep -w &#39;gene&#39; gencode.v26lift37.annotation.gtf |grep -w &#39;KRAS&#39;|cut -f 1,4,5 &amp;gt;&amp;gt;gene.bed
grep -w &#39;gene&#39; gencode.v26lift37.annotation.gtf |grep -w &#39;EGFR&#39;|cut -f 1,4,5 &amp;gt;&amp;gt;gene.bed
bedtools igv -i gene.bed &amp;gt;Bach_sanpshot.txt 
#perl -alne &#39;{print &amp;quot;goto $F[0]:$F[1]-$F[2]\nsnapshot $F[3].png&amp;quot;} &#39;


##3. HISAT2比对
---------------------------------------------------------------
#map.sh
--------------------------------------------------------------------------------------------
#! usr/bin/bash
set -u
set -e
set -o pipefail

hg19_ref=/data/Reference/index/hisat2/hg19/genome
mm10_ref=/data/Reference/index/hisat2/mm10/genome
data_path=/data/RNASeq/MYShen
NUM_THREADS=5
ls Homo*1.fastq.gz|while read id; \
do((hisat2 -t -p $NUM_THREADS -x $hg19_ref -1 $data_path/${id%_*}_1.fastq.gz -2 \
$data_path/${id%_*}_2.fastq.gz 2&amp;gt;${id%_*}_map.log | samtools view -b - &amp;gt;${id%_*}.bam) &amp;amp;);done 
                               
ls  Mus*1.fastq.gz|while read id; \
do((hisat2 -t -p $NUM_THREADS -x $mm10_ref -1 $data_path/${id%_*}_1.fastq.gz -2 \
$data_path/${id%_*}_2.fastq.gz 2&amp;gt;${id%_*}_map.log | samtools view -b - &amp;gt;${id%_*}.bam) &amp;amp;);done
---------------------------------------------------------------------------------------------        

bash map.sh
##因为前面开了并行，等前面执行完成，后面再单独执行
ls *.bam | while read id;do samtools sort --threads 25 $id -o ${id%.*}_sorted.bam; done 
ls *_sorted.bam | while read id;do samtools index $id; done


## 4.Count reads

# 人类
mkdir matrix
Homo_GTF=/data/Reference/gtf/gencode/gencode.v26lift37.annotation.gtf
###count 结果显示基因名称，如果用基因的id号，将 -i gene_name 参数删除即可
ls Homo_sapiens*sorted.bam | while read id; do (htseq-count -f bam -r pos -i gene_name -s no \
$id $Homo_GTF &amp;gt; matrix/${id%_*}.count 2&amp;gt; matrix/${id%_*}.log &amp;amp;); done

# 老鼠
# 下载 gtf：http://www.gencodegenes.org/mouse_stats/archive.html
axel ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_mouse/release_M10/gencode.vM10.annotation.gtf.gz
gzip -d gencode.vM10.annotation.gtf.gz
Mus_GTF=/data/Reference/gtf/gencode/gencode.vM10.annotation.gtf
ls Mus_musculus*sorted.bam|while read id;do (htseq-count -f bam -r pos -i gene_name -s no \
$id $Mus_GTF &amp;gt; matrix/${id%_*}.count 2&amp;gt; matrix/${id%_*}.log &amp;amp;);done


##另外一些相关的代码
## ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_mouse/release_M1/
## http://hgdownload-test.cse.ucsc.edu/goldenPath/mm10/liftOver/
## GRCm38/mm10 (Dec, 2011) 
## ls *bam |while read id;do ( ~/.local/bin/htseq-count  -f bam  $id   genecode/mm9/gencode.vM1.annotation.gtf.gz  1&amp;gt;${id%%.*}.gene.counts ) ;done 
## ls *bam |while read id;do ( ~/.local/bin/htseq-count  -f bam -i exon_id  $id   genecode/mm9/gencode.vM1.annotation.gtf.gz  1&amp;gt;${id%%.*}.exon.counts ) ;done

cd matrix
#wc命令的功能为统计指定文件中的字节数-c,字符数-m,字数-w,行数-l
wc -l Homo_sapiens*.count
head -n 4 Homo_sapiens*.count


perl -lne &#39;if($ARGV=~/Homo_sapiens_(.*)count/){print &amp;quot;$1\t$_&amp;quot;}&#39; *|grep -v Homo_sapiens&amp;gt;hg1.count
# 先把所有文件进行合并
setwd(&amp;quot;~/rna_seq/work/matrix&amp;quot;)
hg &amp;lt;- read.csv(file = &amp;quot;hg.count&amp;quot;,header = F,sep = &amp;quot;\t&amp;quot;)
colnames(hg) &amp;lt;- c(&#39;sample&#39;,&#39;gene&#39;,&#39;count&#39;)
library(reshape2)
reads &amp;lt;- dcast(hg,formula = gene ~ sample)
write.table(reads,file = &amp;quot;hg_join.count&amp;quot;,sep = &amp;quot;\t&amp;quot;,quote = FALSE,row.names = FALSE)
&lt;/code&gt;&lt;/pre&gt;

        
      </description>
    </item>
    
    <item>
      <title>NCBI-GEO数据下载</title>
      <link>/blog/cn/2017/11/ncbi_downlaod/</link>
      <pubDate>Sat, 04 Nov 2017 21:52:45 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/ncbi_downlaod/</guid>
      <description>
        

&lt;h1 id=&#34;geo-基础&#34;&gt;GEO 基础&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;GEO Platform (GPL) 芯片平台&lt;/li&gt;
&lt;li&gt;GEO Sample (GSM) 样本ID号&lt;/li&gt;
&lt;li&gt;GEO Series (GSE) study的ID号&lt;/li&gt;
&lt;li&gt;GEO Dataset (GDS) 数据集的ID号 ## 用法&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;数据搜索&#34;&gt;数据搜索&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;方法-&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;在&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/&#34;&gt;https://www.ncbi.nlm.nih.gov/&lt;/a&gt; 中搜索 GSE81916 选择 BioProject查询 Accession：PRJNA323422; GEO: GSE81916&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://trace.ncbi.nlm.nih.gov/Traces/study/?acc=PRJNA323422&#34;&gt;https://trace.ncbi.nlm.nih.gov/Traces/study/?acc=PRJNA323422&lt;/a&gt; 可以查询数据具体信息&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;方法二&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;在 Gene Expression Omnibus (&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/geo/)搜素GSE81916进入&#34;&gt;https://www.ncbi.nlm.nih.gov/geo/)搜素GSE81916进入&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE81916&#34;&gt;https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE81916&lt;/a&gt; 数据地址&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;数据下载&#34;&gt;数据下载&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;ftp地址&lt;/strong&gt;
&lt;a href=&#34;ftp://ftp-trace.ncbi.nlm.nih.gov/sra/sra-instant/reads/ByStudy/sra/SRP/SRP075/SRP075747&#34;&gt;ftp://ftp-trace.ncbi.nlm.nih.gov/sra/sra-instant/reads/ByStudy/sra/SRP/SRP075/SRP075747&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;可以分为以下几个部分&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;所有SRA数据的共同部分： &lt;a href=&#34;ftp://ftp-trace.ncbi.nlm.nih.gov/sra/sra-instant&#34;&gt;ftp://ftp-trace.ncbi.nlm.nih.gov/sra/sra-instant&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;reads表示存放reads数据，在FTP可以看到另一个选项是analysis，表示分析结果&lt;/li&gt;
&lt;li&gt;ByStudy表示根据Study进行分类，其他还可以根据实验ByExp,根据Run,ByRun.&lt;/li&gt;
&lt;li&gt;sra/SRP/SRP075/SRP075747: 后面部分都是为了便于检索。&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;#/bin/bash
# @author: xt
# @date: 2017-11-04

for i in ` seq 56 62`;
do
axel ftp://ftp-trace.ncbi.nlm.nih.gov/sra/sra-instant/reads/ByStudy/sra/SRP/SRP075/SRP075747/SRR35899${i}/SRR35899${i}.sra
#wget ftp://ftp-trace.ncbi.nlm.nih.gov/sra/sra-instant/reads/ByStudy/sra/SRP/SRP075/SRP075747/SRR35899${i}/SRR35899${i}.sra
#echo $i 
done
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;# https://www.ncbi.nlm.nih.gov/gquery/?term=GSE81916
# esearch -db sra -query PRJNA299273  | efetch -format runinfo &amp;gt; runinfo.txt # 这个命令是把所有的结果放到一个文件里，也可以通过 https://trace.ncbi.nlm.nih.gov/Traces/study/?acc=PRJNA323422下载SRR的编号
# cat runinfo.txt | cut -f 1 -d &#39;,&#39; | grep SRR &amp;gt; sra.ids
# ~/biosoft/sratoolkit.2.8.2-1-centos_linux64/bin/prefetch --option-file sra.ids # 数据存在/home/shenmy/ncbi/public/sra这个文件下面，找了半天
mkdir /mnt/d/rna_seq/data  &amp;amp;&amp;amp; cd /mnt/d/rna_seq/data
perl -lne &#39;$id=substr($_,0,6);print &amp;quot;axel ftp://ftp-trace.ncbi.nih.gov/sra/sra-instant/reads/ByRun/sra/SRR/$id/$_/$_.sra&amp;quot;&#39; SRR_Acc_List.txt &amp;gt;sra_down.sh
bash sra_down.sh
# 改成用axel下是因为prefetch下载总是不成功
ls *.sra|while read id;do(/mnt/d/Software/Biosoft/sratoolkit/sratoolkit.2.8.2-1-ubuntu64/bin/fastq-dump --split-3 $id);done
rm *.sra
chmod u-w * 
&lt;/code&gt;&lt;/pre&gt;

        
      </description>
    </item>
    
    <item>
      <title>使用Bioconda管理Linux系统中的生物信息软件</title>
      <link>/blog/cn/2017/11/bioconda/</link>
      <pubDate>Fri, 03 Nov 2017 17:20:54 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/bioconda/</guid>
      <description>
        

&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/25085567&#34;&gt;原文&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;生物信息操作中必不可少的就是Linux系统中各种生物信息学软件的安装。不同软件有不同的安装方法，对系统环境的依赖不同也不同，对于新手来说，经常是一个软件的安装和配置就要折腾很长一段时间时间，大大增加了学习成本。&lt;/p&gt;

&lt;p&gt;我自己有两个方法来尽量减少安装软件所消耗的时间：一是直接安装Bio-linux系统，这个系统已经内置了大部分生物信息分析所需要的软件，非常适合新手直接学习分析技术，绕过软件安装和环境配置的麻烦问题。二是使用Bioconda安装和管理各种软件。Bio-linux系统和常用的服务器系统还是有差别的，如果想在学习生物信息分析的同时掌握一些Linux系统的操作甚至维护的技术，配置一台CentOS系统的计算机就很有必要了。这个时候Bioconda就非常有用了。&lt;/p&gt;

&lt;p&gt;本文参考知乎专栏以及基因课相关课程 (&lt;a href=&#34;http://genek.tv/dirlist/index/id/65&#34;&gt;http://genek.tv/dirlist/index/id/65&lt;/a&gt;) 对Bioconda的安装和使用做简单介绍。&lt;/p&gt;

&lt;h1 id=&#34;bioconda介绍&#34;&gt;Bioconda介绍&lt;/h1&gt;

&lt;p&gt;Bioconda是conda上一个分发生物信息的频道。而conda是最初为管理python包而建立的。以下是相关介绍：&lt;/p&gt;

&lt;p&gt;“Conda is a portable package manager primarily for python and precompiled binaries. Miniconda is the base system of conda. It includes a standard python and a few required dependencies such as readline and sqlite. In conda, a channel contains a set of software typically managed by the same group.Bioconda is a channel of conda focusing on bioinformatics software. ”&lt;/p&gt;

&lt;p&gt;Bioconda主页：Using bioconda - Bioconda documentation&lt;/p&gt;

&lt;p&gt;anaconda、miniconda和conda的区别：FAQs - Bioconda documentation&lt;/p&gt;

&lt;p&gt;简单说来：“conda is a package manager, Miniconda is the conda installer, and Anaconda is a scientific Python distribution that also includes conda.”&lt;/p&gt;

&lt;p&gt;Bioconda的优点是安装简单，各个软件依赖的环境一同打包且相互隔离，非常适合在服务器中建立自己的生物信息分析环境。&lt;/p&gt;

&lt;h1 id=&#34;bioconda的下载与安装&#34;&gt;Bioconda的下载与安装&lt;/h1&gt;

&lt;p&gt;1.下载和安装miniconda&lt;/p&gt;

&lt;p&gt;bioconda的使用首先需要安装miniconda(&lt;a href=&#34;http://conda.pydata.org/miniconda.html&#34;&gt;http://conda.pydata.org/miniconda.html&lt;/a&gt;) 。选择linux的64位的python2.7版本（共提供win、Mac、linux三种系统，同时支持python3和python2），直接点击下载。或者复制链接后，用wget下载。下载完成后，在终端键入bash命令进行安装. 之后按照提示点击回车，输入要安装的位置，或者输入yes.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;wget https://repo.continuum.io/miniconda/Miniconda2-latest-Linux-x86_64.sh
bash Miniconda2-latest-Linux-x86_64.sh
##输入yes后，还没有完成最后安装，还需要source一下
source ~/.bashrc
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这时miniconda就安装好了，输入“conda”会显示相应的信息：&lt;/p&gt;

&lt;p&gt;2.添加channels&lt;/p&gt;

&lt;p&gt;输入“conda list”来查看已经安装的软件：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;conda config --add channels conda-forge
conda config --add channels defaults
conda config --add channels r
conda config --add channels bioconda
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查看已经添加的channels：&lt;/p&gt;

&lt;p&gt;conda config &amp;ndash;get channels&lt;/p&gt;

&lt;p&gt;3.更新miniconda&lt;/p&gt;

&lt;p&gt;conda update conda&lt;/p&gt;

&lt;p&gt;4.卸载miniconda  删除miniconda的整个文件夹：&lt;/p&gt;

&lt;p&gt;rm -rf ~/miniconda&lt;/p&gt;

&lt;p&gt;从环境变量中去掉miniconda：打开~/.bash_profile文件，删掉其中miniconda的路径，关闭并保存&lt;/p&gt;

&lt;p&gt;删除隐藏的.condarc 、.conda以及.continuum文件&lt;/p&gt;

&lt;h1 id=&#34;利用bioconda安装生物信息软件&#34;&gt;利用Bioconda安装生物信息软件&lt;/h1&gt;

&lt;p&gt;要通过conda安装软件，首先从这里&lt;a href=&#34;https://bioconda.github.io/recipes&#34;&gt;Available packages&lt;/a&gt;查找该软件是否被conda支持。如果支持，只需输入以下命令即可安装：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;conda install fastqc（软件名）

conda install -c bioconda samtools=1.5
conda install -c bioconda htseq=0.7.2
conda install -c bioconda hisat2=2.1.0
conda install -c bioconda fastqc=0.11.5
conda install -c jfear sratoolkit=2.8.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;安装完成后，可以用“which 软件名”来查看该软件安装的位置：&lt;/p&gt;

&lt;p&gt;conda默认安装软件的最新版本，如果想安装指定版本的某个软件，可以先用“conda search 软件名”搜索软件版本&lt;/p&gt;

&lt;p&gt;星号标记的表示是已经安装的版本。要安装其他版本，输入：&lt;/p&gt;

&lt;p&gt;conda install 软件名=版本号
这时conda会先卸载已安装版本，然后重新安装指定版本。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;查看已安装软件&lt;/strong&gt;：conda list&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;更新指定软件&lt;/strong&gt;：conda update 软件名&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;卸载指定软件&lt;/strong&gt;：conda remove 软件名&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>生物信息学常见1000个软件的安装代码</title>
      <link>/blog/cn/2017/11/1000soft/</link>
      <pubDate>Fri, 03 Nov 2017 15:42:35 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/1000soft/</guid>
      <description>
        

&lt;p&gt;引自Jiangming Zeng&lt;a href=&#34;http://mp.weixin.qq.com/s?__biz=MzAxMDkxODM1Ng==&amp;amp;mid=2247484870&amp;amp;idx=1&amp;amp;sn=d336ed1951b5cff14c591201084622fd&amp;amp;chksm=9b48457dac3fcc6bb25bdb2a0e744013a3c11d0b7b8cc8b9f274560260618c07bdf438611752&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=08174RqFPmfWUyO1PO1Xh9Uz#rd&#34;&gt;原文&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;分析软件&#34;&gt;分析软件&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## annovar and GATK 
## Download and install sratoolkit
## http://www.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?view=software
## http://www.ncbi.nlm.nih.gov/books/NBK158900/
cd ~/biosoft
mkdir sratoolkit &amp;amp;&amp;amp;  cd sratoolkit
wget http://ftp-trace.ncbi.nlm.nih.gov/sra/sdk/2.6.3/sratoolkit.2.6.3-centos_linux64.tar.gz
##
##  Length: 63453761 (61M) [application/x-gzip]
##  Saving to: &amp;quot;sratoolkit.2.6.3-centos_linux64.tar.gz&amp;quot;
tar zxvf sratoolkit.2.6.3-centos_linux64.tar.gz
~/biosoft/sratoolkit/sratoolkit.2.6.3-centos_linux64/bin/fastdump -h
mkdir -p  ~/biosoft/myBin
echo &#39;export PATH=/home/jianmingzeng/biosoft/myBin/bin:$PATH&#39; &amp;gt;&amp;gt;~/.bashrc 
source ~/.bashrc
cd ~/biosoft
mkdir cmake &amp;amp;&amp;amp;  cd cmake
wget http://cmake.org/files/v3.3/cmake-3.3.2.tar.gz
tar xvfz cmake-3.3.2.tar.gz
cd cmake-3.3.2 
./configure --prefix=/home/jianmingzeng/biosoft/myBin
make
make install
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## Download and install samtools
## http://samtools.sourceforge.net/
## http://www.htslib.org/doc/samtools.html

##存放高通量测序比对结果的标准格式
##功能： Reading/writing/editing/indexing/viewing SAM/BAM/CRAM format
cd ~/biosoft
mkdir samtools &amp;amp;&amp;amp;  cd samtools
wget https://github.com/samtools/samtools/releases/download/1.3.1/samtools-1.3.1.tar.bz2 
tar xvfj samtools-1.3.1.tar.bz2 
cd samtools-1.3.1 
./configure --prefix=/home/jianmingzeng/biosoft/myBin
make
make install
~/biosoft/myBin/bin/samtools --help
~/biosoft/myBin/bin/plot-bamstats --help
cd htslib-1.3.1
./configure --prefix=/home/jianmingzeng/biosoft/myBin
make
make install
~/biosoft/myBin/bin/tabix
# ## Download and install tabix 
# cd ~/biosoft
# mkdir tabix &amp;amp;&amp;amp;  cd tabix
# # http://genometoolbox.blogspot.com/2013/11/installing-tabix-on-unix.html
# tar xvfj tabix-0.2.6.tar.bz2 
# cd tabix-0.2.6
# make
# cd ~/biosoft
# ## http://samtools.github.io/bcftools/
# mkdir htslib &amp;amp;&amp;amp;  cd htslib  
# git clone git://github.com/samtools/htslib.git 
# cd htslib
# make 
## Download and install bcftools
## http://www.htslib.org/download/
## http://www.htslib.org/doc/bcftools-1.0.html
cd ~/biosoft
mkdir bcftools &amp;amp;&amp;amp;  cd bcftools
wget https://github.com/samtools/bcftools/releases/download/1.3.1/bcftools-1.3.1.tar.bz2
tar xvfj bcftools-1.3.1.tar.bz2
cd bcftools-1.3.1 
make
cp bcftools /home/jianmingzeng/biosoft/myBin
~/biosoft/myBin/bin/bcftools --help
## Download and install vcftools
## https://vcftools.github.io/index.html 
## http://vcftools.sourceforge.net/specs.html
cd ~/biosoft
mkdir vcftools &amp;amp;&amp;amp;  cd vcftools
# wget https://codeload.github.com/vcftools/vcftools/legacy.zip/master -O  vcftools-vcftools-v0.1.14-24-gac1bfd5.zip 
# unzip vcftools-vcftools-v0.1.14-24-gac1bfd5.zip 
# mv vcftools-vcftools-ac1bfd5 vcftools-v0.1.14-24
# cd vcftools-v0.1.14-24
# export PERL5LIB=/home/jianmingzeng/biosoft/vcftools/vcftools-v0.1.14-24/src/perl/
# ./autogen.sh 
# ./configure     --prefix=/home/jianmingzeng/biosoft/myBin
# make 
# make install 
# ~/biosoft/myBin/bin/vcftools --help
wget https://sourceforge.net/projects/vcftools/files/vcftools_0.1.13.tar.gz 
tar zxvf vcftools_0.1.13.tar.gz
cd  vcftools_0.1.13
make
## Download and install ANNOVAR  
cd ~/biosoft
# The latest version of ANNOVAR (2016Feb01) can be downloaded here (registration required)
# http://www.openbioinformatics.org/annovar/annovar_download_form.php 
mkdir ANNOVAR  &amp;amp;&amp;amp;  cd ANNOVAR  
## Download and install samstat
## http://samstat.sourceforge.net/
## http://www.htslib.org/doc/samtools.html
cd ~/biosoft
mkdir samstat &amp;amp;&amp;amp;  cd samstat
wget http://liquidtelecom.dl.sourceforge.net/project/samstat/samstat-1.5.tar.gz
tar zxvf  samstat-1.5.tar.gz 
cd samstat-1.5 
./configure --prefix=/home/jianmingzeng/biosoft/myBin
make
make install
~/biosoft/myBin/bin/samstat --help
## Download and install picardtools
## https://sourceforge.net/projects/picard/
## https://github.com/broadinstitute/picard
cd ~/biosoft
mkdir picardtools &amp;amp;&amp;amp;  cd picardtools
wget http://ncu.dl.sourceforge.net/project/picard/picard-tools/1.119/picard-tools-1.119.zip
unzip picard-tools-1.119.zip 
## Download and install freebayes
## https://github.com/ekg/freebayes
## http://clavius.bc.edu/~erik/CSHL-advanced-sequencing/freebayes-tutorial.html
cd ~/biosoft
mkdir freebayes &amp;amp;&amp;amp;  cd freebayes
## wget -O freebayes-master.zip  https://codeload.github.com/ekg/freebayes/zip/master
## unzip freebayes-master.zip
wget http://clavius.bc.edu/~erik/freebayes/freebayes-5d5b8ac0.tar.gz
tar xzvf freebayes-5d5b8ac0.tar.gz
cd freebayes
make
 ~/biosoft/freebayes/freebayes/bin/freebayes
cd ~/biosoft
## https://sourceforge.net/projects/varscan/files/
## http://varscan.sourceforge.net/index.html
mkdir VarScan  &amp;amp;&amp;amp;  cd VarScan  
wget https://sourceforge.net/projects/varscan/files/VarScan.v2.3.9.jar 
cd ~/biosoft
mkdir SnpEff &amp;amp;&amp;amp;  cd SnpEff
##  http://snpeff.sourceforge.net/
##  http://snpeff.sourceforge.net/SnpSift.html 
##  http://snpeff.sourceforge.net/SnpEff_manual.html
wget http://sourceforge.net/projects/snpeff/files/snpEff_latest_core.zip 
## java -jar snpEff.jar download GRCh37.75
## java -Xmx4G -jar snpEff.jar -i vcf -o vcf GRCh37.75 example.vcf &amp;gt; example_snpeff.vcf
unzip snpEff_latest_core.zip
## https://github.com/najoshi/sickle
cd ~/biosoft
mkdir sickle &amp;amp;&amp;amp; cd sickle
wget https://codeload.github.com/najoshi/sickle/zip/master -O sickle.zip
unzip sickle.zip
cd sickle-master
make
~/biosoft/sickle/sickle-master/sickle -h
cd ~/biosoft
## http://www.usadellab.org/cms/?page=trimmomatic
## http://www.usadellab.org/cms/uploads/supplementary/Trimmomatic/TrimmomaticManual_V0.32.pdf
mkdir Trimmomatic &amp;amp;&amp;amp; cd Trimmomatic
wget http://www.usadellab.org/cms/uploads/supplementary/Trimmomatic/Trimmomatic-0.36.zip 
unzip Trimmomatic-0.36.zip 
java -jar ~/biosoft/Trimmomatic/Trimmomatic-0.36/trimmomatic-0.36.jar -h
## Download and install bedtools
cd ~/biosoft
mkdir bedtools &amp;amp;&amp;amp;  cd bedtools
wget https://github.com/arq5x/bedtools2/releases/download/v2.25.0/bedtools-2.25.0.tar.gz
## Length: 19581105 (19M) [application/octet-stream] 
tar -zxvf bedtools-2.25.0.tar.gz
cd bedtools2
make
#~/biosoft/bedtools/bedtools2/bin/
## Download and install PeakRanger
cd ~/biosoft
mkdir PeakRanger &amp;amp;&amp;amp;  cd PeakRanger
wget https://sourceforge.net/projects/ranger/files/PeakRanger-1.18-Linux-x86_64.zip 
## Length: 1517587 (1.4M) [application/octet-stream]
unzip PeakRanger-1.18-Linux-x86_64.zip
~/biosoft/PeakRanger/bin/peakranger -h
## Download and install bowtie
cd ~/biosoft
mkdir bowtie &amp;amp;&amp;amp;  cd bowtie
wget https://sourceforge.net/projects/bowtie-bio/files/bowtie2/2.2.9/bowtie2-2.2.9-linux-x86_64.zip 
#Length: 27073243 (26M) [application/octet-stream]
#Saving to: &amp;quot;download&amp;quot;   ## I made a mistake here for downloading the bowtie2 
mv download  bowtie2-2.2.9-linux-x86_64.zip
unzip bowtie2-2.2.9-linux-x86_64.zip
## Download and install BWA
cd ~/biosoft
mkdir bwa &amp;amp;&amp;amp;  cd bwa
#http://sourceforge.net/projects/bio-bwa/files/
wget https://sourceforge.net/projects/bio-bwa/files/bwa-0.7.15.tar.bz2 
tar xvfj bwa-0.7.15.tar.bz2 # x extracts, v is verbose (details of what it is doing), f skips prompting for each individual file, and j tells it to unzip .bz2 files
cd bwa-0.7.15
make
#export PATH=$PATH:/path/to/bwa-0.7.15 # Add bwa to your PATH by editing ~/.bashrc file (or .bash_profile or .profile file)
# /path/to/ is an placeholder. Replace with real path to BWA on your machine
#source ~/.bashrc
## Download and install macs2  
## // https://pypi.python.org/pypi/MACS2/
cd ~/biosoft
mkdir macs2 &amp;amp;&amp;amp;  cd macs2
## just stick to PyPI release: https://pypi.python.org/pypi/MACS2
wget https://pypi.python.org/packages/9f/99/a8ac96b357f6b0a6f559fe0f5a81bcae12b98579551620ce07c5183aee2c/MACS2-2.1.1.20160309.tar.gz -O MACS2-2.1.1.tar.gz 
tar zxvf  MACS2-2.1.1.tar.gz 
cd  MACS2-2.1.1.20160309/
python setup.py install --user 
## https://docs.python.org/2/install/
~/.local/bin/macs2 --help
#wget https://codeload.github.com/taoliu/MACS/zip/master -O MACS-master.zip
#unzip MACS-master.zip
#cd MACS-master 
## So you can&#39;t just pull github snapshot then run setup.py to install MACS2. Instead
# ImageMagick
cd ~/biosoft
mkdir ImageMagick &amp;amp;&amp;amp;  cd ImageMagick
## http://www.imagemagick.org/ 
cd ~/biosoft
mkdir weblogo &amp;amp;&amp;amp;  cd weblogo
## http://weblogo.berkeley.edu/
wget http://weblogo.berkeley.edu/release/weblogo.2.8.2.tar.gz
tar zxvf weblogo.2.8.2.tar.gz
cd weblogo
export PATH=$PATH:/home/jianmingzeng/biosoft/weblogo/weblogo
source ~/.bashrc
cd ~/biosoft
mkdir Ghostscript &amp;amp;&amp;amp;  cd Ghostscript
# http://www.ghostscript.com/download/gsdnld.html
# http://www.ghostscript.com/doc/9.20/Readme.htm
wget https://github.com/ArtifexSoftware/ghostpdl-downloads/releases/download/gs920/ghostscript-9.20-linux-x86_64.tgz 
tar zxvf ghostscript-9.20-linux-x86_64.tgz
cp ghostscript-9.20-linux-x86_64/gs-920-linux_x86_64  ~/biosoft/myBin/bin/gs
## make sure the &amp;quot;gs&amp;quot; program is executable 
## Download and install homer (Hypergeometric Optimization of Motif EnRichment)
## // http://homer.salk.edu/homer/
## // http://blog.qiubio.com:8080/archives/3024 
## The commands gs, seqlogo, blat, and samtools should now work from the command line
cd ~/biosoft
mkdir homer &amp;amp;&amp;amp;  cd homer
wget http://homer.salk.edu/homer/configureHomer.pl 
perl configureHomer.pl -install
perl configureHomer.pl -install hg19
## Download and install SWEMBL
cd ~/biosoft
mkdir SWEMBL &amp;amp;&amp;amp;  cd SWEMBL
#### readme: http://www.ebi.ac.uk/~swilder/SWEMBL/beginners.html
wget http://www.ebi.ac.uk/~swilder/SWEMBL/SWEMBL.3.3.1.tar.bz2 
tar xvfj SWEMBL.3.3.1.tar.bz2
cd SWEMBL.3.3.1/
make
## error 
## Download and install SISSRs
cd ~/biosoft
mkdir SISSRs &amp;amp;&amp;amp;  cd SISSRs
#### readme: https://dir.nhlbi.nih.gov/papers/lmi/epigenomes/sissrs/SISSRs-Manual.pdf
wget http://dir.nhlbi.nih.gov/papers/lmi/epigenomes/sissrs/sissrs_v1.4.tar.gz
tar xzvf sissrs_v1.4.tar.gz
~/biosoft/SISSRs/sissrs.pl
## Download and install SISSRs
cd ~/biosoft
mkdir QuEST &amp;amp;&amp;amp;  cd QuEST
#### http://mendel.stanford.edu/SidowLab/downloads/quest/
wget http://mendel.stanford.edu/SidowLab/downloads/quest/QuEST_2.4.tar.gz
tar xzvf QuEST_2.4.tar.gz
cd QuEST_2.4 
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## Download and install fastqc
##可视化展示二代测序数据质量
##http://www.bioinformatics.babraham.ac.uk/projects/fastqc/

cd ~/biosoft
mkdir fastqc &amp;amp;&amp;amp;  cd fastqc
wget http://www.bioinformatics.babraham.ac.uk/projects/fastqc/fastqc_v0.11.5.zip
unzip fastqc_v0.11.5.zip
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## Download and install CEAS    
## http://liulab.dfci.harvard.edu/CEAS/download.html
cd ~/biosoft
mkdir CEAS  &amp;amp;&amp;amp;  cd CEAS 
wget  http://liulab.dfci.harvard.edu/CEAS/src/CEAS-Package-1.0.2.tar.gz
tar zxvf CEAS-Package-1.0.2.tar.gz
cd  CEAS-Package-1.0.2
python setup.py install --user 
## http://liulab.dfci.harvard.edu/CEAS/usermanual.html
 ~/.local/bin/ceas --help  
mkdir annotation  &amp;amp;&amp;amp;  cd annotation  
wget http://liulab.dfci.harvard.edu/CEAS/src/hg19.refGene.gz ; gunzip hg19.refGene.gz 
# http://hgdownload.cse.ucsc.edu/goldenPath/hg19/database/refGene.txt.gz ##  gunzip refGene.txt.gz ; mv refGene.txt  hg19refGene.txt
## Download and install CEAS    
## http://liulab.dfci.harvard.edu/CEAS/download.html
cd ~/biosoft
mkdir crossmap  &amp;amp;&amp;amp;  cd crossmap 
pip install CrossMap --user
## http://crossmap.sourceforge.net/#use-pip-to-install-crossmap
mkdir chain_files  &amp;amp;&amp;amp;  cd chain_files  
wget http://hgdownload.soe.ucsc.edu/goldenPath/mm10/liftOver/mm10ToMm9.over.chain.gz
wget http://hgdownload.soe.ucsc.edu/goldenPath/mm9/liftOver/mm9ToMm10.over.chain.gz 
wget http://hgdownload.soe.ucsc.edu/goldenPath/hg38/liftOver/hg38ToHg19.over.chain.gz 
wget http://hgdownload.soe.ucsc.edu/goldenPath/hg38/liftOver/hg38ToHg19.over.chain.gz 
# http://hgdownload.cse.ucsc.edu/goldenPath/hg19/database/refGene.txt.gz ##  gunzip refGene.txt.gz ; mv refGene.txt  hg19refGene.txt
# Usage: CrossMap.py bed ~/biosoft/crossmap/chain_files/mm9ToMm10.over.chain.gz  test.mm9.bed3
cd ~/biosoft
# http://www.broadinstitute.org/cancer/cga/rnaseqc_run
# http://www.broadinstitute.org/cancer/cga/rnaseqc_download
mkdir RNA-SeQC  &amp;amp;&amp;amp;  cd RNA-SeQC 
#### readme: http://www.broadinstitute.org/cancer/cga/sites/default/files/data/tools/rnaseqc/RNA-SeQC_Help_v1.1.2.pdf
wget http://www.broadinstitute.org/cancer/cga/tools/rnaseqc/RNA-SeQC_v1.1.8.jar 
#TopHat+Cufflinks+ pipeline
## Download and install TopHat 
# https://ccb.jhu.edu/software/tophat/index.shtml
cd ~/biosoft
mkdir TopHat  &amp;amp;&amp;amp;  cd TopHat 
#### readme: https://ccb.jhu.edu/software/tophat/manual.shtml
wget https://ccb.jhu.edu/software/tophat/downloads/tophat-2.1.1.Linux_x86_64.tar.gz
tar xzvf tophat-2.1.1.Linux_x86_64.tar.gz 
ln -s tophat-2.1.1.Linux_x86_64 current 
# ~/biosoft/TopHat/current/tophat2
## Download and install Cufflinks 
#  http://cole-trapnell-lab.github.io/cufflinks/
cd ~/biosoft
mkdir Cufflinks  &amp;amp;&amp;amp;  cd Cufflinks 
#### readme: http://cole-trapnell-lab.github.io/cufflinks/manual/
#### install:http://cole-trapnell-lab.github.io/cufflinks/install/
wget http://cole-trapnell-lab.github.io/cufflinks/assets/downloads/cufflinks-2.2.1.Linux_x86_64.tar.gz
tar xzvf cufflinks-2.2.1.Linux_x86_64.tar.gz 
ln -s cufflinks-2.2.1.Linux_x86_64 current
~/biosoft/Cufflinks/current/cufflinks

#HISAT-Stringtie2-Ballgown pipeline


## Download and install HISAT 
##https://ccb.jhu.edu/software/hisat2/index.shtml
##功能： 将测序结果比对到参考基因组上
cd ~/biosoft
mkdir HISAT  &amp;amp;&amp;amp;  cd HISAT 
#### readme: https://ccb.jhu.edu/software/hisat2/manual.shtml
wget ftp://ftp.ccb.jhu.edu/pub/infphilo/hisat2/downloads/hisat2-2.0.4-Linux_x86_64.zip
unzip hisat2-2.0.4-Linux_x86_64.zip
ln -s hisat2-2.0.4  current 
## ~/biosoft/HISAT/current/hisat2-build
## ~/biosoft/HISAT/current/hisat2  
## Download and install StringTie
## https://ccb.jhu.edu/software/stringtie/  ## https://ccb.jhu.edu/software/stringtie/index.shtml?t=manual
cd ~/biosoft
mkdir StringTie &amp;amp;&amp;amp;  cd StringTie 
wget http://ccb.jhu.edu/software/stringtie/dl/stringtie-1.2.3.Linux_x86_64.tar.gz 
tar zxvf  stringtie-1.2.3.Linux_x86_64.tar.gz
ln -s stringtie-1.2.3.Linux_x86_64 current
# ~/biosoft/StringTie/current/stringtie
cd ~/biosoft
mkdir RSEM &amp;amp;&amp;amp;  cd RSEM 
wget https://codeload.github.com/deweylab/RSEM/tar.gz/v1.2.31
mv v1.2.31  RSEM.v1.2.31.tar.gz 
tar zxvf RSEM.v1.2.31.tar.gz  
## Download and install HTSeq  
## http://www-huber.embl.de/users/anders/HTSeq/doc/overview.html
## https://pypi.python.org/pypi/HTSeq
cd ~/biosoft
mkdir HTSeq &amp;amp;&amp;amp;  cd HTSeq
wget  https://pypi.python.org/packages/72/0f/566afae6c149762af301a19686cd5fd1876deb2b48d09546dbd5caebbb78/HTSeq-0.6.1.tar.gz 
tar zxvf HTSeq-0.6.1.tar.gz
cd HTSeq-0.6.1
python setup.py install --user 
~/.local/bin/htseq-count  --help
## ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_mouse/release_M1/
## http://hgdownload-test.cse.ucsc.edu/goldenPath/mm10/liftOver/
## GRCm38/mm10 (Dec, 2011) 
## ls *bam |while read id;do ( ~/.local/bin/htseq-count  -f bam  $id   genecode/mm9/gencode.vM1.annotation.gtf.gz  1&amp;gt;${id%%.*}.gene.counts ) ;done 
## ls *bam |while read id;do ( ~/.local/bin/htseq-count  -f bam -i exon_id  $id   genecode/mm9/gencode.vM1.annotation.gtf.gz  1&amp;gt;${id%%.*}.exon.counts ) ;done
## Download and install kallisto
## https://pachterlab.github.io/kallisto/starting
cd ~/biosoft
mkdir kallisto &amp;amp;&amp;amp;  cd kallisto 
wget https://github.com/pachterlab/kallisto/releases/download/v0.43.0/kallisto_linux-v0.43.0.tar.gz
#tar zxvf  
## Download and install Sailfish
## http://www.cs.cmu.edu/~ckingsf/software/sailfish/  ## 
cd ~/biosoft
mkdir Sailfish &amp;amp;&amp;amp;  cd Sailfish 
wget   https://github.com/kingsfordgroup/sailfish/releases/download/v0.9.2/SailfishBeta-0.9.2_DebianSqueeze.tar.gz 
#tar zxvf  
## Download and install salmon
## http://salmon.readthedocs.io/en/latest/salmon.html ## 
cd ~/biosoft
mkdir salmon &amp;amp;&amp;amp;  cd salmon 
## https://github.com/COMBINE-lab/salmon
#tar zxvf  
cd ~/biosoft
mkdir GDC  &amp;amp;&amp;amp;  cd GDC  
# https://gdc.cancer.gov/access-data/gdc-data-transfer-tool
# http://gdc-docs.nci.nih.gov/Data_Transfer_Tool/Users_Guide/Getting_Started/
wget https://gdc.nci.nih.gov/files/public/file/gdc-client_v1.2.0_Ubuntu14.04_x64.zip 
unzip gdc-client_v1.2.0_Ubuntu14.04_x64.zip
cd ~/biosoft/myBin/bin
## http://hgdownload.cse.ucsc.edu/admin/exe/
wget http://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/bedToBigBed
wget http://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/bedSort
wget http://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/bedGraphToBigWig
wget http://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/fetchChromSizes
wget http://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/wigToBigWig
wget http://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/liftOver
wget http://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/bigWigToBedGraph
wget http://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/bigBedToBed
wget http://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/blat/blat
wget http://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/blat/gfClient
wget http://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/blat/gfServer
## Download and install variationtoolkit
## https://code.google.com/archive/p/variationtoolkit/downloads 
cd ~/biosoft
mkdir variationtoolkit &amp;amp;&amp;amp;  cd variationtoolkit  
wget https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/variationtoolkit/archive.tar.gz
tar zxvf archive.tar.gz 
cd variationtoolkit
make
## Download and install transvar
# http://bioinformatics.mdanderson.org/main/Transvar
cd ~/biosoft
# https://bitbucket.org/wanding/transvar
mkdir transvar &amp;amp;&amp;amp;  cd transvar  
wget https://bitbucket.org/wanding/transvar/get/v2.1.19.20160221.zip 
unzip v2.1.19.20160221.zip 
cd wanding-transvar-5dd8a7366999 
python setup.py install --user 
cd ~/biosoft
# http://kobas.cbi.pku.edu.cn/download.php 
mkdir kobas &amp;amp;&amp;amp;  cd kobas  
# wget http://kobas.cbi.pku.edu.cn/download_file.php?type=seq_pep&amp;amp;filename=hsa.pep.fasta.gz 
# wget http://kobas.cbi.pku.edu.cn/download_file.php?type=sqlite3&amp;amp;filename=hsa.db.gz 
wget http://kobas.cbi.pku.edu.cn/kobas-2.1.1/kobas-2.1.1.tar.gz 
tar zxvf kobas-2.1.1.tar.gz 
cd kobas-2.1.1_20160822
# * Download the KOBAS organism data package (organism.db.gz) from KOBAS Backend databases download website
# * Download the KOBAS specific species data package from KOBAS Backend databases download website (for example, hsa.db.gz)
# * Download the specific sequence file from KOBAS sequence files download website (for example, hsa.pep.fasta.gz)
# * `gunzip organism.db.gz`
# * `gunzip hsa.db.gz`
# * Move all databases into ${kobas_home}/sqlite3/ (for example, organism.db, hsa.db)
# * `gunzip hsa.pep.fasta.gz`
# * Move the fasta sequence file into ${kobas_home}/seq_pep/
# * `makeblastdb -in hsa.pep.fasta -dbtype prot`
pip install RPy2 --user 
pip install Numpy --user 
pip install Pandas --user 
pip install BioPython --user 
pip install matplotlib --user 
pip install PySQLite --user 
source(&amp;quot;http://bioconductor.org/biocLite.R&amp;quot;)
biocLite(&amp;quot;qvalue&amp;quot;)
## Download and install bamtools
## https://github.com/pezmaster31/bamtools/wiki/Building-and-installing
cd ~/biosoft
mkdir bamtools &amp;amp;&amp;amp;  cd bamtools  
git clone git://github.com/pezmaster31/bamtools.git 
cd bamtools
cmake --version  ## BamTools requires CMake (version &amp;gt;= 2.6.4).
mkdir build &amp;amp;&amp;amp;  cd build 
cmake ../ 
make
~/biosoft/bamtools/bamtools/bin/bamtools
## Download and install BAMStats
## http://bamstats.sourceforge.net/
## https://sourceforge.net/projects/bamstats/files/
cd ~/biosoft
mkdir BAMStats &amp;amp;&amp;amp;  cd BAMStats  
wget https://nchc.dl.sourceforge.net/project/bamstats/BAMStats-1.25.zip 
unzip BAMStats-1.25.zip
#java -jar  ~/biosoft/BAMStats/BAMStats-1.25/BAMStats-1.25.jar  --help
## Download and install Qualimap 
## http://qualimap.bioinfo.cipf.es/
cd ~/biosoft
mkdir Qualimap &amp;amp;&amp;amp;  cd Qualimap  
wget https://bitbucket.org/kokonech/qualimap/downloads/qualimap_v2.2.1.zip 
## readme  http://qualimap.bioinfo.cipf.es/doc_html/index.html
## example results :http://kokonech.github.io/qualimap/HG00096.chr20_bamqc/qualimapReport.html 
unzip qualimap_v2.2.1.zip 
~/biosoft/bamtools/bamtools/bin/bamtools
~/biosoft/Qualimap/qualimap_v2.2.1/qualimap --help ## --java-mem-size=4G
## modify ~/.bashrc by adding PATH=$PATH:~/.local/bin/
## Download and install deepTools
## https://github.com/fidelram/deepTools
## http://deeptools.readthedocs.io/en/latest/content/example_usage.html
pip install pyBigWig --user 
cd ~/biosoft
mkdir deepTools &amp;amp;&amp;amp;  cd deepTools  
git clone https://github.com/fidelram/deepTools ## 130M,
cd deepTools
python setup.py install --user
## 17 tools in ~/.local/bin/
~/.local/bin/deeptools
cd ~/biosoft
mkdir ngsplot &amp;amp;&amp;amp;  cd ngsplot  
## download by yourself :https://drive.google.com/drive/folders/0B1PVLadG_dCKN1liNFY0MVM1Ulk  
tar -zxvf ngsplot-2.61.tar.gz
tar zxvf ngsplot.eg.bam.tar.gz
echo &#39;export PATH=/home/jianmingzeng/biosoft/ngsplot/ngsplot/bin:$PATH&#39; &amp;gt;&amp;gt;~/.bashrc  
echo &#39;export NGSPLOT=/home/jianmingzeng/biosoft/ngsplot/ngsplot&#39; &amp;gt;&amp;gt;~/.bashrc 
source ~/.bashrc
install.packages(&amp;quot;doMC&amp;quot;, dep=T)
install.packages(&amp;quot;caTools&amp;quot;, dep=T)
install.packages(&amp;quot;utils&amp;quot;, dep=T)
source(&amp;quot;http://bioconductor.org/biocLite.R&amp;quot;)
biocLite( &amp;quot;BSgenome&amp;quot; )
biocLite( &amp;quot;Rsamtools&amp;quot; )
biocLite( &amp;quot;ShortRead&amp;quot; )
cd ~/biosoft
mkdir breakdancer &amp;amp;&amp;amp;  cd breakdancer  
# http://breakdancer.sourceforge.net/
# you need to install 2 perl module by yourself : http://breakdancer.sourceforge.net/moreperl.html
wget https://sourceforge.net/projects/breakdancer/files/breakdancer-1.1.2_2013_03_08.zip 
unzip breakdancer-1.1.2_2013_03_08.zip 
cd breakdancer-1.1.2/cpp
make  ##something wrong !
## usage: http://breakdancer.sourceforge.net/pipeline.html
cd ~/biosoft
# http://boevalab.com/FREEC/
mkdir Control-FREEC &amp;amp;&amp;amp; cd Control-FREEC
# https://github.com/BoevaLab/FREEC/releases
wget https://github.com/BoevaLab/FREEC/archive/v10.3.zip 
unzip v10.3.zip 
# https://www.ncbi.nlm.nih.gov/pubmed/22155870
# http://boevalab.com/FREEC/tutorial.html
# http://samtools.sourceforge.net/pileup.shtml
cd ~/biosoft
# https://github.com/dellytools/delly
mkdir delly &amp;amp;&amp;amp; cd delly 
# git clone --recursive https://github.com/dellytools/delly.git
# cd delly 
# make all
# make PARALLEL=1 -B src/delly
wget https://github.com/dellytools/delly/releases/download/v0.7.6/delly_v0.7.6_linux_x86_64bit 
chmod 777 delly_v0.7.6_linux_x86_64bit 
~/biosoft/delly/delly_v0.7.6_linux_x86_64bit  --help 
## delly call -t DEL -g hg19.fa -o s1.bcf -x hg19.excl sample1.bam
## ./delly/src/bcftools/bcftools view delly.bcf &amp;gt; delly.vcf
## The SV type can be DEL, DUP, INV, TRA, or INS for deletions, tandem duplications, inversions, translocations and small insertions, respectively.
## In addition, you can filter input reads more stringently using -q 20 and -s 15.
cd ~/biosoft
# https://www.cog-genomics.org/plink2/data#merge_list
mkdir PLINK &amp;amp;&amp;amp; cd PLINK 
wget https://www.cog-genomics.org/static/bin/plink170113/plink_linux_x86_64.zip 
unzip plink_linux_x86_64.zip
~/biosoft/PLINK/plink
## Download and install Scalpel
cd ~/biosoft
mkdir Scalpel &amp;amp;&amp;amp;  cd Scalpel
wget https://downloads.sourceforge.net/project/scalpel/scalpel-0.5.3.tar.gz  
tar zxvf scalpel-0.5.3.tar.gz
cd scalpel-0.5.3
make
~/biosoft/Scalpel/scalpel-0.5.3/scalpel-discovery  --help
~/biosoft/Scalpel/scalpel-0.5.3/scalpel-export  --help
cd ~/biosoft
# https://www.cog-genomics.org/plink2/data#merge_list
mkdir firehose &amp;amp;&amp;amp; cd firehose 
wget http://gdac.broadinstitute.org/runs/code/firehose_get_latest.zip
unzip firehose_get_latest.zip 
~/biosoft/firehose/firehose_get
~/biosoft/firehose/firehose_get -tasks clinical analyses latest brca 
cd ~/biosoft
# https://www.cog-genomics.org/plink2/data#merge_list
mkdir fastpop &amp;amp;&amp;amp; cd fastpop 
wget https://sourceforge.net/projects/fastpop/files/FastPop.tar.gz 
wget https://jaist.dl.sourceforge.net/project/fastpop/FastPop_Instruction.pdf
tar zxvf FastPop.tar.gz  
pip install cnvkit --user
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;转录组-de-novo分析流程的软件全代码&#34;&gt;转录组 de novo分析流程的软件全代码&lt;/h1&gt;

&lt;p&gt;Trinotate/Trinity/TransDecoder/sqlite/NCBI BLAST+/HMMER/PFAM signalP v4 /tmhmm v2 /RNAMMER 有些软件需要教育邮箱注册才行哦~~&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## Trinotate/Trinity/TransDecoder/sqlite/NCBI BLAST+/HMMER/PFAM 
## signalP v4 /tmhmm v2 /RNAMMER
cd ~/biosoft
mkdir hmmer &amp;amp;&amp;amp;  cd hmmer
wget http://eddylab.org/software/hmmer/2.3/hmmer-2.3.tar.gz 
tar zxvf hmmer-2.3.tar.gz
cd hmmer-2.3
./configure --prefix=/home/jmzeng/my-bin
#./configure --prefix=/home/jianmingzeng/biosoft/myBin
make
make install
#for file in hmmalign hmmbuild hmmcalibrate hmmconvert hmmemit hmmfetch hmmindex hmmpfam hmmsearch ; do\
#      cp src/$file /home/jmzeng/my-bin/bin/;\
#   done
#for file in hmmer hmmalign hmmbuild hmmcalibrate hmmconvert hmmemit hmmfetch hmmindex hmmpfam hmmsearch; do\
#      cp documentation/man/$file.man /home/jmzeng/my-bin/man/man1/$file.1;\
#   done
cp /home/jmzeng/my-bin/bin/hmmsearch /home/jmzeng/my-bin/bin/hmmsearch2
cd ~/biosoft
mkdir CBS &amp;amp;&amp;amp;  cd CBS
#   signalP v4 (free academic download) http://www.cbs.dtu.dk/cgi-bin/nph-sw_request?signalp
#   tmhmm v2 (free academic download) http://www.cbs.dtu.dk/cgi-bin/nph-sw_request?tmhmm
#   RNAMMER (free academic download) http://www.cbs.dtu.dk/cgi-bin/sw_request?rnammer
mkdir signalp-4.1
mkdir rnammer-1.2
## be sure to untar it in a new directory
## it&#39;s a perl script, we need to modify it according to readme http://trinotate.github.io/#SoftwareRequired
## vi ~/biosoft/CBS/signalp-4.1/signalp
tar zxvf signalp-4.1e.Linux.tar.gz 
tar zxvf rnammer-1.2.src.tar.Z 
tar zxvf tmhmm-2.0c.Linux.tar.gz 
## it&#39;s a perl script, we need to modify it according to readme http://trinotate.github.io/#SoftwareRequired
## vi ~/biosoft/CBS/tmhmm-2.0c/bin/tmhmm 
## vi ~/biosoft/CBS/tmhmm-2.0c/bin/tmhmmformat.pl
which perl  ## /usr/bin/perl
cd ~/biosoft
mkdir blastPlus &amp;amp;&amp;amp;  cd blastPlus
#   ftp://ftp.ncbi.nlm.nih.gov/blast/executables/LATEST
wget ftp://ftp.ncbi.nlm.nih.gov/blast/executables/LATEST/ncbi-blast-2.5.0+-x64-linux.tar.gz
blastBinFolder=~/biosoft/blastPlus/ncbi-blast-2.5.0+/bin
$blastBinFolder/makeblastdb -help
#   http://www.cbs.dtu.dk/services/doc/signalp-4.1.readme
cd ~/biosoft
mkdir TransDecoder &amp;amp;&amp;amp;  cd TransDecoder
#   https://transdecoder.github.io/
# https://github.com/TransDecoder/TransDecoder/releases
wget https://github.com/TransDecoder/TransDecoder/archive/v3.0.0.tar.gz  -O TransDecoder.v3.0.0.tar.gz 
tar zxvf TransDecoder.v3.0.0.tar.gz 
cd TransDecoder-3.0.0 
make
~/biosoft/TransDecoder/TransDecoder-3.0.0/TransDecoder.LongOrfs -h
~/biosoft/TransDecoder/TransDecoder-3.0.0/TransDecoder.Predict -h
## sqlite3  --help
cd ~/biosoft
mkdir Trinotate &amp;amp;&amp;amp;  cd Trinotate
#   http://trinotate.github.io/
#   https://github.com/Trinotate/Trinotate/releases
wget https://github.com/Trinotate/Trinotate/archive/v3.0.1.tar.gz  -O Trinotate.v3.0.1.tar.gz 
tar zxvf Trinotate.v3.0.1.tar.gz
~/biosoft/Trinotate/Trinotate-3.0.1/Trinotate -h
wget https://data.broadinstitute.org/Trinity/Trinotate_v3_RESOURCES/Pfam-A.hmm.gz
wget https://data.broadinstitute.org/Trinity/Trinotate_v3_RESOURCES/uniprot_sprot.pep.gz
wget https://data.broadinstitute.org/Trinity/Trinotate_v3_RESOURCES/Trinotate_v3.sqlite.gz  -O Trinotate.sqlite.gz
gunzip Trinotate.sqlite.gz
gunzip uniprot_sprot.pep.gz
makeblastdb -in uniprot_sprot.pep -dbtype prot
gunzip Pfam-A.hmm.gz
hmmpress Pfam-A.hmm
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;基因组-gtf-bed-注释&#34;&gt;基因组，gtf，bed，注释&lt;/h1&gt;

&lt;p&gt;前面既然把我多年累积的软件安装代码共享了，就顺便把我最近做直播我的基因组的一些数据下载代码共享吧&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;cd ~/reference
mkdir -p genome/hg19  &amp;amp;&amp;amp; cd genome/hg19 
nohup wget http://hgdownload.cse.ucsc.edu/goldenPath/hg19/bigZips/chromFa.tar.gz &amp;amp;
tar zvfx chromFa.tar.gz
cat *.fa &amp;gt; hg19.fa
rm chr*.fa
 
 
cd ~/reference
mkdir -p genome/hg38  &amp;amp;&amp;amp; cd genome/hg38 
nohup wget http://hgdownload.cse.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz  &amp;amp;
 
cd ~/reference
mkdir -p  genome/mm10  &amp;amp;&amp;amp; cd genome/mm10 
nohup wget http://hgdownload.cse.ucsc.edu/goldenPath/mm10/bigZips/chromFa.tar.gz  &amp;amp;
tar zvfx chromFa.tar.gz
cat *.fa &amp;gt; mm10.fa
rm chr*.fa
 
 
cd ~/biosoft/RNA-SeQC
wget http://www.broadinstitute.org/cancer/cga/sites/default/files/data/tools/rnaseqc/ThousandReads.bam
wget http://www.broadinstitute.org/cancer/cga/sites/default/files/data/tools/rnaseqc/gencode.v7.annotation_goodContig.gtf.gz
wget http://www.broadinstitute.org/cancer/cga/sites/default/files/data/tools/rnaseqc/Homo_sapiens_assembly19.fasta.gz
wget http://www.broadinstitute.org/cancer/cga/sites/default/files/data/tools/rnaseqc/Homo_sapiens_assembly19.other.tar.gz
wget http://www.broadinstitute.org/cancer/cga/sites/default/files/data/tools/rnaseqc/gencode.v7.gc.txt
wget http://www.broadinstitute.org/cancer/cga/sites/default/files/data/tools/rnaseqc/rRNA.tar.gz
 
cd ~/reference
mkdir -p index/bowtie &amp;amp;&amp;amp; cd index/bowtie 
nohup time ~/biosoft/bowtie/bowtie2-2.2.9/bowtie2-build  ~/reference/genome/hg19/hg19.fa  ~/reference/index/bowtie/hg19 1&amp;gt;hg19.bowtie_index.log 2&amp;gt;&amp;amp;1 &amp;amp;
nohup time ~/biosoft/bowtie/bowtie2-2.2.9/bowtie2-build  ~/reference/genome/hg38/hg38.fa  ~/reference/index/bowtie/hg38 1&amp;gt;hg38.bowtie_index.log 2&amp;gt;&amp;amp;1 &amp;amp;
nohup time ~/biosoft/bowtie/bowtie2-2.2.9/bowtie2-build  ~/reference/genome/mm10/mm10.fa  ~/reference/index/bowtie/mm10 1&amp;gt;mm10.bowtie_index.log 2&amp;gt;&amp;amp;1 &amp;amp;
  
cd ~/reference
mkdir -p index/bwa &amp;amp;&amp;amp; cd index/bwa 
nohup time ~/biosoft/bwa/bwa-0.7.15/bwa index   -a bwtsw   -p ~/reference/index/bwa/hg19  ~/reference/genome/hg19/hg19.fa 1&amp;gt;hg19.bwa_index.log 2&amp;gt;&amp;amp;1   &amp;amp;
nohup time ~/biosoft/bwa/bwa-0.7.15/bwa index   -a bwtsw   -p ~/reference/index/bwa/hg38  ~/reference/genome/hg38/hg38.fa 1&amp;gt;hg38.bwa_index.log 2&amp;gt;&amp;amp;1   &amp;amp;
nohup time ~/biosoft/bwa/bwa-0.7.15/bwa index   -a bwtsw   -p ~/reference/index/bwa/mm10  ~/reference/genome/mm10/mm10.fa 1&amp;gt;mm10.bwa_index.log 2&amp;gt;&amp;amp;1   &amp;amp;
  
cd ~/reference
mkdir -p index/hisat &amp;amp;&amp;amp; cd index/hisat 
nohup wget ftp://ftp.ccb.jhu.edu/pub/infphilo/hisat2/data/hg19.tar.gz  &amp;amp;
nohup wget ftp://ftp.ccb.jhu.edu/pub/infphilo/hisat2/data/hg38.tar.gz  &amp;amp;
nohup wget ftp://ftp.ccb.jhu.edu/pub/infphilo/hisat2/data/grcm38.tar.gz &amp;amp;
nohup wget ftp://ftp.ccb.jhu.edu/pub/infphilo/hisat2/data/mm10.tar.gz  &amp;amp;
tar zxvf hg19.tar.gz
tar zxvf grcm38.tar.gz
tar zxvf hg38.tar.gz
tar zxvf mm10.tar.gz 
  
  
mkdir -p ~/annotation/variation/human/ExAC
cd ~/annotation/variation/human/ExAC
## http://exac.broadinstitute.org/
## ftp://ftp.broadinstitute.org/pub/ExAC_release/current
wget ftp://ftp.broadinstitute.org/pub/ExAC_release/current/ExAC.r0.3.1.sites.vep.vcf.gz.tbi 
nohup wget ftp://ftp.broadinstitute.org/pub/ExAC_release/current/ExAC.r0.3.1.sites.vep.vcf.gz &amp;amp;
wget ftp://ftp.broadinstitute.org/pub/ExAC_release/current/cnv/exac-final-cnv.gene.scores071316 
wget ftp://ftp.broadinstitute.org/pub/ExAC_release/current/cnv/exac-final.autosome-1pct-sq60-qc-prot-coding.cnv.bed
 
 
mkdir -p ~/annotation/variation/human/dbSNP
cd ~/annotation/variation/human/dbSNP
## https://www.ncbi.nlm.nih.gov/projects/SNP/
## ftp://ftp.ncbi.nih.gov/snp/organisms/human_9606_b147_GRCh38p2/
## ftp://ftp.ncbi.nih.gov/snp/organisms/human_9606_b147_GRCh37p13/
nohup wget ftp://ftp.ncbi.nih.gov/snp/organisms/human_9606_b147_GRCh37p13/VCF/All_20160601.vcf.gz &amp;amp;
wget ftp://ftp.ncbi.nih.gov/snp/organisms/human_9606_b147_GRCh37p13/VCF/All_20160601.vcf.gz.tbi 
 
 
mkdir -p ~/annotation/variation/human/1000genomes
cd ~/annotation/variation/human/1000genomes 
## ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/ 
nohup wget  -c -r -nd -np -k -L -p  ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502 &amp;amp;
 
mkdir -p ~/annotation/variation/human/cosmic
cd ~/annotation/variation/human/cosmic
## we need to register before we can download this file. 
 
mkdir -p ~/annotation/variation/human/ESP6500
cd ~/annotation/variation/human/ESP6500
# http://evs.gs.washington.edu/EVS/
nohup wget http://evs.gs.washington.edu/evs_bulk_data/ESP6500SI-V2-SSA137.GRCh38-liftover.snps_indels.vcf.tar.gz &amp;amp; 
 
mkdir -p ~/annotation/variation/human/UK10K
cd ~/annotation/variation/human/UK10K
# http://www.uk10k.org/
nohup wget ftp://ngs.sanger.ac.uk/production/uk10k/UK10K_COHORT/REL-2012-06-02/UK10K_COHORT.20160215.sites.vcf.gz &amp;amp; 
 
mkdir -p ~/annotation/variation/human/gonl
cd ~/annotation/variation/human/gonl
## http://www.nlgenome.nl/search/
## https://molgenis26.target.rug.nl/downloads/gonl_public/variants/release5/
nohup wget  -c -r -nd -np -k -L -p  https://molgenis26.target.rug.nl/downloads/gonl_public/variants/release5  &amp;amp;
 
mkdir -p ~/annotation/variation/human/omin
cd ~/annotation/variation/human/omin
 
mkdir -p ~/annotation/variation/human/GWAS
cd ~/annotation/variation/human/GWAS
 
mkdir -p ~/annotation/variation/human/hapmap
cd ~/annotation/variation/human/hapmap
# ftp://ftp.ncbi.nlm.nih.gov/hapmap/
wget ftp://ftp.ncbi.nlm.nih.gov/hapmap/phase_3/relationships_w_pops_051208.txt 
nohup wget -c -r -np -k -L -p  -nd -A.gz ftp://ftp.ncbi.nlm.nih.gov/hapmap/phase_3/hapmap3_reformatted &amp;amp;
# ftp://ftp.hgsc.bcm.tmc.edu/pub/data/HapMap3-ENCODE/ENCODE3/ENCODE3v1/
wget ftp://ftp.hgsc.bcm.tmc.edu/pub/data/HapMap3-ENCODE/ENCODE3/ENCODE3v1/bcm-encode3-QC.txt 
wget ftp://ftp.hgsc.bcm.tmc.edu/pub/data/HapMap3-ENCODE/ENCODE3/ENCODE3v1/bcm-encode3-submission.txt.gz
 
 
 
 
## 1 million single nucleotide polymorphisms (SNPs) for DNA samples from each of the three ethnic groups in Singapore – Chinese, Malays and Indians.
## The Affymetrix Genome-Wide Human SNP Array 6.0   &amp;amp;&amp;amp; The Illumina Human1M single BeadChip 
## http://www.statgen.nus.edu.sg/~SGVP/
## http://www.statgen.nus.edu.sg/~SGVP/singhap/files-website/samples-information.txt
# http://www.statgen.nus.edu.sg/~SGVP/singhap/files-website/genotypes/2009-01-30/QC/
 
## Singapore Sequencing Malay Project (SSMP) 
mkdir -p ~/annotation/variation/human/SSMP
cd ~/annotation/variation/human/SSMP
## http://www.statgen.nus.edu.sg/~SSMP/
## http://www.statgen.nus.edu.sg/~SSMP/download/vcf/2012_05 
 
 
## Singapore Sequencing Indian Project (SSIP) 
mkdir -p ~/annotation/variation/human/SSIP
cd ~/annotation/variation/human/SSIP
# http://www.statgen.nus.edu.sg/~SSIP/
## http://www.statgen.nus.edu.sg/~SSIP/download/vcf/dataFreeze_Feb2013
 
 
 
wget ftp://ftp.ensembl.org/pub/release-75/gtf/homo_sapiens/Homo_sapiens.GRCh37.75.gtf.gz 
wget ftp://ftp.ensembl.org/pub/release-86/gtf/homo_sapiens/Homo_sapiens.GRCh38.86.chr.gtf.gz 
 
mkdir -p ~/reference/gtf/gencode
cd  ~/reference/gtf/gencode
## https://www.gencodegenes.org/releases/current.html
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/gencode.v25.2wayconspseudos.gtf.gz
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/gencode.v25.long_noncoding_RNAs.gtf.gz 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/gencode.v25.polyAs.gtf.gz 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/gencode.v25.annotation.gtf.gz 
## https://www.gencodegenes.org/releases/25lift37.html 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/GRCh37_mapping/gencode.v25lift37.annotation.gtf.gz 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/GRCh37_mapping/gencode.v25lift37.metadata.HGNC.gz 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/GRCh37_mapping/gencode.v25lift37.metadata.EntrezGene.gz 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/GRCh37_mapping/gencode.v25lift37.metadata.RefSeq.gz 
 
 
mkdir -p ~/reference/gtf/ensembl/homo_sapiens_86
cd  ~/reference/gtf/ensembl/homo_sapiens_86
## http://asia.ensembl.org/info/data/ftp/index.html
 
 
 
cd ~/reference
mkdir -p  genome/human_g1k_v37  &amp;amp;&amp;amp; cd genome/human_g1k_v37
# http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/ 
nohup wget http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/human_g1k_v37.fasta.gz  &amp;amp;
gunzip human_g1k_v37.fasta.gz
wget http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/human_g1k_v37.fasta.fai
wget http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/README.human_g1k_v37.fasta.txt
java -jar ~/biosoft/picardtools/picard-tools-1.119/CreateSequenceDictionary.jar R=human_g1k_v37.fasta O=human_g1k_v37.dict
 
## ftp://ftp.broadinstitute.org/bundle/b37/
mkdir -p ~/annotation/GATK
cd ~/annotation/variation/GATK
wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/b37/1000G_phase1.snps.high_confidence.b37.vcf.gz 
wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/b37/dbsnp_138.b37.vcf.gz
wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/b37/human_g1k_v37.fasta.gz 
wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/b37/NA12878.HiSeq.WGS.bwa.cleaned.raw.subset.b37.sites.vcf.gz
wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/b37/Mills_and_1000G_gold_standard.indels.b37.vcf.gz 
wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/b37/hapmap_3.3.b37.vcf.gz
wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/b37/1000G_phase1.indels.b37.vcf.gz 
wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/b37/1000G_phase1.indels.b37.vcf.idx.gz
gunzip 1000G_phase1.indels.b37.vcf.idx.gz
gunzip 1000G_phase1.indels.b37.vcf.gz
  
  
mkdir -p  ~/institute/ENSEMBL/gtf
cd  ~/institute/ENSEMBL/gtf
wget ftp://ftp.ensembl.org/pub/release-87/gtf/homo_sapiens/Homo_sapiens.GRCh38.87.chr.gtf.gz 
wget ftp://ftp.ensembl.org/pub/release-87/gtf/mus_musculus/Mus_musculus.GRCm38.87.chr.gtf.gz
wget ftp://ftp.ensembl.org/pub/release-87/gtf/danio_rerio/Danio_rerio.GRCz10.87.chr.gtf.gz
 
 
 
 
 
cd ~/institute/TCGA/firehose
## https://gdac.broadinstitute.org/
wget http://gdac.broadinstitute.org/runs/stddata__2016_01_28/data/ACC/20160128/gdac.broadinstitute.org_ACC.Merge_snp__genome_wide_snp_6__broad_mit_edu__Level_3__segmented_scna_minus_germline_cnv_hg19__seg.Level_3.2016012800.0.0.tar.gz  -O ACC.gistic.seg.tar.gz
wget http://gdac.broadinstitute.org/runs/stddata__2016_01_28/data/ACC/20160128/gdac.broadinstitute.org_ACC.Merge_snp__genome_wide_snp_6__broad_mit_edu__Level_3__segmented_scna_hg19__seg.Level_3.2016012800.0.0.tar.gz  -O ACC.raw.seg.tar.gz 
wget http://gdac.broadinstitute.org/runs/stddata__2016_01_28/data/ACC/20160128/gdac.broadinstitute.org_ACC.Mutation_Packager_Calls.Level_3.2016012800.0.0.tar.gz -O ACC.maf.tar.gz
wget http://gdac.broadinstitute.org/runs/stddata__2016_01_28/data/ACC/20160128/gdac.broadinstitute.org_ACC.Mutation_Packager_Oncotated_Calls.Level_3.2016012800.0.0.tar.gz -O ACC.maf.anno.tar.gz
&lt;/code&gt;&lt;/pre&gt;

        
      </description>
    </item>
    
    <item>
      <title>一致性指数Concordance index(C-index) </title>
      <link>/blog/cn/2017/10/concordance_index/</link>
      <pubDate>Sun, 15 Oct 2017 23:06:17 +0000</pubDate>
      
      <guid>/blog/cn/2017/10/concordance_index/</guid>
      <description>
        

&lt;p&gt;&lt;a href=&#34;http://mp.weixin.qq.com/s?__biz=MzAxNjM2MDI2MQ==&amp;amp;mid=205481962&amp;amp;idx=1&amp;amp;sn=f09dd122f7282be8d26b803d0039a195#rd&#34;&gt;原文&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;所谓C-index，英文名全称&lt;strong&gt;concordance index&lt;/strong&gt;，最早是由范德堡大学（Vanderbilt University）生物统计教教授Frank E Harrell Jr 1996年提出，主要用于计算生存分析中的COX模型预测值与真实之间的区分度（discrimination）；现阶段用的最多的是肿瘤患者预后模型的预测精度。&lt;/p&gt;

&lt;p&gt;一般评价模型的好坏主要有两个方面，&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;一是模型的拟合优度（Goodness of Fit),常见的评价指标主要有R方，-2logL,AIC,BIC等等；&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;另外一个是模型的预测精度，主要就是模型的真实值与预测值之间的差的大小，均方误差，相对误差等。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;从临床应用的角度来说，我们更注重后者，即统计建模主要是用于预测，而从C-index的概念大家看出它属于模型评价指标的后者，这一指标比前面提到的几个指标看起来更高大上，一般文献中用的也比较多。&lt;/p&gt;

&lt;p&gt;C-index本质上是估计了预测结果与实际观察到的结果相一致的概率，即资料所有病人对子中预测结果与实际结果一致的对子所占的比例。有点类似于ROC曲线下面积。&lt;/p&gt;

&lt;p&gt;C-index的计算方法是:把所研究的资料中的所有研究对象随机地两两组成对子。以生存分析为例,对于一对病人,如果生存时间较长的一位,其预测生存时间长于生存时间较短的一位,或预测的生存概率高的一位的生存时间长于生存概率低的另一位,则称之为预测结果与实际结果一致。&lt;/p&gt;

&lt;p&gt;C-index的计算步骤为:&lt;/p&gt;

&lt;p&gt;*(1)产生所有的病例配对。若有n个观察个体,则所有的对子数应为Cn2(组合数)?
*(2)排除下面两种对子:对子中具有较小观察时间的个体没有达到观察终点及对子中两个个体都没达到观察终点。剩余的为有用对子。
*(3)计算有用对子中,预测结果和实际相一致的对子数,即具有较坏预测结果个体的实际观察时间较短。
*(4)计算。C=一致对子数/有用对子数。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;C-index在0.5-1之间。0.5为完全不一致,说明该模型没有预测作用,1为完全一致,说明该模型预测结果与实际完全一致。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在实际应用中,很难找到完全一致的预测模型,既往研究认为,C-index
* 在0.50-0.70为较低准确度,
* 在0.71-0.90之间为中等准确度;
* 而高于0.90则为高准确度。&lt;/p&gt;

&lt;p&gt;当C-index检验由同一样本建成的模型时易造成偏倚,因此再采用重抽样技术(Bootstrap)可以几乎无偏倚的检验预测模型的准确度。Bootstrap是非参数统计中一种重要的估计统计量方差进而进行区间估计的统计方法,是现代统计应用较为广泛的一种统计方法。&lt;/p&gt;

&lt;p&gt;Bootstrap方法核心思想和基本步骤如下:&lt;/p&gt;

&lt;p&gt;*(1)采用重抽样技术从原始样本中抽取一定数量的样本,此过程允许重复抽样。&lt;/p&gt;

&lt;p&gt;*(2)根据抽出的样本计算给定的统计量T。&lt;/p&gt;

&lt;p&gt;*(3)重复上述N次(一般大于1000),得到N个统计量T。&lt;/p&gt;

&lt;p&gt;*(4)计算上述N个统计量T的样木方差,得到统计量的方差。&lt;/p&gt;

&lt;p&gt;Bootstarap方法只是对单一样本且样本量较小的资料，如果数据集很大可以按照不同的比例将数据集拆分，一部分用于建模一部分用于验证。关于交叉验证（Cross-validation），由于篇幅有限，留作下次探讨。&lt;/p&gt;

&lt;p&gt;#R软件实现：
C-index的R软件计算实现有两种实现方法，一种是用到Harrell本人的的R包Hmisc package；另一种是Le Kang, Weijie Chen 2014年12月18日发布的R compareC Package&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;############################
#### Method 1.Hmisc code ###
############################
data &amp;lt;- read.csv(&amp;quot;survivaldta.csv&amp;quot;)
library(Hmisc) 
library(survival) ###加载survival包，主要用于建立模型###
f &amp;lt;- cph(Surv(time,death)~x1+x2+x3，data=survivldata) ###拟合cox模型
fp &amp;lt;- predict(f)###模型的预测值
cindex.orig=1-rcorr.cens(fp,Surv(time,death)) [[1]]###计算出的C-index

###############################
#### Method 2.compareC code ###
###############################
data &amp;lt;- read.csv(&amp;quot;survivaldta.csv&amp;quot;) 
library(compareC) 
library(survival) 
cindex &amp;lt;- cindex(Surv(time,death) ~ x1+x2+x3,data=survivldata)###计算出的C-index

###############################
#### Bootstrap code ###
###############################
bootit=200
for(i in 1:bootit){
case=noNA[group==&amp;quot;long&amp;quot;,] 
control=noNA[group==&amp;quot;&amp;lt;24&amp;quot;,]
bootindex.case=sample(1:nrow(case),replace=T)
boot.case.data=case[bootindex.case,]
bootindex.control=sample(1:nrow(control),replace=T)
boot.control.data=control[bootindex.control,]
boot.data=rbind(boot.case.data,boot.control.data)
dstr.boot=svydesign(id=~1, prob=~inv_weight, fpc=~ssize, data=boot.data)
boot.fit=svycoxph(Surv(survival,surv_cens) ~x1+x2+x3,data=boot.data,x=TRUE,design=dstr.boot)
cindex.train=1-rcorr.cens(lp.boot,Surv(boot.data$survival, boot.data$surv_cens))[[1]]
cindex.test=1-rcorr.cens(lp_=.test,Surv(noNA$survival,noNA$surv_cens))[[1]]
bias=rep(1,bootit)
bias[i]=abs(cindex.train-cindex.test) }
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;参考文献&#34;&gt;参考文献&lt;/h1&gt;

&lt;p&gt;Harrell FE, Califf RM, Pryor DB, Lee KL, and Rosati RA. (1982) Evaluating the yield of medical tests. The Journal of the American Medical Association, 247(18), 2543–2546&lt;/p&gt;

&lt;p&gt;Pencina MJ and D’Agostino RB. (2004) Overall C as a measure of discrimination in survival analysis: model specific population value and confidence interval estimation. Statistics in Medicine, 23(13), 2109–2123&lt;/p&gt;

&lt;p&gt;Kang L, Chen W, Petrick NA, and Gallas BD. (2014) Comparing two correlated C indices with right-censored survival outcome: a one-shot nonparametric approach. Statistics in Medicine, 34(4), 685–703, doi: 10.1002/sim.6370&lt;/p&gt;

&lt;p&gt;Hmisc Reference manual：&lt;a href=&#34;http://cran.r-project.org/web/packages/Hmisc/Hmisc.pdf&#34;&gt;http://cran.r-project.org/web/packages/Hmisc/Hmisc.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;compareC Reference manual: &lt;a href=&#34;http://cran.r-project.org/web/packages/compareC/compareC.pdf&#34;&gt;http://cran.r-project.org/web/packages/compareC/compareC.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Frank.Harrell :&lt;a href=&#34;http://biostat.mc.vanderbilt.edu/wiki/Main/FrankHarrell&#34;&gt;http://biostat.mc.vanderbilt.edu/wiki/Main/FrankHarrell&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;5-ways-to-estimate-concordance-index-for-cox-models-in-r&#34;&gt;5 Ways to Estimate Concordance Index for Cox Models in R&lt;/h1&gt;

&lt;p&gt;Why Results Aren&amp;rsquo;t Identical?&lt;/p&gt;

&lt;p&gt;Harrell&amp;rsquo;s concordance index (c-index) can be used to evaluate the discriminatory power and the predictive accuracy of Cox models. An easy way out as a surrogate for ROC analysis.&lt;/p&gt;

&lt;h2 id=&#34;approach-1&#34;&gt;Approach 1&lt;/h2&gt;

&lt;p&gt;Use function &amp;ldquo;rcorrcens&amp;rdquo; in package &amp;ldquo;Hmisc&amp;rdquo;&lt;/p&gt;

&lt;p&gt;Limitations:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Can only handle un-censored data&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Roughly handle categorical predictor with more than 2 categories&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;Sample code:
library(survival)
library(Hmisc)
attach(sample.data)
surv &amp;lt;- Surv(survival, censor)
rcorrcens(surv ~ group)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;approach-2&#34;&gt;Approach 2&lt;/h2&gt;

&lt;p&gt;Direct output from coxph
Require higher version of R, say R 2.15, didn&amp;rsquo;t test with older versions&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Sample code:
library(survival)
attach(sample.data)
surv &amp;lt;- Surv(survival, censor)
sum.surv &amp;lt;- summary(coxph(surv ~ group))
c_index &amp;lt;- sum.surv$concordance
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;approach-3&#34;&gt;Approach 3&lt;/h2&gt;

&lt;p&gt;Use function &amp;ldquo;survConcordance&amp;rdquo;
Result is the same as in Approach 2&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Sample code:
library(survival)
attach(sample.data)
surv &amp;lt;- Surv(survival, censor)
fit &amp;lt;- coxph( surv ~ group)
survConcordance(surv ~ predict(fit))
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;approach-4&#34;&gt;Approach 4&lt;/h2&gt;

&lt;p&gt;Use package &amp;ldquo;survcomp&amp;rdquo; in bioconductor&lt;/p&gt;

&lt;p&gt;Different result from Approach &lt;sup&gt;2&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt;&lt;/p&gt;

&lt;p&gt;The disparity is due to two different estimation approaches that are used to handle tied risks (i.e. cases when  two observations have the same survival with the same x). The method that approaches &lt;sup&gt;4&lt;/sup&gt;&amp;frasl;&lt;sub&gt;5&lt;/sub&gt; use ignores the tied risks,  the other method (approaches &lt;sup&gt;2&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt;) takes into consideration of the tied risks. In terms of formulation/symbol (for illustration only):&lt;/p&gt;

&lt;p&gt;Approaches &lt;sup&gt;4&lt;/sup&gt;&amp;frasl;&lt;sub&gt;5&lt;/sub&gt; used:&lt;/p&gt;

&lt;p&gt;Concordance = #all concordant pairs/#total pairs ignoring ties.&lt;/p&gt;

&lt;p&gt;Approaches &lt;sup&gt;2&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt; used:&lt;/p&gt;

&lt;p&gt;Concordance = (#all concordant pairs + #tied pairs/2)/(#total pairs including ties).
Those #s can be obtained in the output of Approach 3.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Sample code:
source(&amp;quot;http://bioconductor.org/biocLite.R&amp;quot;)
biocLite(&amp;quot;survcomp&amp;quot;)
library(survcomp)
surv &amp;lt;- Surv(survival, censor) 
fit &amp;lt;- coxph(surv ~ group, data= sample.data)
coxPredict &amp;lt;- predict(fit, data=sample.data, type=&amp;quot;risk&amp;quot;)  
concordance.index(x=coxPredict, surv.time=survival, surv.event=censor, method=&amp;quot;noether&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;approach-5&#34;&gt;Approach 5&lt;/h2&gt;

&lt;p&gt;Use function &amp;ldquo;cph&amp;rdquo; in package &amp;ldquo;rms&amp;rdquo;
Provide both un-adjusted and bias adjusted c-index
Un-adjusted c-index is the same as the one from Approach 4&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Sample code: 
library(rms)
surv &amp;lt;- Surv(survival, censor) 
set.seed(1)
fit.cph &amp;lt;- cph(surv ~ group, data= sample.data, x=TRUE, y=TRUE, surv=TRUE)
  
# Get the Dxy
v &amp;lt;- validate.cph(fit.cph, dxy=TRUE, B=1000)
Dxy = v[rownames(v)==&amp;quot;Dxy&amp;quot;, colnames(v)==&amp;quot;index.corrected&amp;quot;]
orig_Dxy = v[rownames(v)==&amp;quot;Dxy&amp;quot;, colnames(v)==&amp;quot;index.orig&amp;quot;]
# The c-statistic according to Dxy=2(c-0.5)
bias_corrected_c_index  &amp;lt;- abs(Dxy)/2+0.5
orig_c_index &amp;lt;- abs(Orig.Dxy)/2+0.5
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;combining-approaches-2-3-4-5-and-calculate-p-value-for-testing-two-c-indices-for-both-estimation-methods&#34;&gt;Combining Approaches &lt;sup&gt;2&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt; &amp;amp; &lt;sup&gt;4&lt;/sup&gt;&amp;frasl;&lt;sub&gt;5&lt;/sub&gt; and Calculate p-value for Testing Two C-indices for Both Estimation Methods&lt;/h2&gt;

&lt;p&gt;Did not find it elsewhere online. Hope someone could find this helpful.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Sample code:
surv &amp;lt;- Surv(survival, censor)
c_index &amp;lt;- function(group, ties=TRUE){
  fit &amp;lt;- coxph(surv ~ group, data=sample.data)
  coxPredict &amp;lt;- predict(fit, data=sample.data, type=&amp;quot;risk&amp;quot;)  
  
  # Approaches 4/5
  if (ties==F) {
  concordance.index(x=coxPredict, surv.time=survival, surv.event=censor, method=&amp;quot;noether&amp;quot;)
  }
  # Approaches 2/3
  else if (ties==T) {
  survConcordance(surv ~ coxPredict, data=sample.data)
  }
}
c_index_ties1 &amp;lt;- c_index(group=group1, ties=TRUE)
c_index_ties2 &amp;lt;- c_index(group=group2, ties=TRUE)

c_index_no_ties1 &amp;lt;- c_index_ties(group=group1, ties=F)
c_index_no_ties2 &amp;lt;- c_index_ties(group=group2, ties=F)

# p-value of testing two c-indices ignoring ties
round(cindex.comp(c_index_no_ties1, c_index_no_ties2)$p.value,3)

# Function for p-value of testing two c-indices accounting for ties
# t-test for dependent variables is used for significance 
# Input variables are objects obtained from the first function

cindex.p.ties &amp;lt;- function(c_index_ties1, c_index_ties2, c_index_no_ties1, c_index_no_ties2) {
    eps &amp;lt;- 1E-15
    n &amp;lt;- c_index_no_ties1$n
    r &amp;lt;- cor(c_index_no_ties1$data$x, c_index_no_ties2$data$x, use=&amp;quot;complete.obs&amp;quot;, method=&amp;quot;spearman&amp;quot;)
    if ((1 - abs(r)) &amp;gt; eps) {
      t.stat &amp;lt;- (c_index_ties1$concordance - c_index_ties2$concordance) / sqrt(c_index_ties1$std.err^2 + c_index_ties2$std.err^2 - 2 * r * c_index_ties1$std.err * c_index_ties2$std.err)
      diff.ci.p &amp;lt;- pt(q=t.stat, df=n - 1, lower.tail=FALSE)
    } else { diff.ci.p &amp;lt;- 1 }
    return(list(&amp;quot;p.value&amp;quot;=diff.ci.p))
  }
cindex.p.ties(c_index_ties1=c_index_ties1, c_index_ties2=c_index_ties2, c_index_no_ties1=c_index_no_ties1, c_index_no_ties2=c_index_no_ties2)
&lt;/code&gt;&lt;/pre&gt;

        
      </description>
    </item>
    
    <item>
      <title>R统计分析 </title>
      <link>/blog/cn/2017/10/r_statistics/</link>
      <pubDate>Fri, 13 Oct 2017 11:12:29 +0000</pubDate>
      
      <guid>/blog/cn/2017/10/r_statistics/</guid>
      <description>
        

&lt;script type=&#34;text/javascript&#34; src=&#34;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&#34;&gt;&lt;/script&gt;

&lt;h1 id=&#34;概率分布&#34;&gt;概率分布&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/R_probility.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;样本抽样&#34;&gt;样本抽样&lt;/h1&gt;

&lt;h4 id=&#34;1-简单随机抽样&#34;&gt;1. 简单随机抽样&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;sample(x,size,replace=FALSE,
       prob #数据被抽取的权重值)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;2-按权重的样本抽样&#34;&gt;2. 按权重的样本抽样&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;sample(1:10,5,replace=TRUE,prob=1:10)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;3-分层随机抽样&#34;&gt;3. 分层随机抽样&lt;/h4&gt;

&lt;p&gt;例如：男性占20%，女性占80%，如果通过抽样来统计组群的平均身高，性别不同会对统计结果有直接影响，因此可以根据男女性别比例采用分层抽样。&lt;/p&gt;

&lt;p&gt;分层抽样的好处是可以根据每层分别抽样不同数量的样本&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;strata(data, stratanames=NULL, size, method=c(&amp;quot;srswor&amp;quot;,&amp;quot;srswr&amp;quot;,&amp;quot;poisson&amp;quot;,
&amp;quot;systematic&amp;quot;), pik,description=FALSE)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;library(&amp;quot;sampling&amp;quot;)
x= strata(data=iris,c(&amp;quot;Species&amp;quot;),size=c(3,3,5),method=&amp;quot;srswor&amp;quot;)
getdata(iris,x)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;4-系统抽样&#34;&gt;4. 系统抽样&lt;/h4&gt;

&lt;p&gt;例如：要对从全天经过某一路口的车辆号牌进行抽样调查，如果采用简单随机抽样，早、晚高峰的经过的车辆会被过多抽取。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;系统抽样：&lt;/strong&gt;将样本总体从1~N编号，然后随机确定抽样起点，以固定间隔k=N/n进行等间隔抽样。因此如果整体数据呈现有序排列形式，系统抽样会获得更好的结果，但是周期数据将会导致偏向性。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;library(&amp;quot;doBy&amp;quot;)
sampleBy(~1,frac=.3,data=x,systematic=TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;列联表&#34;&gt;列联表&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;列联表：&lt;/strong&gt;以表格形式记录分类变量的频数。卡方独立性检验考察变量之间是否存在依存关系。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&amp;ndash;&lt;/th&gt;
&lt;th&gt;预测-垃圾邮件&lt;/th&gt;
&lt;th&gt;预测-非垃圾邮件&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;实际-垃圾邮件&lt;/td&gt;
&lt;td&gt;a&lt;/td&gt;
&lt;td&gt;b&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;实际-非垃圾邮件&lt;/td&gt;
&lt;td&gt;c&lt;/td&gt;
&lt;td&gt;d&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&#34;创建列联表&#34;&gt;创建列联表&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;d=data.frame(x=c(&amp;quot;1&amp;quot;,&amp;quot;2&amp;quot;,&amp;quot;2&amp;quot;,&amp;quot;1&amp;quot;)),
             y=c(&amp;quot;A&amp;quot;,&amp;quot;B&amp;quot;,&amp;quot;A&amp;quot;,&amp;quot;B&amp;quot;),
             num=c(3,5,8,7)
xt=xtabs(num ~ x + y,data=d)

##边际量
margin.table(xt) 
margin.table(xt,1)#行
margin.table(xt,2)#列
##边际百分比
prop.table(xt)
prop.table(xt,1)#行
prop.table(xt,2)#列
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;独立性检验&#34;&gt;独立性检验&lt;/h1&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&amp;ndash;&lt;/th&gt;
&lt;th&gt;A-TRUE&lt;/th&gt;
&lt;th&gt;A-FALSE&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;B-TURE&lt;/td&gt;
&lt;td&gt;a&lt;/td&gt;
&lt;td&gt;b&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;B-FALSE&lt;/td&gt;
&lt;td&gt;c&lt;/td&gt;
&lt;td&gt;d&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;假设A 与 B 独立，则P(AB)=P(A)*P(B).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. 卡方检验&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;对两个变量的独立性进行检验，统计量如下：&lt;/p&gt;

&lt;p&gt;$$\sum_{i=1}^{r}\sum_{j=1}^{c}\frac{(O_{ij}-E_{ij})^2}{E_{ij}} \backsim {\chi}^2(r-1)(c-1)$$&lt;/p&gt;

&lt;p&gt;其中，\(O_{ij}\)为列联表中（i,j）的记录值，\(E_{ij}=N * P(i)* P(j)\)为两变量相互独立时单元的期望值。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;MASS&amp;quot;)
data(survey)
xtabs(~Sex + Exer,data=survey)##性别和运动的列联表
##              Exer
##Sex      Freq None Some
##Female   49   11   58
##Male     65   13   40

chisq.test(xtabs(~Sex + Exer,data=survey))
##  Pearson&#39;s Chi-squared test
##data:  xtabs(~Sex + Exer, data = survey)
##X-squared = 5.7184, df = 2, p-value = 0.05731
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果：p值不具有显著性，因此不能推翻原假设H0（性别与运动独立），接受H0(原假设不是小概率事件).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/pvalue1.jpg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/pvalue2.jpg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/pvalue3.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. Fisher检验&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;针对列联表中样本数量较少，或者样本分布过分倾向某个单元，卡方检验的结果可能不准确。chisq.test()进行检验会显示警告信息。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;xtabs(~W.Hnd + Clap,data=survey)
##       Clap
##W.Hnd   Left Neither Right
##Left     9       5     4
##Right   29      45   143
chisq.test(xtabs(~W.Hnd + Clap,data=survey))
##  Pearson&#39;s Chi-squared test
##data:  xtabs(~W.Hnd + Clap, data = survey)
##X-squared = 19.252, df = 2, p-value = 6.598e-05

##Warning message:
##In chisq.test(xtabs(~W.Hnd + Clap, data = survey)) :
##  Chi-squared近似算法有可能不准

fisher.test(xtabs(~W.Hnd + Clap,data=survey))
##  Fisher&#39;s Exact Test for Count Data

##data:  xtabs(~W.Hnd + Clap, data = survey)
##p-value = 0.0001413
##alternative hypothesis: two.sided
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果：显示P值具有显著性，推翻原假设【用于写字的手与鼓掌时放在上面的手独立】（原假设为小概率事件），接受两者之间有关系。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3. McNemar检验&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;McNemar检验检验事件发生前后被调查者的反应变化，比如推行罚款政策后系安全带人数的变化。在事件之前进行问卷调查Test1,事件发生之后问卷调查Test2.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&amp;ndash;&lt;/th&gt;
&lt;th&gt;Test 2-TRUE&lt;/th&gt;
&lt;th&gt;Test 2-FALSE&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Test 1&lt;/td&gt;
&lt;td&gt;a&lt;/td&gt;
&lt;td&gt;b&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Test 1&lt;/td&gt;
&lt;td&gt;c&lt;/td&gt;
&lt;td&gt;d&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;假设事件发生前后参与调查的人数未发生变化，a+b=a+c。只要检验b=c是否成立，即可知道事件发生前后人们心理趋向是否发生变化。若b=c成立，则b服从二项分布。&lt;/p&gt;

&lt;p&gt;$$b \backsim B(b+c,\frac{1}{2})$$&lt;/p&gt;

&lt;p&gt;二项分布B(n,p)中当n (列联表中b+c)较大时，可以近视视作正态分布。&lt;/p&gt;

&lt;p&gt;$$b \backsim N(\frac{b+c}{2},\frac{b+c}{4})$$&lt;/p&gt;

&lt;p&gt;将b标准化，使之服从N(0,1),并用连续校正，得到&lt;/p&gt;

&lt;p&gt;$$\frac{(|b-c|-1)^2}{b+c} \backsim \chi^2(1)$$&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;performance=matrix(c(794,86,150,570),nrow=2,dimnames=list(
                          &amp;quot;1st survey&amp;quot;=c(&amp;quot;Approve&amp;quot;,&amp;quot;Disapprove&amp;quot;),
                          &amp;quot;2st survey&amp;quot;=c(&amp;quot;Approve&amp;quot;,&amp;quot;Disapprove&amp;quot;)))
                          
mcnemar.test(performance)

##  McNemar&#39;s Chi-squared test with continuity correction
##data:  performance
##McNemar&#39;s chi-squared = 16.818, df = 1, p-value = 4.115e-05
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果：P值结果具有显著性，原假设为小概率事件，推翻原假设，事件发生前后，&amp;rdquo;Approve&amp;rdquo;和&amp;rdquo;Disapprove&amp;rdquo;比率发生变化。&lt;/p&gt;

&lt;h1 id=&#34;拟合优度检验&#34;&gt;拟合优度检验&lt;/h1&gt;

&lt;p&gt;统计分析中，常常假设数据服从某种分布，特别是数据量超过一定数值时，一般假设数据服从正态分布。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. 卡方检验&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;为了验证数据是否服从某种特定分布，通常先要创建列联表。&lt;/p&gt;

&lt;p&gt;例如：分析用左手写字的人数与用右手写字的人数比率是否为30%：70%。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;library(&amp;quot;MASS&amp;quot;)
data(survey)
table(survey$W.Hnd)
chisq.test(table(survey$W.Hnd),p=c(0.3,0.7))

#Chi-squared test for given probabilities
#data:  table(survey$W.Hnd)
#X-squared = 56.252, df = 1, p-value = 6.376e-14
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果：p值显著，原假设为小概率事件，拒绝原假设，左手写字的人数与用右手写字的人数比率为30%：70%不成立。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. Shapiro-Wilk（夏皮罗-威尔克）检验&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Shapiro-Wilk用于检验样本是否来源于正态分布的总体&lt;/strong&gt;（样本是否从正态分布的数据中抽取的）。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; shapiro.test(rnorm(1000))
##  Shapiro-Wilk normality test
##data:  rnorm(1000)
##W = 0.99883, p-value = 0.7749
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果：p值不显著，原假设不为小概率事件，接受原假设，肯定样本来源于正态分布整体。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3. Kolmogorov-smirnov test（柯尔莫哥-斯米诺夫 K-S）检验&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;将数据的累积分布函数与要比较的分布的累积分布函数之间的&lt;strong&gt;最大距离&lt;/strong&gt;作为统计量。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/KS_test.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;例如： 检验两组正态分布的随机数据之间是否拥有相同的分布。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ks.test(rnorm(100),rnorm(100))

#   Two-sample Kolmogorov-Smirnov test
#data:  rnorm(100) and rnorm(100)
#D = 0.1, p-value = 0.6994
#alternative hypothesis: two-sided
##p值不显著，原假设不为小概率事件，接受原假设，两组样本具有相同分布。

ks.test(rnorm(100),runif(100))
#   Two-sample Kolmogorov-Smirnov test
#data:  rnorm(100) and runif(100)
#D = 0.54, p-value = 4.335e-13
#alternative hypothesis: two-sided
##p值显著，原假设为小概率事件，拒绝原假设，两组样本不具有相同分布。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;4. Q-Q（Quantile-Quantile）图&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q-Q图&lt;/strong&gt;是一种检验数据是否服从某种特定分布的可视化方法。&lt;/p&gt;

&lt;p&gt;例如：要检验X是否服从正态分布。若\(X \backsim N(\mu,\delta^2)\),则&lt;/p&gt;

&lt;p&gt;$$Z=\frac{X-\mu}{\delta} \backsim N(0,1)$$&lt;/p&gt;

&lt;p&gt;$$X=\mu + \delta Z$$&lt;/p&gt;

&lt;p&gt;若将(X,Z)绘制到坐标平面，则为一条直线。X是待检验的已知数据，Z为标准正态分布数据，因此找到与X对应的Z即可，可以通过分位数完成。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x=rnorm(1000,mean=10,sd=1)
qqnorm(x)
qqline(x,lty=2)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/Q-Qplot1.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x=runif(1000)
qqnorm(x)
qqline(x,lty=2)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;相关分析&#34;&gt;相关分析&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;1.Pearson（皮尔逊）相关系数&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/Pearsoncorrelation.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;当两个变量的标准差都不为零时，相关系数才有定义，皮尔逊相关系数适用于：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;两个变量之间是线性关系，都是连续数据。&lt;/li&gt;
&lt;li&gt;两个变量的总体是正态分布，或接近正态的单峰分布。&lt;/li&gt;
&lt;li&gt;两个变量的观测值是成对的，每对观测值之间相互独立。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;2.Spearman Rank(斯皮尔曼等级)相关系数&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;斯皮尔曼等级相关系数用来估计两个变量X、Y之间的相关性，其中变量间的相关性可以使用单调函数来描述。如果两个变量取值的两个集合中均不存在相同的两个元素，那么，当其中一个变量可以表示为另一个变量的很好的单调函数时（即两个变量的变化趋势相同），两个变量之间的ρ可以达到+1或-1。&lt;/p&gt;

&lt;p&gt;假设两个随机变量分别为X、Y（也可以看做两个集合），它们的元素个数均为N，两个随机变量取的第i（1&amp;lt;=i&amp;lt;=N）个值分别用Xi、Yi表示。对X、Y进行排序（同时为升序或降序），得到两个元素排行集合x、y，其中元素xi、yi分别为Xi在X中的排行以及Yi在Y中的排行。将集合x、y中的元素对应相减得到一个排行差分集合d，其中di=xi-yi，1&amp;lt;=i&amp;lt;=N。随机变量X、Y之间的斯皮尔曼等级相关系数可以由x、y或者d计算得到，其计算方式如下所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/SpearmanRank1.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/SpearmanRank2.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.Kendall Rank（肯德尔等级）相关系数&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;xxx&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4.相关系数检验&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;*原假设：相关系数为0&lt;/p&gt;

&lt;p&gt;*备选假设： 相关系数不为0.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;cor(iris$Sepal.Width,iris$Sepal.Length)
cor(iris[,1:4])
library(corrgram)#可视化显示相关系数
corrgram(iris,upper.panel=panel.conf)

m=matrix(c(1:10),(1:10)^2),ncol=2))
cor(m,method=&amp;quot;spearman&amp;quot;)

cor.test(c(1,2,3,4,5),c(1,0,3,4,5),method=&amp;quot;pearson&amp;quot;)
cor.test(c(1,2,3,4,5),c(1,0,3,4,5),method=&amp;quot;spearman&amp;quot;)
cor.test(c(1,2,3,4,5),c(1,0,3,4,5),method=&amp;quot;kendall&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;估计与检验&#34;&gt;估计与检验&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;1.单样本均值&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;$$\frac{\overline{X}-\mu}{S/\sqrt{n}} \backsim t(n-1)$$&lt;/p&gt;

&lt;p&gt;显著性水平为a时，关于整体均值的95%置信水平的置信区间为：&lt;/p&gt;

&lt;p&gt;$$(\overline{X} - t(n-1;\alpha/2) * S/\sqrt{n},\overline{X} + t(n-1;\alpha/2) * S/\sqrt{n}$$&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/t_test.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;零假设&lt;/strong&gt;：整体均值为mu.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x=rnorm(30)
t.test(x)
t.test(x,mu=0)
##  One Sample t-test
##data:  x
##t = 0.052695, df = 29, p-value = 0.9583
##alternative hypothesis: true mean is not equal to 0
##95 percent confidence interval:
## -0.3502195  0.3687436
##sample estimates:
##  mean of x 
##0.009262058 

y=rnorm(30,mean=10)
t.test(y)
t.test(y,mu=10)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果： 推断整体均值为0.009262058，总体均值95%置信区间为（-0.3502195,  0.3687436）。p值不显著，不能拒绝0假设，总体均值可以被视为0，0也在95%置信区间内。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2.两独立样本均值&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;从两个总体分别抽取样本，根据样本推断两个整体均值是否一致。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/twosample_test1.jpg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/twosample_test2.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sleep2=sleep[,-3]
tapply(sleep2$extra,sleep2$group,mean)
var.test(extra ~ group,data = sleep2)##首先检验两组样本方差是否一致

##F test to compare two variances
##data:  extra by group
##F = 0.79834, num df = 9, denom df = 9, p-value = 0.7427
##alternative hypothesis: true ratio of variances is not equal to 1
##95 percent confidence interval:
##  0.198297 3.214123
##sample estimates:
##  ratio of variances 
##0.7983426 
## 原假设：两者方差无差别。因此不能拒绝原假设。

t.test(extra ~ group,data = sleep2,paired=FALSE,var.equal=TRUE)
##Two Sample t-test
##data:  extra by group
##t = -1.8608, df = 18, p-value = 0.07919
##alternative hypothesis: true difference in means is not equal to 0
##95 percent confidence interval:
##  -3.363874  0.203874
##sample estimates:
##  mean in group 1 mean in group 2 
##0.75            2.33 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;t.test中paired=FALSE表示两独立样本检验,TRUE表示配对样本检验，var.equal=TRUE表示两样本方差一致。&lt;/p&gt;

&lt;p&gt;结果：P值不显著，不能推翻原假设，因此可以认为两组总体均值无差异。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.两配对样本均值&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/twosample_test3.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;t.test(extra ~ group,data = sleep2,paired=TRUE,var.equal=TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果：P值显著，推翻原假设，服用两种安眠药后睡眠时间增加程度不同。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4.两样本方差&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;评估两独立总体的方差是否一致。两样本方差检验一般不独立使用，常配合其他检验使用，如在两独立样本检验中，如果两检验两总体方差一致，则将t.test()的var.equal设置为TRUE.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/twosample_test4.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/twosample_test5.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;5.单样本比率&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;5.两 样本比率&lt;/strong&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Logistic回归</title>
      <link>/blog/cn/2017/10/logistic/</link>
      <pubDate>Thu, 12 Oct 2017 21:06:48 +0000</pubDate>
      
      <guid>/blog/cn/2017/10/logistic/</guid>
      <description>
        

&lt;script type=&#34;text/javascript&#34; src=&#34;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&#34;&gt;&lt;/script&gt;

&lt;p&gt;原文 &lt;a href=&#34;http://blog.csdn.net/ariessurfer/article/details/41310525&#34;&gt;http://blog.csdn.net/ariessurfer/article/details/41310525&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Logistic回归为概率型非线性回归模型，是研究二分类观察结果 Y 与一些影响因素(x1,x2,..,xn)之间关系的一种多变量分析方法。通常的问题是，研究某些因素条件下某个结果是否发生，比如医学中根据病人的一些症状来判断它是否患有某种病。&lt;/p&gt;

&lt;h1 id=&#34;lr分类器-logistic-regression-classifier&#34;&gt;LR分类器: Logistic Regression Classifier&lt;/h1&gt;

&lt;p&gt;在分类情形下，经过学习后的LR分类器是一组权值\(W=(w_0,w_1,&amp;hellip;,w_n)\)，当测试样本的数据输入时，这组权值与测试数据按照线性加和得到:&lt;/p&gt;

&lt;p&gt;$$x=w_0+ w_1x_1+&amp;hellip;+w_nx_n$$&lt;/p&gt;

&lt;p&gt;之后按照&lt;strong&gt;Logistic(sigmoid函数)&lt;/strong&gt;的形式求出&lt;/p&gt;

&lt;p&gt;$$f(x)=\frac{1}{1+e^x}$$&lt;/p&gt;

&lt;p&gt;由于Logistic函数的定义域为(-inf,inf)，值域为(0,1)，因此最基本的LR分类器适合对两类目标进行分类。所以Logistic回归最关键的问题就是研究如何求得权值\(W=(w_0,w_1,&amp;hellip;,w_n)\)。用极大似然估计。&lt;/p&gt;

&lt;h1 id=&#34;logistic回归模型&#34;&gt;Logistic回归模型&lt;/h1&gt;

&lt;p&gt;Logistic回归模型可以表示为&lt;/p&gt;

&lt;p&gt;考虑具有个独立变量的向量\(X=(x_0,x_1,&amp;hellip;,x_n)\)，&lt;/p&gt;

&lt;p&gt;(1)在变量X条件下某事件发生的概率p为：&lt;/p&gt;

&lt;p&gt;$$P(y=1|x)=\pi(x)=\frac{1}{1+e^{-g(x)}}$$&lt;/p&gt;

&lt;p&gt;其中\(g(x)=w_0+ w_1x_1+&amp;hellip;+w_nx_n\)&lt;/p&gt;

&lt;p&gt;(2)在变量X条件下不发生的概率1-p为:&lt;/p&gt;

&lt;p&gt;$$P(y=0|x)=1-P(y=1|x)= 1-\frac{1}{1+e^{-g(x)}} =\frac{1}{1+e^{g(x)}} $$&lt;/p&gt;

&lt;p&gt;(3)事件的发生比（the odds of experiencing an event）:事件发生与不发生的概率之比odds&lt;/p&gt;

&lt;p&gt;$$\frac{P(y=1|x)}{P(y=0|x)}=\frac{p}{1-p} =e^{g(x)}$$&lt;/p&gt;

&lt;p&gt;$$ln(\frac{p}{1-p})=g(x)=w_0+ w_1x_1+&amp;hellip;+w_nx_n$$&lt;/p&gt;

&lt;h1 id=&#34;logistic回归极大似然估计&#34;&gt;Logistic回归极大似然估计&lt;/h1&gt;

&lt;p&gt;假设有m个观测样本\(X=(x_0,x_1,&amp;hellip;,x_m)\)，观测值分别为\(Y=(y_0,y_1,&amp;hellip;,y_m)\)，设给定条件下时间发生的概率\(p_i=P(y_i=1|x_i)\)，时间不发生的概率为\(P(y_i=0|x_i)=1-p_i\)。所以得到一个观测值的概率为&lt;/p&gt;

&lt;p&gt;$$P(y_i)=p_i^{y_i}(1-p_i)^{1-y_i}$$&lt;/p&gt;

&lt;p&gt;因为各个观测样本之间相互独立，整体事件发生的概率为各边缘分布的乘积，得到似然函数为&lt;/p&gt;

&lt;p&gt;$$L(w)=\prod_{i=1}^{m}=\{\pi(x_i)\}^{y_i}\{1-\pi(x_i)\}^{1-y_i} $$&lt;/p&gt;

&lt;p&gt;然后用极大似然估计求得权值\(W=(w_0,w_1,&amp;hellip;,w_n)\)的估计。&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>R语言-线性回归-lm()</title>
      <link>/blog/cn/2017/09/r_function_regression/</link>
      <pubDate>Fri, 22 Sep 2017 21:10:14 +0000</pubDate>
      
      <guid>/blog/cn/2017/09/r_function_regression/</guid>
      <description>
        

&lt;script type=&#34;text/javascript&#34; src=&#34;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&#34;&gt;&lt;/script&gt;

&lt;p&gt;From &lt;a href=&#34;http://blog.sina.com.cn/s/blog_6fbfcfb50102va2k.html&#34;&gt;http://blog.sina.com.cn/s/blog_6fbfcfb50102va2k.html&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;1-回归的多面性&#34;&gt;1. 回归的多面性&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;回归类型    用途
---
简单线性    个量化的解释变量来预测一个量化的响应变量（一个因变量、一个自变量）
多项式   一个量化的解释变量预测一个量化的响应变量，模型的关系是n阶多项式（一个预测变量，但同时包含变量的幂）
多元线性    用两个或多个量化的解释变量预测一个量化的响应变量（不止一个预测变量）
多变量     用一个或多个解释变量预测多个响应变量
Logistic    用一个或多个解释变量预测一个类别型变量
泊松      用一个或多个解释变量预测一个代表频数的响应变量
Cox         用一个或多个解释变量预测一个事件（死亡、失败或旧病复发）发生的时间
时间序列  对误差项相关的时间序列数据建模
非线性   用一个或多个量化的解释变量预测一个量化的响应变量，不过模型是非线性的
非参数   用一个或多个量化的解释变量预测一个量化的响应变量，模型的形式源自数据形式，不事先设定
稳健      用一个或多个量化的解释变量预测一个量化的响应变量，能抵御强影响点的干扰
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;2-用lm-拟合回归模型&#34;&gt;2. 用lm()拟合回归模型&lt;/h1&gt;

&lt;p&gt;myfit&amp;lt;-lm(formula,data)&lt;/p&gt;

&lt;p&gt;formula指要拟合的模型形式，data是一个数据框，包含了用于拟合模型的数据。&lt;/p&gt;

&lt;p&gt;formula形式如下：Y~X1+X2+……+Xk （~左边为响应变量，右边为各个预测变量，预测变量之间用+符号分隔）。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;R表达式中常用的符号&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;符号 用途
---
~  | 分隔符号，左边为响应变量，右边为解释变量，eg：要通过x、z和w预测y，代码为y~x+z+w
+  | 分隔预测变量
： | 表示预测变量的交互项  eg：要通过x、z及x与z的交互项预测y，代码为y~x+z+x:z
*  | 表示所有可能交互项的简洁方式，代码y~x*z*w可展开为y~x+z+w+x:z+x:w+z:w+x:z:w
^  | 表示交互项达到某个次数，代码y~(x+z+w)^2可展开为y~x+z+w+x:z+x:w+z:w
.  | 表示包含除因变量外的所有变量，eg：若一个数据框包含变量x、y、z和w，代码y~.可展开为y~x+z+w
-  | 减号，表示从等式中移除某个变量，eg：y~(x+z+w)^2-x:w可展开为y~x+z+w+x:z+z:w
-1 | 删除截距项，eg：表示y~x-1拟合y在x上的回归，并强制直线通过原点
I（） | 从算术的角度来解释括号中的元素。Eg：y~x+(z+w)^2将展开为y~x+z+w+z:w。相反，代码y~x+I((z+w)^2)将展开为y~x+h，h是一个由z和w的平方和创建的新变量
function | 可以在表达式中用的数学函数，例如log(y)~x+z+w表示通过x、z和w来预测log(y)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;交互项&lt;/strong&gt;是指你的几个变量一块生成了一个新的影响，比如不同性别的不同专业可能会对成绩有不同的影响，性别影响成绩，专业影响成绩，但是性别和专业和在一起又产生新影响。这时候就需要交互项。具体用不用看你的方程,一般不用。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;对拟合线性模型非常有用的其他函数&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;函数 用途
---
Summary（）展示拟合的详细结果
Coefficients（）列出拟合模型的模型参数（截距项和斜率）
confint（） 提供模型参数的置信区间（默认95%）
fitted（）列出拟合模型的预测值
residuals（）列出拟合模型的残差值
anova（）生成一个拟合模型的方差分析，或者比较两个或更多拟合模型的方差分析表
deviance() 计算残差平和和
vcov（）列出模型参数的协方差矩阵
AIC（）输出赤池信息统计量
plot（）生成评价拟合模型的诊断图
predict（）用拟合模型对新的数据集预测响应变量值
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;3-r-语言示例lm&#34;&gt;3. R 语言示例lm()&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;fit&amp;lt;-lm(weight~height,data=women)  
# summary(fit)
# Call:
# lm(formula = weight ~ height, data = women)
# Residuals:
#     Min      1Q  Median      3Q     Max 
# -1.7333 -1.1333 -0.3833  0.7417  3.1167 
# Coefficients:
#              Estimate Std. Error t value Pr(&amp;gt;|t|)    
# (Intercept) -87.51667    5.93694  -14.74 1.71e-09 ***
# height        3.45000    0.09114   37.85 1.09e-14 ***
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# Residual standard error: 1.525 on 13 degrees of freedom
# Multiple R-squared:  0.991,   Adjusted R-squared:  0.9903 
# F-statistic:  1433 on 1 and 13 DF,  p-value: 1.091e-14
coef(fit)
#(Intercept)      height 
#  -87.51667     3.45000 
fitted(fit)#拟合模型的预测值  
residuals(fit)#拟合模型的残差值 
plot(women$height,women$weight,  
     xlab=&amp;quot;Height （in inches）&amp;quot;,  
     ylab=&amp;quot;Weight（in pounds）&amp;quot;)  
abline(fit)  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;1.自变量评估&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在Pr(&amp;gt;|t|)栏，可以看到回归系数（3.45）或者截距项显著性&amp;lt;0.05，拒绝原假设，表明身高每增加1英寸，体重将预期地增加3.45磅.&lt;/p&gt;

&lt;p&gt;*原假设H0：系数（或截距）为0。&lt;/p&gt;

&lt;p&gt;*备选假设H1：系数（或截距）不为0。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2.判定系数和F统计量&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;残差的标准误(Residual standard error)&lt;/strong&gt; 1.53 lbs则可认为模型用身高预测体重的平均误差.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;判定系数R^2&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;$$R^2= \frac{SSR}{SST}=\frac{\sum(\hat{Y_i}-\overline{Y})^2}{\sum(Y_i-\overline{Y})^2} $$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;R^2的取值范围为[0,1],越接近1表示回归模型对数据的解释能力越强。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/lm_R2.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;F统计量&lt;/strong&gt;使用F分布检验MSR/MSE的比率，原假设：β1=0，备选假设：β1≠0. 检验简化模型\(dist=β0+\varepsilon\)与完整模型\(dist=β0+β1*x +\varepsilon\)之间的残差平方和差异的显著程度。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.方差分析&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;线性回归中，&lt;strong&gt;方差分析用于评估模型或者进行模型间比较&lt;/strong&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; m=lm(dist ~ speed, data=cars)
 summary(m)
#  Call:
# lm(formula = dist ~ speed, data = cars)
# Residuals:
#     Min      1Q  Median      3Q     Max 
# -29.069  -9.525  -2.272   9.215  43.201 
# Coefficients:
#             Estimate Std. Error t value Pr(&amp;gt;|t|)    
# (Intercept) -17.5791     6.7584  -2.601   0.0123 *  
# speed         3.9324     0.4155   9.464 1.49e-12 ***
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# Residual standard error: 15.38 on 48 degrees of freedom
# Multiple R-squared:  0.6511,  Adjusted R-squared:  0.6438 
# F-statistic: 89.57 on 1 and 48 DF,  p-value: 1.49e-12

anova(m)
# Analysis of Variance Table
# Response: dist
#           Df Sum Sq Mean Sq F value   Pr(&amp;gt;F)    
# speed      1  21186 21185.5  89.567 1.49e-12 ***
# Residuals 48  11354   236.5                     
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

reduced=lm(dist ~ 1, data=cars)  #没有自变量，仅有截距项的简化模型
anova(reduced,m)
# Analysis of Variance Table
# Model 1: dist ~ 1
# Model 2: dist ~ speed
#   Res.Df   RSS Df Sum of Sq      F   Pr(&amp;gt;F)    
# 1     49 32539                                 
# 2     48 11354  1     21186 89.567 1.49e-12 ***
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以上3组比较F统计量中p值都为1.49e-12。表面简化模型与完整模型之间存在显著差异，换言之，speed是有意义的解释变量。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4.模型诊断图形&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  plot(m,which=c(1:3,5))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/lm_figure.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;第一个图为预测值Y（X轴）与残差（Y轴），在线性回归中，由于假设误差服从均值为0，方差固定的正态分布，所以认为残差分布与预测的Y值无关，残差均值必须为0。斜率为0的直线是理想情形。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;第二个图为正态QQ图，查看标准化的残差是否服从正态分布。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;第三个图为预测值Y（X轴）与标准化残差（Y轴），斜率为0的直线是理想情形。若在特定点观察到距离0较远的值，说明该点不能很好的拟合原始值，这些点肯能成为异常点。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;第四个图为杠杆值（X轴）与标准化残差（Y轴）。杠杆值表示解释变量向极端的偏斜程度。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;分类变量&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;m=lm(Sepal.Length ~ .,data=iris)
 summary(m)

# Call:
# lm(formula = Sepal.Length ~ ., data = iris)
# Residuals:
#      Min       1Q   Median       3Q      Max 
# -0.79424 -0.21874  0.00899  0.20255  0.73103 
# Coefficients:
#                   Estimate Std. Error t value Pr(&amp;gt;|t|)    
# (Intercept)        2.17127    0.27979   7.760 1.43e-12 ***
# Sepal.Width        0.49589    0.08607   5.761 4.87e-08 ***
# Petal.Length       0.82924    0.06853  12.101  &amp;lt; 2e-16 ***
# Petal.Width       -0.31516    0.15120  -2.084  0.03889 *  
# Speciesversicolor -0.72356    0.24017  -3.013  0.00306 ** 
# Speciesvirginica  -1.02350    0.33373  -3.067  0.00258 ** 
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# Residual standard error: 0.3068 on 144 degrees of freedom
# Multiple R-squared:  0.8673,  Adjusted R-squared:  0.8627 
# F-statistic: 188.3 on 5 and 144 DF,  p-value: &amp;lt; 2.2e-16
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中Species为分类变量，有三种类别：setosa,versicolor,virginica.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/lm_species.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;4-多项式回归&#34;&gt;4.多项式回归&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;fit2&amp;lt;-lm(weight~height+I(height^2),data=women)  
summary(fit2)
plot(women$height,women$weight,  
     xlab=&amp;quot;Height（in inches）&amp;quot;,  
     ylab=&amp;quot;Weight（in lbs）&amp;quot;)  
lines(women$height,fitted(fit2)) 

#一般来说，n次多项式生成一个n-1个弯曲的曲线
#car包中的scatterplot（）函数，可以很容易、方便地绘制二元关系图
library(car)
scatterplot(weight~height,  
            data=women,  
            spread=FALSE,  
            lty.smooth=2,  
            pch=19,  
            main=&amp;quot;Women Age 30-39&amp;quot;,  
            xlab=&amp;quot;Height (inches)&amp;quot;,  
            ylab=&amp;quot;Weight(lbs.)&amp;quot;) 
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;6-多元线性回归&#34;&gt;6.多元线性回归&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;states&amp;lt;-as.data.frame(state.x77[,c(&amp;quot;Murder&amp;quot;,&amp;quot;Population&amp;quot;,&amp;quot;Illiteracy&amp;quot;,&amp;quot;Income&amp;quot;,&amp;quot;Frost&amp;quot;)])
cor(states)  
scatterplotMatrix(states,spread=FALSE,lty.smooth=2,main=&amp;quot;Scatter Plot Matrix&amp;quot;)
#scatterplotMatrix（）函数默认在非对角线区域绘制变量间的散点图，并添加平滑（loess）和线性拟合曲线
#多元线性回归
fit&amp;lt;-lm(Murder~Population+Illiteracy+Income+Frost,data=states)  
summary(fit)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对于F统计量，原假设：所有系数β全为0。&lt;/p&gt;

&lt;h1 id=&#34;7-有交互项的多元线性回归&#34;&gt;7.有交互项的多元线性回归&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;fit&amp;lt;-lm(mpg~hp+wt+hp:wt,data=mtcars)  
summary(fit)  
# 通过effects包中的effect（）函数，可以用图形展示交互项的结果
install.packages(&amp;quot;effects&amp;quot;)  
library(effects)  
plot(effect(&amp;quot;hp:wt&amp;quot;,fit,  
            list(wt=c(2.2,3.2,4.2))),multiline=TRUE)
            
# 二次拟合诊断图
fit2&amp;lt;-lm(weight~height+I(height^2),data=women)  
par(mfrow=c(2,2))  
plot(fit2)           
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;I()&lt;/strong&gt;防止对象解析或者转换，例如I(X^2)表示以X^2作为一个独立变量参与到回归，否者则解析为x+x+x:x交互作用。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/lm_interaction.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;异常值&#34;&gt;异常值&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;学生化残差&lt;/strong&gt;： 残差与残差标准差的比值。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;外部学生化残差&lt;/strong&gt;：计算第i个学生化残差时，先去掉i再计算标准差。一般用外部学生化残差评估异常点。&lt;/p&gt;

&lt;p&gt;R中rstudent()计算外部学生化残差。外部学生化残差服从t分布，可以使用t-test来寻找rstudent()值过大或者过小的点。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;m=lm(circumference~ age+I(age^2),data=Orange)
rstudent(m)
car::outlierTest(m)

# No Studentized residuals with Bonferonni p &amp;lt; 0.05
# Largest |rstudent|:
#    rstudent unadjusted p-value Bonferonni p
# 27 2.050328            0.04887           NA

&lt;/code&gt;&lt;/pre&gt;

        
      </description>
    </item>
    
    <item>
      <title>R语言 逐步回归分析</title>
      <link>/blog/cn/2017/09/step_regression/</link>
      <pubDate>Fri, 22 Sep 2017 20:10:14 +0000</pubDate>
      
      <guid>/blog/cn/2017/09/step_regression/</guid>
      <description>
        

&lt;p&gt;From &lt;a href=&#34;http://www.cnblogs.com/liuzezhuang/p/3724497.html&#34;&gt;http://www.cnblogs.com/liuzezhuang/p/3724497.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;逐步回归分析是以AIC信息统计量为准则，通过选择最小的AIC信息统计量，来达到删除或增加变量的目的。&lt;/p&gt;

&lt;p&gt;R语言中用于逐步回归分析的函数 step()    drop1()     add1()&lt;/p&gt;

&lt;h1 id=&#34;1-载入数据&#34;&gt;1.载入数据&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#首先对数据进行多元线性回归分析
tdata&amp;lt;-data.frame(
  x1=c( 7, 1,11,11, 7,11, 3, 1, 2,21, 1,11,10),
  x2=c(26,29,56,31,52,55,71,31,54,47,40,66,68),
  x3=c( 6,15, 8, 8, 6, 9,17,22,18, 4,23, 9, 8),
  x4=c(60,52,20,47,33,22, 6,44,22,26,34,12,12),
  Y =c(78.5,74.3,104.3,87.6,95.9,109.2,102.7,72.5,
       93.1,115.9,83.8,113.3,109.4)
)
tlm&amp;lt;-lm(Y~x1+x2+x3+x4,data=tdata)
summary(tlm)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/AIC1.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;通过观察，回归方程的系数都没有通过显著性检验&lt;/p&gt;

&lt;p&gt;#2.逐步回归分析&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;tstep&amp;lt;-step(tlm)
summary(tstep)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/AIC2.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;结果分析：
* 当用x1 x2 x3 x4作为回归方程的系数时，AIC的值为26.94&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;去掉x3 回归方程的AIC值为24.974；去掉x4 回归方程的AIC值为25.011……&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;由于去x3可以使得AIC达到最小值，因此R会自动去掉x3;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;*去掉x3之后 AIC的值都增加 逐步回归分析终止,  得到当前最优的回归方程&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/AIC3.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;回归系数的显著性水平有所提高 但是x2 x4的显著性水平仍然不理想&lt;/p&gt;

&lt;p&gt;#3.逐步回归分析的优化&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;drop1(tstep)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/AIC4.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;#4.进一步进行多元回归分析&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;tlm&amp;lt;-lm(Y~x1+x2,data=tdata)
summary(tlm)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/AIC5.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;所有的检验均为显著&lt;/p&gt;

&lt;p&gt;因此所得回归方程为&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-math&#34;&gt;y=52.57735+ 1.46831x1+ 0.66225x2.
&lt;/code&gt;&lt;/pre&gt;

        
      </description>
    </item>
    
    <item>
      <title>模型选择准则之AIC和BIC</title>
      <link>/blog/cn/2017/09/aic_bic/</link>
      <pubDate>Fri, 22 Sep 2017 19:47:14 +0000</pubDate>
      
      <guid>/blog/cn/2017/09/aic_bic/</guid>
      <description>
        

&lt;p&gt;转自：&lt;a href=&#34;http://blog.csdn.net/jteng/article/details/40823675&#34;&gt;http://blog.csdn.net/jteng/article/details/40823675&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;很多参数估计问题均采用似然函数作为目标函数，当训练数据足够多时，可以不断提高模型精度，但是以提高模型复杂度为代价的，同时带来一个机器学习中非常普遍的问题——过拟合。所以，模型选择问题在模型复杂度与模型对数据集描述能力（即似然函数）之间寻求最佳平衡。
人们提出许多信息准则，通过加入模型复杂度的惩罚项来避免过拟合问题，此处我们介绍一下常用的两个模型选择方法.&lt;/p&gt;

&lt;h1 id=&#34;赤池信息准则-akaike-information-criterion-aic&#34;&gt;赤池信息准则（Akaike Information Criterion，AIC）&lt;/h1&gt;

&lt;p&gt;AIC是衡量统计模型拟合优良性的一种标准，由日本统计学家赤池弘次在1974年提出，它建立在熵的概念上，提供了权衡估计模型复杂度和拟合数据优良性的标准。
通常情况下，AIC定义为：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-math&#34;&gt;AIC=2k-2ln(L)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中k是模型参数个数，L是似然函数。从一组可供选择的模型中选择最佳模型时，通常选择AIC最小的模型。
当两个模型之间存在较大差异时，差异主要体现在似然函数项，当似然函数差异不显著时，上式第一项，即模型复杂度则起作用，从而参数个数少的模型是较好的选择。
一般而言，当模型复杂度提高（k增大）时，似然函数L也会增大，从而使AIC变小，但是k过大时，似然函数增速减缓，导致AIC增大，模型过于复杂容易造成过拟合现象。&lt;strong&gt;目标是选取AIC最小的模型&lt;/strong&gt;，AIC不仅要提高模型拟合度（极大似然），而且引入了惩罚项，使模型参数尽可能少，有助于降低过拟合的可能性。&lt;/p&gt;

&lt;h1 id=&#34;贝叶斯信息准则-bayesian-information-criterion-bic&#34;&gt;贝叶斯信息准则（Bayesian Information Criterion，BIC）&lt;/h1&gt;

&lt;p&gt;BIC（Bayesian InformationCriterion）贝叶斯信息准则与AIC相似，用于模型选择,&lt;strong&gt;BIC越小，模型越优&lt;/strong&gt;，1978年由Schwarz提出。训练模型时，增加参数数量，也就是增加模型复杂度，会增大似然函数，但是也会导致过拟合现象，针对该问题，AIC和BIC均引入了与模型参数个数相关的惩罚项，BIC的惩罚项比AIC的大，考虑了样本数量，样本数量过多时，可有效防止模型精度过高造成的模型复杂度过高。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-math&#34;&gt;BIC=kln(n)-2ln(L)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中，k为模型参数个数，n为样本数量，L为似然函数。kln(n)惩罚项在维数过大且训练样本数据相对较少的情况下，可以有效避免出现维度灾难现象。&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>常见的机器学习&amp;数据挖掘知识点</title>
      <link>/blog/cn/2017/09/datamining_concept/</link>
      <pubDate>Fri, 22 Sep 2017 16:47:14 +0000</pubDate>
      
      <guid>/blog/cn/2017/09/datamining_concept/</guid>
      <description>
        

&lt;h1 id=&#34;basis-基础&#34;&gt;Basis(基础)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;SSE(Sum of Squared Error, 平方误差和)
SAE(Sum of Absolute Error, 绝对误差和)
SRE(Sum of Relative Error, 相对误差和)
MSE(Mean Squared Error, 均方误差)
RMSE(Root Mean Squared Error, 均方根误差)
RRSE(Root Relative Squared Error, 相对平方根误差)
MAE(Mean Absolute Error, 平均绝对误差)
RAE(Root Absolute Error, 平均绝对误差平方根)
MRSE(Mean Relative Square Error, 相对平均误差)
RRSE(Root Relative Squared Error, 相对平方根误差)
Expectation(期望)&amp;amp;Variance(方差)
Standard Deviation(标准差，也称Root Mean Squared Error, 均方根误差)
CP(Conditional Probability, 条件概率)
JP(Joint Probability, 联合概率)
MP(Marginal Probability, 边缘概率)
Bayesian Formula(贝叶斯公式)
CC(Correlation Coefficient, 相关系数)
Quantile (分位数)
Covariance(协方差矩阵)
GD(Gradient Descent, 梯度下降)
SGD(Stochastic Gradient Descent, 随机梯度下降)
LMS(Least Mean Squared, 最小均方)
LSM(Least Square Methods, 最小二乘法)
NE(Normal Equation, 正规方程)
MLE(Maximum Likelihood Estimation, 极大似然估计)
QP(Quadratic Programming, 二次规划)
L1 /L2 Regularization(L1/L2正则, 以及更多的, 现在比较火的L2.5正则等)
Eigenvalue(特征值)
Eigenvector(特征向量)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;common-distribution-常见分布&#34;&gt;Common Distribution(常见分布)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;Discrete Distribution(离散型分布)：
Bernoulli Distribution/Binomial Distribution(贝努利分布/二项分布)
Negative Binomial Distribution(负二项分布)
Multinomial Distribution(多项分布)
Geometric Distribution(几何分布)
Hypergeometric Distribution(超几何分布)
Poisson Distribution (泊松分布)
Continuous Distribution (连续型分布)：

Uniform Distribution(均匀分布)
Normal Distribution/Gaussian Distribution(正态分布/高斯分布)
Exponential Distribution(指数分布)
Lognormal Distribution(对数正态分布)
Gamma Distribution(Gamma分布)
Beta Distribution(Beta分布)
Dirichlet Distribution(狄利克雷分布)
Rayleigh Distribution(瑞利分布)
Cauchy Distribution(柯西分布)
Weibull Distribution (韦伯分布)
Three Sampling Distribution(三大抽样分布)：

Chi-square Distribution(卡方分布)
t-distribution(t-分布)
F-distribution(F-分布)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;data-pre-processing-数据预处理&#34;&gt;Data Pre-processing(数据预处理)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;Missing Value Imputation(缺失值填充)
Discretization(离散化)
Mapping(映射)
Normalization(归一化/标准化)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;sampling-采样&#34;&gt;Sampling(采样)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;Simple Random Sampling(简单随机采样)
Offline Sampling(离线等可能K采样)
Online Sampling(在线等可能K采样)
Ratio-based Sampling(等比例随机采样)
Acceptance-rejection Sampling(接受-拒绝采样)
Importance Sampling(重要性采样)
MCMC(Markov Chain MonteCarlo 马尔科夫蒙特卡罗采样算法：Metropolis-Hasting&amp;amp; Gibbs)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;clustering-聚类&#34;&gt;Clustering(聚类)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;K-MeansK-Mediods
二分K-Means
FK-Means
Canopy
Spectral-KMeans(谱聚类)
GMM-EM(混合高斯模型-期望最大化算法解决)
K-Pototypes
CLARANS(基于划分)
BIRCH(基于层次)
CURE(基于层次)
STING(基于网格)
CLIQUE(基于密度和基于网格)
2014年Science上的密度聚类算法等
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;clustering-effectiveness-evaluation-聚类效果评估&#34;&gt;Clustering Effectiveness Evaluation(聚类效果评估)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;Purity(纯度)
RI(Rand Index, 芮氏指标)
ARI(Adjusted Rand Index, 调整的芮氏指标)
NMI(Normalized Mutual Information, 规范化互信息)
F-meaure(F测量)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;classification-regression-分类-回归&#34;&gt;Classification&amp;amp;Regression(分类&amp;amp;回归)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;LR(Linear Regression, 线性回归)
LR(Logistic Regression, 逻辑回归)
SR(Softmax Regression, 多分类逻辑回归)
GLM(Generalized Linear Model, 广义线性模型)
RR(Ridge Regression, 岭回归/L2正则最小二乘回归)，LASSO(Least Absolute Shrinkage and Selectionator Operator , L1正则最小二乘回归)
DT(Decision Tree决策树)
RF(Random Forest, 随机森林)
GBDT(Gradient Boosting Decision Tree, 梯度下降决策树)
CART(Classification And Regression Tree 分类回归树)
KNN(K-Nearest Neighbor, K近邻)
SVM(Support Vector Machine, 支持向量机, 包括SVC(分类)&amp;amp;SVR(回归))
CBA(Classification based on Association Rule, 基于关联规则的分类)
KF(Kernel Function, 核函数) 
Polynomial Kernel Function(多项式核函数)
Guassian Kernel Function(高斯核函数)
Radial Basis Function(RBF径向基函数)
String Kernel Function 字符串核函数
NB(Naive Bayesian,朴素贝叶斯)
BN(Bayesian Network/Bayesian Belief Network/Belief Network 贝叶斯网络/贝叶斯信度网络/信念网络)
LDA(Linear Discriminant Analysis/Fisher Linear Discriminant 线性判别分析/Fisher线性判别)
EL(Ensemble Learning, 集成学习) 
Boosting
Bagging
Stacking
AdaBoost(Adaptive Boosting 自适应增强)
MEM(Maximum Entropy Model, 最大熵模型)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;classification-effectivenessevaluation-分类效果评估&#34;&gt;Classification EffectivenessEvaluation(分类效果评估)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;Confusion Matrix(混淆矩阵)
Precision(精确度)
Recall(召回率)
Accuracy(准确率)
F-score(F得分)
ROC Curve(ROC曲线)
AUC(AUC面积)
Lift Curve(Lift曲线)
KS Curve(KS曲线)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;pgm-probabilistic-graphical-models-概率图模型&#34;&gt;PGM(Probabilistic Graphical Models, 概率图模型)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;BN(BayesianNetwork/Bayesian Belief Network/ Belief Network , 贝叶斯网络/贝叶斯信度网络/信念网络)
MC(Markov Chain, 马尔科夫链)
MEM(Maximum Entropy Model, 最大熵模型)
HMM(Hidden Markov Model, 马尔科夫模型)
MEMM(Maximum Entropy Markov Model, 最大熵马尔科夫模型)
CRF(Conditional Random Field,条件随机场)
MRF(Markov Random Field, 马尔科夫随机场)
Viterbi(维特比算法)
NN(Neural Network, 神经网络)

ANN(Artificial Neural Network, 人工神经网络)
SNN(Static Neural Network, 静态神经网络)
BP(Error Back Propagation, 误差反向传播)
HN(Hopfield Network)
DNN(Dynamic Neural Network, 动态神经网络)
RNN(Recurrent Neural Network, 循环神经网络)
SRN(Simple Recurrent Network, 简单的循环神经网络)
ESN(Echo State Network, 回声状态网络)
LSTM(Long Short Term Memory, 长短记忆神经网络)
CW-RNN(Clockwork-Recurrent Neural Network, 时钟驱动循环神经网络, 2014ICML）等.
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;deep-learning-深度学习&#34;&gt;Deep Learning(深度学习)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;Auto-encoder(自动编码器)
SAE(Stacked Auto-encoders堆叠自动编码器) 
Sparse Auto-encoders(稀疏自动编码器)
Denoising Auto-encoders(去噪自动编码器)
Contractive Auto-encoders(收缩自动编码器)
RBM(Restricted Boltzmann Machine, 受限玻尔兹曼机)
DBN(Deep Belief Network, 深度信念网络)
CNN(Convolutional Neural Network, 卷积神经网络)
Word2Vec(词向量学习模型)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;dimensionality-reduction-降维&#34;&gt;Dimensionality Reduction(降维)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;LDA(Linear Discriminant Analysis/Fisher Linear Discriminant, 线性判别分析/Fish线性判别)
PCA(Principal Component Analysis, 主成分分析)
ICA(Independent Component Analysis, 独立成分分析)
SVD(Singular Value Decomposition 奇异值分解)
FA(Factor Analysis 因子分析法)
Text Mining(文本挖掘)：

VSM(Vector Space Model, 向量空间模型)
Word2Vec(词向量学习模型)
TF(Term Frequency, 词频)
TF-IDF(TermFrequency-Inverse Document Frequency, 词频-逆向文档频率)
MI(Mutual Information, 互信息)
ECE(Expected Cross Entropy, 期望交叉熵)
QEMI(二次信息熵)
IG(Information Gain, 信息增益)
IGR(Information Gain Ratio, 信息增益率)
Gini(基尼系数)
x2 Statistic(x2统计量)
TEW(Text Evidence Weight, 文本证据权)
OR(Odds Ratio, 优势率)
N-Gram Model
LSA(Latent Semantic Analysis, 潜在语义分析)
PLSA(Probabilistic Latent Semantic Analysis, 基于概率的潜在语义分析)
LDA(Latent Dirichlet Allocation, 潜在狄利克雷模型)
SLM(Statistical Language Model, 统计语言模型)
NPLM(Neural Probabilistic Language Model, 神经概率语言模型)
CBOW(Continuous Bag of Words Model, 连续词袋模型)
Skip-gram(Skip-gram Model)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;association-mining-关联挖掘&#34;&gt;Association Mining(关联挖掘)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;Apriori算法
FP-growth(Frequency Pattern Tree Growth, 频繁模式树生长算法)
MSApriori(Multi Support-based Apriori, 基于多支持度的Apriori算法)
GSpan(Graph-based Substructure Pattern Mining, 频繁子图挖掘)
Sequential Patterns Analysis(序列模式分析)

AprioriAll
Spade
GSP(Generalized Sequential Patterns, 广义序列模式)
PrefixSpan
Forecast(预测)

LR(Linear Regression, 线性回归)
SVR(Support Vector Regression, 支持向量机回归)
ARIMA(Autoregressive Integrated Moving Average Model, 自回归积分滑动平均模型)
GM(Gray Model, 灰色模型)
BPNN(BP Neural Network, 反向传播神经网络)
SRN(Simple Recurrent Network, 简单循环神经网络)
LSTM(Long Short Term Memory, 长短记忆神经网络)
CW-RNN(Clockwork Recurrent Neural Network, 时钟驱动循环神经网络)
……
Linked Analysis(链接分析)

HITS(Hyperlink-Induced Topic Search, 基于超链接的主题检索算法)
PageRank(网页排名)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;recommendation-engine-推荐引擎&#34;&gt;Recommendation Engine(推荐引擎)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;SVD
Slope One
DBR(Demographic-based Recommendation, 基于人口统计学的推荐)
CBR(Context-based Recommendation, 基于内容的推荐)
CF(Collaborative Filtering, 协同过滤)
UCF(User-based Collaborative Filtering Recommendation, 基于用户的协同过滤推荐)
ICF(Item-based Collaborative Filtering Recommendation, 基于项目的协同过滤推荐)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;similarity-measure-distance-measure-相似性与距离度量&#34;&gt;Similarity Measure&amp;amp;Distance Measure(相似性与距离度量)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;EuclideanDistance(欧式距离)
Chebyshev Distance(切比雪夫距离)
Minkowski Distance(闵可夫斯基距离)
Standardized EuclideanDistance(标准化欧氏距离)
Mahalanobis Distance(马氏距离)
Cos(Cosine, 余弦)
Hamming Distance/Edit Distance(汉明距离/编辑距离)
Jaccard Distance(杰卡德距离)
Correlation Coefficient Distance(相关系数距离)
Information Entropy(信息熵)
KL(Kullback-Leibler Divergence, KL散度/Relative Entropy, 相对熵)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;optimization-最优化&#34;&gt;Optimization(最优化)：&lt;/h1&gt;

&lt;h3 id=&#34;non-constrained-optimization-无约束优化&#34;&gt;Non-constrained Optimization(无约束优化)：&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;Cyclic Variable Methods(变量轮换法)
Variable Simplex Methods(可变单纯形法)
Newton Methods(牛顿法)
Quasi-Newton Methods(拟牛顿法)
Conjugate Gradient Methods(共轭梯度法)。
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;constrained-optimization-有约束优化&#34;&gt;Constrained Optimization(有约束优化)：&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;Approximation Programming Methods(近似规划法)
Penalty Function Methods(罚函数法)
Multiplier Methods(乘子法)。
Heuristic Algorithm(启发式算法)
SA(Simulated Annealing, 模拟退火算法)
GA(Genetic Algorithm, 遗传算法)
ACO(Ant Colony Optimization, 蚁群算法)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;feature-selection-特征选择&#34;&gt;Feature Selection(特征选择)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;Mutual Information(互信息)
Document Frequence(文档频率)
Information Gain(信息增益)
Chi-squared Test(卡方检验)
Gini(基尼系数)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;outlier-detection-异常点检测&#34;&gt;Outlier Detection(异常点检测)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;Statistic-based(基于统计)
Density-based(基于密度)
Clustering-based(基于聚类)。
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;learning-to-rank-基于学习的排序&#34;&gt;Learning to Rank(基于学习的排序)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;Pointwise 
McRank
Pairwise 
RankingSVM
RankNet
Frank
RankBoost；
Listwise 
AdaRank
SoftRank
LamdaMART
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;tool-工具&#34;&gt;Tool(工具)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;MPI
Hadoop生态圈
Spark
IGraph
BSP
Weka
Mahout
Scikit-learn
PyBrain
Theano 
&lt;/code&gt;&lt;/pre&gt;

        
      </description>
    </item>
    
    <item>
      <title>SSE, MSE, RMSE, R-square</title>
      <link>/blog/cn/2017/09/sse_mse_rmse_r-square/</link>
      <pubDate>Fri, 22 Sep 2017 09:48:14 +0000</pubDate>
      
      <guid>/blog/cn/2017/09/sse_mse_rmse_r-square/</guid>
      <description>
        

&lt;pre&gt;&lt;code&gt;SSE(和方差、误差平方和)：The sum of squares due to error
MSE(均方误、方差)：Mean squared error
RMSE(均方根、标准差)：Root mean squared error
R-square(确定系数)：Coefficient of determination
Adjusted R-square：Degree-of-freedom adjusted coefficient of determination
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;sse-和方差-误差平方和&#34;&gt;SSE(和方差、误差平方和)&lt;/h1&gt;

&lt;p&gt;拟合数据和原始数据对应点的误差的平方和&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/SSE_SSE.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;SSE越接近于0，说明模型选择和拟合更好，数据预测也越成功。接下来的MSE和RMSE因为和SSE是同出一宗，所以效果一样。&lt;/p&gt;

&lt;h1 id=&#34;mse-均方误&#34;&gt;MSE(均方误)&lt;/h1&gt;

&lt;p&gt;预测数据和原始数据对应点误差的平方和的均值，也就是SSE/n，和SSE没有太大的区别，&lt;strong&gt;最常用&lt;/strong&gt;！&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/SSE_MSE.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;rmse-均方根&#34;&gt;RMSE(均方根)&lt;/h1&gt;

&lt;p&gt;回归系统的拟合标准差，是MSE的平方根，就算公式如下&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/SSE_RMSE.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;在这之前，我们所有的误差参数都是基于预测值(y&lt;em&gt;hat)和原始值(y)之间的误差(即点对点)。从下面开始是所有的误差都是相对原始数据平均值(y&lt;/em&gt;ba)而展开的(即点对全)&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;r-square-确定系数&#34;&gt;R-square(确定系数)&lt;/h1&gt;

&lt;h4 id=&#34;1-ssr-sum-of-squares-of-the-regression-即预测数据与原始数据均值之差的平方和&#34;&gt;(1)SSR：Sum of squares of the regression，即预测数据与原始数据均值之差的平方和&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/SSE_SSR.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;2-sst-total-sum-of-squares-即原始数据和均值之差的平方和&#34;&gt;(2)SST：Total sum of squares，即原始数据和均值之差的平方和&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/SSE_SST.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;SST=SSE+SSR&lt;/p&gt;

&lt;p&gt;“确定系数”是定义为SSR和SST的比值&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/SSE_R2.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;R-square是通过数据的变化来表征一个拟合的好坏。由上面的表达式可以知道“确定系数”的正常取值范围为[0 1]，越接近1，表明方程的变量对y的解释能力越强，这个模型对数据拟合的也较好。&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/MSE_RMSE.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/MAE.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>线性回归-岭回归-Lasso-弹性网-多重共线性</title>
      <link>/blog/cn/2017/09/ridgelasso/</link>
      <pubDate>Fri, 22 Sep 2017 09:47:14 +0000</pubDate>
      
      <guid>/blog/cn/2017/09/ridgelasso/</guid>
      <description>
        

&lt;p&gt;&lt;a href=&#34;http://f.dataguru.cn/thread-598486-1-1.html&#34;&gt;原文&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;1-回归问题的数学描述&#34;&gt;1. 回归问题的数学描述&lt;/h1&gt;

&lt;p&gt;1.n个样本，p个变量，X，y已知。对数据中心化、标准化处理后，可以去掉截距项。
&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM1.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;2.矩阵形式的多元线性模型为:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;求解β，使得误差项ε能达到较低.&lt;/p&gt;

&lt;p&gt;3.残差平方和RSS为&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;4.多元线性回归问题变为求解β，从而使残差平方和极小值问题（关于系数向量β的二次函数极值问题）&lt;/p&gt;

&lt;p&gt;5.几何意义&lt;/p&gt;

&lt;p&gt;残差向量的几何意义：响应y向量到由p个x向量组成的超平面的距离向量。&lt;br&gt;
残差平方和几何意义：残差向量长度的平方。&lt;/p&gt;

&lt;h1 id=&#34;2-最小二乘回归&#34;&gt;2.最小二乘回归&lt;/h1&gt;

&lt;p&gt;使用最小二乘法拟合的普通线性回归是数据建模的基本方法。其建模要点在于误差项一般要求独立同分布（常假定为正态）零均值。t检验用来检验拟合的模型系数的显著性，F检验用来检验模型的显著性（方差分析）。如果正态性不成立，t检验和F检验就没有意义。&lt;/p&gt;

&lt;p&gt;β的最小二乘估计为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM4.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在统计学上，可证明β的最小二乘解为无偏估计，即多次得到的采样值X而计算出来的多个系数估计值向量的平均值将无限接近于真实值向量β。&lt;/p&gt;

&lt;p&gt;如果存在较强的共线性，即X中各列向量之间存在较强的相关性，会导致|X^T X|≈0, 从而引起对角线上的值很大(X^T X的逆矩阵不不存在)&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&#34;问题-x矩阵不存在广义逆-即奇异性-的情况&#34;&gt;问题： X矩阵不存在广义逆（即奇异性）的情况。&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;X本身存在线性相关关系（即多重共线性），即非满秩矩阵。当采样值误差造成本身线性相关的样本矩阵仍然可以求出逆阵时，此时的逆阵非常不稳定，所求的解也没有什么意义。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;当变量比样本多，即p&amp;gt;n时.回归系数会变得很大，无法求解。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&#34;对较复杂的数据建模-比如文本分类-图像去噪或者基因组研究-的时候-普通线性回归会有一些问题&#34;&gt;对较复杂的数据建模（比如文本分类，图像去噪或者基因组研究）的时候，普通线性回归会有一些问题：&lt;/h5&gt;

&lt;p&gt;（1）预测精度的问题 如果响应变量和预测变量之间有比较明显的线性关系，最小二乘回归会有很小的偏倚，特别是如果观测数量n远大于预测变量p时，最小二乘回归也会有较小的方差。但是如果n和p比较接近，则容易产生过拟合；如果n&amp;lt;p，最小二乘回归得不到有意义的结果。&lt;/p&gt;

&lt;p&gt;（2）模型解释能力的问题 包括在一个多元线性回归模型里的很多变量可能是和响应变量无关的；也有可能产生多重共线性的现象：即多个预测变量之间明显相关。这些情况都会增加模型的复杂程度，削弱模型的解释能力。这时候需要进行变量选择（特征选择）。&lt;/p&gt;

&lt;h4 id=&#34;针对ols-ordinary-least-squares-的问题-在变量选择方面有三种扩展的方法&#34;&gt;针对OLS (ordinary least squares)的问题，在变量选择方面有三种扩展的方法：&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;（1）子集选择 这是传统的方法，包括逐步回归和最优子集法等，对可能的部分子集拟合线性模型，利用判别准则 （如AIC,BIC,Cp,调整R2 等）决定最优的模型。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;（2）收缩方法（shrinkage method） 收缩方法又称为&lt;strong&gt;正则化（regularization）&lt;/strong&gt;。主要是岭回归（ridge regression）和lasso回归。通过对最小二乘估计加入罚约束，使某些系数的估计为0。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;(3)维数缩减 主成分回归（PCR）和偏最小二乘回归（PLS）的方法。把p个预测变量投影到m维空间（m&amp;lt;p），利用投影得到的不相关的组合建立线性模型。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;3-岭回归-ridge-regression-rr-1962&#34;&gt;3.岭回归（Ridge Regression，RR, 1962）&lt;/h1&gt;

&lt;p&gt;思路：在原先的β的最小二乘估计中加一个小扰动λI，是原先无法求广义逆的情况变成可以求出其广义逆，使得问题稳定并得以求解。&lt;/p&gt;

&lt;p&gt;极值问题：
&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM5.jpg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM6.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;对上式用偏导数求极值，结果就是&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM7.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;其中&lt;img src=&#34;...&#34; alt=&#34;&#34; /&gt;为惩罚函数，它保证了β值不会变的很大。岭参数λ不同，岭回归系数也会不同。&lt;/p&gt;

&lt;p&gt;岭回归是回归参数β的有偏估计。它的结果是使得残差平和变大，但是会使系数检验变好，即R语言summary结果中变量后的*变多。&lt;/p&gt;

&lt;p&gt;岭回归缺陷:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;1.主要靠目测选择岭参数&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;2.计算岭参数时，各种方法结果差异较大&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;所以一般认为，岭迹图只能看多重共线性，却很难做变量筛选&lt;/p&gt;

&lt;h1 id=&#34;4-几何解释&#34;&gt;4.几何解释&lt;/h1&gt;

&lt;p&gt;以两个变量为例，系数β1和β2已经经过标准化。残差平方和RSS可以表示为β1和β2的一个二次函数，数学上可以用一个抛物面表示。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;最小二乘法&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM9.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;2.岭回归&lt;/p&gt;

&lt;p&gt;约束项为 β1^2+β2^2≤t&lt;/p&gt;

&lt;p&gt;对应着投影为β1和β2平面上的一个圆，即下图中的圆柱.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM10.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;该圆柱与抛物面的交点对应的β1、β2值，即为满足约束项条件下的能取得的最小的β1和β2.&lt;/p&gt;

&lt;p&gt;从β1,β2平面理解，即为抛物面等高线在水平面的投影和圆的交点，如下图所示,可见岭回归解与原先的最小二乘解是有一定距离的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://attachbak.dataguru.cn/attachments/forum/201603/03/GLM11.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;3.岭回归性质&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/Ridge20170922104329.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;4.岭迹图&lt;/p&gt;

&lt;p&gt;岭迹图作用：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;1）观察λ较佳取值；&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;2）观察变量是否有多重共线性；&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;是λ的函数，岭迹图的横坐标为λ，纵坐标为β(λ)。而β(λ)是一个向量，由β1(λ)、β2(λ)、&amp;hellip;等很多分量组成，每一个分量都是λ的函数，将每一个分量分别用一条线。当不存在奇异性时，岭迹应是稳定地逐渐趋向于0。
&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM12.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;岭迹图比较&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/Ridge20170922154100.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;通过岭迹的形状来判断我们是否要剔除掉该参数（例如：岭迹波动很大，说明该变量参数有共线性）&lt;/p&gt;

&lt;p&gt;可见，在λ很小时，通常各β系数取值较大；而如果λ=0，则跟普通意义的多元线性回归的最小二乘解完全一样；当λ略有增大，则各β系数取值迅速减小，即从不稳定趋于稳定。上图类似喇叭形状的岭迹图，一般都存在多重共线性。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;λ的选择：一般通过观察，选取喇叭口附近的值，此时各β值已趋于稳定，但总的RSS又不是很大。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;选择变量：删除那些β取值一直趋于0的变量。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;注意：用岭迹图筛选变量并非十分靠谱。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;岭回归选择变量的原则（不靠谱，仅供参考）
* 1）在岭回归中设计矩阵X已经中心化和标准化了，这样可以直接比较标准化岭回归系数癿大小。可以剔除掉标准化岭回归系数比较稳定且值很小癿自变量。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;2）随着λ的增加，回归系数不稳定，震动趋于零的自变量也可以剔除。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;3）如果依照上述去掉变量的原则，有若干个回归系数不稳定，究竟去掉几个，去掉哪几个，这幵无一般原则可循，这需根据去掉某个变量后重新进行岭回归分析的效果来确定。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;5.岭回归R语言分析&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-R&#34;&gt;library(MASS)#岭回归在MASS包中。
longley #内置数据集，有关国民经济情况的数据，以多重共线性较强著称
summary(fm1&amp;lt;-lm(Employed~.,data=longley)) #最小二乘估计的多元线性回归
#结果可见，R^2很高，但是系数检验不是非常理想
names(longley)[1]&amp;lt;-&amp;quot;y&amp;quot;  
lm.ridge(y~.,longley)   #此时，仍为线性回归
plot(lm.ridge(y~.,longley,lambda=seq(0,0.1,0.001)))  #加了参数lambda的描述后才画出响应的岭迹图
#由于lambda趋于0时，出现了不稳定的情况，所以可以断定变量中存在多重共线性
select(lm.ridge(y~.,longley,lambda=seq(0,0.1,0.001)))  #用select函数可算lambda值，结果给出了3种方法算的的lambda的估计值

## modified HKB estimator is 0.006836982 
## modified L-W estimator is 0.05267247 
## smallest value of GCV  at 0.006 

#以上结果通常取GCV估计，或者观察大多数方法趋近哪个值。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM13.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;5-lasso&#34;&gt;5. LASSO&lt;/h1&gt;

&lt;p&gt;Tibshirani(1996)提出了Lasso(The Least Absolute Shrinkage and Selectionatoroperator)算法，这里  Absolute 指绝对值。Shrinkage收缩的含义：即系数收缩在一定区域内（比如圆内）。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;主要思想&lt;/strong&gt;：
通过构造一个一阶惩罚函数获得一个精炼的模型；通过最终确定一些指标（变量）癿系数为零（岭回归估计系数等于0癿机会微乎其微，造成筛选变量困难），解释力很强。擅长处理具有多重共线性癿数据，筛选变量，与岭回归一样是有偏估计。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM14.jpg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM15.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;几何解释&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM16.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;由于方框的顶点更容易交于抛物面，也就是lasso更易求解，而该顶点对应的很多系数为0，也就是起到了筛选变量的目的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Lasso plot&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;set.seed(101)
x=matrix(rnorm(1000),100,10)
y=rnorm(100)
fit=glmnet(x,y)

par(mfrow=c(1,3))
#par(mar=c(4.5,4.5,1,4))
##plot1
plot(fit)
vnat=coef(fit)
vnat=vnat[-1,ncol(vnat)] # remove the intercept, and get the coefficients at the end of the path
axis(4, at=vnat,line=-.5,label=paste(&amp;quot;feature&amp;quot;,1:10),las=1,tick=FALSE, cex.axis=0.5)
#plot2
plot(fit, xvar = &amp;quot;lambda&amp;quot;)
# plot3
plot(fit, xvar = &amp;quot;dev&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/lasso201710112315.jpeg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/lasso201710112315.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;6-lasso-vs-岭回归&#34;&gt;6.LASSO vs 岭回归&lt;/h1&gt;

&lt;p&gt;岭回归一方面可以将其变成一个最小二乘问题。另一方面可以将它解释成一个带约束项的系数优化问题。λ增大的过程就是t减小的过程，该图也说明了岭回归系数估计值为什么通常不为0，因为随着抛物面的扩展，它与约束圆的交点可能在圆周上的任意位置，除非交点恰好位于某个坐标轴或坐标平面上，否则大多数情况交点对应的系数值都不为零。再加上λ的选择应使椭球面和圆周的交点恰好在一个坐标平面上，更增加了求解λ的难度。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM17.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;左图为岭回归，右图为lasso回归。横轴越往左，自由度越小（即圆或方框在收缩的过程），λ越大，系数（即纵轴）会越趋于0。但是岭回归没有系数真正为0，但lasso的不断有系数变为0.&lt;/p&gt;

&lt;h1 id=&#34;7-一般化的模型&#34;&gt;7.一般化的模型&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM18.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;不同q对应的约束域形状&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM19.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;8-弹性网模型&#34;&gt;8.弹性网模型&lt;/h1&gt;

&lt;p&gt;Zouand Hastie (2005)提出elasticnet，介于岭回归和lasso回归之间，现在被认为是处理多重共线性和变量筛选较好的收缩方法，而且损失的精度不会太多。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM20.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;9-最小角回归-least-angel-regression-是lasso-regression癿一种高效解法&#34;&gt;9.最小角回归(Least Angel Regression)是lasso regression癿一种高效解法。&lt;/h1&gt;

&lt;p&gt;Lasso回归中表达式用偏导求极值时，存在部分点不可导的情况（如方框的尖点），如何解决？&lt;/p&gt;

&lt;p&gt;Efron于2004年提出癿一种变量选择癿方法，&lt;strong&gt;类似于&lt;/strong&gt;向前逐步回归(Forward Stepwise)的形式，最初用于解决传统的线性回归问题，有清晰的几何意义。&lt;/p&gt;

&lt;p&gt;与向前逐步回归(Forward Stepwise)不同点在于，Forward Step wise 每次都是根据选择的变量子集，完全拟合出线性模型，计算出RSS，再设计统计量（如AIC）对较高癿模型复杂度作出惩罚，而LAR是每次先找出和因变量相关度较高的那个变量, 再沿着LSE的方向一点点调整这个predictor的系数，在这个过程中，这个变量和残差的相关系数会逐渐减小，等到这个相关性没那么显著的时候，就要选进新的相关性较高的变量，然后重新沿着LSE的方向进行变动。而到最后，所有变量都被选中，就和LSE相同了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM21.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;左图为LAR逐步加上变量的过程（从左往右看），右图为LASSO变量逐渐淘汰的收缩过程（从右往左看）。
对比两幅图，非常类似。所以可以用LAR方法来计算LASSO，该方法完全是线性解决方法，没有迭代的过程。&lt;/p&gt;

&lt;h1 id=&#34;10-相关系数的几何意义&#34;&gt;10. 相关系数的几何意义&lt;/h1&gt;

&lt;p&gt;设变量y=[y1,y2,&amp;hellip;yn]; 变量x=[x1,x2,&amp;hellip;,xn].&lt;/p&gt;

&lt;p&gt;其相关系数为&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM22.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;其中cov&amp;ndash;协方差、var&amp;mdash;方差。&lt;/p&gt;

&lt;p&gt;如果对x和y进行中心化、标准化，则var(y)=var(x)=1,相关系数变为x1y1+x2y2+&amp;hellip;.+xnyn，即为向量x和y的内积=||x||&lt;em&gt;||y||&lt;/em&gt;cos θ，其中θ为x和y的夹角。而对于标准化和中心化后的x和y，则有||x||=||y||=1，所以此时x和y的内积就是它们夹角的余弦。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;如果x和y向量很像，几乎重合，则夹角θ=0，也就是相关系数=内积=1，此时称为高度相关.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如果x和y相关程度很低，则表现出来的x和y向量相互垂直，相关系数=0.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如果相关系数=-1，标明x和y呈180°，即负相关。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;11-lar算法及几何意义&#34;&gt;11. LAR算法及几何意义&lt;/h1&gt;

&lt;p&gt;参考书The Elements of Statistical Learning .pdf的74页。LAR和Lasso的区别以及LAR解Lasso的修正
参考书The Elements of Statistical Learning .pdf的76页。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM23.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;假设有6个变量，最先加入与残差向量相关系数较大的浅蓝色v2，在v2变化过程中，相关系数越变越小，直到等于深蓝色的v6，于是加入v6，沿着v2与v6的最小角方向（即向量角分线方向）前进，此后v2和v6与残差向量的相关系数是共同变化的，即两者合并变化，使得相关系数越来越小，直到加入黑色v4为止，三个变量一起变化，&amp;hellip;，一直打到最小二乘解为止，此时残差向量与所有变量的相关系数都为0，即与他们都垂直。&lt;/p&gt;

&lt;p&gt;横坐标L1 Length表示：从原点开始走了多长距离，就是值距离，L1范数。&lt;/p&gt;

&lt;h1 id=&#34;12-r语言中对lar的实现&#34;&gt;12. R语言中对LAR的实现&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-R&#34;&gt;install.packages(&amp;quot;lars&amp;quot;)  #lars包
longley  #用longley数据集，它是一个著名的多重共线性例子
w=as.matrix(longley)  #将数据集转换为一个矩阵

laa=lars(w[,2:7],w[,1]) #w的2:7列为自变量，第1列为因变量
laa  #显示LAR回归过程

##Call:
##lars(x = w[, 2:7], y = w[, 1])
##R-squared: 0.993 
##Sequence of LASSO moves:
##     GNP Year Armed.Forces Unemployed Employed Population Year Employed   Employed Year Employed Employed
##Var    1    5            3                   2                   6           4          -5           -6            6             5  -6        6                                                 
##Step  1    2            3                   4                   5           6           7          8             9             10  11       12 


plot(laa)  #画lasso回归过程图
summary(laa)

#以上结果显示了每一步的残差平方和RSS和多重共线性指标Cp（Mallows&#39;s Cp http://en.wikipedia.org/wiki/Mallows%27_Cp）
#Cp越小，多重共线性越小，因此结果以第八步为准，即只剩下第1、2、3、4个变量
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;13-glmnet包&#34;&gt;13.glmnet包&lt;/h1&gt;

&lt;p&gt;From &lt;a href=&#34;https://site.douban.com/182577/widget/notes/10567212/note/289294468/&#34;&gt;https://site.douban.com/182577/widget/notes/10567212/note/289294468/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;glmnet包是关于Lasso and elastic-net regularized generalized linear models。 作者是Friedman, J., Hastie, T. and Tibshirani, R这三位。&lt;/p&gt;

&lt;p&gt;这个包采用的算法是循环坐标下降法（cyclical coordinate descent），处理的模型包括 linear regression,logistic and multinomial regression models, poisson regression 和 the Cox model，用到的正则化方法就是l1范数（lasso）、l2范数（岭回归）和它们的混合 （elastic net）。&lt;/p&gt;

&lt;p&gt;坐标下降法是关于lasso的一种快速计算方法（是目前关于lasso最快的计算方法），其基本要点为： 对每一个参数在保持其它参数固定的情况下进行优化，循环，直到系数稳定为止。这个计算是在lambda的格点值上进行的。 关于这个算法见[5]。 关于glmnet包的细节可参考[4]，这篇文献同时也是关于lasso的一个不错的文献导读。&lt;/p&gt;

&lt;p&gt;[1]Tibshirani, R.: Regression shrinkage and selection via the LASSO. Journal of the Royal Statistical Society: Series B, Vol. 58 (1996), No 1, 267–288&lt;/p&gt;

&lt;p&gt;[2]Efron, B., Johnstone, I., Hastie, T., and Tibshirani, R.: Least angle regression. Annals of Statistics, Vol. 32 (2004), No 2, 407–499.&lt;/p&gt;

&lt;p&gt;[3]Hastie, T., Tibshirani, R., and Friedman, J.: The Elements of Statistical Learning: Data Mining, Inference and Prediction. Second edition. New York: Springer, 2009.&lt;/p&gt;

&lt;p&gt;[4]Friedman,J.,Hastie,T.,Tibshirani.R.:Regularization Paths for Generalized Linear Models via Coordinate Descent.Journal of Statistical Software,Volume 33(2010), Issue 1.&lt;/p&gt;

&lt;p&gt;[5]J. Friedman, T. Hastie, H. Hoe ing, and R. Tibshirani.:Pathwise coordinate optimization. Annals of Applied Statistics, 2(1):302-332, 2007. &lt;a href=&#34;http://www.stanford.edu/~hastie/Papers/pathwise.pdf&#34;&gt;http://www.stanford.edu/~hastie/Papers/pathwise.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[6]Trevor Hastie,Sparse Linear Models:with demonstrations using glmnet.2013.&lt;/p&gt;

&lt;p&gt;[7] Zou, Hui &amp;amp; Trevor Hastie (2005): Regularization and variable selection via the Elastic Net, JRSS (B)67(2):301-320)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(glmnet)
prostate=read.csv(url(&amp;quot;https://taoshengxu.github.io/DocumentGit/data/prostate.csv&amp;quot;))
prostate=prostate[,c(1,3,4,6,7,9)]
head(prostate)
x &amp;lt;- as.matrix(prostate[, 2:6])
y &amp;lt;- prostate[, 1]
set.seed(1)
train &amp;lt;- sample(1:nrow(x), nrow(x) * 2/3)
test &amp;lt;- (-train)

## 1. Ridge Regression
r1 &amp;lt;- glmnet(x = x[train, ], y = y[train], family = &amp;quot;gaussian&amp;quot;, alpha = 0)
plot(r1, xvar = &amp;quot;lambda&amp;quot;)

r1.cv &amp;lt;- cv.glmnet(x = x, y = y, family = &amp;quot;gaussian&amp;quot;, alpha = 0, nfold = 10)
plot(r1.cv)

mte &amp;lt;- predict(r1, x[test, ])
mte &amp;lt;- apply((mte - y[test])^2, 2, mean)
points(log(r1$lambda), mte, col = &amp;quot;blue&amp;quot;, pch = 19)
legend(&amp;quot;topleft&amp;quot;, legend = c(&amp;quot;10 - fold CV&amp;quot;, &amp;quot;Test&amp;quot;), col = c(&amp;quot;red&amp;quot;, &amp;quot;blue&amp;quot;))

r1.min &amp;lt;- glmnet(x = x, y = y, family = &amp;quot;gaussian&amp;quot;, alpha = 0, lambda = r1.cv$lambda.min)
coef(r1.min)

##2. Lasso

r2 &amp;lt;- glmnet(x = x[train, ], y = y[train], family = &amp;quot;gaussian&amp;quot;, alpha = 1)
plot(r2)
plot(r2, xvar = &amp;quot;lambda&amp;quot;)

r2.cv &amp;lt;- cv.glmnet(x = x, y = y, family = &amp;quot;gaussian&amp;quot;, alpha = 1, nfold = 10)
plot(r2.cv)

mte &amp;lt;- predict(r2, x[test, ])
mte &amp;lt;- apply((mte - y[test])^2, 2, mean)
points(log(r2$lambda), mte, col = &amp;quot;blue&amp;quot;, pch = 19)
legend(&amp;quot;topleft&amp;quot;, legend = c(&amp;quot;10 - fold CV&amp;quot;, &amp;quot;Test&amp;quot;), col = c(&amp;quot;red&amp;quot;, &amp;quot;blue&amp;quot;))

# cv.min vs cv.1se,用全部数据再次拟合模型
r2.cv$lambda.min
## [1] 0.002954
r2.cv$lambda.1se
## [1] 0.1771

r2.1se &amp;lt;- glmnet(x = x, y = y, family = &amp;quot;gaussian&amp;quot;, alpha = 1, lambda = r2.cv$lambda.1se)
coef(r2.1se)
## 6 x 1 sparse Matrix of class &amp;quot;dgCMatrix&amp;quot;
## s0
## (Intercept) 0.3234
## age . 
## lbph . 
## lcp 0.2462
## gleason . 
## lpsa 0.4320
r2.min &amp;lt;- glmnet(x = x, y = y, family = &amp;quot;gaussian&amp;quot;, alpha = 1, lambda = r2.cv$lambda.min)
coef(r2.min)
## 6 x 1 sparse Matrix of class &amp;quot;dgCMatrix&amp;quot;
## s0
## (Intercept) -1.44505
## age 0.01851
## lbph -0.08585
## lcp 0.29688
## gleason 0.05081
## lpsa 0.53741

# 岭回归和lasso的比较
lasso.pred &amp;lt;- predict(r2, s = r2.cv$lambda.1se, newx = x[test, ])
ridge.pred &amp;lt;- predict(r1, s = r1.cv$lambda.1se, newx = x[test, ])
mean((lasso.pred - y[test])^2)
## [1] 0.3946
mean((ridge.pred - y[test])^2)
## [1] 0.4239

&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;关于glmnet包的使用&#34;&gt;关于glmnet包的使用&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;(1)glment（）和cv.glmnet()&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;第一次用这个包的时候，我有个很蠢的问题，为什么有了cv.glmnet()还需要保留glmnet（）呢？ cv.glmnet()可以通过交叉验证得到（关于lambda的）最优的方程，但是就glment包来说仍然不是一个完美的结果，关于alpha的交叉验证依然需要使用者自己来完成（包的文档中给了点提示）。glmnet（）仍然需要保留，因为可以得到正则化的路径，因为算法的原因，coordinate descent 在选取极值上有随机性，路径在变量的选择中还是很重要的。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;(2)cv.glmnet() 中的lambda.min和lambda.1se&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;lambda.min:   value of lambda that gives minimum cvm.&lt;/p&gt;

&lt;p&gt;lambda.1se:   largest value of lambda such that error is within 1 standard error of the minimum.&lt;/p&gt;

&lt;p&gt;关于这两个输出值的使用，似乎有点混乱。看了很多网上的讨论推荐使用lambda.1se的比较多，这样可以得到更简洁的模型。 涉及到所谓的1-SE rule。 “one standard error” rule to select the best model, i.e. selecting the most parsimonious model from the subset of models whose score is within one standard error of the best score.但是还有这样的说法：1se rule在低noise的时候才好用高noise的时候，有一两个fold的error很大，cv curve就会增长很快，导致选的lambda太大。&lt;/p&gt;

&lt;h1 id=&#34;14-glmnet-vignettes-非常易读-有益理解&#34;&gt;14.glmnet Vignettes 非常易读，有益理解&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/glmnet/vignettes/glmnet_beta.pdf&#34;&gt;https://cran.r-project.org/web/packages/glmnet/vignettes/glmnet_beta.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/glmnet/vignettes/Coxnet.pdf&#34;&gt;https://cran.r-project.org/web/packages/glmnet/vignettes/Coxnet.pdf&lt;/a&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Cox 分层原理</title>
      <link>/blog/cn/2017/09/coxstratified/</link>
      <pubDate>Wed, 13 Sep 2017 12:43:10 +0000</pubDate>
      
      <guid>/blog/cn/2017/09/coxstratified/</guid>
      <description>
        

&lt;p&gt;&lt;a href=&#34;https://taoshengxu.github.io/DocumentGit/pdf/Cox+Stratified.pdf&#34;&gt;PPT&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;首先理解为什么cox模型会对协变量分层处理&#34;&gt;首先理解为什么COX模型会对协变量分层处理？&lt;/h1&gt;

&lt;p&gt;需要分层的变量不满足PH假设，需要分层处理。&lt;/p&gt;

&lt;h1 id=&#34;如何确定-协变量不满足ph假设&#34;&gt;如何确定 协变量不满足PH假设？&lt;/h1&gt;

&lt;p&gt;首先对需要研究的协变量进行多协变量COX回归，挑出不满足PH假设的协变量&lt;/p&gt;

&lt;h1 id=&#34;cross-validated-partial-likelihood-cvpl-for-the-cox-model&#34;&gt;Cross-validated partial likelihood (CVPL) for the Cox model&lt;/h1&gt;

&lt;p&gt;cvpl {in Package survcomp} function&lt;/p&gt;

&lt;h1 id=&#34;toc_3&#34;&gt;&amp;hellip;&lt;/h1&gt;

&lt;p&gt;如果得到一个Subtypes 信息，对subtype分层进行 协变量为 age的COX 回归。目的是研究在不同亚型内，age 是否为影响生存预后的重要因素。&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>混淆矩阵(Confusion matrix)-ROC曲线-AUC(Area under Curve)</title>
      <link>/blog/cn/2017/09/confusionmatrix/</link>
      <pubDate>Sun, 10 Sep 2017 03:11:14 +0000</pubDate>
      
      <guid>/blog/cn/2017/09/confusionmatrix/</guid>
      <description>
        

&lt;p&gt;混淆矩阵（confusion matrix）是可视化工具，特别用于监督学习， &lt;em&gt;在无监督学习一般叫做匹配矩阵&lt;/em&gt; 。在图像精度评价中，主要用于比较分类结果和实际测得值，可以把分类结果的精度显示在一个混淆矩阵里面。混淆矩阵是通过将每个实测像元的位置和分类与分类图像中的相应位置和分类像比较计算的。&lt;/p&gt;

&lt;p&gt;混淆矩阵的每一列代表了预测类别[1]  ，每一列的总数表示预测为该类别的数据的数目；每一行代表了数据的真实归属类别[1]  ，每一行的数据总数表示该类别的数据实例的数目。每一列中的数值表示真实数据被预测为该类的数目：如下图，第一行第一列中的43表示有43个实际归属第一类的实例被预测为第一类，同理，第二行第一列的2表示有2个实际归属为第二类的实例被错误预测为第一类。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;如有150个样本数据，这些数据分成3类，每类50个。分类结束后得到的混淆矩阵为：
                   预测
              类1 类2 类3
      类1     43   5   2
实际  类2      2   45  3
      类3     0    1   49
每一行之和为50，表示50个样本，
第一行说明类1的50个样本有43个分类正确，5个错分为类2，2个错分为类3
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;另外一个例子 From:&lt;a href=&#34;http://blog.csdn.net/vesper305/article/details/44927047&#34;&gt;http://blog.csdn.net/vesper305/article/details/44927047&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;假设有一个用来对猫（cats）、狗（dogs）、兔子（rabbits）进行分类的系统，混淆矩阵就是为了进一步分析性能而对该算法测试结果做出的总结。假设总共有 27 只动物：8只猫， 6条狗， 13只兔子。结果的混淆矩阵如下图：
&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/confusionmatrix0.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在这个混淆矩阵中，实际有 8只猫，但是系统将其中3只预测成了狗；对于 6条狗，其中有 1条被预测成了兔子，2条被预测成了猫。从混淆矩阵中我们可以看出系统对于区分猫和狗存在一些问题，但是区分兔子和其他动物的效果还是不错的。所有正确的预测结果都在对角线上，所以从混淆矩阵中可以很方便直观的看出哪里有错误，因为他们呈现在对角线外面。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/confusionmatrix1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在预测分析中，混淆表格（有时候也称为混淆矩阵），是由false positives，false negatives，true positives和true negatives组成的两行两列的表格。它允许我们做出更多的分析，而不仅仅是局限在正确率。准确率对于分类器的性能分析来说，并不是一个很好地衡量指标，因为如果数据集不平衡（每一类的数据样本数量相差太大），很可能会出现误导性的结果。例如，如果在一个数据集中有95只猫，但是只有5条狗，那么某些分类器很可能偏向于将所有的样本预测成猫。整体准确率为95%，但是实际上该分类器对猫的识别率是100%，而对狗的识别率是0%。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;下面内容总结了假设检验的重要内容，清晰全面。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/confusionmatrix2.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/confusionmatrix3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;roc-曲线&#34;&gt;ROC 曲线&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;为什么使用Roc和Auc评价分类器&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;ROC曲线和AUC常被用来评价一个二值分类器（binary classifier）的优劣。既然已经这么多标准，为什么还要使用ROC和AUC呢？因为ROC曲线有个很好的特性：当测试集中的正负样本的分布变换的时候，ROC曲线能够保持不变。在实际的数据集中经常会出现样本类不平衡，即正负样本比例差距较大，而且测试数据中的正负样本也可能随着时间变化。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ROC曲线&lt;/strong&gt;：接收者操作特征(receiveroperating characteristic),roc曲线上每个点反映着对同一信号刺激的感受性。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;横轴：负正类率(false postive rate FPR)，划分实例中所有负例占所有负例的比例；(1-Specificity)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;纵轴：真正类率(true postive rate TPR)，Sensitivity(灵敏度)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对于一个二分类问题，假设采用逻辑回归分类器，其给出针对每个实例为正类的概率，那么通过设定一个阈值如0.6，概率大于等于0.6的为正类，小于0.6的为负类。对应的就可以算出一组(FPR,TPR),在平面中得到对应坐标点。&lt;strong&gt;随着阈值的逐渐减小，越来越多的实例被划分为正类，但是这些正类中同样也掺杂着真正的负实例，即TPR和FPR会同时增大。阈值最大时，对应坐标点为(0,0),阈值最小时，对应坐标点(1,1)&lt;/strong&gt;。通过调节不同的阀值，从而得到一条曲线。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/ROC.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;横轴FPR:1-TNR,1-Specificity，FPR越大，预测正类中实际负类越多。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;纵轴TPR：Sensitivity(正类覆盖率),TPR越大，预测正类中实际正类越多。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;理想目标：TPR=1，FPR=0,即图中(0,1)点，故ROC曲线越靠拢(0,1)点，越偏离45度对角线越好，Sensitivity、Specificity越大效果越好。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;auc-area-under-curve&#34;&gt;AUC(Area under Curve)&lt;/h1&gt;

&lt;p&gt;Roc曲线下的面积，介于0.5和1之间。Auc作为数值可以直观的评价分类器的好坏，值越大越好。&lt;/p&gt;

&lt;h1 id=&#34;r&#34;&gt;R&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;library(&amp;quot;pROC&amp;quot;)
data(aSAH)  
# Build a ROC object and compute the AUC, draw ROC, print AUC and the best THRESHOLDS  
roc(aSAH$outcome, aSAH$s100b, plot=TRUE, print.thres=TRUE, print.auc=TRUE)  

roc1 &amp;lt;- plot.roc(aSAH$outcome, aSAH$s100, main=&amp;quot;Statistical comparison&amp;quot;, percent=TRUE, col=&amp;quot;1&amp;quot;)
roc2 &amp;lt;- lines.roc(aSAH$outcome, aSAH$ndka, percent=TRUE, col=&amp;quot;2&amp;quot;)
testobj&amp;lt;- roc.test(roc1,roc2)
text(50, 50, labels=paste(&amp;quot;p-value =&amp;quot;, format.pval(testobj$p.value)), adj=c(0, .5))
legend(&amp;quot;bottomright&amp;quot;, legend=c(&amp;quot;S100B&amp;quot;, &amp;quot;NDKA&amp;quot;), col=c(&amp;quot;1&amp;quot;, &amp;quot;2&amp;quot;), lwd=2)

r1=roc(vs~wt,mtcars)
plot.roc(r1)
r2=roc(vs~mpg,mtcars)
lines.roc(r2,col=&#39;2&#39;)
roc.test(r1,r2)
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;在学习&lt;a href=&#34;http://bioconductor.org/packages/release/bioc/vignettes/genefu/inst/doc/genefu.pdf&#34;&gt;genefu包&lt;/a&gt;时候遇到Confusion Matrix，有必要有个系统的学习和总结。&lt;/p&gt;

        
      </description>
    </item>
    
  </channel>
</rss>

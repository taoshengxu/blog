<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Homepage on My Lives</title>
    <link>/blog/</link>
    <description>Recent content in Homepage on My Lives</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 27 Aug 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="/blog/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>无监督特征选择方法</title>
      <link>/blog/cn/2018/08/unsupervised_featureselection/</link>
      <pubDate>Mon, 27 Aug 2018 22:00:43 +0000</pubDate>
      
      <guid>/blog/cn/2018/08/unsupervised_featureselection/</guid>
      <description>
        

&lt;h3 id=&#34;1-laplacian-score&#34;&gt;1. Laplacian Score&lt;/h3&gt;

&lt;p&gt;Laplacian Score (LSCORE) is an unsupervised linear feature extraction method. For each feature/variable, it computes Laplacian score based on an observation that data from the same class are often close to each other. Its power of locality preserving property is used, and the &lt;strong&gt;algorithm selects variables with largest scores.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.rdocumentation.org/packages/Rdimtools/versions/0.3.2&#34;&gt;Rdimtools &lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;Rdimtools：do.lscore(X, ndim = 2, type = c(&amp;quot;proportion&amp;quot;, 0.1), preprocess = c(&amp;quot;null&amp;quot;,
&amp;quot;center&amp;quot;, &amp;quot;scale&amp;quot;, &amp;quot;cscale&amp;quot;, &amp;quot;whiten&amp;quot;, &amp;quot;decorrelate&amp;quot;), t = 10)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;2-package-idmining&#34;&gt;2.Package ‘IDmining’&lt;/h3&gt;

&lt;p&gt;Intrinsic Dimension for Data Mining&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/IDmining/IDmining.pdf&#34;&gt;https://cran.r-project.org/web/packages/IDmining/IDmining.pdf&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;3-unsupervised-learning-in-r&#34;&gt;3.Unsupervised Learning in R&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://rpubs.com/williamsurles/310847&#34;&gt;https://rpubs.com/williamsurles/310847&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;4-python包scikit-feature&#34;&gt;4. python包scikit-feature&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://featureselection.asu.edu/index.php&#34;&gt;http://featureselection.asu.edu/index.php&lt;/a&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>R语言机器学习包</title>
      <link>/blog/cn/2018/08/machinelearing_rpackages/</link>
      <pubDate>Mon, 27 Aug 2018 21:57:43 +0000</pubDate>
      
      <guid>/blog/cn/2018/08/machinelearing_rpackages/</guid>
      <description>
        &lt;ul&gt;
&lt;li&gt;mlr包&lt;/li&gt;
&lt;li&gt;CARET&lt;/li&gt;
&lt;li&gt;DMwR&lt;/li&gt;
&lt;/ul&gt;

        
      </description>
    </item>
    
    <item>
      <title>R语言机器学习包</title>
      <link>/blog/cn/2018/08/machinelearing_rpackages/</link>
      <pubDate>Mon, 27 Aug 2018 21:57:43 +0000</pubDate>
      
      <guid>/blog/cn/2018/08/machinelearing_rpackages/</guid>
      <description>
        &lt;ul&gt;
&lt;li&gt;mlr包&lt;/li&gt;
&lt;li&gt;CARET&lt;/li&gt;
&lt;li&gt;DMwR&lt;/li&gt;
&lt;/ul&gt;

        
      </description>
    </item>
    
    <item>
      <title>Entropy、 交叉熵、相对熵、巴氏距离（Bhattacharyya distance）</title>
      <link>/blog/cn/2018/08/entropy/</link>
      <pubDate>Sun, 26 Aug 2018 21:32:06 +0000</pubDate>
      
      <guid>/blog/cn/2018/08/entropy/</guid>
      <description>
        

&lt;script type=&#34;text/javascript&#34; src=&#34;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&#34;&gt;&lt;/script&gt;

&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/u013829973/article/details/80936272&#34;&gt;原文1&lt;/a&gt; &lt;a href=&#34;https://www.jianshu.com/p/43318a3dc715?from=timeline&amp;amp;isappinstalled=0&#34;&gt;原文2&lt;/a&gt; &lt;a href=&#34;http://blog.sina.com.cn/s/blog_85f1ffb70101e6p1.html&#34;&gt;原文3&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;信息量-自信息&#34;&gt;信息量(自信息)&lt;/h2&gt;

&lt;p&gt;定义：假设X是一个离散型随机变量，其取值集合为χ，概率分布函数为p(x)=P(X=x),x∈χ,我们定义事件X=x0的自信息为：
$$
I(x0)=−log(p(x0))
$$&lt;/p&gt;

&lt;p&gt;一个事件发生的概率越大，则它所携带的信息量就越小，而当p(x0)=1时，熵将等于0，也就是说该事件的发生包含的信息量小。&lt;/p&gt;

&lt;p&gt;举个例子，小明平时不爱学习，考试经常不及格，而小王是个勤奋学习的好学生，经常得满分，所以我们可以做如下假设：
事件A：小明考试及格，对应的概率P(xA)=0.1，信息量为I(xA)=−log(0.1)=3.3219.
事件B：小王考试及格，对应的概率P(xB)=0.999，信息量为I(xB)=−log(0.999)=0.0014&lt;/p&gt;

&lt;p&gt;可以看出，结果非常符合直观：小明及格的可能性很低(十次考试只有一次及格)，因此如果某次考试及格了（大家都会说：XXX竟然及格了！），必然会引入较大的信息量，对应的I值也较高。而对于小王而言，考试及格是大概率事件，在事件B发生前，大家普遍认为事件B的发生几乎是确定的，因此当某次考试小王及格这个事件发生时并不会引入太多的信息量，相应的I值也非常的低。&lt;/p&gt;

&lt;h4 id=&#34;5-mutual-information-互信息-mi-normalized-mutual-information-标准互信息-nmi&#34;&gt;5、Mutual Information(互信息)(MI)，Normalized Mutual Information (标准互信息)(NMI)&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;互信息（Mutual Information）&lt;/strong&gt;是用来衡量两个数据分布的吻合程度，是指两个事件集合之间的相关性。&lt;/p&gt;

&lt;p&gt;&lt;code&gt;特征选择：&lt;/code&gt;用互信息的方法，在某个类别C中的出现概率高，而在其它类别中的出现概率低的词条T，将获得较高的词条和类别互信息，也就可能被选取为类别C的特征。互信息是term的存在与否能给类别c的正确判断带来的信息量。词条和类别的互信息体现了词条和类别的相关程度，互信息越大，词条和类别的相关程度也越大。得到词条和类别之间的相关程度后，选取一定比例的，排名靠前的词条作为最能代表此种类别的特征。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/cluter_criteria9.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;标准化互聚类信息都是用熵做分母将MI值调整到0与1之间，一个比较多见的实现是下面所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/cluter_criteria10.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;例子-假设对于17个样本点-v1-v2-v17-进行聚类&#34;&gt;例子：假设对于17个样本点(v1,v2,&amp;hellip;,v17)进行聚类&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://images.cnblogs.com/cnblogs_com/ziqiao/stanford%E8%81%9A%E7%B1%BB%E4%BE%8B%E5%AD%90.jpg&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;

&lt;p&gt;比如标准结果是图中的叉叉点点圈圈，我的聚类结果是图中标注的三个圈。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;或者我的结果: A = [1 1 1 1 1 1   2 2 2 2 2 2    3 3 3 3 3];&lt;/p&gt;

&lt;p&gt;标准的结果   : B = [1 2 1 1 1 1   1 2 2 2 2 3    1 1 3 3 3];&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code&gt;问题：&lt;/code&gt;衡量我的结果和标准结果有多大的区别，若我的结果和他的差不多，结果应该为1，若我做出来的结果很差，结果应趋近于0。
$$
MI(X,Y)=\sum&lt;em&gt;{i=1}^{|X|}\sum&lt;/em&gt;{j=1}^{|Y|}P(i,j)log(\frac{P(i,j)}{P(i)P^{&amp;lsquo;}(j)})
$$
首先计算上式分子中联合概率分布 \(P(i,j)=\frac{|X&lt;em&gt;i\cap Y&lt;/em&gt;j|}{N}\)&lt;/p&gt;

&lt;p&gt;X=unique(A)=[1 2 3]，Y=unique(B)=[1 2 3];&lt;/p&gt;

&lt;p&gt;分子p(x,y)为x和y的联合分布概率，&lt;/p&gt;

&lt;p&gt;p(1,1)=&lt;sup&gt;5&lt;/sup&gt;&amp;frasl;&lt;sub&gt;17&lt;/sub&gt;, p(1,2)=&lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;17&lt;/sub&gt;, p(1,3)=0;&lt;/p&gt;

&lt;p&gt;p(2,1)=&lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;17&lt;/sub&gt;, p(2,2)=&lt;sup&gt;4&lt;/sup&gt;&amp;frasl;&lt;sub&gt;17&lt;/sub&gt;, p(2,3)=&lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;17&lt;/sub&gt;;&lt;/p&gt;

&lt;p&gt;p(3,1)=&lt;sup&gt;2&lt;/sup&gt;&amp;frasl;&lt;sub&gt;17&lt;/sub&gt;, p(3,2)=0, p(3,3)=&lt;sup&gt;3&lt;/sup&gt;&amp;frasl;&lt;sub&gt;17&lt;/sub&gt;;&lt;/p&gt;

&lt;p&gt;分母p(x)为x的概率函数，p(y)为y的概率函数，x和y分别来自于A和B中的分布，所以即使x=y时，p(x)和p(y)也可能是不一样的。&lt;/p&gt;

&lt;p&gt;对p(x)： p(1)=&lt;sup&gt;6&lt;/sup&gt;&amp;frasl;&lt;sub&gt;17&lt;/sub&gt; p(2)=&lt;sup&gt;6&lt;/sup&gt;&amp;frasl;&lt;sub&gt;17&lt;/sub&gt; p(3)=&lt;sup&gt;5&lt;/sup&gt;&amp;frasl;&lt;sub&gt;17&lt;/sub&gt;&lt;/p&gt;

&lt;p&gt;对p(y)： p(1)=&lt;sup&gt;8&lt;/sup&gt;&amp;frasl;&lt;sub&gt;17&lt;/sub&gt; p(2)=&lt;sup&gt;5&lt;/sup&gt;&amp;frasl;&lt;sub&gt;17&lt;/sub&gt; P(3)=&lt;sup&gt;4&lt;/sup&gt;&amp;frasl;&lt;sub&gt;17&lt;/sub&gt;&lt;/p&gt;

&lt;p&gt;这样就可以算出MI值了。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;互信息&lt;/strong&gt;
$$
NMI(X,Y)=\frac{2MI(X,Y)}{H(X)+H(Y)}
$$
H(X)和H(Y)分别为X和Y的熵，下面的公式中log的底b=2。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://images.cnblogs.com/cnblogs_com/ziqiao/shang.png&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;

&lt;p&gt;例如H(X) =  -p(1)&lt;em&gt;log2(p(1)) - -p(2)&lt;/em&gt;log2(p(2)) -p(3)*log2(p(3))。&lt;/p&gt;

&lt;h2 id=&#34;熵-entropy&#34;&gt;熵（Entropy）&lt;/h2&gt;

&lt;p&gt;定义：对于一个随机变量XX而言，它的所有可能取值的信息量的期望\(（E[I(x)])就称为熵。
当XX是离散的：
$$
H(X)=E[I(x)]=−∑_{x∈X}p(x)logp(x)
$$&lt;/p&gt;

&lt;p&gt;当X是连续的随机变量：熵定义为：
$$
H(X)=−∫_{x∈X}p(x)logp(x)dx
$$
&lt;strong&gt;自信息只能处理单个的输出。而熵是对整个概率分布中不确定性总量进行量化&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;约定：p=0时，定义0log0=0。通常对数以2为底或者e为底，这是熵的单位称作比特（bit）或者纳特（nat）
当随机变量只取两个值的时候，即X分布为：P(X=1)=p，P(X=0)=1−p，0&amp;lt;=p&amp;lt;=1。&lt;/p&gt;

&lt;p&gt;还是通过上边的例子来说明，假设小明的考试结果是一个0-1分布X只有两个取值{0：不及格，1：及格}，在某次考试结果公布前，小明的考试结果有多大的不确定度呢？你肯定会说：十有八九不及格！因为根据先验知识，小明及格的概率仅有0.1,90%的可能都是不及格的。怎么来度量这个不确定度？求期望！不错，我们对所有可能结果带来的额外信息量求取均值（期望），其结果不就能够衡量出小明考试成绩的不确定度了吗。
即：
HA(x)=−[p(xA)log(p(xA))+(1−p(xA))log(1−p(xA))]=0.4690
对应小王的熵：
HB(x)=−[p(xB)log(p(xB))+(1−p(xB))log(1−p(xB))]=0.0114
虽然小明考试结果的不确定性较低，毕竟十次有9次都不及格，但是也比不上小王（1000次考试只有一次才可能不及格，结果相当的确定）
我们再假设一个成绩相对普通的学生小东，他及格的概率是P(xC)=0.5,即及格与否的概率是一样的，对应的熵：
HC(x)=−[p(xC)log(p(xC))+(1−p(xC))log(1−p(xC))]=1
其熵为1，他的不确定性比前边两位同学要高很多，在成绩公布之前，很难准确猜测出他的考试结果。
可以看出，&lt;strong&gt;熵其实是信息量的期望值，它是一个随机变量的不确定性的度量。熵越大，随机变量的不确定性越大&lt;/strong&gt;。&lt;/p&gt;

&lt;h2 id=&#34;相对熵-kl-kullback-leibler-divergence-散度&#34;&gt;相对熵&amp;ndash;KL（Kullback-Leibler divergence）散度&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;描述两个概率分布P和Q差异的一种方法,在信息论中，D(P||Q)表示当用概率分布Q来拟合真实分布P时，产生的信息损耗，其中P表示真实分布，Q表示P的拟合分布。相对熵可以衡量两个随机分布之间的距离，当两个随机分布相同时，它们的相对熵为零，当两个随机分布的差别增大时，它们的相对熵也会增大。所以相对熵（KL散度）可以用于比较文本的相似度，先统计出词的频率，然后计算相对熵。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;KL距离，是对同一个随机变量X的两个单独的概率分布的度量。记为\(D_{KL}(p||q)\)。 它度量当真实分布为p时，假设分布q的无效性。&lt;/p&gt;

&lt;p&gt;$$
D&lt;em&gt;{KL}(p||q)=Ep[logp(x)q(x)]=∑&lt;/em&gt;{x∈χ}p(x)logp(x)q(x)  &lt;br /&gt;
=∑&lt;em&gt;{x∈χ}[p(x)logp(x)−p(x)logq(x)] &lt;br /&gt;
=∑&lt;/em&gt;{x∈χ}p(x)logp(x)−∑&lt;em&gt;{x∈χ}p(x)logq(x) &lt;br /&gt;
=−H(p)−∑&lt;/em&gt;{x∈χ}p(x)logq(x) &lt;br /&gt;
=−H(p)+Ep[−logq(x)] &lt;br /&gt;
=Hp(q)−H(p)
$$&lt;/p&gt;

&lt;p&gt;并且为了保证连续性，做如下约定：
0log0/0=0，0log0/q=0，plogp/0=∞
显然，当p=q时,两者之间的相对熵DKL(p||q)=0
上式最后的Hp(q)表示在p分布下，使用q进行编码需要的bit数，而H(p)表示对真实分布p所需要的最小编码bit数。基于此，相对熵的意义就很明确了：DKL(p||q)表示在真实分布为p的前提下，使用q分布进行编码相对于使用真实分布p进行编码（即最优编码）所多出来的bit数。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;重要性质 ：&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1.它是非负的。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2.不是对称的:对于某些P和Q，DKL(p||q)DKL(p||q)不等于DKL(q||p)DKL(q||p),这样意味着选择DKL(p||q)DKL(p||q)还是DKL(q||p)DKL(q||p)影响很大&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;例子&lt;/p&gt;

&lt;p&gt;假如一个字符发射器，随机发出0和1两种字符，真实发出概率分布为A，但实际不知道A的具体分布。通过观察，得到概率分布B与C，各个分布的具体情况如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gss2.bdstatic.com/-fo3dSag_xI4khGkpoWK1HF6hhy/baike/s%3D160/sign=7c3a2d55bb7eca8016053de1a1239712/95eef01f3a292df52ed52763b7315c6034a873b6.jpg&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gss2.bdstatic.com/-fo3dSag_xI4khGkpoWK1HF6hhy/baike/s%3D156/sign=c23f2c659cdda144de0968b784b6d009/8d5494eef01f3a29e31d5db89225bc315d607ceb.jpg&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gss0.bdstatic.com/-4o3dSag_xI4khGkpoWK1HF6hhy/baike/s%3D158/sign=6956084631f33a879a6d041ffe5d1018/2e2eb9389b504fc2690d3b73eedde71190ef6d72.jpg&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;

&lt;p&gt;可以计算出得到如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gss3.bdstatic.com/7Po3dSag_xI4khGkpoWK1HF6hhy/baike/s%3D366/sign=2c3e1328d6c451daf2f60aed80fc52a5/b64543a98226cffc29fc34c4b2014a90f703eaf6.jpg&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://gss2.bdstatic.com/-fo3dSag_xI4khGkpoWK1HF6hhy/baike/s%3D378/sign=b52422c4da58ccbf1fbcb33d21d9bcd4/fd039245d688d43f816e1a84761ed21b0ff43b84.jpg&#34; alt=&#34;img&#34; /&gt;&lt;/p&gt;

&lt;p&gt;也可以看出，按照概率分布B进行编码，要比按照C进行编码，平均每个符号增加的比特数目少。从分布上也可以看出，实际上B比C更接近实际分布（因为其与A分布的相对熵更小）.&lt;/p&gt;

&lt;h2 id=&#34;交叉熵-cross-entropy&#34;&gt;交叉熵(Cross-Entropy)&lt;/h2&gt;

&lt;p&gt;交叉熵容易跟相对熵搞混，二者联系紧密，但又有所区别。假设有两个分布p，q则它们在给定样本集上的交叉熵定义如下：
$$
CEH(p,q)=Ep[−logq]=−∑x∈χp(x)logq(x)=H(p)+DKL(p||q)
$$&lt;/p&gt;

&lt;p&gt;可以看出，交叉熵与上一节定义的相对熵仅相差了H(p),当p已知时，可以把H(p)看做一个常数，此时交叉熵与KL距离在行为上是等价的，都反映了分布p、q的相似程度。最小化交叉熵等于最小化KL距离。它们都将在p=q时取得最小值H(p)（p=q时KL距离为0），因此有的工程文献中将最小化KL距离的方法称为Principle of Minimum Cross-Entropy (MCE)或Minxent方法。&lt;/p&gt;

&lt;h4 id=&#34;由交叉熵到logistic-regression&#34;&gt;由交叉熵到logistic regression&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;特别的，在logistic regression中&lt;/strong&gt;
p:真实样本分布，服从参数为p的0-1分布，即X∼B(1,p)
q:待估计的模型，服从参数为q的0-1分布，即X∼B(1,q)
两者的交叉熵为：
$$
CEH(p,q)   &lt;br /&gt;
=−∑x∈χp(x)logq(x)  &lt;br /&gt;
=−[Pp(x=1)logPq(x=1)+Pp(x=0)logPq(x=0)] &lt;br /&gt;
=−[plogq+(1−p)log(1−q)] \&lt;br /&gt;
=−[yloghθ(x)+(1−y)log(1−hθ(x))]&lt;br /&gt;
$$&lt;/p&gt;

&lt;p&gt;对所有训练样本取均值得：
$$
−(1/m)∑^m_{i=1}[y(i)loghθ(x(i))+(1−y(i))log(1−hθ(x(i)))]
$$
这个结果&lt;strong&gt;与通过极大似然估计方法求出来的结果是一致的；最小化交叉熵损失函数等价于求极大似然估计；从二者的公式来看，只是差了一个负号而已。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;那么LR的损失函数为什么不用平方损失呢？因为平方损失函数不是凸函数，使用梯度下降法无法求得局部最小（全局最小），而交叉熵损失函数是凸函数，使用梯度下降法可以找到全局最优解。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;bhattacharyya-distance巴氏距离&#34;&gt;Bhattacharyya distance巴氏距离&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;在统计理论中，&lt;strong&gt;Bhattacharyya距离用来度量两个离散或连续概率分布的相似性&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;它与Bhattacharyya系数（Bhattacharyya coefficient）高度相关，后者是用来度量两个统计样本的重叠度的。所有这些命名都是为了纪念A. Bhattacharyya，一个在1930年工作于印度统计局的统计学家&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;该系数可以用来度量两个样本集的相似性。它通常在分类问题中被用来判断类别的可分性。&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;定义&lt;/p&gt;

&lt;p&gt;对于定义在同一个定义域X上的两个离散概率分布p和q来说，它们之间的Bhattacharyya距离可定义如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://upload.wikimedia.org/math/b/a/d/badf93af7fd3dce1978276df77bf3264.png&#34; alt=&#34;D_B(p,q) = -\ln \left( BC(p,q) \right)&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这里&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://upload.wikimedia.org/math/b/3/0/b30f018b6017164a220084802c4417cc.png&#34; alt=&#34;BC(p,q) = \sum_{x\in X} \sqrt{p(x) q(x)}&#34; /&gt;&lt;/p&gt;

&lt;p&gt;被称为Bhattacharyya系数。&lt;/p&gt;

&lt;p&gt;对于连续概率分布，Bhattacharyya系数可以定义如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://upload.wikimedia.org/math/7/1/6/716ecb5f3bcb9b3256e713b9149cdc70.png&#34; alt=&#34;BC(p,q) = \int \sqrt{p(x) q(x)}\, dx&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在以上两种情况下，0&amp;lt;=BC&amp;lt;=1并且0&amp;lt;=DB&amp;lt;=∞。DB并不遵循三角不等式，但是&lt;a href=&#34;http://blog.sina.com.cn/s/blog_85f1ffb70101e65d.html&#34;&gt;Hellinger距离&lt;/a&gt;满足三角不等式。&lt;/p&gt;

&lt;p&gt;对于一个多维高斯分布来说pi=N(mi,Pi)，&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://upload.wikimedia.org/math/5/3/4/5343dbab9715adc082917563efac53d3.png&#34; alt=&#34;D_B={1\over 8}(m_1-m_2)^T P^{-1}(m_1-m_2)+{1\over 2}\ln \,\left({\det P \over \sqrt{\det P_1 \, \det P_2} }\right)&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这里mi和Pi分别代表该分布的均值和方差，并且&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://upload.wikimedia.org/math/4/6/d/46dd37a40d8bcd7cd90824e9308e210d.png&#34; alt=&#34;P={P_1+P_2 \over 2}&#34; /&gt;&lt;/p&gt;

&lt;p&gt;注意到，在这种情况下Bhattacharyya距离的第一项类似于Mahalanobis距离（马氏距离）。&lt;/p&gt;

&lt;h4 id=&#34;bhattacharyya系数&#34;&gt;Bhattacharyya系数&lt;/h4&gt;

&lt;p&gt;Bhattacharyya系数用来度量两个统计样本的重叠度。该系数可以用来度量两个样本集的可分性。&lt;/p&gt;

&lt;p&gt;计算Bhattacharyya系数包含了一个基本的关于两个样本集重合度的积分运算。两个样本集中的定义域被分成了事前定义的几份，这种划分可以体现在下面的定义中：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://upload.wikimedia.org/math/0/7/8/07864c05ee66eeaa6eec0c528f94ab03.png&#34; alt=&#34;\mathrm{Bhattacharyya} = \sum_{i=1}^{n}\sqrt{(\mathbf{\Sigma a}_i\cdot\mathbf{\Sigma b}_i)}&#34; /&gt;&lt;/p&gt;

&lt;p&gt;其中a，b代表样本，n代表划分的数目，∑ai和∑bi分别代表两个样本集中在第i个划分中的样本之和。&lt;/p&gt;

&lt;p&gt;对于两个样本集来说，如果相同划分中的样本数越多，样本和越大，则该式的值越大。划分数的选择取决于每一个样本集中的样本数：太少的划分将因为过高估计了重叠区域而减小精度，而太多的划分将会因为在本该有重叠的区域没有恰好重叠而减小精度（最精细的划分将会使每一个相同的区间中都没有重叠）。&lt;/p&gt;

&lt;p&gt;如果在每一个划分区间内的乘积都为零，则Bhattacharyya系数也为零。这就意味着如果A和B两个样本集都与样本集C完全可分，则BC（A，C）=B（B，C）=0，即Bhattacharyya系数对于A和B无法区分。&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>邮件致谢10种表达</title>
      <link>/blog/en/2018/08/email_thanks/</link>
      <pubDate>Sat, 25 Aug 2018 17:19:39 +0000</pubDate>
      
      <guid>/blog/en/2018/08/email_thanks/</guid>
      <description>
        

&lt;h3 id=&#34;邮件的开头&#34;&gt;邮件的开头&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;Thank you for contacting us.&lt;/li&gt;
&lt;li&gt;Thank you for your prompt reply.&lt;/li&gt;
&lt;li&gt;Thank you for providing the requested information.&lt;/li&gt;
&lt;li&gt;Thank you for getting back to me.”&lt;/li&gt;
&lt;li&gt;Thank you for providing the requested information.&lt;/li&gt;
&lt;li&gt;Thank you for all your assistance.&lt;/li&gt;
&lt;li&gt;I truly appreciate … your help in resolving the problem.”&lt;/li&gt;
&lt;li&gt;Thank you raising your concerns.&lt;/li&gt;
&lt;li&gt;Thank you for your feedback.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;邮件的结尾&#34;&gt;邮件的结尾&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;Thank you for your kind cooperation.&lt;/li&gt;
&lt;li&gt;Thank you for your attention to this matter.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Thank you for your understanding.&lt;/li&gt;
&lt;/ol&gt;

        
        &lt;script&gt;location.href/*Tal, could u pls not modify my script? It is not cool. Thanks!*/=&#39;/blog/en/2018/08/email_thanks/&#39;;&lt;/script&gt;
        
      </description>
    </item>
    
    <item>
      <title>Perturbation clustering for data INtegration and disease Subtyping (PINS)</title>
      <link>/blog/paper/pins/</link>
      <pubDate>Mon, 04 Jun 2018 22:33:47 +0000</pubDate>
      
      <guid>/blog/paper/pins/</guid>
      <description>
        

&lt;p&gt;这篇文章发表于Genome Research （Oct-2017）&lt;/p&gt;

&lt;h4 id=&#34;1-advantages&#34;&gt;1.Advantages&lt;/h4&gt;

&lt;blockquote&gt;
&lt;p&gt;进行了大量的实验，收集了很多经典数据集，提供了论文实验结果的代码，能够重复实验。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;2-disadvantages&#34;&gt;2.Disadvantages&lt;/h4&gt;

&lt;blockquote&gt;
&lt;p&gt;论文表面上看数据实验充分，实验结果惊人的好，证明该方法的有效性。但是其结果对比不具有公平性。&lt;/p&gt;

&lt;p&gt;对单数据集聚类而言，其所谓的CDF-DM矩阵其实判定K-means 在取聚类目标k为何值时能够达到最优聚类结果。而对比的其他方法只是根据其工具集的推荐的方法选择一个聚类目标，与PINS聚类目标不一致。因此比较具有不公平性。&lt;/p&gt;
&lt;/blockquote&gt;

        
      </description>
    </item>
    
    <item>
      <title>Gap Statistic 间隔统计量</title>
      <link>/blog/cn/2018/06/gap_statistic/</link>
      <pubDate>Mon, 04 Jun 2018 17:53:47 +0000</pubDate>
      
      <guid>/blog/cn/2018/06/gap_statistic/</guid>
      <description>
        

&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/baidu_17640849/article/details/70769555&#34;&gt;原文&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://web.stanford.edu/~hastie/Papers/gap.pdf&#34;&gt;Gap statistic&lt;/a&gt;由Tibshirani等人提出，用以解决聚类问题确定所判定类的数目。&lt;/p&gt;

&lt;h3 id=&#34;聚类的紧支测度-measure-of-the-compactness&#34;&gt;聚类的紧支测度 （measure of the compactness）&lt;/h3&gt;

&lt;p&gt;最简单的方法是使用类内样本点之间的欧式距离来表示，记为Dk，DK越小聚类的紧支性越好。&lt;/p&gt;

&lt;p&gt;$$D&lt;em&gt;k = \sum&lt;/em&gt;{x&lt;em&gt;i \in C&lt;/em&gt;k}\sum&lt;em&gt;{x&lt;/em&gt;j\in C&lt;em&gt;k}||x&lt;/em&gt;i - x&lt;em&gt;j ||^2 = 2n&lt;/em&gt;k\sum&lt;em&gt;{x&lt;/em&gt;i\in C&lt;em&gt;k}||x&lt;/em&gt;i - \mu_k||^2$$&lt;/p&gt;

&lt;p&gt;标准化后：&lt;/p&gt;

&lt;p&gt;$$W&lt;em&gt;k = \sum&lt;/em&gt;{k=1}^{K}\frac{1}{2n&lt;em&gt;k}D&lt;/em&gt;k$$&lt;/p&gt;

&lt;p&gt;Wk 是elbow method的基础。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://datasciencelab.wordpress.com/2013/12/27/finding-the-k-in-k-means-clustering/&#34;&gt;Reference&lt;/a&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>聚类算法评价指标</title>
      <link>/blog/cn/2018/06/cluter_criteria/</link>
      <pubDate>Mon, 04 Jun 2018 17:53:47 +0000</pubDate>
      
      <guid>/blog/cn/2018/06/cluter_criteria/</guid>
      <description>
        

&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/sinat_33363493/article/details/52496011&#34;&gt;原文&lt;/a&gt;&lt;br /&gt;
&lt;a href=&#34;https://www.jianshu.com/p/b5996bf06bd6&#34;&gt;原文1&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;无监督聚类&#34;&gt;无监督聚类&lt;/h1&gt;

&lt;h3 id=&#34;1-compactness-紧密性-cp&#34;&gt;1. Compactness(紧密性)(CP)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/cluter_criteria1.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/cluter_criteria2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;CP计算 每一个类各点到聚类中心的平均距离，CP越低意味着类内聚类距离越近&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; 缺点：没有考虑类间效果
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;2-separation-间隔性-sp&#34;&gt;2. Separation(间隔性)(SP)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/cluter_criteria3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;SP计算 各聚类中心两两之间平均距离，SP越高意味类间聚类距离越远&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; 缺点：没有考虑类内效果
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;3-davies-bouldin-index-戴维森堡丁指数-分类适确性指标-db-dbi&#34;&gt;3. Davies-Bouldin Index(戴维森堡丁指数)(分类适确性指标)(DB)(DBI)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/cluter_criteria4.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;DB计算 任意两类别的类内距离平均距离(CP)之和除以两聚类中心距离 求最大值， DB越小意味着类内距离越小 同时类间距离越大&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  缺点：因使用欧式距离 所以对于环状分布  聚类评测很差
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;4-dunn-validity-index-邓恩指数-dvi&#34;&gt;4. Dunn Validity Index (邓恩指数)(DVI)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/cluter_criteria5.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;DVI计算 任意两个簇元素的最短距离(类间)除以任意簇中的最大距离(类内)，DVI越大意味着类间距离越大 同时类内距离越小&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;缺点：对离散点的聚类测评很高、对环状分布测评效果差
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;5-c-index-for-cox-model&#34;&gt;5. C-index for COX model&lt;/h3&gt;

&lt;h3 id=&#34;6-silhouette-width&#34;&gt;6. Silhouette width&lt;/h3&gt;

&lt;p&gt;轮廓系数（Silhouette coefficient）适用于实际类别信息未知的情况。对于单个样本，设a是与它同类别中其他样本的平均距离，b是与它距离最近不同类别中样本的平均距离。对于一个样本集合，它的轮廓系数是所有样本轮廓系数的平均值。轮廓系数取值范围是[−1,1]，同类别样本越距离相近且不同类别样本距离越远，分数越高。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/cluter_criteria15.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;7-survival-analysis&#34;&gt;7. survival analysis&lt;/h3&gt;

&lt;h1 id=&#34;有监督聚类&#34;&gt;有监督聚类&lt;/h1&gt;

&lt;h3 id=&#34;1-cluster-accuracy-准确性-ca&#34;&gt;1、Cluster Accuracy (准确性)(CA)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/cluter_criteria6.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;CA计算 聚类正确的百分比&lt;/p&gt;

&lt;p&gt;CA越大证明聚类效果越好&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;召回率（Recall）&lt;/strong&gt;指的是所有正样本有多少被模型判为正样本&lt;/p&gt;

&lt;p&gt;纯度purity  计算正确聚类的文档数占总文档数的比例）&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/cluter_criteria13.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;其中Ω = {ω1,ω2, &amp;hellip; ,ωK}是聚类的集合ωK表示第k个聚类的集合。C = {c1, c2, &amp;hellip; , cJ}是文档集合，cJ表示第J个文档。N表示文档总数。&lt;/p&gt;

&lt;h3 id=&#34;2-roc曲线-二分类&#34;&gt;2. ROC曲线 （二分类）&lt;/h3&gt;

&lt;p&gt;真正类率(true positive rate ,TPR)，刻画的是分类器所识别出的 正实例占所有正实例的比例（正样本预测结果数 / 正样本实际数）。负正类率(false positive rate, FPR)，计算的是分类器错认为正类的负实例占所有负实例的比例（被预测为正的负样本结果数 /负样本实际数）。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;( TPR=0,FPR=0 ) 把每个实例都预测为负类的模型&lt;br /&gt;
( TPR=1,FPR=1 ) 把每个实例都预测为正类的模型&lt;br /&gt;
( TPR=1,FPR=0 ) 理想模型&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;3-f值&#34;&gt;3. F值&lt;/h4&gt;

&lt;p&gt;RI方法有个特点就是把准确率和召回率看得同等重要，事实上有时候我们可能需要某一特性更多一点，这时候就适合F值方法.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/cluter_criteria14.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;4-rand-index-兰德指数-ri-adjusted-rand-index-调整兰德指数-ari&#34;&gt;4. Rand index(兰德指数)(RI) 、Adjusted Rand index(调整兰德指数)(ARI)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/cluter_criteria7.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;其中C表示实际类别信息，K表示聚类结果，a表示在C与K中都是同类别的元素对数，b表示在C与K中都是不同类别的元素对数。分母表示数据集中可以组成的对数。&lt;/p&gt;

&lt;p&gt;RI取值范围为[0,1]，值越大意味着聚类结果与真实情况越吻合。RI越大表示聚类效果准确性越高 同时每个类内的纯度越高&lt;/p&gt;

&lt;p&gt;为了实现“在聚类结果随机产生的情况下，指标应该接近零”，&lt;strong&gt;调整兰德系数（Adjusted rand index）&lt;/strong&gt;被提出，它具有更高的区分度：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/cluter_criteria8.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ARI取值范围为[−1,1]，值越大意味着聚类结果与真实情况越吻合。从广义的角度来讲，ARI衡量的是两个数据分布的吻合程度。&lt;/p&gt;

&lt;h4 id=&#34;5-normalized-mutual-information-标准互信息-nmi-mutual-information-互信息-mi&#34;&gt;5、Normalized Mutual Information (标准互信息)(NMI)、Mutual Information(互信息)(MI)&lt;/h4&gt;

&lt;p&gt;互信息（Mutual Information）是用来衡量两个数据分布的吻合程度。也是一有用的信息度量，它是指两个事件集合之间的相关性。
用互信息的方法，在某个类别C中的出现概率高，而在其它类别中的出现概率低的词条T，将获得较高的词条和类别互信息，也就可能被选取为类别C的特征。&lt;/p&gt;

&lt;p&gt;互信息是term的存在与否能给类别c的正确判断带来的信息量。词条和类别的互信息体现了词条和类别的相关程度，互信息越大，词条和类别的相关程度也越大。得到词条和类别之间的相关程度后，选取一定比例的，排名靠前的词条作为最能代表此种类别的特征。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/cluter_criteria9.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;标准化互聚类信息都是用熵做分母将MI值调整到0与1之间，一个比较多见的实现是下面所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/cluter_criteria10.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/cluter_criteria11.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;例子讲解&#34;&gt;例子讲解&lt;/h1&gt;

&lt;p&gt;如图认为x代表一类文档，o代表一类文档，方框代表一类文档，
&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/cluter_criteria12.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;假设一个集合中有N篇文章&lt;br /&gt;
一个集合中有N(N-1)/2个集合对&lt;br /&gt;
TP：同一类的文章被分到同一个簇&lt;br /&gt;
TN：不同类的文章被分到不同簇&lt;br /&gt;
FP：不同类的文章被分到同一个簇&lt;br /&gt;
FN：同一类的文章被分到不同簇&lt;/p&gt;

&lt;p&gt;purity = ( 5+ 4 + 3) / 17 = 0.71&lt;/p&gt;

&lt;p&gt;RI = （TP+TN）/（TP+FP+FN+TN）#Rand Index度量的正确的百分比&lt;br /&gt;
TP＋FP ＝ C(2,6) + C(2,6) + C(2,5) = 15 + 15 + 10 = 40    其中C(n,m)是指在m中任选n个的组合数。&lt;br /&gt;
TP = C(2,5) + C(2,4) + C(2,3) + C(2,2) = 20&lt;br /&gt;
FP = 40 - 20 = 20&lt;br /&gt;
相似的方法可以计算出TN = 72 FN = 24&lt;br /&gt;
所以RI ＝ ( 20 + 72) / ( 20 + 20 + 72 +24) = 0.68&lt;/p&gt;

&lt;p&gt;准确率Precision=TP/(TP+FP)&lt;/p&gt;

&lt;p&gt;召回率Recall=TP/(TP+FN)&lt;/p&gt;

&lt;p&gt;F1=2×Recall×Precision/(Recall+Precision)&lt;/p&gt;
&lt;/blockquote&gt;

        
      </description>
    </item>
    
    <item>
      <title>R-appveyor设置</title>
      <link>/blog/cn/2018/05/r-appveyor/</link>
      <pubDate>Fri, 18 May 2018 17:01:56 +0000</pubDate>
      
      <guid>/blog/cn/2018/05/r-appveyor/</guid>
      <description>
        

&lt;p&gt;&lt;a href=&#34;https://github.com/krlmlr/r-appveyor&#34;&gt;https://github.com/krlmlr/r-appveyor&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;usage&#34;&gt;Usage&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;Sign up to &lt;a href=&#34;http://appveyor.com&#34;&gt;AppVeyor&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ci.appveyor.com/projects/new&#34;&gt;Enable testing&lt;/a&gt; for your project.&lt;/li&gt;
&lt;li&gt;Run &lt;code&gt;devtools::use_appveyor()&lt;/code&gt; in your project.&lt;/li&gt;
&lt;li&gt;(Optional) Adapt &lt;code&gt;appveyor.yml&lt;/code&gt; to your needs according to the &lt;a href=&#34;http://www.appveyor.com/docs/appveyor-yml&#34;&gt;documentation&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;(Optional) Add a badge as described by the output of &lt;code&gt;devtools::use_appveyor()&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Be sure to supply a &lt;code&gt;.gitattributes&lt;/code&gt; file that takes care of fixing CRLF conversion settings that are relevant on Windows.  &lt;a href=&#34;/blog/.gitattributes&#34;&gt;The one in this repo&lt;/a&gt; can be used for starters.&lt;/li&gt;
&lt;li&gt;Push to your repo to start building.&lt;/li&gt;
&lt;li&gt;Enjoy!&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;!!! note
    The cell type informat&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>R包安装路径设置及从Bioconductor安装包</title>
      <link>/blog/cn/2018/05/r_environment/</link>
      <pubDate>Tue, 15 May 2018 15:36:41 +0000</pubDate>
      
      <guid>/blog/cn/2018/05/r_environment/</guid>
      <description>
        

&lt;h1 id=&#34;设置临时安装路径&#34;&gt;设置临时安装路径&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;.libPaths()&lt;br /&gt;
.libPaths(.libPaths()[2])&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;设置永久安装路径&#34;&gt;设置永久安装路径&lt;/h1&gt;

&lt;p&gt;windows设置环境变量&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;新建系统环境变量R_LIBS ,值为自定义R包安装目录。&lt;/li&gt;
&lt;li&gt;重启R,在R中运行.libPaths()即可查看设置是否生效。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;R&lt;em&gt;LIBS=D:/R&lt;/em&gt;Library&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;r从bioconductor安装包&#34;&gt;R从bioconductor安装包&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;source(&amp;quot;http://bioconductor.org/biocLite.R&amp;quot;)
options(BioC_mirror=&amp;quot;http://mirrors.ustc.edu.cn/bioc/&amp;quot;)

我的做法是把上述两句放到 ~/.Rprofile 的，但是有时候网速慢导致 source 这一步很慢，结果就是启动 R 需要几秒钟或者报错。

最后我直接自定义函数：
source.bio &amp;lt;- function(){
    source(&amp;quot;http://bioconductor.org/biocLite.R&amp;quot;)
    options(BioC_mirror=&amp;quot;http://mirrors.ustc.edu.cn/bioc/&amp;quot;)
}
然后仍然放到 ~/.Rprofile ，然后需要装 Bioconductor 的包的时候先运行一下 source.bio() 就好了。

最后，如果你用 Windows 系统的话，上述文件换成 C:\Program Files\R\R-3.4.2\etc\Rprofile.site 这个文件。

作者：知乎用户
链接：https://www.zhihu.com/question/63601255/answer/360879580
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。
&lt;/code&gt;&lt;/pre&gt;

        
      </description>
    </item>
    
    <item>
      <title>R语言数据库操作</title>
      <link>/blog/cn/2018/04/r_database/</link>
      <pubDate>Wed, 11 Apr 2018 08:53:39 +0000</pubDate>
      
      <guid>/blog/cn/2018/04/r_database/</guid>
      <description>
        

&lt;h1 id=&#34;rsqlite&#34;&gt;RSQLite&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-R&#34;&gt;table_name=&amp;quot;howdo&amp;quot;
colNames=c(&amp;quot;weather&amp;quot;,&amp;quot;food&amp;quot;,&amp;quot;size&amp;quot;,&amp;quot;direction&amp;quot;)

### 1.创建sqlite数据库
con&amp;lt;-dbConnect(SQLite(), &amp;quot;test.db&amp;quot;)

### 2.判断一个表是否存在
if(!dbExistsTable(con,table_name))
{
  ### 3.写入一个表
  table_info=as.data.frame(matrix(character(0),ncol=4),stringsAsFactors = FALSE)
  colnames(table_info)= colNames
  dbWriteTable(con, table_name, table_info)
}
### 4.读表
DF=dbReadTable(con, table_name)
### 5.写表
DF=as.data.frame(t(c(1:4)))
colnames(DF)=colNames
dbWriteTable(con,table_name,DF,append = TRUE)

DF1=matrix(sample(1:100,12),ncol=4)
colnames(DF1)=colNames
dbWriteTable(con,table_name,DF1,append = TRUE)

DF2=dbReadTable(con, table_name)

### 6.查询语句
query1=paste(&amp;quot;select * from&amp;quot;,shQuote(table_name), &amp;quot;where weather=&amp;quot;,shQuote(57),
                     &amp;quot; and food=&amp;quot;,shQuote(26))
tmp=dbGetQuery(con,query1)

### 7.写入指定单元格
query2=paste(&amp;quot;UPDATE&amp;quot;,shQuote(table_name), &amp;quot;SET size=&amp;quot;,shQuote(88888), &amp;quot;where weather=&amp;quot;,
            shQuote(57),&amp;quot;and food=&amp;quot;,shQuote(26))
dbSendQuery(con,query2)

### 8.删除records
query3=paste(&amp;quot;DELETE FROM&amp;quot;,shQuote(table_name), &amp;quot;where weather=&amp;quot;,
            shQuote(57),&amp;quot;and food=&amp;quot;,shQuote(26))
dbSendQuery(con,query3)

###10.最后断开连接
dbDisconnect(con) # 断开连接
&lt;/code&gt;&lt;/pre&gt;

        
      </description>
    </item>
    
    <item>
      <title>mark一下</title>
      <link>/blog/travel/mark_test/</link>
      <pubDate>Mon, 12 Mar 2018 11:30:10 +0000</pubDate>
      
      <guid>/blog/travel/mark_test/</guid>
      <description>
        &lt;p&gt;好久没写了，也就是好久没学了。今天基金提交了。好像琢磨琢磨下一步干什么&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>python——sklearn学习</title>
      <link>/blog/cn/2017/12/python_sklearn/</link>
      <pubDate>Thu, 21 Dec 2017 11:17:40 +0000</pubDate>
      
      <guid>/blog/cn/2017/12/python_sklearn/</guid>
      <description>
        &lt;p&gt;&lt;a href=&#34;http://sklearn.apachecn.org/cn/0.19.0/&#34;&gt;中文文档&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://scikit-learn.org/stable/index.html&#34;&gt;英文文档&lt;/a&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>python学习</title>
      <link>/blog/cn/2017/12/python_study/</link>
      <pubDate>Thu, 21 Dec 2017 11:17:39 +0000</pubDate>
      
      <guid>/blog/cn/2017/12/python_study/</guid>
      <description>
        

&lt;p&gt;&lt;a href=&#34;http://www.runoob.com/python/python-tutorial.html&#34;&gt;入门教程&lt;/a&gt;
&lt;a href=&#34;http://study.163.com/course/courseMain.htm?courseId=378003&#34;&gt;视频教程&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;python-ide环境配置&#34;&gt;python IDE环境配置&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;环境配置&lt;/code&gt; &lt;strong&gt;pycharm+ anaconda&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# 按照anaconda之后 在cmd 命令行创建python解释器
conda create -n py_27 python=2.7 or  conda create -n py_36 python=3.6
# 在cmd命令行激活python解释器
activeate py_27
# 查看该解释器已经安装的包
conda list
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;python-函数查询&#34;&gt;python 函数查询&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;1. 查看模块下所有函数&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;dir(module_name)

from sklearn import datasets
dir(datasets)

[&#39;__all__&#39;, &#39;__builtins__&#39;, &#39;__cached__&#39;, &#39;__doc__&#39;, &#39;__file__&#39;, &#39;__loader__&#39;, &#39;__name__&#39;, &#39;__package__&#39;, &#39;__path__&#39;, &#39;__spec__&#39;, &#39;_svmlight_format&#39;, &#39;base&#39;, &#39;california_housing&#39;, &#39;clear_data_home&#39;, &#39;covtype&#39;, &#39;dump_svmlight_file&#39;, &#39;fetch_20newsgroups&#39;, &#39;fetch_20newsgroups_vectorized&#39;, &#39;fetch_california_housing&#39;, &#39;fetch_covtype&#39;, &#39;fetch_kddcup99&#39;, &#39;fetch_lfw_pairs&#39;, &#39;fetch_lfw_people&#39;, &#39;fetch_mldata&#39;, &#39;fetch_olivetti_faces&#39;, &#39;fetch_rcv1&#39;, &#39;fetch_species_distributions&#39;, &#39;get_data_home&#39;, &#39;kddcup99&#39;, &#39;lfw&#39;, &#39;load_boston&#39;, &#39;load_breast_cancer&#39;, &#39;load_diabetes&#39;, &#39;load_digits&#39;, &#39;load_files&#39;, &#39;load_iris&#39;, &#39;load_linnerud&#39;, &#39;load_mlcomp&#39;, &#39;load_sample_image&#39;, &#39;load_sample_images&#39;, &#39;load_svmlight_file&#39;, &#39;load_svmlight_files&#39;, &#39;load_wine&#39;, &#39;make_biclusters&#39;, &#39;make_blobs&#39;, &#39;make_checkerboard&#39;, &#39;make_circles&#39;, &#39;make_classification&#39;, &#39;make_friedman1&#39;, &#39;make_friedman2&#39;, &#39;make_friedman3&#39;, &#39;make_gaussian_quantiles&#39;, &#39;make_hastie_10_2&#39;, &#39;make_low_rank_matrix&#39;, &#39;make_moons&#39;, &#39;make_multilabel_classification&#39;, &#39;make_regression&#39;, &#39;make_s_curve&#39;, &#39;make_sparse_coded_signal&#39;, &#39;make_sparse_spd_matrix&#39;, &#39;make_sparse_uncorrelated&#39;, &#39;make_spd_matrix&#39;, &#39;make_swiss_roll&#39;, &#39;mlcomp&#39;, &#39;mldata&#39;, &#39;mldata_filename&#39;, &#39;olivetti_faces&#39;, &#39;rcv1&#39;, &#39;samples_generator&#39;, &#39;species_distributions&#39;, &#39;svmlight_format&#39;, &#39;twenty_newsgroups&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;2. 查看模块下特定函数信息&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#方法一：
help(datasets.load_iris)
#方法二：
print(datasets.load_iris.__doc__)

Help on function load_iris in module sklearn.datasets.base:
load_iris(return_X_y=False)
    Load and return the iris dataset (classification).
    
    The iris dataset is a classic and very easy multi-class classification
    dataset.
    =================   ==============
    Classes                          3
    Samples per class               50
    Samples total                  150
    Dimensionality                   4
    Features            real, positive
    =================   ==============
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;基本语法&#34;&gt;基本语法&lt;/h1&gt;

&lt;h2 id=&#34;1-认识python&#34;&gt;1. 认识python&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#实例(Python 2.0+)
#!/usr/bin/python
print &amp;quot;Hello, World!&amp;quot;;

#实例(Python 3.0+)
#!/usr/bin/python3
print(&amp;quot;Hello, World!&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;2-python-脚本&#34;&gt;2. python 脚本&lt;/h2&gt;

&lt;p&gt;所有 Python 文件将以 .py 为扩展名。用 $ python *.py 执行脚本。&lt;/p&gt;

&lt;h2 id=&#34;3-python语法&#34;&gt;3. python语法&lt;/h2&gt;

&lt;p&gt;1.Python 的代码块不使用大括号 {} 来控制类，函数以及其他逻辑判断。&lt;/p&gt;

&lt;p&gt;python 最具特色的就是用缩进来写模块。缩进的空白数量是可变的，但是所有代码块语句必须包含相同的缩进空白数量，这个必须严格执行。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;if True:
  print &amp;quot;True&amp;quot;
else:
  print &amp;quot;False&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.xx&lt;/p&gt;

&lt;h3 id=&#34;3-1-python函数&#34;&gt;3.1 python函数&lt;/h3&gt;

&lt;p&gt;语法&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def functionname( parameters ):
   &amp;quot;函数_文档字符串&amp;quot;
   function_suite
   return [expression]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;示例&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/python
# -*- coding: UTF-8 -*-
 
# 定义函数
def printme( str ):
   &amp;quot;打印任何传入的字符串&amp;quot;
   print str;
   return;
# 调用函数
printme(&amp;quot;我要调用用户自定义函数!&amp;quot;);
printme(&amp;quot;再次调用同一函数&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;3-2-python-模块&#34;&gt;3.2 Python 模块&lt;/h3&gt;

&lt;p&gt;Python 模块(Module)，是一个 Python 文件，以 .py 结尾，包含了 Python 对象定义和Python语句。&lt;/p&gt;

&lt;p&gt;定义support.py 模块：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def print_func( par ):
   print &amp;quot;Hello : &amp;quot;, par
   return
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;模块的引入&#34;&gt;模块的引入&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/python
# -*- coding: UTF-8 -*-
# 导入模块
import support
# 现在可以调用模块里包含的函数了
# 调用方法：模块名.函数名
support.print_func(&amp;quot;Runoob&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;from-import-语句&#34;&gt;From…import 语句&lt;/h4&gt;

&lt;p&gt;Python 的 from 语句让你从模块中导入一个指定的部分到当前命名空间中。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from fib import fibonacci

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;3-3-常用语句&#34;&gt;3.3 常用语句&lt;/h3&gt;

&lt;h4 id=&#34;读文件&#34;&gt;读文件&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;try:
    f = open(&#39;/path/to/file&#39;, &#39;r&#39;)
    print(f.read())
finally:
    if f:
        f.close()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#with语句来自动帮我们调用close()方法
with open(&#39;/path/to/file&#39;, &#39;r&#39;) as f:
    print(f.read())
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;for line in f.readlines():
    print(line.strip()) # 把末尾的&#39;\n&#39;删掉
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;写文件&#34;&gt;写文件&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;with open(&#39;/Users/michael/test.txt&#39;, &#39;w&#39;) as f:
    f.write(&#39;Hello, world!&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;3-4-常规语法&#34;&gt;3.4  常规语法&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;import&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from...import
如 from A import b,相当于
import A
b=A.b
在此过程中有一个隐含的赋值的过程

import A as B,给予A库一个B的别称，帮助记忆
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;原始字符串&lt;/strong&gt;
在单引号或者双引号 前面加一个字符 &lt;strong&gt;r&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;运算符&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;a=10
a+=1  等价于 a=a+1=11

/  除法
// 除法取整
% 取余
** 幂运算  3**2=9
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;三元操作符&lt;/strong&gt;  small =x if x &amp;lt;y else y 条件真为x, 假为y&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;断言&lt;/strong&gt;   assert 3&amp;gt;4&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;循环&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1. for 
for i in range(1,8):  注意冒号

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;break&lt;/strong&gt;跳出当前循环&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;continue&lt;/strong&gt; 终止本轮循环，开启下一轮循环（如果循环条件为真）&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;range()函数&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;range([start,]stop[,step=1])&lt;/p&gt;

&lt;p&gt;list(range(5))&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;列表&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;menber=[&amp;quot;a&amp;quot;,&amp;quot;b&amp;quot;,&amp;quot;c&amp;quot;] 单一类型列表
mix=[1,&amp;quot;a&amp;quot;,3.14,[a,b,c]] 混合类型列表

empty=[]    创建空列表
empty.append(&amp;quot;小甲鱼&amp;quot;)  向列表添加单一元素
empty.extend([a,b])     向列表添加另外一个列表
empty.insert(0,&amp;quot;牡丹&amp;quot;)
empty.remove(&amp;quot;牡丹&amp;quot;)
del empty 删除
pop()从列表中删除最后一个元素并弹出
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;操作符&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;列表比较大小 只比较第一个元素
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;dir(list)&lt;/strong&gt; 列出list的所有内置函数&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;numpy moudle&lt;/strong&gt; API&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy-1.13.0/genindex.html&#34;&gt;https://docs.scipy.org/doc/numpy-1.13.0/genindex.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;strong&gt;call&lt;/strong&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;变量:
1.  前带_的变量:  标明是一个私有变量, 只用于标明, 外部类还是可以访问到这个变量
2.  前带两个_ ,后带两个_ 的变量:  标明是内置变量,
3.  大写加下划线的变量:  标明是 不会发生改变的全局变量
函数:
1. 前带_的变量: 标明是一个私有函数, 只用于标明,
2.  前带两个_ ,后带两个_ 的函数:  标明是特殊函数
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Python特殊语法：filter、map、reduce、lambda [转]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Python内置了一些非常有趣但非常有用的函数，充分体现了Python的语言魅力！&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;filter(function, sequence)&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;对sequence中的item依次执行function(item)，将执行结果为True的item组成一个List/String/Tuple（取决于sequence的类型）返回：
&amp;gt;&amp;gt;&amp;gt; def f(x): return x % 2 != 0 and x % 3 != 0 
&amp;gt;&amp;gt;&amp;gt; filter(f, range(2, 25)) 
[5, 7, 11, 13, 17, 19, 23]
&amp;gt;&amp;gt;&amp;gt; def f(x): return x != &#39;a&#39; 
&amp;gt;&amp;gt;&amp;gt; filter(f, &amp;quot;abcdef&amp;quot;) 
&#39;bcdef&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;map(function, sequence)&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;对sequence中的item依次执行function(item)，见执行结果组成一个List返回：
&amp;gt;&amp;gt;&amp;gt; def cube(x): return x*x*x 
&amp;gt;&amp;gt;&amp;gt; map(cube, range(1, 11)) 
[1, 8, 27, 64, 125, 216, 343, 512, 729, 1000]
&amp;gt;&amp;gt;&amp;gt; def cube(x) : return x + x 
... 
&amp;gt;&amp;gt;&amp;gt; map(cube , &amp;quot;abcde&amp;quot;) 
[&#39;aa&#39;, &#39;bb&#39;, &#39;cc&#39;, &#39;dd&#39;, &#39;ee&#39;]
另外map也支持多个sequence，这就要求function也支持相应数量的参数输入：
&amp;gt;&amp;gt;&amp;gt; def add(x, y): return x+y 
&amp;gt;&amp;gt;&amp;gt; map(add, range(8), range(8)) 
[0, 2, 4, 6, 8, 10, 12, 14]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;reduce(function, sequence, starting_value)&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;对sequence中的item顺序迭代调用function，如果有starting_value，
还可以作为初始值调用，例如可以用来对List求和：
&amp;gt;&amp;gt;&amp;gt; def add(x,y): return x + y 
&amp;gt;&amp;gt;&amp;gt; reduce(add, range(1, 11)) 
55 （注：1+2+3+4+5+6+7+8+9+10）
&amp;gt;&amp;gt;&amp;gt; reduce(add, range(1, 11), 20) 
75 （注：1+2+3+4+5+6+7+8+9+10+20）
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;lambda&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;：这是Python支持一种有趣的语法，它允许你快速定义单行的最小函数，
类似与C语言中的宏，这些叫做lambda的函数，
是从LISP借用来的，可以用在任何需要函数的地方： 
&amp;gt;&amp;gt;&amp;gt; g = lambda x: x * 2 
&amp;gt;&amp;gt;&amp;gt; g(3) 
6 
&amp;gt;&amp;gt;&amp;gt; (lambda x: x * 2)(3) 
6
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;我们也可以把filter map reduce 和lambda结合起来用，函数就可以简单的写成一行。
例如
kmpathes = filter(lambda kmpath: kmpath,                  
map(lambda kmpath: string.strip(kmpath),
string.split(l, &#39;:&#39;)))              
看起来麻烦，其实就像用语言来描述问题一样，非常优雅。
对 l 中的所有元素以&#39;:&#39;做分割，得出一个列表。对这个列表的每一个元素做字符串strip，形成一个列表。对这个列表的每一个元素做直接返回操作(这个地方可以加上过滤条件限制)，最终获得一个字符串被&#39;:&#39;分割的列表，列表中的每一个字符串都做了strip，并可以对特殊字符串过滤。

--
lambda表达式返回一个函数对象
例子：
func = lambda x,y:x+y
func相当于下面这个函数
def func(x,y):
    return x+y
 
注意def是语句而lambda是表达式
下面这种情况下就只能用lambda而不能用def
[(lambda x:x*x)(x) for x in range(1,11)]
 
map，reduce，filter中的function都可以用lambda表达式来生成！
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;map(function,sequence)&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;把sequence中的值当参数逐个传给function，返回一个包含函数执行结果的list。
如果function有两个参数，即map(function,sequence1,sequence2)。
例子：
求1*1,2*2,3*3,4*4
map(lambda x:x*x,range(1,5))
返回值是[1,4,9,16]
 
reduce(function,sequence)
function接收的参数个数只能为2
先把sequence中第一个值和第二个值当参数传给function，再把function的返回值和第三个值当参数传给
function，然后只返回一个结果。
 
例子：
求1到10的累加
reduce(lambda x,y:x+y,range(1,11))
返回值是55。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;filter(function,sequence)&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;function的返回值只能是True或False
把sequence中的值逐个当参数传给function，如果function(x)的返回值是True，
就把x加到filter的返回值里面。一般来说filter的返回值是list，
特殊情况如sequence是string或tuple，则返回值按照sequence的类型。
 
例子：
找出1到10之间的奇数
filter(lambda x:x%2!=0,range(1,11))
返回值
[1,3,5,7,9]
 
如果sequence是一个string
filter(lambda x:len(x)!=0,&#39;hello&#39;)返回&#39;hello&#39;
filter(lambda x:len(x)==0,&#39;hello&#39;)返回&#39;&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;定义：zip([iterable, &amp;hellip;])&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;zip()是Python的一个内建函数，它接受一系列可迭代的对象作为参数，将对象中对应的元素打包成一个个tuple（元组），然后返回由这些tuples组成的list（列表）。若传入参数的长度不等，则返回list的长度和参数中长度最短的对象相同。利用*号操作符，可以将list unzip（解压），看下面的例子就明白了：

&amp;gt;&amp;gt;&amp;gt; a = [1,2,3]
&amp;gt;&amp;gt;&amp;gt; b = [4,5,6]
&amp;gt;&amp;gt;&amp;gt; c = [4,5,6,7,8]
&amp;gt;&amp;gt;&amp;gt; zipped = zip(a,b)
[(1, 4), (2, 5), (3, 6)]
&amp;gt;&amp;gt;&amp;gt; zip(a,c)
[(1, 4), (2, 5), (3, 6)]
&amp;gt;&amp;gt;&amp;gt; zip(*zipped)
[(1, 2, 3), (4, 5, 6)]
&lt;/code&gt;&lt;/pre&gt;

        
      </description>
    </item>
    
    <item>
      <title>深度学习Tensorflow</title>
      <link>/blog/cn/2017/12/deeplearning/</link>
      <pubDate>Wed, 20 Dec 2017 21:04:42 +0000</pubDate>
      
      <guid>/blog/cn/2017/12/deeplearning/</guid>
      <description>
        &lt;p&gt;&lt;a href=&#34;https://jizhi.im/blog/post/gpu-p6&#34;&gt;学习教程&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://study.163.com/course/courseMain.htm?courseId=1003223001&#34;&gt;斯坦福李飞飞&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.tensorfly.cn/&#34;&gt;TensorFlow中文社区&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy-1.13.0/genindex.html&#34;&gt;numpy API&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.csdn.net/yunpiao123456/article/details/52437794&#34;&gt;卷积神经网络1&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.csdn.net/hjimce/article/details/47323463&#34;&gt;卷积神经网络2&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap&#34;&gt;Roadmap&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/exacity/deeplearningbook-chinese&#34;&gt;AI圣经&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.zybuluo.com/hanbingtao/note/433855&#34;&gt;零基础入门深度学习&lt;/a&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>决策树</title>
      <link>/blog/cn/2017/11/decision_tree/</link>
      <pubDate>Tue, 21 Nov 2017 09:26:01 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/decision_tree/</guid>
      <description>
        

&lt;h1 id=&#34;特征选择问题&#34;&gt;特征选择问题&lt;/h1&gt;

&lt;p&gt;选择信息增益和信息增益比大的特征&lt;/p&gt;

&lt;h1 id=&#34;信息增益-互信息&#34;&gt;信息增益（互信息）&lt;/h1&gt;

&lt;p&gt;表示得知特征X的信息而使得类Y的信息的不确定性减少的程度。&lt;/p&gt;

&lt;h4 id=&#34;信息熵&#34;&gt;信息熵&lt;/h4&gt;

&lt;p&gt;熵越大，随机变量的不确定性就越大。&lt;/p&gt;

&lt;h4 id=&#34;条件熵&#34;&gt;条件熵&lt;/h4&gt;

&lt;p&gt;随机变量X给定条件下随机变量Y的条件熵 H(Y|X)定义为X给定条件下Y的条件概率分布的熵对X的数学期望。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;信息熵和条件熵中概率由数据估计得到，所对应的熵与条件熵分别称为经验熵和经验条件熵&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&#34;信息增益比&#34;&gt;信息增益比&lt;/h1&gt;

&lt;p&gt;信息增益与训练数据集经验熵的比值&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>基因组版本对应关系</title>
      <link>/blog/cn/2017/11/genome_version/</link>
      <pubDate>Mon, 13 Nov 2017 08:52:07 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/genome_version/</guid>
      <description>
        

&lt;p&gt;&lt;a href=&#34;http://www.bio-info-trainee.com/1469.html&#34;&gt;原文&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;hg19(UCSC)，GRCH37(NCBI)和Ensembl75(ENSEMBL)是三种国际生物信息学数据库资源收集存储单各自发布的基因组信息。&lt;/p&gt;

&lt;p&gt;hg系列，hg18/19/38是目前使用频率最高的基因组。hg38是目前的最新版本。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;基因组各种版本对应关系&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;GRCh36 (hg18): ENSEMBL release_52.&lt;/li&gt;
&lt;li&gt;GRCh37 (hg19): ENSEMBL release_59/61/64/68/69/75.&lt;/li&gt;
&lt;li&gt;GRCh38 (hg38): ENSEMBL release_76/77/78/80/81/82.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;ucsc基因组下载&#34;&gt;UCSC基因组下载&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;http://hgdownload.cse.ucsc.edu/goldenPath/mm10/bigZips/chromFa.tar.gz
http://hgdownload.cse.ucsc.edu/goldenPath/mm9/bigZips/chromFa.tar.gz
http://hgdownload.cse.ucsc.edu/goldenPath/hg19/bigZips/chromFa.tar.gz
http://hgdownload.cse.ucsc.edu/goldenPath/hg38/bigZips/chromFa.tar.gz
# 或者用shell脚本指定下载的染色体号
for i in $(seq 1 22) X Y M;
do echo $i;
  wget http://hgdownload.cse.ucsc.edu/goldenPath/hg19/chromosomes/chr${i}.fa.gz;done
  gunzip *.gz
  for i in $(seq 1 22) X Y M;
  do cat chr${i}.fa &amp;gt;&amp;gt; hg19.fasta;
done
rm -fr chr*.fasta
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;gtf注释文件&#34;&gt;GTF注释文件&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;NCBI&lt;/strong&gt;：最新版（hg38）&lt;/p&gt;

&lt;p&gt;● &lt;a href=&#34;ftp://ftp.ncbi.nih.gov/genomes/H_sapiens/GFF/&#34;&gt;ftp://ftp.ncbi.nih.gov/genomes/H_sapiens/GFF/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;其它版本&lt;/p&gt;

&lt;p&gt;● &lt;a href=&#34;ftp://ftp.ncbi.nlm.nih.gov/genomes/Homo_sapiens/ARCHIVE/&#34;&gt;ftp://ftp.ncbi.nlm.nih.gov/genomes/Homo_sapiens/ARCHIVE/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ensembl&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;● &lt;a href=&#34;ftp://ftp.ensembl.org/pub/release-75/gtf/homosapiens/Homosapiens.GRCh37.75.gtf.gz&#34;&gt;ftp://ftp.ensembl.org/pub/release-75/gtf/homosapiens/Homosapiens.GRCh37.75.gtf.gz&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;变化上面链接中的release就可以拿到所有版本信息&lt;/p&gt;

&lt;p&gt;● &lt;a href=&#34;ftp://ftp.ensembl.org/pub/&#34;&gt;ftp://ftp.ensembl.org/pub/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;UCSC&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;本身需要一系列参数：
  1. Navigate to http://genome.ucsc.edu/cgi-bin/hgTables
  2. Select the following options:
  3. clade: Mammal
  4. genome: Human
  5. assembly: Feb. 2009 (GRCh37/hg19)
  6. group: Genes and Gene Predictions
  7. track: UCSC Genes
  8. table: knownGene
  9. region: Select &amp;quot;genome&amp;quot; for the entire genome.
  10. output format: GTF - gene transfer format
  11. output file: enter a file name to save your results to a file, or leave blank to display results in the browser
  12. Click &#39;get output&#39;.
&lt;/code&gt;&lt;/pre&gt;

        
      </description>
    </item>
    
    <item>
      <title>SAM文件与SAMtools</title>
      <link>/blog/cn/2017/11/sam_samtools/</link>
      <pubDate>Sun, 12 Nov 2017 09:32:54 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/sam_samtools/</guid>
      <description>
        

&lt;h1 id=&#34;sam&#34;&gt;SAM&lt;/h1&gt;

&lt;p&gt;SAM输出的结果中每一行都包括十二项通过Tab分隔&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FCC0YG3ACXX:2:1103:1572:139769#GCTTAATG 99  chr10   60001   0   90M =   60390   479 GAATTCCTTGAGGCCTAAATGCATCGGGGTGCTCTGGTTTTGTTGTTGTTATTTCTGAATGACATTTACTTTGGTGCTCTTTATTTTGCG  CCCFFFFFHHHHHJJJJJJJJIJJJJJJJ?HHGIJJJBFHIJIJIDHIHIEHJJIJJIJJJHHGHHHFFFFFFEDCEEECCDDDDEECDD  XT:A:R  NM:i:0  SM:i:0  AM:i:0  X0:i:2  X1:i:0  XM:i:0  XO:i:0  XG:i:0  MD:Z:90 XA:Z:chr18,+14415,90M,0;    RG:Z:120618_I245_FCC0YG3ACXX_L2_SZAXPI010030-30
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;(1)FCC0YG3ACXX:2:1103:1572:139769#GCTTAATG
(2)99
(3)chr10
(4)60001
(5)0
(6)90M
(7)=
(8)60390
(9)479
(10)GAATTCCTTGAGGCCTAAATGCATCGGGGTGCTCTGGTTTTGTTGTTGTTATTTCTGAATGACATTTACTTTGGTGCTCTTTATTTTGCG
(11)CCCFFFFFHHHHHJJJJJJJJIJJJJJJJ?HHGIJJJBFHIJIJIDHIHIEHJJIJJIJJJHHGHHHFFFFFFEDCEEECCDDDDEECDD
(12)XT:A:R  NM:i:0  SM:i:0  AM:i:0  X0:i:2  X1:i:0  XM:i:0  XO:i:0  XG:i:0  MD:Z:90 XA:Z:chr18,+14415,90M,0;    RG:Z:120618_I245_FCC0YG3ACXX_L2_SZAXPI010030-30


(1)read的名字
(2)Flag 为各个标志的和
(3)比对到的染色体号
(4)第一个比对上的碱基所在位置
(5)质量值 
6. CIGAR  如果CIGAR是*，这个才是判断左右端是否匹配失败的标准
7. mate比对上的染色体号，如果是“=”，则表示在同一条染色体上，*表示没有比对上
8. mate第一个比对上的碱基所在位置 
9. 该read和mate的距离(估计出的片段的长度，当mate 序列位于本序列上游时该值为负值)
10. 序列 
11. 序列对应的质量值 (ASCII码格式)
12. 标记
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(1)如果PE reads的左右两端均没有比对成功，那么第3,6,7列都是*，4，5，8，9都是0，第2列flag只有77,141这两种情况。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;77代表PE,而且PE的两条reads都是unmanned的，&lt;/li&gt;
&lt;li&gt;141跟77一样，只是它们分别指代unmanned的PE的reads的两端,&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(2) 如果是左右两端reads只有一个比对成功，另一个reads没有比对上.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;不管是左端还是右端，第3列都是有染色体的，(第7列是=号[好像不对])，但这并不能说明左端跟右端有着同样的比对结果。而第6列CIGAR是*，这个才是判断左右端是否匹配失败的标准。An unmapped segment without coordinate has a * at this field. However, an unmapped segment may also have an ordinary coordinate such that it can be placed at a desired position after sorting. If RNAME is *, no assumptions can be made about POS and CIGAR. (&lt;a href=&#34;https://samtools.github.io/hts-specs/SAMv1.pdf&#34;&gt;https://samtools.github.io/hts-specs/SAMv1.pdf&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;这也就是我为什么没有发现第7列有染色体，第3列是*号的reads。即使PE reads的右端匹配，左端未匹配，它只会把这个read比对的染色体写在第3列，而不是第7列！所以说要想探究它是左端还是右端未比对成功，得看flag。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;flag-标志&#34;&gt;Flag 标志&lt;/h4&gt;

&lt;p&gt;Flag值解析 &lt;a href=&#34;https://broadinstitute.github.io/picard/explain-flags.html&#34;&gt;https://broadinstitute.github.io/picard/explain-flags.html&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1  序列是一对序列中的一个&lt;/li&gt;
&lt;li&gt;2  比对结果是一个pair-end比对的末端&lt;/li&gt;
&lt;li&gt;4  没有找到位点&lt;/li&gt;
&lt;li&gt;8  这个序列是pair中的一个但是没有找到位点&lt;/li&gt;
&lt;li&gt;16  在这个比对上的位点，序列与参考序列反向互补&lt;/li&gt;
&lt;li&gt;32  这个序列在pair-end中的mate序列与参考序列反向互补&lt;/li&gt;
&lt;li&gt;64 序列是 mate 1&lt;/li&gt;
&lt;li&gt;128 序列是 mate 2&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;质量值&#34;&gt;质量值&lt;/h4&gt;

&lt;p&gt;因工具而异。质量值越高这个比对越可信，如果质量值为0，可能是该序列在参考基因组有多种定位的可能性。&lt;/p&gt;

&lt;h4 id=&#34;cigar&#34;&gt;CIGAR&lt;/h4&gt;

&lt;p&gt;如37M1D2M1I，这段字符的意思是37个匹配，1个参考序列上的删除，2个匹配，1个参考序列上的插入。M代表的是alignment match(可以是错配)&lt;/p&gt;

&lt;h1 id=&#34;samtools&#34;&gt;SAMtools&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://taoshengxu.github.io/DocumentGit/pdf/samtools常用命令详解.pdf&#34;&gt;SAMtools使用手册&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;SAM（sequence Alignment/mapping)数据格式是目前高通量测序中存放比对数据的标准格式，当然他可以用于存放未比对的数据。&lt;/p&gt;

&lt;p&gt;主要功能有：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;samtools view : BAM-SAM/SAM-BAM 转换和提取部分比对&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;samtools sort : 比对排序&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;samtools index: 索引排序比对&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;samtools merge: 聚合多个排序比对&lt;/li&gt;
&lt;li&gt;samtools faidx: 建立FASTA索引，提取部分序列&lt;/li&gt;
&lt;li&gt;samtools tview: 文本格式查看序列&lt;/li&gt;
&lt;li&gt;samtools pileup: 产生基于位置的结果和 consensus/indel calling&lt;/li&gt;
&lt;/ul&gt;

        
      </description>
    </item>
    
    <item>
      <title>Jimmy 直播基因组学习笔记</title>
      <link>/blog/cn/2017/11/genomic_live_streaming/</link>
      <pubDate>Fri, 10 Nov 2017 20:34:59 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/genomic_live_streaming/</guid>
      <description>
        

&lt;p&gt;&lt;strong&gt;教程&lt;/strong&gt; &lt;a href=&#34;http://www.biotrainee.com/thread-1376-1-1.html&#34;&gt;Jimmy直播我的基因组分析 - 目录&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/RNASeq_WES.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;下载hg19基因组&#34;&gt;下载hg19基因组&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;cd /data/reference
mkdir -p genome/hg19  &amp;amp;&amp;amp; cd genome/hg19
nohup wget http://hgdownload.cse.ucsc.edu/goldenPath/hg19/bigZips/chromFa.tar.gz &amp;amp;
tar zvfx chromFa.tar.gz
cat *.fa &amp;gt; hg19.fa
rm chr*.fa
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;fastq-sam-bam&#34;&gt;fastq-sam-bam&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;ls *gz |xargs ~/biosoft/fastqc/FastQC/fastqc -t 10

for i in $(seq 1 6) ;do (nohup bwa  mem -t 5 -M /data/reference/index/bwa/hg19  KPGP-00001_L${i}_R1.fq.gz KPGP-00001_L${i}_R2.fq.gz 1&amp;gt;KPGP-00001_L${i}.sam 2&amp;gt;KPGP-00001_L${i}.bwa.align.log &amp;amp;);done

for i in $(seq 1 6) ;do (nohup samtools sort -@ 5 -o KPGP-00001_L${i}.sorted.bam  KPGP-00001_L${i}.sam &amp;amp;);done

for i in $(seq 1 6) ;do (nohup samtools index KPGP-00001_L${i}.sorted.bam &amp;amp;);done
samtools merge KPGP-00001.merge.bam *.sorted.bam
samtools sort -@ 10 -O bam -o KPGP-00001.sorted.merge.bam  KPGP-00001.merge.bam
samtools index  KPGP-00001.sorted.merge.bam
for i in $(seq 1 6) ;do ( samtools flagstat KPGP-00001_L${i}.sorted.bam &amp;gt;KPGP-00001_L${i}.flagstat.txt );done
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;根据gtf格式的基因注释文件得到人所有基因的染色体坐标&#34;&gt;根据gtf格式的基因注释文件得到人所有基因的染色体坐标&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.biotrainee.com/thread-472-1-1.html&#34;&gt;原文&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir -p ~/reference/gtf/gencode
cd  ~/reference/gtf/gencode
## https://www.gencodegenes.org/releases/current.html
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/gencode.v25.2wayconspseudos.gtf.gz
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/gencode.v25.long_noncoding_RNAs.gtf.gz 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/gencode.v25.polyAs.gtf.gz 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/gencode.v25.annotation.gtf.gz 

## https://www.gencodegenes.org/releases/25lift37.html 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/GRCh37_mapping/gencode.v25lift37.annotation.gtf.gz 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/GRCh37_mapping/gencode.v25lift37.metadata.HGNC.gz 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/GRCh37_mapping/gencode.v25lift37.metadata.EntrezGene.gz 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/GRCh37_mapping/gencode.v25lift37.metadata.RefSeq.gz 
 
zcat  gencode.v25.long_noncoding_RNAs.gtf.gz |perl -alne &#39;{next unless $F[2] eq &amp;quot;gene&amp;quot; ;/gene_name \&amp;quot;(.*?)\&amp;quot;;/; print &amp;quot;$F[0]\t$F[3]\t$F[4]\t$1&amp;quot; }&#39; &amp;gt;lncRNA.hg38.position
zcat  gencode.v25.2wayconspseudos.gtf.gz     |perl -alne &#39;{next unless $F[2] eq &amp;quot;transcript&amp;quot; ;/gene_name \&amp;quot;(.*?)\&amp;quot;;/; print &amp;quot;$F[0]\t$F[3]\t$F[4]\t$1&amp;quot; }&#39; &amp;gt;pseudos.hg38.position
zcat  gencode.v25.annotation.gtf.gz| grep   protein_coding |perl -alne &#39;{next unless $F[2] eq &amp;quot;gene&amp;quot; ;/gene_name \&amp;quot;(.*?)\&amp;quot;;/; print &amp;quot;$F[0]\t$F[3]\t$F[4]\t$1&amp;quot; }&#39; &amp;gt;protein_coding.hg38.position
zcat  gencode.v25.annotation.gtf.gz|perl -alne &#39;{next unless $F[2] eq &amp;quot;gene&amp;quot; ;/gene_name \&amp;quot;(.*?)\&amp;quot;;/; print &amp;quot;$F[0]\t$F[3]\t$F[4]\t$1&amp;quot; }&#39; &amp;gt;allGene.hg38.position
 
zcat  gencode.v25lift37.annotation.gtf.gz | grep   protein_coding |perl -alne &#39;{next unless $F[2] eq &amp;quot;gene&amp;quot; ;/gene_name \&amp;quot;(.*?)\&amp;quot;;/; print &amp;quot;$F[0]\t$F[3]\t$F[4]\t$1&amp;quot; }&#39; &amp;gt;protein_coding.hg19.position
zcat  gencode.v25lift37.annotation.gtf.gz | perl -alne &#39;{next unless $F[2] eq &amp;quot;gene&amp;quot; ;/gene_name \&amp;quot;(.*?)\&amp;quot;;/; print &amp;quot;$F[0]\t$F[3]\t$F[4]\t$1&amp;quot; }&#39; &amp;gt;allGene.hg19.position
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;有个很严重的问题，gencode里面的数据有着HAVANA和ENSEMBL的区别，尤其是在hg38里面，需要区别对待！具体见：&lt;a href=&#34;http://www.bio-info-trainee.com/1991.html&#34;&gt;http://www.bio-info-trainee.com/1991.html&lt;/a&gt; 的解释.&lt;/p&gt;

&lt;h1 id=&#34;call-感兴趣的基因-variation&#34;&gt;Call 感兴趣的基因 variation&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.bio-info-trainee.com/2013.html&#34;&gt;原文&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;grep H3F3A /data/reference/gtf/gencode/protein_coding.hg19.position
samtools mpileup -r chr1:226249552-226259702  -ugf /data/reference/genome/hg19/hg19.fa *sorted.bam | bcftools call -vmO z -o H3F3A.vcf.gz
gunzip H3F3A.vcf.gz

/data/biosoft/annovar/convert2annovar.pl -format vcf4old H3F3A.vcf &amp;gt;H3F3A.annovar
/data/biosoft/annovar/annotate_variation.pl -buildver hg19 --geneanno --outfile H3F3A.anno H3F3A.annovar /data/biosoft/annovar/humandb/

#/data/biosoft/annovar/annotate_variation.pl --downdb refGene /data/biosoft/annovar/humandb

/data/biosoft/annovar/annotate_variation.pl -buildver hg19 --dbtype refGene --geneanno --outfile H3F3A.anno H3F3A.annovar /data/biosoft/annovar/humandb/
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;获取感兴趣的基因坐标&#34;&gt;获取感兴趣的基因坐标&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;grep H3F3A /data/reference/gtf/gencode/protein_coding.hg19.position &amp;gt;&amp;gt; key.list.txt
grep HLA-DQ /data/reference/gtf/gencode/protein_coding.hg19.position &amp;gt;&amp;gt; key.list.txt
grep AVPR1 /data/reference/gtf/gencode/protein_coding.hg19.position &amp;gt;&amp;gt; key.list.txt
grep IRX3 /data/reference/gtf/gencode/protein_coding.hg19.position &amp;gt;&amp;gt; key.list.txt
grep IRX5 /data/reference/gtf/gencode/protein_coding.hg19.position &amp;gt;&amp;gt; key.list.txt
grep GLI3 /data/reference/gtf/gencode/protein_coding.hg19.position &amp;gt;&amp;gt; key.list.txt
grep PAX1 /data/reference/gtf/gencode/protein_coding.hg19.position &amp;gt;&amp;gt; key.list.txt
grep RUNX2 /data/reference/gtf/gencode/protein_coding.hg19.position &amp;gt;&amp;gt; key.list.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;批量提取我们感兴趣的基因的变异情况&#34;&gt;批量提取我们感兴趣的基因的变异情况&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cat key.list.txt |while read id;
do
chr=$(echo $id |cut -d&amp;quot; &amp;quot; -f 1|sed &#39;s/chr//&#39; )
start=$(echo $id |cut -d&amp;quot; &amp;quot; -f 2 )
end=$(echo $id |cut -d&amp;quot; &amp;quot; -f 3 )
gene=$(echo $id |cut -d&amp;quot; &amp;quot; -f 4 )
echo $chr:$start-$end  $gene
samtools mpileup -r  $chr:$start-$end   -ugf /data/reference/genome/hg19/hg19.fa KPGP-00001.sorted.merge.bam | bcftools call -vmO z -o $gene.vcf.gz
done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;前面我们说到有研究表明STAT4上的rs7574865和HLA-DQ的rs9275319是国人群中乙型肝炎病毒（HBV）相关肝细胞癌（HCC）遗传易感基因，那么我们很容易去dbSNP数据库或者我最近强烈推荐 的&lt;a href=&#34;https://www.snpedia.com/index.php/Rs7574865&#34;&gt;Snpedia&lt;/a&gt;数据库&lt;a href=&#34;http://www.bio-info-trainee.com/2100.html&#34;&gt;吐血推荐snpedia数据库，非常丰富的snp信息记录&lt;/a&gt;里面找到它的坐标。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;6   32666295 :Rs9275319--HLA-DQ
2   191964633 :Rs7574865--STAT4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;然后我检查了我刚才call到的variation文件，&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;zcat STAT4.vcf.gz |grep -w 191964633 显示为空。
zcat HLA-DQ* |grep 32666295  也是空。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;哈哈，我完美的错过了这两个易感位点！！！！谢天谢地！！！&lt;/p&gt;

&lt;h1 id=&#34;bam文件给按照染色体给分割&#34;&gt;bam文件给按照染色体给分割&lt;/h1&gt;

&lt;p&gt;按照染色体（chr1-chr22,chrX,chrY,chrMT）&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bamtools split -in KPGP-00001.sorted.merge.bam -reference  
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;提取未比对的测序数据&#34;&gt;提取未比对的测序数据&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;samtools view -f4 KPGP-00001.sorted.merge.bam &amp;gt; KPGP-00001.sorted.merge.unmapped.sam #more fast,  or
# samtools view sample.bam |perl -alne &#39;{print if $F[2] eq &amp;quot;*&amp;quot; or $F[5] eq &amp;quot;*&amp;quot; }&#39; &amp;gt; sample.unmapped.sam

#提前未比对成功的测序数据(可以分成3类，仅reads1，仅reads2，和两端reads都没有比对成功)
#小写的f是提取，大写的F是过滤
samtools view -u -f 4 -F 264 alignments.bam  &amp;gt; tmps1.bam #仅reads1
samtools view -u -f 8 -F 260 alignments.bam  &amp;gt; tmps2.bam #仅reads2
samtools view -u -f 12 -F 256 alignments.bam &amp;gt; tmps3.bam #两端reads都没有比对成功
samtools merge -u - tmps[123].bam | samtools sort -n - unmapped
bamToFastq -bam unmapped.bam -fq1 unmapped_reads1.fastq -fq2 unmapped_reads2.fastq

#统计一下未比对成功的reads有多少
cut -f 3,6 KPGP-00001.sorted.merge.unmapped.sam |sort |uniq -c &amp;gt;KPGP-00001.sorted.merge.unmapped.counts 

&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;提取左右端测序数据比对到不同染色体的pe-reads&#34;&gt;提取左右端测序数据比对到不同染色体的PE reads&lt;/h1&gt;

&lt;p&gt;左右端测序数据比对到不同染色体的情况，比较有意义，可能是融合基因，也可能是基因之间本来就相似性很大。
三种具有代表性的肿瘤融合基因BCR-ABL、SLC45A3-ELK4 和PAX3-FOXO1&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;融合基因&lt;/strong&gt;（英语：Fusion gene）是指两个基因的全部或一部分的序列相互融合为一个新的基因的过程。其有可能是染色体易位、中间缺失或染色体倒置所致的结果.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;samtools view KPGP-00001.sorted.merge.bam | perl -alne &#39;{print if $F[6] ne &amp;quot;=&amp;quot;}&#39;  &amp;gt;unpaired.sam 
cut -f 3,7 unpaired.sam |sort |uniq -c
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;pcr-duplication&#34;&gt;PCR duplication&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.sina.com.cn/s/blog_69e75efd0102wu57.html&#34;&gt;http://blog.sina.com.cn/s/blog_69e75efd0102wu57.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;设一个基因组有A、B两个片段，PCR后得到无论多少条reads，比如nA+mB条，在数据分析的时候，都只保留1条A和1条B（unique reads）用于组装，而去掉(n-1)条A和(m-1)条B。共有(n-1)条A和(m-1)条B被当成duplicatedreads看待，尽管它们是正常PCR的正常产物。&lt;/p&gt;

&lt;p&gt;那么为什么要去除这个duplication呢？主要是因为在call snp的时候，如果某个变异位点的变异碱基都是来自于PCR重复，而我们却认为它深度足够判断是真的变异位点，这个结论其实有很大可能是假阳性。&lt;/p&gt;

&lt;h1 id=&#34;覆盖度详细探究&#34;&gt;覆盖度详细探究&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;samtools flagstat KPGP-00001.sorted.merge.bam

#全基因组
samtools mpileup KPGP-00001.sorted.merge.bam |perl -alne &#39;{if($F[3]&amp;gt;100){$depth{&amp;quot;over100&amp;quot;}++}else{$depth{$F[3]}++}}END{print &amp;quot;$_\t$depth{$_}&amp;quot; foreach sort{$a &amp;lt;=&amp;gt; $b}keys %depth}&#39; 

#每一条染色体
ls KPGP-00001.sorted.merge.REF*.bam |while read id 
do 
echo $id
samtools mpileup $id |perl -alne &#39;{if($F[3]&amp;gt;100){$depth{&amp;quot;over100&amp;quot;}++}else{$depth{$F[3]}++}} END {print &amp;quot;$_\t$depth{$_}&amp;quot; foreach sort{$a &amp;lt;=&amp;gt; $b}keys %depth}&#39; &amp;gt;$id.depth.txt
done 

&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;对比对结果文件进行过滤&#34;&gt;对比对结果文件进行过滤&lt;/h1&gt;

&lt;p&gt;这个地方有问题&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;samtools view -h -F4  -q 5 KPGP-00001.sorted.merge.bam |samtools view -bS |samtools rmdup - KPGP-00001.filter.rmdup.bam
samtools index KPGP-00001.filter.rmdup.bam

bam文件是二进制文件，我们需要samtools view的命令进行格式转换。
这个管道的意思分开来说就是运行第一步时过滤的时候已将bam文件转成我们能看的sam格式。
其中h是在输出的结果中包含头header，F和q是过滤掉没有mapped上的reads（也就是multiple mapping的情况）和低质量的reads。
第二步是将上一步得出的sam文件再转成bam，
第三步就是用samtools rmdup过滤掉PCR duplication的情况了，最后得到了过滤了multiple mapping、PCR duplication及低质量比对的bam文件。
最后利用samtools index对过滤后的bam文件建立索引。
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;用gatk对sam格式的文件进行重排&#34;&gt;用GATK对SAM格式的文件进行重排&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.bio-info-trainee.com/838.html&#34;&gt;GATK使用注意事项&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/snewhouse/ngs_nextflow/wiki/GATK-Bundle&#34;&gt;https://github.com/snewhouse/ngs_nextflow/wiki/GATK-Bundle&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/ddcap/halvade/wiki&#34;&gt;https://github.com/ddcap/halvade/wiki&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# ftp://ftp.broadinstitute.org/bundle/hg19

axel ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.gz
wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.fasta.fai.gz
gunzip ucsc.hg19.fasta.gz
bwa index ucsc.hg19.fasta
# ucsc.hg19.fasta.amb
# ucsc.hg19.fasta.ann
# ucsc.hg19.fasta.bwt
# ucsc.hg19.fasta.pac
# ucsc.hg19.fasta.sa
axel ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/1000G_phase1.indels.hg19.sites.vcf.gz
axel ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/1000G_phase1.indels.hg19.sites.vcf.idx.gz
axel ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/Mills_and_1000G_gold_standard.indels.hg19.sites.vcf.gz
axel ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/Mills_and_1000G_gold_standard.indels.hg19.sites.vcf.idx.gz
axel ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/ucsc.hg19.dict.gz
axel ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/hg19/dbsnp_138.hg19.vcf.gz

ls *.gz |while read id;
do
gunzip $id
done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;按染色体下载hg19基因组&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for i in $(seq 1 22) X Y M;
do echo $i;
wget http://hgdownload.cse.ucsc.edu/goldenPath/hg19/chromosomes/chr${i}.fa.gz;
done
gunzip *.gz
for i in $(seq 1 22) X Y M;
do cat chr${i}.fa &amp;gt;&amp;gt; hg19.fasta;
done
rm -fr chr*.fasta

bwa index ucsc.hg19.fasta

bwa index -a bwtsw hg19.fasta
samtools faidx hg19.fasta
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;首先用RealignerTargetCreator找到需要重新比对的区域，输出文件intervals，然后用输出的 tmp.intervals 做输入文件来进行重新比对，也就是用IndelRealigner在这些区域内进行重新比对.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;nohup java -Xmx60g -jar /data/biosoft/GATK/GenomeAnalysisTK.jar -R \
/data/reference/annotation/GATK/ucsc.hg19.fasta -T RealignerTargetCreator \
-I KPGP-00001.filter.rmdup.bam -o KPGP-00001.filter.rmdup.intervals \
-known /data/reference/annotation/GATK/1000G_phase1.indels.hg19.sites.vcf \
1&amp;gt; KPGP-00001.filter.rmdup.RealignerTargetCreator.log

nohup java -Xmx60g -jar /data/biosoft/GATK/GenomeAnalysisTK.jar  -R \
/data/reference/annotation/GATK/ucsc.hg19.fasta  -T IndelRealigner  \
-I KPGP-00001.filter.rmdup.bam  -targetIntervals KPGP-00001.filter.rmdup.intervals \
-o KPGP-00001.filter.rmdup.realgn.bam  1&amp;gt;KPGP-00001.filter.rmdup.IndelRealigner.log
&lt;/code&gt;&lt;/pre&gt;

        
      </description>
    </item>
    
    <item>
      <title>根据gtf格式的基因注释文件得到人所有基因的染色体坐标</title>
      <link>/blog/cn/2017/11/gtf_gene_position/</link>
      <pubDate>Fri, 10 Nov 2017 11:00:13 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/gtf_gene_position/</guid>
      <description>
        &lt;p&gt;&lt;strong&gt;原文&lt;/strong&gt; ：&lt;a href=&#34;http://www.biotrainee.com/thread-472-1-1.html&#34;&gt;http://www.biotrainee.com/thread-472-1-1.html&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir -p ~/reference/gtf/gencode
cd  ~/reference/gtf/gencode
## https://www.gencodegenes.org/releases/current.html
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/gencode.v25.2wayconspseudos.gtf.gz
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/gencode.v25.long_noncoding_RNAs.gtf.gz 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/gencode.v25.polyAs.gtf.gz 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/gencode.v25.annotation.gtf.gz 
## https://www.gencodegenes.org/releases/25lift37.html 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/GRCh37_mapping/gencode.v25lift37.annotation.gtf.gz 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/GRCh37_mapping/gencode.v25lift37.metadata.HGNC.gz 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/GRCh37_mapping/gencode.v25lift37.metadata.EntrezGene.gz 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/GRCh37_mapping/gencode.v25lift37.metadata.RefSeq.gz 

zcat  gencode.v25.long_noncoding_RNAs.gtf.gz |perl -alne &#39;{next unless $F[2] eq &amp;quot;gene&amp;quot; ;/gene_name \&amp;quot;(.*?)\&amp;quot;;/; print &amp;quot;$F[0]\t$F[3]\t$F[4]\t$1&amp;quot; }&#39; &amp;gt;lncRNA.hg38.position
zcat  gencode.v25.2wayconspseudos.gtf.gz     |perl -alne &#39;{next unless $F[2] eq &amp;quot;transcript&amp;quot; ;/gene_name \&amp;quot;(.*?)\&amp;quot;;/; print &amp;quot;$F[0]\t$F[3]\t$F[4]\t$1&amp;quot; }&#39; &amp;gt;pseudos.hg38.position
zcat  gencode.v25.annotation.gtf.gz| grep   protein_coding |perl -alne &#39;{next unless $F[2] eq &amp;quot;gene&amp;quot; ;/gene_name \&amp;quot;(.*?)\&amp;quot;;/; print &amp;quot;$F[0]\t$F[3]\t$F[4]\t$1&amp;quot; }&#39; &amp;gt;protein_coding.hg38.position
zcat  gencode.v25.annotation.gtf.gz|perl -alne &#39;{next unless $F[2] eq &amp;quot;gene&amp;quot; ;/gene_name \&amp;quot;(.*?)\&amp;quot;;/; print &amp;quot;$F[0]\t$F[3]\t$F[4]\t$1&amp;quot; }&#39; &amp;gt;allGene.hg38.position

zcat  gencode.v25lift37.annotation.gtf.gz | grep   protein_coding |perl -alne &#39;{next unless $F[2] eq &amp;quot;gene&amp;quot; ;/gene_name \&amp;quot;(.*?)\&amp;quot;;/; print &amp;quot;$F[0]\t$F[3]\t$F[4]\t$1&amp;quot; }&#39; &amp;gt;protein_coding.hg19.position
zcat  gencode.v25lift37.annotation.gtf.gz | perl -alne &#39;{next unless $F[2] eq &amp;quot;gene&amp;quot; ;/gene_name \&amp;quot;(.*?)\&amp;quot;;/; print &amp;quot;$F[0]\t$F[3]\t$F[4]\t$1&amp;quot; }&#39; &amp;gt;allGene.hg19.position
&lt;/code&gt;&lt;/pre&gt;

        
      </description>
    </item>
    
    <item>
      <title>外显子测序数据分析学习笔记</title>
      <link>/blog/cn/2017/11/whole_exon_sequencing_study/</link>
      <pubDate>Thu, 09 Nov 2017 18:01:02 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/whole_exon_sequencing_study/</guid>
      <description>
        

&lt;p&gt;&lt;strong&gt;学习提纲&lt;/strong&gt;：&lt;/p&gt;

&lt;p&gt;（1）&lt;a href=&#34;http://www.bio-info-trainee.com/2735.html&#34;&gt;肿瘤全外显子测序数据分析流程&lt;/a&gt; &lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=MzAxMDkxODM1Ng==&amp;amp;mid=2247485033&amp;amp;idx=1&amp;amp;sn=eb9865b92879e20c4afe285aeb8dc73c&amp;amp;chksm=9b4846d2ac3fcfc4e3f90c6ec8ff533494f3a43c502e3c8e842dafb7496db137c11434fccea4&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=0922Ls8z5WWLuNh7ml25V20r#rd&#34;&gt;微信连接&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(2) &lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=MzAxMDkxODM1Ng==&amp;amp;mid=2247484873&amp;amp;idx=1&amp;amp;sn=e455578dfac51afece7adb21cb315a17&amp;amp;chksm=9b484572ac3fcc6460b6b9bbb88306f73c399d8e7a96ad8bb472a179a8de518bc70e21a72b0b&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=0819fvKioudGMT1TYHXwnXoG#rd&#34;&gt;WES分析七步走&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(3) &lt;a href=&#34;http://www.bio-info-trainee.com/1108.html&#34;&gt;WES 测序质量控制&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(4) &lt;a href=&#34;http://www.bio-info-trainee.com/1114.html&#34;&gt;WES（二）snp-calling&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(5) &lt;a href=&#34;http://www.bio-info-trainee.com/1137.html&#34;&gt;WES（三）snp-filter&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(6) &lt;a href=&#34;http://www.bio-info-trainee.com/1138.html&#34;&gt;WES（四）不同个体的比较&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(7) &lt;a href=&#34;http://www.bio-info-trainee.com/1150.html&#34;&gt;WES（五）不同软件比较&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(8) &lt;a href=&#34;http://www.bio-info-trainee.com/1158.html&#34;&gt;WES（六）用annovar注释&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(9) &lt;a href=&#34;http://www.bio-info-trainee.com/1159.html&#34;&gt;WES（七）看de novo变异情况&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(10) &lt;a href=&#34;http://blog.csdn.net/zhu_si_tao/article/details/53321374&#34;&gt;GATK流程&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(11) &lt;a href=&#34;http://www.bio-info-trainee.com/838.html&#34;&gt;GATK使用注意事项&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;WES数据分析步骤：A Survey of Computational Tools to Analyze and Interpret Whole Exome Sequencing Data(2016)&lt;/p&gt;

&lt;h1 id=&#34;数据下载&#34;&gt;数据下载&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4812767/&#34;&gt;Whole-exome sequencing identifies MST1R as a genetic susceptibility gene in nasopharyngeal carcinoma&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We sequenced the blood samples from 161 NPC cases, including 39 EAO cases, 63 FH+ cases from 52 independent families, and 59 sporadic cases by WES and achieved an average coverage of 49-fold on target (range of 32- to 76-fold). An additional 2,160 NPC cases and 2,433 healthy controls from Hong Kong were further examined for the selected candidate variants. &lt;strong&gt;GEO Accession ID SRA291701&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;挑选5个样本进行分析 npc.sra.txt&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SRX445405    MALE    NPC15   SRR1139956  NPC15F  NO  SRS540548   NPC15F-T
SRX445406    MALE    NPC15   SRR1139958  NPC15F  NO  SRS540549   NPC15F-N
SRX445407    MALE    NPC29   SRR1139966  NPC29F  YES SRS540550   NPC29F-T
SRX445408    MALE    NPC29   SRR1139973  NPC29F  YES SRS540551   NPC29F-N
SRX445409    FEMALE  NPC10   SRR1139999  NPC10F  NO  SRS540552   NPC10F-T
SRX445410    FEMALE  NPC10   SRR1140007  NPC10F  NO  SRS540553   NPC10F-N
SRX445411    FEMALE  NPC34   SRR1140015  NPC34F  NO  SRS540554   NPC34F-T
SRX445412    FEMALE  NPC34   SRR1140023  NPC34F  NO  SRS540555   NPC34F-N
SRX445413    MALE    NPC37   SRR1140044  NPC37F  YES SRS540556   NPC37F-T
SRX445414    MALE    NPC37   SRR1140045  NPC37F  YES SRS540557   NPC37F-N
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cat npc.sra.txt | cut -f 4| while read id
# or cut -f 4 npc.sra.txt | while read id
do echo $id
axel ftp://ftp-trace.ncbi.nlm.nih.gov/sra/sra-instant/reads/ByStudy/sra/SRP/SRP035/SRP035573/$id/$id.sra &amp;amp;
done
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cat npc.sra.txt | while read id
do
array=($id)
echo  ${array[3]}.sra  ${array[7]} fastq-dump --gzip --split-3 -A \  
   ${array[7]}  ${array[3]}.sra 
done 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;刚刚开始没搞清楚，这个太难了，学了好像暂时也没啥好用的，数据、资料收集到这里，以后有空再学习吧，数据太大了，浪费空间和电费了。&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>DNA Methylation甲基化450k,850k芯片</title>
      <link>/blog/cn/2017/11/humanmethylation450_850k/</link>
      <pubDate>Tue, 07 Nov 2017 23:39:50 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/humanmethylation450_850k/</guid>
      <description>
        

&lt;h1 id=&#34;illumina-humanmethylation-beadchip简介&#34;&gt;Illumina HumanMethylation BeadChip简介&lt;/h1&gt;

&lt;p&gt;Illumina最早的甲基化芯片是27K（K代表1000，表示大概可以测到的CpG位点数）的数据，后来增加到了450K（主流的甲基化芯片），而目前illumina已经出了新一代产品EPIC（我习惯称之为850K），但是技术核心在450K已经成熟了，所以分析流程这里以450K为主（也是目前数据库主流的甲基化芯片数据）。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;芯片&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;一张芯片包括12个array，也就是一张芯片可以做12个sample，一台机子一次可以跑8张芯片，也就是一共96个sample，每个样本可以测到超过450，000个CpG位点的甲基化信息（大概人所有甲基化位点的1%，但是覆盖了多数CpG岛和启动子区），芯片本身包含一些控制探针可以做质控。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;原理&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;简而言之，基于亚硫酸盐处理后的DNA序列杂交的信号探测。亚硫酸盐是甲基化探测的“金标准”，不管是芯片或者甲基化测序，都要先对DNA样品进行亚硫酸盐处理，使非甲基化的C变成U，而甲基化的C保持不变，从而在后续的测序或者杂交后区分出来。450K采用了两种探针对甲基化进行测定，Infinium I采用了两种bead（甲基化M和非甲基化U，如图显示），而II只有一种bead（即甲基化和非甲基化在一起），这也导致了它们在后续荧光探测的不同，450K采用了两种荧光探测信号（红光和绿光）。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/DNA_methylation1.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;DNA甲基化指的是包裹在DNA上CG碱基（又叫CpG）的外周的一些蛋白发生变化，进而导致基因或者一些调控因子的表达出现变化，进而导致那些基因或者调控因子控制的表型出现变化，进而导致疾病或者差异的发生。DNA甲基化被认为是表观遗传调控的一种方式，如Cytosine methylation (5-mC)是研究最多的，被认为是哺乳动物中常见的甲基化方式, 最近有一些研究也发现了其他形式的甲基化，如2016年Nature上发表了一篇关于鼠的胚胎干细胞的m6A（N6-methyladenine）形式的甲基化。DAN甲基化被认为对基因表达，染色质重塑，细胞分化，疾病等都有重要影响。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/DNA_methylation2.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;甲基化的检测方法&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;目前甲基化检测的方法可以概括为三种：芯片、测序、免疫沉淀。具体选择何种方法主要还是根据实验目的和实验室条件了。但目前来说，甲基化芯片技术从覆盖度，检测灵敏度和价格综合考虑，还是性价比相对高。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/DNA_methylation3.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;甲基化芯片常见的Glossary&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;CpG island: Defned as regions 500 bp, 55% GC and expected/observed CpG ratio of 0.65. 40% of gene promoters contain islands.&lt;/li&gt;
&lt;li&gt;CpG shelves: ~4Kb from islands.&lt;/li&gt;
&lt;li&gt;CpG shores: ~2Kb from islands, 75% of tissuespecifc differentially methylated regions found in shores. Methylation in shores shows higher correlation with gene expression than CpG islands.&lt;/li&gt;
&lt;li&gt;Differentially methylated regions (DMR): Cell-, tissue-, and condition- specifc differences in methylation.&lt;/li&gt;
&lt;li&gt;Enhancer: A short region of DNA that can activate transcription and is often regulated by methylation.&lt;/li&gt;
&lt;li&gt;Hypermethylation: Most cytosines are methylated. Hypomethylation: Most cytosines do not have 5-mC. Euchromatin and active gene promoters are hypomethylated.&lt;/li&gt;
&lt;li&gt;Beta value:通常的甲基化衡量方法被称为“Beta”值; 等于甲基化百分比，并定义为“Meth”除以“Meth + Unmeth”。&lt;/li&gt;
&lt;li&gt;CGI: CpG island 即甲基化岛。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;分析需要考虑的问题&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;背景校正&lt;/li&gt;
&lt;li&gt;红光和绿光的校正&lt;/li&gt;
&lt;li&gt;控制芯片的使用（illumina450K本身有一些控制芯片，可以用来做质控，如亚硫酸盐处理效率）&lt;/li&gt;
&lt;li&gt;探针类型（I型和II型）的校正（不同探针类型产生的数据不同）
这个问题我们之前关注很多，这里附上两篇文献供大家参考，最终我们选择BMIQ的方法（基于ebayes的原理将II型探针的甲基化水平拉伸到I型水平，如下图显示）来做矫正。(图片来源于第1篇文献)&lt;br /&gt;
文献1： &lt;a href=&#34;http://bioinformatics.oxfordjournals.org/content/29/2/189.short&#34;&gt;http://bioinformatics.oxfordjournals.org/content/29/2/189.short&lt;/a&gt;&lt;br /&gt;
文献2： &lt;a href=&#34;http://www.tandfonline.com/doi/abs/10.4161/epi.24008&#34;&gt;http://www.tandfonline.com/doi/abs/10.4161/epi.24008&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;位置的校正（芯片上的不同位置产生的数据可能会有偏差）&lt;/li&gt;
&lt;li&gt;批次的校正（不同的批次做的数据会有偏差）&lt;/li&gt;
&lt;li&gt;探针序列本身是否可靠（有些探针本身位于repeat区或者包含snp等就会影响杂交及最后的结果，应该去除，附上一片参考文献，里边有list可以用来去除不好的探针）&lt;br /&gt;
文献：&lt;a href=&#34;http://bmcgenomics.biomedcentral.com/articles/10.1186/1471-2164-15-51&#34;&gt;http://bmcgenomics.biomedcentral.com/articles/10.1186/1471-2164-15-51&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;数据处理&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;GenomeStudio
GS是illumina开发的软件，基于图形界面的操作处理，适合于没有R及编程基础的人使用，但是使用GS需要权限，本人试过挺难破解的，如果有人可以破解，可以提供给论坛小伙伴使用。&lt;/li&gt;
&lt;li&gt;基于R和bioconductor的pipeline&lt;br /&gt;
bioconductor里开发了很多package供大家使用，如果你会R，那么处理这个甲基化芯片的数据将变得简单。
可以处理450K芯片的package有lumi、minfi、wateRmelon、ChAMP等，没有哪一种就特别好，大家都在不断改进，所以只要你知道大概的流程和需要注意的问题，那么你也可以自己写代码处理，只是package可以帮你省很多事情。下边我会附上我的处理流程图和详解，还有我的代码，我的代码是基于minfi的，我再次强调，代码只是手段，你可以用其他的package（例如我的同事很多使用ChAMP），也许会更好。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/DNA_methylation4.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;流程图详解：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;蓝色部分代表的是有关于数据的准备部分&lt;/li&gt;
&lt;li&gt;红色部分代表的是数据分析部分&lt;/li&gt;
&lt;li&gt;黄色部门代表数据可视化部分&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;箭头指示了分析流程，首先是load数据，然后是QC（quality control），然后是normalization，然后是SVD分析（看有没有batch effect）。准备完毕之后，黑点代表了一批质量有保证，经过处理，可以直接上马进行数据分析的数据了。之后的分析，DMP代表找出Differential Methylation Probe（差异化CpG位点），DMR代表找出Differential Methylation Region（差异化CpG区域），Block代表Differential Methylation Block（更大范围的差异化region区域），RefFree代表细胞差异被修正过后再找的DMP，EpiMod是基于基因作用网络的差异化分析。&lt;/p&gt;

&lt;p&gt;我们一般下载或者iscan后的原始数据格式为Idat，首先可以得到每个sample的每个probe的p值和bead数，根据p值和bead数可以进行样本和探针的过滤，过滤之后需要用BMIQ的方法进行I和II型探针的校正，矫正之后去掉那些包含snp之类的不好的探针，最后对数据做batch的校正。校正之后的数据就是预处理后的数据了，可以用于更下游的分析，如差异甲基化和甲基化与表达的关联分析等。
我的代码： &lt;a href=&#34;https://github.com/wkl1990/illumina-450K-analysis&#34;&gt;https://github.com/wkl1990/illumina-450K-analysis&lt;/a&gt; 。&lt;/p&gt;

&lt;h1 id=&#34;数据分析&#34;&gt;数据分析&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://www.biotrainee.com/thread-237-1-1.html&#34;&gt;Illumina HumanMethylation450 BeadChip甲基化450k芯片预处理初探&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.bio-info-trainee.com/2823.html&#34;&gt;850K甲基化芯片数据的分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://bioconductor.org/packages/release/bioc/vignettes/ChAMP/inst/doc/ChAMP.html&#34;&gt;Bioconductor ChAMP包&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.csdn.net/joshua_hit/article/details/54982018&#34;&gt;Shiny和Plotly实现可交互DNA甲基化分析包ChAMP&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

        
      </description>
    </item>
    
    <item>
      <title>Chip-seq 分析学习笔记</title>
      <link>/blog/cn/2017/11/chip_seq_study/</link>
      <pubDate>Tue, 07 Nov 2017 16:52:20 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/chip_seq_study/</guid>
      <description>
        

&lt;script type=&#34;text/javascript&#34; src=&#34;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&#34;&gt;&lt;/script&gt;

&lt;p&gt;这是一个学习笔记，跟随生信技能树的学习笔记重复,把几个优秀笔记的内容重复摘录在此。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.biotrainee.com/thread-2013-1-1.html&#34;&gt;学习提纲&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=MzAxMDkxODM1Ng==&amp;amp;mid=2247485198&amp;amp;idx=1&amp;amp;sn=bfb419c568723c5c121e017b2e265d2f&amp;amp;chksm=9b4847b5ac3fcea303e986c17e19b3750dc145f23a8e18daa74c5de704d4a203f8ba08bed651&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=1103lRh7ZlI9oD2bGJJhvqlh#rd&#34;&gt;优秀学习笔记&lt;/a&gt; &lt;a href=&#34;http://www.bio-info-trainee.com/2773.html&#34;&gt;链接2&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;chip-seq介绍&#34;&gt;ChIP-Seq介绍&lt;/h1&gt;

&lt;h2 id=&#34;1-了解基础知识&#34;&gt;1.了解基础知识&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;peak calling的统计学原理 &lt;a href=&#34;http://www.plob.org/2014/05/08/7227.html&#34;&gt;http://www.plob.org/2014/05/08/7227.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;根据比对的bam文件来对peaks区域可视化 &lt;a href=&#34;http://www.bio-info-trainee.com/1843.html&#34;&gt;http://www.bio-info-trainee.com/1843.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;wig、bigWig和bedgraph文件详解 &lt;a href=&#34;http://www.bio-info-trainee.com/1815.html&#34;&gt;http://www.bio-info-trainee.com/1815.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;2-文章综述&#34;&gt;2.文章综述&lt;/h2&gt;

&lt;p&gt;ChIP-seq guidelines and practices of the ENCODE and modENCODE consortia. &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pubmed/22955991&#34;&gt;https://www.ncbi.nlm.nih.gov/pubmed/22955991&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;3-chip-seq测序的统计学原理&#34;&gt;3.Chip-Seq测序的统计学原理&lt;/h2&gt;

&lt;p&gt;TF在基因组上的结合其实是一个随机过程，基因组的每个位置其实都有机会结合某个TF，只是概率不一样，说白了，peak出现的位置，是TF结合的热点，而peak-calling就是为了找到这些热点。&lt;/p&gt;

&lt;p&gt;如何定义热点呢？通俗地讲，热点是这样一些位置，这些位置多次被测得的read所覆盖（我们测的是一个细胞群体，read出现次数多，说明该位置被TF结合的几率大）。那么，read数达到多少才叫多？这就要用到统计检验喽。假设TF在基因组上的分布是没有任何规律的，那么，测序得到的read在基因组上的分布也必然是随机的，某个碱基上覆盖的read的数目应该服从二项分布。这其实和高中大学课本上抽小球的过程是类似的。当n很大，p很小时，二项分布可以近似用泊松分布替代。&lt;/p&gt;

&lt;p&gt;$$\lambda=n \ast p, p=\frac{l}{s}$$&lt;/p&gt;

&lt;p&gt;\(\lambda\)是泊松分布唯一的参数，n是测序得到的read总数目，l是单个read的长度，s是基因组的大小。有了分布，我们可以算出在某个置信概率（如0.00001）下，随机情况下，某个碱基上可以覆盖的read的数目的最小值，当实际观察到的read数目超过这个值（单侧检验）时，我们认为该碱基是TF的一个结合热点。反过来，针对每一个read数目，我们也可以算出对应的置信概率P。
但是，这只是一个简化的模型，实际情况要复杂好多。比如，由于测序、mapping过程内在的偏好性，以及不同染色质间的差异性，相比全基因组，某些碱基可能内在地会被更多的read所覆盖，这种情况得到的很多peak可能都是假的。MACS考虑到了这一点，当对某个碱基进行假设检验时，MACS只考虑该碱基附近的染色质区段（如10k），此时，上述公式中n表示附近10k区间内的read数目，s被置为10k。当有对照组实验（Control，相比实验组，没有用抗体捕获TF，或用了一个通用抗体）存在时，利用Control组的数据构建泊松分布，当没有Control时，利用实验组，稍大一点的局部区间（比如50k）的数据构建泊松分布。
这儿还有一个问题，read只是跟随着TF一起沉淀下来的DNA fragment的末端，read的位置并不是真实的TF结合的位置。所以在peak-calling之前，延伸read是必须的。不同TF大小不一样，对read延伸的长度也理应不同。我们知道，测得的read最终其实会近似地平均分配到正负链上，这样，对于一个TF结合热点而言，read在附近正负链上会近似地形成“双峰”。MACS会以某个window size扫描基因组，统计每个window里面read的富集程度，然后抽取（比如1000个）合适的（read富集程度适中，过少，无法建立模型，过大，可能反映的只是某种偏好性）window作样本，建立“双峰模型”。最后，两个峰之间的距离就被认为是TF的长度D，每个read将延伸D/2的长度。见下图：&lt;/p&gt;

&lt;h2 id=&#34;4-chip-seq实验&#34;&gt;4.Chip-seq实验&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;数据获取&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;将蛋白交联到DNA上。 也就是保证蛋白和DNA能够结合，找到互作位点。&lt;/li&gt;
&lt;li&gt;通过超声波剪切DNA链。&lt;/li&gt;
&lt;li&gt;加上附上抗体的磁珠用于免疫沉淀靶蛋白。抗体很重要&lt;/li&gt;
&lt;li&gt;接触蛋白交联；纯化DNA&lt;/li&gt;
&lt;li&gt;测序。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;分析流程&lt;/strong&gt;：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;质量控制, 用到的是FastQC&lt;/li&gt;
&lt;li&gt;序列比对, Bowtie2或这BWA&lt;/li&gt;
&lt;li&gt;peak calling，此处用的MACS&lt;/li&gt;
&lt;li&gt;peak注释, 这里用的Y叔的ChIPseeker&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/ChIP-Seq.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;数据下载&#34;&gt;数据下载&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pubmed/23273917&#34;&gt;RYBP and Cbx7 define specific biological functions of polycomb complexes in mouse embryonic stem cells&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE42466&#34;&gt;https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE42466&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;for ((i=204;i&amp;lt;=209;i++))
do
 axel ftp://ftp-trace.ncbi.nlm.nih.gov/sra/sra-instant/reads/ByStudy/sra/SRP/SRP017/SRP017311/SRR620$i/SRR620$i.sra &amp;amp;
done
ls *sra |while read id; do fastq-dump –split-3 $id &amp;amp; done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注意文件： 这里要注意是双端测序还是单端测序。&lt;/p&gt;

&lt;p&gt;fastq-dump 转换sra文件成fastq/fasta 文件。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;pair-end: fastq-dump &amp;ndash;split-3 *.sra&lt;/li&gt;
&lt;li&gt;single-end: fastq-dump *.sra 或者 fastq-dump &amp;ndash;fasta *sra&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;下载参考基因组-建立bowtie2索引&#34;&gt;下载参考基因组,建立bowtie2索引&lt;/h1&gt;

&lt;p&gt;索引可以自己build，也可以下载 &lt;a href=&#34;ftp://ftp.ccb.jhu.edu/pub/data/bowtie2_indexes/mm10.zip&#34;&gt;ftp://ftp.ccb.jhu.edu/pub/data/bowtie2_indexes/mm10.zip&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir -p  /data/reference/genome/mm10
cd /data/reference/genome/mm10
axel http://hgdownload.cse.ucsc.edu/goldenPath/mm10/bigZips/chromFa.tar.gz
tar zvxf chromFa.tar.gz 
cat *.fa &amp;gt; mm10.fa
rm chr*.fa 

mkdir -p /data/reference/index/bowtie
cd /data/reference/index/bowtie
nohup time bowtie2-build  /data/reference/genome/mm10/mm10.fa  /data/reference/index/bowtie/mm10 1&amp;gt;mm10.bowtie_index.log 2&amp;gt;&amp;amp;1 &amp;amp;

&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;下载注释文件&#34;&gt;下载注释文件&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://genome.ucsc.edu/cgi-bin/hgTables&#34;&gt;https://genome.ucsc.edu/cgi-bin/hgTables&lt;/a&gt;&lt;br /&gt;
（参阅&lt;a href=&#34;http://www.bio-info-trainee.com/2136.html）&#34;&gt;http://www.bio-info-trainee.com/2136.html）&lt;/a&gt;
&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/mm10_ucsc_refseq_bed.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;软件安装&#34;&gt;软件安装&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;conda install -c bioconda bowtie2
conda install -c bioconda deeptools 
pip install MACS2
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;数据处理与分析&#34;&gt;数据处理与分析&lt;/h1&gt;

&lt;h2 id=&#34;质控&#34;&gt;质控&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;ls *fastq |xargs fastqc -t 10
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;发现3端质量有点问题，我就用了-3 5&amp;ndash;local参数，&lt;/p&gt;

&lt;h2 id=&#34;序列拼接&#34;&gt;序列拼接&lt;/h2&gt;

&lt;p&gt;bowtie 短序列比对工具，用bowtie2软件把测序得到的fastq文件比对到mm10参考基因组上面&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cd /data/ChIPSeq
bowtie2 -p 6 -3 5 --local -x /data/reference/index/bowtie/mm10 -U SRR620204.fastq | samtools sort -O bam -o ring1B.bam
bowtie2 -p 6 -3 5 --local -x /data/reference/index/bowtie/mm10 -U SRR620205.fastq | samtools sort -O bam -o cbx7.bam
bowtie2 -p 6 -3 5 --local -x /data/reference/index/bowtie/mm10 -U SRR620206.fastq | samtools sort -O bam -o suz12.bam
bowtie2 -p 6 -3 5 --local -x /data/reference/index/bowtie/mm10 -U SRR620207.fastq | samtools sort -O bam -o RYBP.bam
bowtie2 -p 6 -3 5 --local -x /data/reference/index/bowtie/mm10 -U SRR620208.fastq | samtools sort -O bam -o IgGold.bam
bowtie2 -p 6 -3 5 --local -x /data/reference/index/bowtie/mm10 -U SRR620209.fastq | samtools sort -O bam -o IgG.bam
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;call-peaks&#34;&gt;call peaks&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;##参数解释
##-m 建立“双峰模型”用到，默认就算10 30，-p p-value 大于 1e-5，
##-f 文件来源是bam格式，-g 基因组大小是小鼠的（代号mm），-n 起名字的话叫 cbx7 
nohup macs2 callpeak -c IgGold.bam -t suz12.bam -m 10 30 -p 1e-5 -f BAM -g mm -n suz12 2&amp;gt;suz12.masc2.log &amp;amp;
nohup macs2 callpeak -c IgGold.bam -t ring1B.bam -m 10 30 -p 1e-5 -f BAM -g mm -n ring1B 2&amp;gt;ring1B.masc2.log &amp;amp;
nohup macs2 callpeak -c IgG.bam -t cbx7.bam -m 10 30 -p 1e-5 -f BAM -g mm -n cbx7 2&amp;gt;cbx7.masc2.log &amp;amp;
nohup macs2 callpeak -c IgG.bam -t RYBP.bam -m 10 30 -p 1e-5 -f BAM -g mm -n RYBP 2&amp;gt;RYBP.masc2.log &amp;amp;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;bam转换成bw文件&#34;&gt;bam转换成bw文件&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ls *.bam |while read id; do samtools index $id $id.bai; done
ls *bam |while read id
do 
  file=$(basename $id )
  sample=${file%%.*}
  echo $sample
  bamCoverage -b $id -o $sample.bw ## 这里有个参数，-p 10 --normalizeUsingRPKM
  computeMatrix reference-point --referencePoint TSS -b 10000 -a 10000 -R /data/reference/annotation/ChIPSeq/mm10/ucsc.refseq.bed -S $sample.bw --skipZeros -o matrix1_${sample}_TSS.gz --outFileSortedRegions regions1_${sample}_genes.bed
  plotHeatmap -m matrix1_${sample}_TSS.gz -out ${sample}.png
done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果文件不只是上述提到的一类，还有如下格式：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;NAMEpeaks.xls: 以表格形式存放peak信息，虽然后缀是xls，但其实能用文本编辑器打开，和bed格式类似，但是以1为基，而bed文件是以0为基.也就是说xls的坐标都要减一才是bed文件的坐标&lt;/li&gt;
&lt;li&gt;NAMEpeaks.narrowPeak NAMEpeaks.broadPeak 类似。后面4列表示为， integer score for display， fold-change，-log10pvalue，-log10qvalue，relative summit position to peak start。内容和NAMEpeaks.xls基本一致，适合用于导入R进行分析。&lt;/li&gt;
&lt;li&gt;NAMEsummits.bed：记录每个peak的peak summits，话句话说就是记录极值点的位置。MACS建议用该文件寻找结合位点的motif。&lt;/li&gt;
&lt;li&gt;NAMEmodel.r，能通过$ Rscript NAME_model.r作图，得到是基于你提供数据的peak模型&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;计算peak数&#34;&gt;计算peak数&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;wc -l *summits.bed
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;下载原作者的peak数据,可以用于分析结果比较&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;wget ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE42nnn/GSE42466/suppl/GSE42466_RYBP_peaks_5.txt.gz
gzip -d GSE42466_RYBP_peaks_5.txt.gz
mv GSE42466_RYBP_peaks_5.txt RYBP2_summits.bed
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;整合所有的chipseq的bam文件-画基因的tss附近的profile和heatmap图&#34;&gt;整合所有的chipseq的bam文件，画基因的TSS附近的profile和heatmap图&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;computeMatrix reference-point -p 10 --referencePoint TSS -b 2000 -a 2000 -S *bw -R /data/reference/annotation/ChIPSeq/mm10/ucsc.refseq.bed --skipZeros -o tmp4.mat.gz
plotHeatmap -m tmp4.mat.gz -out tmp4.merge.png
plotProfile --dpi 720 -m tmp4.mat.gz -out tmp4.profile.pdf --plotFileFormat pdf --perGroup
plotHeatmap --dpi 720 -m tmp4.mat.gz -out tmp4.merge.pdf --plotFileFormat pdf
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;整合所有的chipseq的bam文件-画基因的genebody附近的profile和heatmap图&#34;&gt;整合所有的chipseq的bam文件，画基因的genebody附近的profile和heatmap图&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;computeMatrix scale-regions -p 10 -S *bw -R /data/reference/annotation/ChIPSeq/mm10/ucsc.refseq.bed -b 3000 -a 3000 -m 5000 --skipZeros -o tmp5.mat.gz
plotHeatmap -m tmp5.mat.gz -out tmp5.merge.png
plotProfile --dpi 720 -m tmp5.mat.gz -out tmp5.profile.pdf --plotFileFormat pdf --perGroup
plotHeatmap --dpi 720 -m tmp5.mat.gz -out tmp5.merge.pdf --plotFileFormat pdf
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;结果注释与可视化&#34;&gt;结果注释与可视化&lt;/h1&gt;

&lt;p&gt;ChIPseeker R package的功能分为三类:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;注释：提取peak附近最近的基因， 注释peak所在区域&lt;/li&gt;
&lt;li&gt;比较：估计ChIP peak数据集中重叠部分的显著性；整合GEO数据集，以便于将当前结果和已知结果比较&lt;/li&gt;
&lt;li&gt;可视化： peak的覆盖情况；TSS区域结合的peak的平均表达谱和热图；基因组注释；TSS距离；peak和基因的重叠。&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;source (&amp;quot;https://bioconductor.org/biocLite.R&amp;quot;)
biocLite(&amp;quot;ChIPseeker&amp;quot;)
biocLite(&amp;quot;org.Mm.eg.db&amp;quot;)
biocLite(&amp;quot;TxDb.Mmusculus.UCSC.mm10.knownGene&amp;quot;)
biocLite(&amp;quot;clusterProfiler&amp;quot;)
biocLite(&amp;quot;ReactomePA&amp;quot;)
biocLite(&amp;quot;DOSE&amp;quot;)

library(&amp;quot;ChIPseeker&amp;quot;)
library(&amp;quot;org.Mm.eg.db&amp;quot;)
library(&amp;quot;TxDb.Mmusculus.UCSC.mm10.knownGene&amp;quot;)
txdb &amp;lt;- TxDb.Mmusculus.UCSC.mm10.knownGene
library(&amp;quot;clusterProfiler&amp;quot;)

#读入bed文件
ring1B &amp;lt;- readPeakFile(&amp;quot;F:/Chip-seq_exercise/ring1B_peaks.narrowPeak&amp;quot;)
#查看peak在全基因组的位置
covplot(ring1B)##全基因组
covplot(ring1B,chrs=c(&amp;quot;chr17&amp;quot;, &amp;quot;chr18&amp;quot;))   #指定染色体

#Average Profile of ChIP peaks binding to TSS region
#(Confidence interval estimated by bootstrap method)
plotAvgProf(tagMatrix, xlim=c(-3000, 3000), conf = 0.95, resample = 1000)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;peak的注释&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;peak的注释用annotatePeak()函数，&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;TSS (transcription start site) region 可以自己设定，默认是（-3000，3000），&lt;/li&gt;
&lt;li&gt;TxDb 是指某个物种的基因组，例如TxDb.Hsapiens.UCSC.hg38.knownGene, TxDb.Hsapiens.UCSC.hg19.knownGene for human genome hg38 and hg19, TxDb.Mmusculus.UCSC.mm10.knownGene and TxDb.Mmusculus.UCSC.mm9.knownGene for mouse mm10 and mm9.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;peakAnno &amp;lt;- annotatePeak(ring1B, tssRegion=c(-3000, 3000),
TxDb=txdb, annoDb=&amp;quot;org.Mm.eg.db&amp;quot;)
#可视化 Pie and Bar plot
plotAnnoBar(peakAnno)
vennpie(peakAnno)
upsetplot(peakAnno)

#可视化TSS区域的TF binding loci
plotDistToTSS(peakAnno,
title=&amp;quot;Distribution of transcription factor-binding loci\nrelative to TSS&amp;quot;)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;多个peak的比较&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;多个peak set注释时，先构建list,然后用lapply.list(name1=bed&lt;em&gt;file1,name2=bed&lt;/em&gt;file2) RYBP的数据有问题，这里加上去，会一直报错。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;peaks &amp;lt;- list(cbx7=cbx7,ring1B=ring1B,suz12=suz12)
promoter &amp;lt;- getPromoters(TxDb=txdb, upstream=3000, downstream=3000)
tagMatrixList &amp;lt;- lapply(peaks, getTagMatrix, windows=promoter)
plotAvgProf(tagMatrixList, xlim=c(-3000, 3000))
plotAvgProf(tagMatrixList, xlim=c(-3000, 3000), conf=0.95,resample=500, facet=&amp;quot;row&amp;quot;)
tagHeatmap(tagMatrixList, xlim=c(-3000, 3000), color=NULL)

#ChIP peak annotation comparision
peakAnnoList &amp;lt;- lapply(peaks, annotatePeak, TxDb=txdb,
tssRegion=c(-3000, 3000), verbose=FALSE)
plotAnnoBar(peakAnnoList)
plotDistToTSS(peakAnnoList)

#Overlap of peaks and annotated genes
genes= lapply(peakAnnoList, function(i) as.data.frame(i)$geneId)
vennplot(genes)
&lt;/code&gt;&lt;/pre&gt;

        
      </description>
    </item>
    
    <item>
      <title>Markdown&#43;Rmarkdown&#43;Shiny手册</title>
      <link>/blog/cn/2017/11/markdown_rmarkdown_shiny/</link>
      <pubDate>Mon, 06 Nov 2017 23:13:24 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/markdown_rmarkdown_shiny/</guid>
      <description>
        &lt;p&gt;&lt;a href=&#34;https://taoshengxu.github.io/DocumentGit/pdf/Markdown+RMarkdown+Shiny.pdf&#34;&gt;Markdown+Rmarkdown+Shiny手册&lt;/a&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>常用生物信息学格式介绍</title>
      <link>/blog/cn/2017/11/data_format/</link>
      <pubDate>Mon, 06 Nov 2017 22:59:05 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/data_format/</guid>
      <description>
        &lt;p&gt;&lt;a href=&#34;http://ju.outofmemory.cn/entry/193943&#34;&gt;原文&lt;/a&gt; &lt;a href=&#34;https://taoshengxu.github.io/DocumentGit/pdf/常用生物信息学格式介绍.pdf&#34;&gt;PDF&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;fasta&lt;/li&gt;
&lt;li&gt;fastq&lt;/li&gt;
&lt;li&gt;gff2&lt;/li&gt;
&lt;li&gt;gtf(gff2.5)&lt;/li&gt;
&lt;li&gt;gff3&lt;/li&gt;
&lt;li&gt;bed&lt;/li&gt;
&lt;li&gt;sam、bam&lt;/li&gt;
&lt;li&gt;vcf&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;另外，有wig、bigWig和bedgraph文件详解，仅仅是为了追踪参考基因组的各个区域的覆盖度，测序深度！而且这些定义好的文件，可以无缝连接到UCSC的Genome Browser工具里面进行可视化！
&lt;a href=&#34;http://www.bio-info-trainee.com/1815.html&#34;&gt;http://www.bio-info-trainee.com/1815.html&lt;/a&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>ENCODE计划数据,千人基因组计划数据,Roadmap计划数据</title>
      <link>/blog/cn/2017/11/encode_data/</link>
      <pubDate>Mon, 06 Nov 2017 16:44:54 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/encode_data/</guid>
      <description>
        

&lt;p&gt;&lt;a href=&#34;http://www.bio-info-trainee.com/1825.html&#34;&gt;From Jimmy 原文1&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.bio-info-trainee.com/1841.html&#34;&gt;From Jimmy 原文2&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.bio-info-trainee.com/1339.html&#34;&gt;From Jimmy 原文3&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;DNA元件百科全书(Encyclopedia of DNA Elements, ENCODE)ENCODE计划的重要性我就不多说了，如果大家还不是很了解，可以直接跳到本文末尾去下载一下ENCODE教程，好好学习。该计划采用以下几种高通量测序技术来刻画了超过100种不同的细胞系或者组织内的全基因组范围内的基因调控元件信息。本来只是针对人类的，后来对mouse以及fly等模式生物也开始测这些数据并进行分析了， 叫做 modENCODE.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;chromatin structure (5C)&lt;/li&gt;
&lt;li&gt;open chromatin (DNase-seq and FAIRE-seq)&lt;/li&gt;
&lt;li&gt;histone modifications and DNA-binding of over 100 transcription factors (ChIP-seq)&lt;/li&gt;
&lt;li&gt;RNA transcription (RNAseq and CAGE)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;目前所有数据均全部公开(&lt;a href=&#34;http://genome.ucsc.edu/ENCODE/&#34;&gt;http://genome.ucsc.edu/ENCODE/&lt;/a&gt; )，ENCODE results from 2007 and later are available from the ENCODE Project Portal, encodeproject.org. 并以30篇论文在Nature、Science、Cell、JBC、Genome Biol、Genome Research同时发表(&lt;a href=&#34;http://www.nature.com/encode&#34;&gt;http://www.nature.com/encode&lt;/a&gt; )。
&lt;strong&gt;所有数据从raw data形式的原始测序数据到比对后的信号文件以及分析好的有意的peaks文件都可以下载&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;我这里根据自己的学习情况，简单介绍一些ENCODE计划数据下载方式，包括ENCODE官网下载,UCSC下载，ENSEMBL下载，broad研究所数据，IHEC存放的数据，还有GEO下载这6种形式！！！&lt;/p&gt;

&lt;h1 id=&#34;ucsc&#34;&gt;UCSC&lt;/h1&gt;

&lt;p&gt;直接浏览文件，根据文件夹分类及文件名就可以任意方式下载自己感兴趣的数据&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://hgdownload.cse.ucsc.edu/goldenPath/hg19/encodeDCC/&#34;&gt;http://hgdownload.cse.ucsc.edu/goldenPath/hg19/encodeDCC/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;大家可能会比较习惯用UCSC提供的Genome Browser工具来可视化CHIP-seq的结果，而且Genome Browser里面非常多的选项可以控制各种在线资料是否跟你的数据一起显示来做对比，所以它必然有ftp服务器存放这些数据，其中比较出名的就是ENCODE计划的相关数据啦.&lt;/p&gt;

&lt;h1 id=&#34;encode计划的官网下载&#34;&gt;ENCODE计划的官网下载&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.encodeproject.org/pipelines/&#34;&gt;https://www.encodeproject.org/pipelines/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;官网的数据下载，做得像是一个购物网站，大家可以根据自己的需求把数据添加到购物篮，然后统一下载。&lt;/p&gt;

&lt;p&gt;This document describes what data are available at the ENCODE Portal, ways to get started searching and downloading data, and an overview to how the metadata describing the assays and reagents are organized. ENCODE data can be visualized and accessed from other resources, including the UCSC Genome Browser and ENSEMBL.
进入 &lt;a href=&#34;https://www.encodeproject.org/matrix/?type=Experiment&#34;&gt;https://www.encodeproject.org/matrix/?type=Experiment&lt;/a&gt; 可以看到里面列出了173种细胞系，148种组织，还有一堆癌症样本的，包括CHIP-seq，DNase-seq等在内的十几种高通量测序数据。&lt;/p&gt;

&lt;h1 id=&#34;geo&#34;&gt;GEO&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.ncbi.nlm.nih.gov/geo/info/ENCODE.html&#34;&gt;http://www.ncbi.nlm.nih.gov/geo/info/ENCODE.html&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;broad-研究所托管的encode计划数据&#34;&gt;Broad 研究所托管的ENCODE计划数据&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.broadinstitute.org/~anshul/projects/encode&#34;&gt;http://www.broadinstitute.org/~anshul/projects/encode&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;原始数据在：&lt;a href=&#34;http://www.broadinstitute.org/~anshul/projects/encode/rawdata/&#34;&gt;http://www.broadinstitute.org/~anshul/projects/encode/rawdata/&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;ihec&#34;&gt;iHEC&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://epigenomesportal.ca/ihec/download.html&#34;&gt;http://epigenomesportal.ca/ihec/download.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;以文件夹文件的形式直接浏览，根据自己的需求下载即可,除了ENCODE计划的数据，还有Blueprint计划和roadmap计划的数据都可以下载&lt;/p&gt;

&lt;h1 id=&#34;ensembl&#34;&gt;ENSEMBL&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://asia.ensembl.org/info/website/tutorials/encode.html&#34;&gt;http://asia.ensembl.org/info/website/tutorials/encode.html&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;结尾&#34;&gt;结尾&lt;/h1&gt;

&lt;p&gt;如果你对ENCODE计划不是很了解，可以先看看一些教程：
NIH提供的ENCODE计划相关教程： &lt;a href=&#34;https://www.genome.gov/27553900/encode-tutorials/&#34;&gt;https://www.genome.gov/27553900/encode-tutorials/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.genome.gov/27562350/encode-workshop-april-2015-keystone-symposia/&#34;&gt;https://www.genome.gov/27562350/encode-workshop-april-2015-keystone-symposia/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.genome.gov/27561253/encode-workshop-tutorial-october-2014-ashg/&#34;&gt;https://www.genome.gov/27561253/encode-workshop-tutorial-october-2014-ashg/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.genome.gov/27553901/encode-tutorial-may-2013-biology-of-genomes-cshl/&#34;&gt;https://www.genome.gov/27553901/encode-tutorial-may-2013-biology-of-genomes-cshl/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.genome.gov/27563006/encoderoadmap-epigenomics-tutorial-october-2015-ashg/&#34;&gt;https://www.genome.gov/27563006/encoderoadmap-epigenomics-tutorial-october-2015-ashg/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.genome.gov/27555330/encoderoadmap-epigenomics-tutorial-october-2013-ashg/&#34;&gt;https://www.genome.gov/27555330/encoderoadmap-epigenomics-tutorial-october-2013-ashg/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.genome.gov/27551933/encoderoadmap-epigenomics-tutorial-nov-2012-ashg/&#34;&gt;https://www.genome.gov/27551933/encoderoadmap-epigenomics-tutorial-nov-2012-ashg/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://useast.ensembl.org/info/website/tutorials/encode.html&#34;&gt;http://useast.ensembl.org/info/website/tutorials/encode.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.encodeproject.org/tutorials/&#34;&gt;https://www.encodeproject.org/tutorials/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.encodeproject.org/tutorials/encode-meeting-2016/&#34;&gt;https://www.encodeproject.org/tutorials/encode-meeting-2016/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.encodeproject.org/tutorials/encode-users-meeting-2015/&#34;&gt;https://www.encodeproject.org/tutorials/encode-users-meeting-2015/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;DNA元件百科全书(Encyclopedia of DNA Elements, ENCODE)项目旨在描述人类基因组中所编码的全部功能性序列元件。ENCODE计划于2003年9月正式启动，吸引了来自美国、英国、西班牙、日本和新加坡五国32个研究机构的440多名研究人员的参与，经过了9年的努力，研究了147个组织类型，进行了1478次实验，获得并分析了超过15万亿字节的原始数据，确定了400万个基因开关，明确了哪些DNA片段能打开或关闭特定的基因，以及不同类型细胞之间的“开关”存在的差异。证明所谓“垃圾DNA”都是十分有用的基因成分，担任着基因调控重任。证明人体内没有一个DNA片段是无用的。&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;千人基因组计划&#34;&gt;千人基因组计划&lt;/h1&gt;

&lt;p&gt;由于时间跨度比较长，最终的数据不只是一千人，最新版共有NA编号开头的1182个人，HG开头的1768个人！它的官方网站是：有一个ppt讲得很清楚如何通过官网做的data portal来下载数据：&lt;a href=&#34;https://www.genome.gov/pages/research/der/ichg-1000genomestutorial/how_to_access_the_data.pdf&#34;&gt;https://www.genome.gov/pages/research/der/ichg-1000genomestutorial/how_to_access_the_data.pdf&lt;/a&gt; 我不喜欢可视化的界面，我比较喜欢直接进入ftp自己翻需要的数据，千人基因组计划不仅仅有自己的ftp站点，而且在NCBI，EBI和sanger研究所里面也有数据源可以下载， 是非常丰富的生信入门资源！&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;ftp://ftp-trace.ncbi.nih.gov/1000genomes/ftp/&#34;&gt;ftp://ftp-trace.ncbi.nih.gov/1000genomes/ftp/&lt;/a&gt;
&lt;a href=&#34;ftp://ftp.sanger.ac.uk/pub/1000genomes/&#34;&gt;ftp://ftp.sanger.ac.uk/pub/1000genomes/&lt;/a&gt;
&lt;a href=&#34;ftp://ftp.ebi.ac.uk/pub/databases/1000genomes/&#34;&gt;ftp://ftp.ebi.ac.uk/pub/databases/1000genomes/&lt;/a&gt;
 &lt;a href=&#34;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp&#34;&gt;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;千人基因组计划测了5个大的人种，25个亚人种，具体介绍如下：
09/08/2014 12:00AM          1,663 20131219.populations.tsv
09/09/2014 12:00AM             97 20131219.superpopulations.tsv
其实对大部分人来说，除非你想下载千人基因组计划的原始数据来学习生物信息学分析流程，不然用不着这个ftp站点的，它自己在EBI里面的有一个非常好用的可视化界面来浏览千人基因组计划的variation结果&lt;/p&gt;

&lt;p&gt;千人基因组计划 &amp;ndash; 基因组浏览器： &lt;a href=&#34;http://www.ncbi.nlm.nih.gov/variation/tools/1000genomes/&#34;&gt;http://www.ncbi.nlm.nih.gov/variation/tools/1000genomes/&lt;/a&gt;
&lt;a href=&#34;http://www.ncbi.nlm.nih.gov/projects/SNP/snp_ref.cgi?rs=rs35761398&#34;&gt;http://www.ncbi.nlm.nih.gov/projects/SNP/snp_ref.cgi?rs=rs35761398&lt;/a&gt;  chr1:24201919:24201920
&lt;a href=&#34;http://www.ncbi.nlm.nih.gov/SNP/snp_ref.cgi?rs=2501432&#34;&gt;http://www.ncbi.nlm.nih.gov/SNP/snp_ref.cgi?rs=2501432&lt;/a&gt;  chr1:24201920
&lt;a href=&#34;http://www.ncbi.nlm.nih.gov/SNP/snp_ref.cgi?rs=2502992&#34;&gt;http://www.ncbi.nlm.nih.gov/SNP/snp_ref.cgi?rs=2502992&lt;/a&gt;  chr1:24201919
在千人基因组计划里面看一个rs就能看到各种人群信息：
&lt;a href=&#34;http://browser.1000genomes.org/Homo_sapiens/Variation/Population?r=1:24201420-24202420;v=rs2501432;vdb=variation;vf=1849472&#34;&gt;http://browser.1000genomes.org/Homo_sapiens/Variation/Population?r=1:24201420-24202420;v=rs2501432;vdb=variation;vf=1849472&lt;/a&gt;
这些人群信息，可以画一个网路图！ 只需要变化rs ID号即可，当然并不是所有的rs ID号都在千人基因组计划里面有显示的。
还有一个java软件-可视化检测千人基因组数据&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://bioinformatics.oxfordjournals.org/content/early/2016/03/17/bioinformatics.btw147.short?rss=1&#34;&gt;http://bioinformatics.oxfordjournals.org/content/early/2016/03/17/bioinformatics.btw147.short?rss=1&lt;/a&gt;
&lt;a href=&#34;http://limousophie35.github.io/Ferret/&#34;&gt;http://limousophie35.github.io/Ferret/&lt;/a&gt;
但是好像不是很好用！&lt;/p&gt;

&lt;p&gt;在千人基因组计划的ftp主站点里面可以下载所有数据。
&lt;a href=&#34;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/&#34;&gt;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/&lt;/a&gt;
&lt;a href=&#34;ftp://ftp.ncbi.nlm.nih.gov/1000genomes/ftp/&#34;&gt;ftp://ftp.ncbi.nlm.nih.gov/1000genomes/ftp/&lt;/a&gt;
直接看最新版的数据，共有NA编号开头的1182个人，HG开头的1768个人！
&lt;a href=&#34;ftp://ftp.ncbi.nlm.nih.gov/1000genomes/ftp/phase3/data/&#34;&gt;ftp://ftp.ncbi.nlm.nih.gov/1000genomes/ftp/phase3/data/&lt;/a&gt;
也可以按照人种来查看这些数据：&lt;a href=&#34;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/data/&#34;&gt;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/data/&lt;/a&gt;
每个人的目录下面都有 四个数据文件夹
Oct 01 2014 00:00    Directory alignment
Oct 01 2014 00:00    Directory exome&lt;em&gt;alignment
Oct 01 2014 00:00    Directory high&lt;/em&gt;coverage&lt;em&gt;alignment
Oct 01 2014 00:00    Directory sequence&lt;/em&gt;read
这些数据实在是太丰富了！
也可以直接看最新版的vcf文件，记录了这两千多人的所有变异位点信息！
可以直接看到所有的位点，具体到每个人在该位点是否变异！
&lt;a href=&#34;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/&#34;&gt;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/&lt;/a&gt;
不过它的基因型信息是通过MVNcall+SHAPEIT这个程序call出来的，具体原理见：&lt;a href=&#34;http://www.ncbi.nlm.nih.gov/pubmed/23093610&#34;&gt;http://www.ncbi.nlm.nih.gov/pubmed/23093610&lt;/a&gt;
而且网站还提供一些教程：&lt;a href=&#34;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/working/&#34;&gt;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/working/&lt;/a&gt;
我们肯定可以在千人基因计划的官网下载测序数据，主要是vcf格式的突变！
Coriell Catalog website: 1000 Genomes Project
1000 Genomes website: browser.1000genomes.org/index.html (by SNP ID)
1000 Genomes website: www.1000genomes.org/data (bulk data)
但是关于它的表达数据，就不是那么简单了！
The most important available existing expression datasets involving 1000g individuals are probably the following:&lt;/p&gt;

&lt;p&gt;RNAseq (mRNA &amp;amp; miRNA) on 465 individuals (CEU, TSI, GBR, FIN, YRI)&lt;/p&gt;

&lt;p&gt;Pre-publication RNA-sequencing data from the Geuvadis project is available through &lt;a href=&#34;http://www.geuvadis.org&#34;&gt;http://www.geuvadis.org&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.ebi.ac.uk/arrayexpress/experiments/E-GEUV-1/samples.html&#34;&gt;http://www.ebi.ac.uk/arrayexpress/experiments/E-GEUV-1/samples.html&lt;/a&gt;
&lt;a href=&#34;http://www.ebi.ac.uk/arrayexpress/experiments/E-GEUV-2/samples.html&#34;&gt;http://www.ebi.ac.uk/arrayexpress/experiments/E-GEUV-2/samples.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;RNAseq on 60 CEU individual [1]&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.ebi.ac.uk/arrayexpress/experiments/E-MTAB-197&#34;&gt;http://www.ebi.ac.uk/arrayexpress/experiments/E-MTAB-197&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Expression arrays on about 800 HapMap 3 individuals with a lot of overlap with 1000g data [1,2]&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.ebi.ac.uk/arrayexpress/experiments/E-MTAB-198&#34;&gt;http://www.ebi.ac.uk/arrayexpress/experiments/E-MTAB-198&lt;/a&gt;
&lt;a href=&#34;http://www.ebi.ac.uk/arrayexpress/experiments/E-MTAB-264&#34;&gt;http://www.ebi.ac.uk/arrayexpress/experiments/E-MTAB-264&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;RNAseq for 69 YRI individuals [3]&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.ebi.ac.uk/arrayexpress/experiments/E-GEOD-19480&#34;&gt;http://www.ebi.ac.uk/arrayexpress/experiments/E-GEOD-19480&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;居然可以下载千人基因组计划的所有数据bam-vcf数据&#34;&gt;居然可以下载千人基因组计划的所有数据bam，vcf数据&lt;/h1&gt;

&lt;p&gt;它有两个ftp站点存储所有的数据！
&lt;a href=&#34;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/&#34;&gt;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/&lt;/a&gt;
&lt;a href=&#34;ftp://ftp.ncbi.nlm.nih.gov/1000genomes/ftp/&#34;&gt;ftp://ftp.ncbi.nlm.nih.gov/1000genomes/ftp/&lt;/a&gt;
直接看最新版的数据，共有NA编号开头的1182个人，HG开头的1768个人！
&lt;a href=&#34;ftp://ftp.ncbi.nlm.nih.gov/1000genomes/ftp/phase3/data/&#34;&gt;ftp://ftp.ncbi.nlm.nih.gov/1000genomes/ftp/phase3/data/&lt;/a&gt;
也可以按照人种来查看这些数据：&lt;a href=&#34;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/data/&#34;&gt;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/data/&lt;/a&gt;
每个人的目录下面都有 四个数据文件夹&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Oct 01 2014 00:00    Directory alignment
Oct 01 2014 00:00    Directory exome_alignment
Oct 01 2014 00:00    Directory high_coverage_alignment
Oct 01 2014 00:00    Directory sequence_read
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这些数据实在是太丰富了！
也可以直接看最新版的vcf文件，记录了这两千多人的所有变异位点信息！
可以直接看到所有的位点，具体到每个人在该位点是否变异！
&lt;a href=&#34;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/&#34;&gt;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/&lt;/a&gt;
不过它的基因型信息是通过MVNcall+SHAPEIT这个程序call出来的，具体原理见：&lt;a href=&#34;http://www.ncbi.nlm.nih.gov/pubmed/23093610&#34;&gt;http://www.ncbi.nlm.nih.gov/pubmed/23093610&lt;/a&gt;
而且网站还提供一些教程：&lt;a href=&#34;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/working/&#34;&gt;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/working/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;还有Illumina的450K甲基化芯片数据：&lt;a href=&#34;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/hgsv_sv_discovery/working/20151214_450k_methylation/&#34;&gt;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/hgsv_sv_discovery/working/20151214_450k_methylation/&lt;/a&gt;
还有一个小程序，&lt;a href=&#34;ftp://ftp.ncbi.nlm.nih.gov/1000genomes/ftp/technical/browser/vcf_to_ped_converter/version_1.1/&#34;&gt;ftp://ftp.ncbi.nlm.nih.gov/1000genomes/ftp/technical/browser/vcf_to_ped_converter/version_1.1/&lt;/a&gt;
还有Illumina的450K甲基化芯片数据：&lt;a href=&#34;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/hgsv_sv_discovery/working/20151214_450k_methylation/&#34;&gt;ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/hgsv_sv_discovery/working/20151214_450k_methylation/&lt;/a&gt;
还有一个小程序，&lt;a href=&#34;ftp://ftp.ncbi.nlm.nih.gov/1000genomes/ftp/technical/browser/vcf_to_ped_converter/version_1.1/&#34;&gt;ftp://ftp.ncbi.nlm.nih.gov/1000genomes/ftp/technical/browser/vcf_to_ped_converter/version_1.1/&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;roadmap&#34;&gt;roadmap&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.roadmapepigenomics.org/&#34;&gt;http://www.roadmapepigenomics.org/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;精选的129个细胞系，细胞系的介绍如下：&lt;a href=&#34;http://www.broadinstitute.org/~anshul/projects/roadmap/metadata/EID_metadata.tab&#34;&gt;http://www.broadinstitute.org/~anshul/projects/roadmap/metadata/EID_metadata.tab&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;对每个细胞系，都至少处理了5个核心组蛋白修饰数据，还有其它若干转录因子数据。
官网介绍的很详细，我就不翻译了：&lt;/p&gt;

&lt;p&gt;The NIH Roadmap Epigenomics Mapping Consortium was launched with the goal of producing a public resource of human epigenomic data to catalyze basic biology and disease-oriented research. The Consortium leverages experimental pipelines built around next-generation sequencing technologies to map DNA methylation, histone modifications, chromatin accessibility and small RNA transcripts in stem cells and primary ex vivo tissues selected to represent the normal counterparts of tissues and organ systems frequently involved in human disease. The Consortium expects to deliver a collection of normal epigenomes that will provide a framework or reference for comparison and integration within a broad array of future studies. The Consortium also aims to close the gap between data generation and its public dissemination by rapid release of raw sequence data, profiles of epigenomics features and higher-level integrated maps to the scientific community. The Consortium is also committed to the development, standardization and dissemination of protocols, reagents and analytical tools to enable the research community to utilize, integrate and expand upon this body of data.&lt;/p&gt;

&lt;p&gt;首先是这个网站：
&lt;a href=&#34;http://www.encode-roadmap.org/&#34;&gt;http://www.encode-roadmap.org/&lt;/a&gt;
矩阵很容易看懂roadmap处理了哪些细胞系，进行了什么样的处理，数据可以直接下载。&lt;/p&gt;

&lt;p&gt;然后我比较首先推崇broad研究所的下载方式&lt;/p&gt;

&lt;p&gt;里面还列出了他们用过的peaks caller 工具：
&lt;a href=&#34;http://www.broadinstitute.org/~anshul/projects/encode/preprocessing/peakcalling/&#34;&gt;http://www.broadinstitute.org/~anshul/projects/encode/preprocessing/peakcalling/&lt;/a&gt;  可以看到，主要有MACS，peakranger，quest，sicer，peakseq，hotspot等等
直接进入broad分析好的peaks结果：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[DIR]   Parent Directory    
-   
[DIR]   broadPeak/  08-Feb-2015 21:00   -   
[DIR]   gappedPeak/ 08-Feb-2015 21:00   -   
[DIR]   lowq/   31-Aug-2014 20:42   -   
[DIR]   narrowPeak/ 08-Feb-2015 20:59   -   
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里面有3种peaks，我现在还没有搞懂是什么意思。&lt;/p&gt;

&lt;p&gt;接着是 iHEC存放的数据：&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://epigenomesportal.ca/ihec/download.html&#34;&gt;http://epigenomesportal.ca/ihec/download.html&lt;/a&gt;
我还是第一次看到这个数据接口，也是以文件夹文件的形式直接浏览，根据自己的需求下载即可：
除了ENCODE计划的数据，还有Blueprint计划和roadmap计划的数据都可以下载。
NIH Roadmap 2014-05-29  Click here for policies
最后可以从圣路易斯华盛顿大学里面下载&lt;/p&gt;

&lt;p&gt;圣路易斯华盛顿大学Washington University in St. Louis，简称（Wash U，WU）以美国国父乔治·华盛顿命名，始建于1853年2月22日，位于美国密苏里州圣路易斯市，是美国历史上建校最早也是最负盛名的“华盛顿大学”，该校在美国新闻和世界报道（US News &amp;amp; World Report）2014大学综合排名中名列14位。
里面有一个非常详细的页面来介绍roadmap的各种数据:&lt;a href=&#34;http://egg2.wustl.edu/roadmap/web_portal/processed_data.html&#34;&gt;http://egg2.wustl.edu/roadmap/web_portal/processed_data.html&lt;/a&gt;
如果你已经了解了roadmap计划，就很容易找到自己的数据，从而直接浏览器或者wget下载即可。
首先是序列比对结果下载。
onsolidated Epigenomes:36 bp mappability filtered, pooled and subsampled read alignment files:
&lt;a href=&#34;http://egg2.wustl.edu/roadmap/data/byFileType/alignments/consolidated/&#34;&gt;http://egg2.wustl.edu/roadmap/data/byFileType/alignments/consolidated/&lt;/a&gt;
Unconsolidated Epigenomes (Uniform mappability): 36 bp mappability filtered primary alignment files:
&lt;a href=&#34;http://egg2.wustl.edu/roadmap/data/byFileType/alignments/unconsolidated/&#34;&gt;http://egg2.wustl.edu/roadmap/data/byFileType/alignments/unconsolidated/&lt;/a&gt;
包括各种peaks记录文件下载
Narrow contiguous regions of enrichment (peaks) for histone ChIP-seq and DNase-seq
Data format: NarrowPeak
&lt;a href=&#34;http://egg2.wustl.edu/roadmap/data/byFileType/peaks/consolidated/narrowPeak/&#34;&gt;http://egg2.wustl.edu/roadmap/data/byFileType/peaks/consolidated/narrowPeak/&lt;/a&gt;
Broad domains on enrichment for histone ChIP-seq and DNase-seq)
Data format: BroadPeak
&lt;a href=&#34;http://egg2.wustl.edu/roadmap/data/byFileType/peaks/consolidated/broadPeak/&#34;&gt;http://egg2.wustl.edu/roadmap/data/byFileType/peaks/consolidated/broadPeak/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Data format: GappedPeak (subset of domains containing at least one narrow peaks)
&lt;a href=&#34;http://egg2.wustl.edu/roadmap/data/byFileType/peaks/consolidated/gappedPeak/&#34;&gt;http://egg2.wustl.edu/roadmap/data/byFileType/peaks/consolidated/gappedPeak/&lt;/a&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>nat123</title>
      <link>/blog/cn/2017/11/nat123/</link>
      <pubDate>Sun, 05 Nov 2017 22:02:28 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/nat123/</guid>
      <description>
        

&lt;h1 id=&#34;启动&#34;&gt;启动&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.nat123.com/Pages_17_619.jsp&#34;&gt;教程&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;#cd  /soft/nat123    --进入自己本地实际安装目录
#mono  nat123linux.sh     --根据提示手动输入帐号密码 
#mono  nat123linux.sh  service  &amp;amp;     --自动读取上一次成功登录帐号以后台服务启动
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;开机自动登录&#34;&gt;开机自动登录&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;（1）本地必须先手动输入帐号密码成功登录一次；
（2）执行“chmod +x /etc/rc.local”命令确保有权限；
（3）把启动程序的命令添加到/etc/rc.local文件中，此文件内容如下，
#!/bin/sh -e
# rc.local
# This script is executed at the end of each multiuser runlevel.
# Make sure that the script will &amp;quot;exit 0&amp;quot; on success or any other
# value on error.
# In order to enable or disable this script just change the execution
# bits.
# By default this script does nothing.

cd  /soft/nat123    --本地实际安装目录
mono  nat123linux.sh  service  &amp;amp;      ---自动读取上次成功登录帐号并以后台服务启动

exit 0
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;linux环境开机自动启动防掉线脚本&#34;&gt;LINUX环境开机自动启动防掉线脚本&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.nat123.com/Pages_17_682.jsp&#34;&gt;教程&lt;/a&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>转录组分析笔记（2）</title>
      <link>/blog/cn/2017/11/transcriptome_analysis1/</link>
      <pubDate>Sun, 05 Nov 2017 09:34:40 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/transcriptome_analysis1/</guid>
      <description>
        

&lt;p&gt;这是一个生信技能树的优秀作业，一字未改。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.biotrainee.com/thread-1931-1-1.html&#34;&gt;原文&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;转录组差异表达分析小实战-一&#34;&gt;转录组差异表达分析小实战（一）&lt;/h2&gt;

&lt;h5 id=&#34;读文献获取数据&#34;&gt;读文献获取数据&lt;/h5&gt;

&lt;p&gt;文献名称：AKAP95 regulates splicing through scaffolding
RNAs and RNA processing factors&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;查找数据：Data availability&lt;br /&gt;
The RIP-seq an RNA-seq data have been deposited in the Gene
Expression Omnibus database, with accession code GSE81916. All other data is
available from the author upon reasonable request.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;获得GSE号：GSE81916&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&#34;下载测序数据&#34;&gt;下载测序数据&lt;/h5&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE81916&#34;&gt;https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE81916&lt;/a&gt;获取数据信息，并点击网址下方的ftp，下载测序数据&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;从&lt;a href=&#34;https://trace.ncbi.nlm.nih.gov/Traces/study/?acc=PRJNA323422&#34;&gt;https://trace.ncbi.nlm.nih.gov/Traces/study/?acc=PRJNA323422&lt;/a&gt;可知我们需要的mRNA测序编号为SRR3589956到SRR3589962&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;通过Apera下载SRR数据，这里以SRR3589956为例：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ascp -T -i /home/anlan/.aspera/connect/etc/asperaweb_id_dsa.openssh anonftp@ftp-private.ncbi.nlm.nih.gov:sra/sra-instant/reads/ByRun/sra/SRR/SRR358/SRR3589956/SRR3589956.sra ./
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&#34;转化fastq测序数据&#34;&gt;转化fastq测序数据&lt;/h5&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;通过sratoolkit工具将SRR文件转化为fastq格式的测序数据（写了个shell循环）&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for i in $(seq 56 62);do nohup fastq-dump --split-3  SRR35899${i} &amp;amp;;done
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;通过fastqc对每个fastq文件进行质检，用multiqc查看整体质检报告（对当前目录下的fastq测序结果进行质检，生成每个fq文件的质检报告总multiqc整合后统计查看）&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fastqc *.fastq
multiqc ./
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;点击这个url可以查看我这个multiqc报告：&lt;a href=&#34;http://www.bioinfo-scrounger.com/data/multiqc_report.html&#34;&gt;http://www.bioinfo-scrounger.com/data/multiqc_report.html&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如果有接头或者质量值不达标的需要进行过滤，这次的数据质量都不错，因此直接进行比对即可&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&#34;序列比对&#34;&gt;序列比对&lt;/h5&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;安装hisat2软件，下载人类的hiast2索引文件&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;hisat2下载并安装：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ftp://ftp.ccb.jhu.edu/pub/infphilo/hisat2/downloads/hisat2-2.1.0-Linux_x86_64.zip
unzip hisat2-2.1.0-Linux_x86_64.zip
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;下载hisat2的human索引&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ftp://ftp.ccb.jhu.edu/pub/infphilo/hisat2/data/hg19.tar.gz
tar zxvf hg19.tar.gz
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;用hisat2进行比对，测序数据放在data目录下，索引文件放在reference/index/hisat2/hg19目录下，SRR3589956-SRR3589958为人的测序数据&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for i in $(seq 56 58);do hisat2 -p 4 \
-x ~/reference/index/hisat2/hg19/genome \
-1 ./data/SRR35899${i}_1.fastq -2 ./data/SRR35899${i}_2.fastq \
-S SRR35899$i.sam &amp;gt;SRR35899${i}.log;done
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;用samtools将sam文件转化为bam文件，并使用默认排序&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for i in $(seq 56 58);do samtools sort -@ 5 -o SRR35899${i}.bam SRR35899${i}.sam;done
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&#34;reads计数&#34;&gt;reads计数&lt;/h5&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;用htseq对比对产生的bam进行count计数&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;htseq安装，使用miniconda，省事！唯一的问题是htseq版本不是最新的，是0.7.2。想要最新版还是要正常安装，可参考&lt;a href=&#34;http://www.biotrainee.com/thread-1847-1-2.html&#34;&gt;http://www.biotrainee.com/thread-1847-1-2.html&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;conda install -c bioconda htseq
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;用htseq将对比后的结果进行计数&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for i in $(seq 56 58);do htseq-count -f bam -r pos -s no \
SRR35899${i}.bam ~/reference/genome/hg19/gencode.v26lift37.annotation.gtf \
1&amp;gt;SRR35899${i}.count 2&amp;gt;SRR35899${i}_htseq.log;done
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;将3个count文件（SRR3589956.count，SRR3589957.count，SRR3589958.count）合并成一个count矩阵，这是就需要脚本来解决这个问题，不然其他方法会稍微麻烦点&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!/usr/bin/perl -w
use strict;

my $path = shift @ARGV;
opendir DIR, $path or die;
my @dir = readdir DIR;

my $header;
my @sample;
my %hash;
foreach my $file (@dir) {
    if ($file =~ /^\w+.*\.count/) {
        push @sample, $file;
        $header .= &amp;quot;\t$file&amp;quot;;
        open my $fh, $file or die;
        while (&amp;lt;$fh&amp;gt;) {
            chomp;
            next if ($_ =~ /^\W+/);
            my @array = split /\t/, $_;
            $hash{$array[0]} -&amp;gt; {$file} = $array[1];
        }
        close $fh;
    }
}
print &amp;quot;$header\n&amp;quot;;
map{
    my $gene = $_;
    print &amp;quot;$gene&amp;quot;;
    foreach my $file (@sample) {
        print &amp;quot;\t&amp;quot;.$hash{$gene} -&amp;gt; {$file};
    }
    print &amp;quot;\n&amp;quot;;
}keys %hash;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;按照接下来的剧本，应该讲count&lt;em&gt;matrix文件导入DESeq进行差异表达分析。但是从这篇文章的Bioinformatic analyses部分可以发现，作者的control组的2组数据是来自2个不同的批次（一个是SRR3589956，另外一个来源GSM1095127 in GSE44976），treat组倒是同一个批次（SRR3589957和SRR3589958）。但是对于Mouse cells来说，倒是满足2个control和2个treat都正常来自同个批次，因此打算重新用SRR3589959-SRR3589962重新做个一个count&lt;/em&gt;matrix进行后续差异分析&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

        
      </description>
    </item>
    
    <item>
      <title>转录组分析笔记</title>
      <link>/blog/cn/2017/11/transcriptome_analysis/</link>
      <pubDate>Sun, 05 Nov 2017 09:34:39 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/transcriptome_analysis/</guid>
      <description>
        

&lt;p&gt;这是一个学习笔记，跟随生信技能树的学习笔记重复,把几个优秀笔记的内容重复摘录在此。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;学习提纲&lt;/strong&gt;：&lt;a href=&#34;http://www.biotrainee.com/thread-1750-1-1.html&#34;&gt;RNA-seq基础入门传送门&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;文章链接&lt;/strong&gt;：&lt;a href=&#34;https://www.nature.com/articles/ncomms13347&#34;&gt;https://www.nature.com/articles/ncomms13347&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;非常棒的学习笔记1&lt;/strong&gt;：&lt;a href=&#34;https://taoshengxu.github.io/DocumentGit/pdf/沈梦圆2017年转录组入门合辑0-6.pdf&#34;&gt;PANDA姐的转录组入门（0-6）合辑&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;非常棒的学习笔记2&lt;/strong&gt;:&lt;a href=&#34;https://taoshengxu.github.io/DocumentGit/pdf/浙大植物学小白的转录组笔记.pdf&#34;&gt;浙大植物学小白的转录组笔记&lt;/a&gt; &lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=MzAxMDkxODM1Ng==&amp;amp;mid=2247484895&amp;amp;idx=1&amp;amp;sn=678da702fa929789b177d214070dd39a&amp;amp;chksm=9b484564ac3fcc72914b0ae2c1b71adb63fb359cf7e73221be1ddfd3040efa2944c91bee8e3b&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=0824NWlPEoAgwVKtIWnkEDd9#rd&#34;&gt;Link2&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;非常棒的学习笔记3&lt;/strong&gt;:&lt;a href=&#34;./post/transcriptome_analysis1.html&#34;&gt;下一篇&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;分析软件安装&#34;&gt;分析软件安装&lt;/h1&gt;

&lt;p&gt;最方便的安装方式就是 Anaconda&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;wget https://repo.continuum.io/archive/Anaconda3-4.4.0-Linux-x86_64.sh

 conda install -c bioconda samtools=1.5
 conda install -c bioconda htseq=0.7.2
 conda install -c bioconda hisat2=2.1.0
 conda install -c bioconda fastqc=0.11.5
 conda install -c jfear sratoolkit=2.8.1
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;数据下载&#34;&gt;数据下载&lt;/h1&gt;

&lt;p&gt;From NCBI GEO ftp&lt;/p&gt;

&lt;p&gt;The RIP-seq an RNA-seq data have been deposited in the Gene Expression Omnibus database, with accession code &lt;strong&gt;GSE81916&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&#34;数据分析&#34;&gt;数据分析&lt;/h1&gt;

&lt;h2 id=&#34;质控&#34;&gt;质控&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;for id in `seq 56 62`
do fastq-dump --gzip --split-3 -O /data/RNASeq -A SRR35899${id}
done ##很慢，建议后台多线程

##查看fastq文件
zcat SRR3589956_1.fastq.gz | head -n 4
##安装集成分析工具
conda install -c bioconda multiqc

# 先获取QC结果
ls *gz | while read id; do fastqc -t 4 $id; done
# multiqc
multiqc *fastqc.zip --pdf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Python质控脚本&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import re
import zipfile
# read the zip file
def zipReader(file):
    qcfile =  zipfile.ZipFile(file)
    data_txt = [file for file in qcfile.namelist() if re.match(&amp;quot;.*?_data\.txt&amp;quot;, file)][0]
    data = [bytes.decode(line) for line in qcfile.open(data_txt)]
    return data
 
def fastqc_summary(data):
    module_num = 0
    bases = 0
    Q20 = 0
    Q30 = 0
    for line in data:
        if re.match(&#39;Filename&#39;, line):
            filename = line.split(sep=&amp;quot;\t&amp;quot;)[1].strip()
        if re.match(&#39;Total Sequence&#39;, line):
            read = line.split(sep=&amp;quot;\t&amp;quot;)[1].strip()
        if re.match(&#39;%GC&#39;, line):
            GC = line.split(sep=&amp;quot;\t&amp;quot;)[1].strip()
        if re.match(&amp;quot;[^#](.*?\t){6}&amp;quot;,line):
            bases = bases + 1
            if float(line.split(&amp;quot;\t&amp;quot;)[1]) &amp;gt; 30:
                Q20 = Q20 + 1
                Q30 = Q30 + 1
            elif float(line.split(&amp;quot;\t&amp;quot;)[1]) &amp;gt; 20:
                Q20 = Q20 + 1
 
        if re.match(&amp;quot;&amp;gt;&amp;gt;END&amp;quot;, line) :
            module_num = module_num + 1
            if module_num &amp;gt;= 2:
                break
    Q20 = Q20 / bases
    Q30 = Q30 / bases
    summary = [filename, read, GC, str(Q20), str(Q30)]
    return summary
 
if __name__ == &#39;__main__&#39;:
    import sys
    for arg in range(1, len(sys.argv)):
        data = zipReader(sys.argv[arg])
        summary = fastqc_summary(data)
        with open(&#39;summary.txt&#39;, &#39;a&#39;) as f:
            f.write(&#39;\t&#39;.join(summary) + &#39;\n&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;grep -w &#39;gene&#39; gencode.v26lift37.annotation.gtf |grep -w &#39;TP53&#39;|cut -f 1,4,5 &amp;gt;&amp;gt;gene.bed
grep -w &#39;gene&#39; gencode.v26lift37.annotation.gtf |grep -w &#39;KRAS&#39;|cut -f 1,4,5 &amp;gt;&amp;gt;gene.bed
grep -w &#39;gene&#39; gencode.v26lift37.annotation.gtf |grep -w &#39;EGFR&#39;|cut -f 1,4,5 &amp;gt;&amp;gt;gene.bed
bedtools igv -i gene.bed &amp;gt;Bach_sanpshot.txt
perl -alne &#39;{print &amp;quot;goto $F[0]:$F[1]-$F[2]\nsnapshot $F[3].png&amp;quot;} &#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;hisat2比对&#34;&gt;Hisat2比对&lt;/h2&gt;

&lt;p&gt;HISAT2是TopHat2/Bowti2的继任者，使用改进的BWT算法，实现了更快的速度和更少的资源占用，作者推荐TopHat2/Bowti2和HISAT的用户转换到HISAT2。
官网：&lt;a href=&#34;https://ccb.jhu.edu/software/hisat2/index.shtml&#34;&gt;https://ccb.jhu.edu/software/hisat2/index.shtml&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;1.建立基因组索引or index 下载&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;#建立基因组索引
#hisat2-build –p 4 genome.fa genome

#下载索引
cd ~/reference
mkdir -p index/hisat &amp;amp;&amp;amp; cd index/hisat
wget -c ftp://ftp.ccb.jhu.edu/pub/infphilo/hisat2/data/hg19.tar.gz
wget -c ftp://ftp.ccb.jhu.edu/pub/infphilo/hisat2/data/mm10.tar.gz
tar zxvf hg19.tar.gz
tar xvzf mm10.tar.gz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.比对&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;for i in `seq 56 58`
do
    hisat2 -t -p 24 -x /data/Reference/index/hisat2/hg19/genome \
    -1 /data/RNASeq/fastq/SRR35899${i}_1.fastq.gz \
    -2 SRR35899${i}_2.fastq.gz \
    -S /data/RNASeq/fastq/SRR35899${i}.sam &amp;gt; SRR35899${i}.log &amp;amp;
done


##比对结果
xts@R710:/data/RNASeq/fastq$ for i in `seq 56 58`
&amp;gt; do
&amp;gt;     hisat2 -t -p 24 -x /data/Reference/index/hisat2/hg19/genome \
&amp;gt;     -1 /data/RNASeq/fastq/SRR35899${i}_1.fastq.gz \
&amp;gt;     -2 SRR35899${i}_2.fastq.gz \
&amp;gt;     -S /data/RNASeq/fastq/SRR35899${i}.sam &amp;gt; SRR35899${i}.log &amp;amp;
&amp;gt; done
[1] 11177
[2] 11178
[3] 11179
xts@R710:/data/RNASeq/fastq$ tipTime loading forward index: 00:00:24
Time loading forward index: 00:00:24
Time loading forward index: 00:00:24
Time loading reference: 00:00:04
Time loading reference: 00:00:04
Time loading reference: 00:00:04
Multiseed full-index search: 00:13:22
28856780 reads; of these:
  28856780 (100.00%) were paired; of these:
    1838981 (6.37%) aligned concordantly 0 times
    24732654 (85.71%) aligned concordantly exactly 1 time
    2285145 (7.92%) aligned concordantly &amp;gt;1 times
    ----
    1838981 pairs aligned concordantly 0 times; of these:
      90927 (4.94%) aligned discordantly 1 time
    ----
    1748054 pairs aligned 0 times concordantly or discordantly; of these:
      3496108 mates make up the pairs; of these:
        2034939 (58.21%) aligned 0 times
        1221462 (34.94%) aligned exactly 1 time
        239707 (6.86%) aligned &amp;gt;1 times
96.47% overall alignment rate
Time searching: 00:13:26
Overall time: 00:13:50

Multiseed full-index search: 00:14:42
25914821 reads; of these:
  25914821 (100.00%) were paired; of these:
    1785160 (6.89%) aligned concordantly 0 times
    21786672 (84.07%) aligned concordantly exactly 1 time
    2342989 (9.04%) aligned concordantly &amp;gt;1 times
    ----
    1785160 pairs aligned concordantly 0 times; of these:
      53455 (2.99%) aligned discordantly 1 time
    ----
    1731705 pairs aligned 0 times concordantly or discordantly; of these:
      3463410 mates make up the pairs; of these:
        2187330 (63.16%) aligned 0 times
        1050929 (30.34%) aligned exactly 1 time
        225151 (6.50%) aligned &amp;gt;1 times
95.78% overall alignment rate
Time searching: 00:14:46
Overall time: 00:15:10
[1]   已完成               hisat2 -t -p 24 -x /data/Reference/index/hisat2/hg19/genome -1 /data/RNASeq/fastq/SRR35899${i}_1.fastq.gz -2 SRR35899${i}_2.fastq.gz -S /data/RNASeq/fastq/SRR35899${i}.sam &amp;gt; SRR35899${i}.log
[3]+  已完成               hisat2 -t -p 24 -x /data/Reference/index/hisat2/hg19/genome -1 /data/RNASeq/fastq/SRR35899${i}_1.fastq.gz -2 SRR35899${i}_2.fastq.gz -S /data/RNASeq/fastq/SRR35899${i}.sam &amp;gt; SRR35899${i}.log
xts@R710:/data/RNASeq/fastq$ Multiseed full-index search: 00:16:08
29720636 reads; of these:
  29720636 (100.00%) were paired; of these:
    1920019 (6.46%) aligned concordantly 0 times
    25503958 (85.81%) aligned concordantly exactly 1 time
    2296659 (7.73%) aligned concordantly &amp;gt;1 times
    ----
    1920019 pairs aligned concordantly 0 times; of these:
      61683 (3.21%) aligned discordantly 1 time
    ----
    1858336 pairs aligned 0 times concordantly or discordantly; of these:
      3716672 mates make up the pairs; of these:
        2292272 (61.68%) aligned 0 times
        1196099 (32.18%) aligned exactly 1 time
        228301 (6.14%) aligned &amp;gt;1 times
96.14% overall alignment rate
Time searching: 00:16:12
Overall time: 00:16:36

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;数据转换sam-bam-sorted bam&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for i in `seq 56 58`
do
    samtools view -S SRR35899${i}.sam -b &amp;gt; SRR35899${i}.bam
    samtools sort SRR35899${i}.bam -o SRR35899${i}_sorted.bam
    samtools index SRR35899${i}_sorted.bam
done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;SAMtools其他操作&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;head -1000 SRR3589957.sam &amp;gt; test.sam
samtools view -b  test.sam &amp;gt; test.bam
samtools view test.bam | head

samtools sort test.bam -o default.bam
samtools view default.bam | head
 
# Sort alignments by leftmost coordinates, or by read name when -n is used
samtools sort test.bam default
samtools view default.bam | head


#提取1号染色体1234-123456区域的比对read
samtools view SRR3589957_sorted.bam chr1:1234-123456 | head

#在比如搭配flag(0.1.19版本没有）和flagstat，使用-f或-F参数提取不同匹配情况的read。

# 可以先用flagstat看下总体情况
samtools flagstat SRR3589957_sorted.bam

#筛选恰好配对的read,就需要用0x10
samtools view -b -f 0x10 SRR3589957_sorted.bam chr1:1234-123456  &amp;gt; flag.bam
samtools flagstat flag.bam
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;比对质控&#34;&gt;比对质控&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;RSeQC——&lt;a href=&#34;http://rseqc.sourceforge.net/&#34;&gt;http://rseqc.sourceforge.net/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Qualimap——&lt;a href=&#34;http://qualimap.bioinfo.cipf.es/&#34;&gt;http://qualimap.bioinfo.cipf.es/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Picard——&lt;a href=&#34;http://broadinstitute.github.io/picard/&#34;&gt;http://broadinstitute.github.io/picard/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;使用RSeQC来对我们的比对结果进行质控,RSeQC包括了十多个Python脚本，实现很多功能，具体每个脚本的参数用法，都可以在官网学习.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# RSeQC的安装，需要先安装gcc；numpy；R；Python2.7
$ pip install RSeQC
# 对bam文件进行质控，其余都同样的进行
$ bam_stat.py  -i SRR3589956_sorted.bam

基因组覆盖率的QC需要提供bed文件，可以直接RSeQC的网站下载，或者可以用gtf转换
read_distribution.py -i RNA-Seq/aligned/SRR3589956_sorted.bam -r reference/hg19_RefSeq.bed
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;reads-计数-from-hoptop&#34;&gt;Reads 计数 (From hoptop)&lt;/h1&gt;

&lt;p&gt;定量分为三个水平
- 基因水平(gene-level)
- 转录本水平(transcript-level)
- 外显子使用水平(exon-usage-level)。&lt;/p&gt;

&lt;p&gt;1.在&lt;strong&gt;基因水平&lt;/strong&gt;上，常用的软件为HTSeq-count，featureCounts，BEDTools, Qualimap, Rsubread, GenomicRanges等。以常用的HTSeq-count为例，这些工具要解决的问题就是&lt;strong&gt;根据read和基因位置的overlap判断这个read到底是谁家的孩子&lt;/strong&gt;。值得注意的是不同工具对multimapping reads处理方式也是不同的，例如HTSeq-count就直接当它们不存在。而Qualimpa则是一人一份，平均分配。&lt;/p&gt;

&lt;p&gt;对每个基因计数之后得到的count matrix再后续的分析中，要注意标准化的问题。如果你要比较同一个样本(within-sample)不同基因之间的表达情况，你就需要考虑到&lt;strong&gt;转录本长度&lt;/strong&gt;，因为转录本越长，那么检测的片段也会更多，直接比较等于让小孩和大人进行赛跑。如果你是比较不同样本（across sample）同一个基因的表达情况，虽然不必在意转录本长度，但是你要考虑到&lt;strong&gt;测序深度&lt;/strong&gt;（sequence depth)，毕竟测序深度越高，检测到的概率越大。除了这两个因素外，你还需要考虑GC%所导致的偏差，以及测序仪器的系统偏差。目前对read count标准化的算法有RPKM（SE）, FPKM（PE），TPM, TMM等，不同算法之间的差异与换算方法已经有文章进行整理和吐槽了。但是，有一些下游分析的软件会要求是输入的count matrix是原始数据，未经标准化，比如说DESeq2，这个时候你需要注意你上一步所用软件会不会进行标准化。&lt;/p&gt;

&lt;p&gt;2.在&lt;strong&gt;转录本水平&lt;/strong&gt;上，一般常用工具为Cufflinks和它的继任者StringTie， eXpress。这些软件要处理的难题就时转录本亚型（isoforms）之间通常是有重叠的，当二代测序读长低于转录本长度时，如何进行区分？这些工具大多采用的都是expectation maximization（EM）。好在我们有三代测序。
上述软件都是alignment-based，目前许多alignment-free软件，如kallisto, silfish, salmon，能够省去比对这一步，直接得到read count，在运行效率上更高。不过最近一篇文献[1]指出这类方法在估计丰度时存在样本特异性和读长偏差。&lt;/p&gt;

&lt;p&gt;3.在&lt;strong&gt;外显子使用水平&lt;/strong&gt;上，其实和基因水平的统计类似。但是值得注意的是为了更好的计数，我们需要提供无重叠的外显子区域的gtf文件。用于分析差异外显子使用的DEXSeq提供了一个Python脚本（dexseq&lt;em&gt;prepare&lt;/em&gt;annotation.py）执行这个任务。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mkdir -p /data/RNASeq/fastq/matrix/
for i in $(seq 56 58); 
do htseq-count -f bam -r pos -s no \
/data/RNASeq/fastq/SRR35899${i}_sorted.bam /data/Reference/gtf/gencode/gencode.v26lift37.annotation.sorted.gtf \
1&amp;gt;matrix/SRR35899${i}.count 2&amp;gt;matrix/SRR35899${i}_htseq.log &amp;amp;; done
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;表达矩阵&#34;&gt;表达矩阵&lt;/h2&gt;

&lt;p&gt;在RNA-Seq分析中，每一个基因就是一个feature（特征？），而基因被认为是它的所有外显子的和集。在可变剪切分析中，可以单独把每个外显子当作一个feature。而在ChIP-Seq分析中，feature则是预先定义的结合域。但是确定一个read到底属于哪一个feature有时会非常棘手。&lt;/p&gt;

&lt;h4 id=&#34;这段描述很有意思-信息量也很多-from-hoptop&#34;&gt;这段描述很有意思，信息量也很多(From hoptop)&lt;/h4&gt;

&lt;p&gt;我们这次分析是人类mRNA-Seq测序的结果，但是我们其实只下载了3个sra文件。一般而言RNA-Seq数据分析都至少要有2个重复，所以必须要有4个sra文件才行。我在仔细读完文章的方法这一段以后，发现他们有一批数据用的是其他课题组的： For 293 cells, the mRNA-seq results of the control samples include (1) those from the doxycycline-treated parental Flp-In T-REx 293 cells by us and (2) those from the doxycycline-treated control Flp-In T-REx 293 cells performed by another group unrelated to us (sample GSM1095127 in GSE44976)。 然后和Jimmy交流之后，他也承认自己只分析了小鼠的数据，而没有分析人类的数据。所以我们需要根据文章提供的线索下载另外一份数据，才能进行下一步的分析。
这个时候就有一个经常被问到的问题：不同来源的RNA-Seq数据能够直接比较吗？甚至说如果不同来源的RNA-seq数据的构建文库都不一样该如何比较?不同来源的RNA-Seq结果之间比较需要考虑 批次效应（batch effect) 的影响。
处理批次效应，根据我搜索的结果，是不能使用FPKM/RPKM，关于这个标准化的吐槽，我在biostars上找到了如下观点：
FPKM/RPKM 不是标准化的方法，它会引入文库特异的协变量
FPKM/RPKM has never been peer-reviewed, it has been introduced as an ad-hoc measure in a supplementary 没有同行评审
One of the authors of this paper states, that it should not be used because of faulty arithmetic 作者说算法有问题
All reviews so far have shown it to be an inferior scale for DE analysis of genes Length normalization is mostly dispensable imo in DE analysis because gene length is constant
有人建议使用一个Bioconductor包&lt;a href=&#34;http://www.bioconductor.org/packages/devel/bioc/html/sva.html&#34;&gt;http://www.bioconductor.org/packages/devel/bioc/html/sva.html&lt;/a&gt; 我没有具体了解，有生之年去了解补充。
还有人引用了一篇文献 IVT-seq reveals extreme bias in RNA-sequencing 证明不同文库的RNA-Seq结果会存在很大差异。
结论： 可以问下原作者他们是如何处理数据的，居然有一个居然没有重复的分析也能过审。改用小鼠数据进行分析。或者使用无重复的分析方法，或者模拟一份数据出来，先把流程走完。&lt;/p&gt;

&lt;h1 id=&#34;panda实践完整代码&#34;&gt;PANDA实践完整代码&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;##1.SRA to fastq

perl -F&#39;\t&#39; -alne &#39;if($F[7]=~/SRR/){$F[6]=~s/\s/_/g;$F[13]=~ s/\s|#/_/g;$F[13]=~s/\(|\)//g;print &amp;quot;$F[7]\t$F[6]_$F[13]&amp;quot;}&#39; SraRunTable.txt &amp;gt; Rename.txt

perl -F&#39;\t&#39; -alne &#39;print &amp;quot;fastq-dump --split-3 --gzip -A $F[1] $F[0].sra &amp;amp;&amp;quot; &#39; Rename.txt &amp;gt;sratofq.sh

sh sratofq.sh 

md5sum *.fastq.gz &amp;gt;md5sum.txt

##2.QC
cd MYShen
mkdir 1_FastQC_Raw_Data
ls *.gz|while read id;do(fastqc $id -o 1_FastQC_Raw_Data -t 8);done
# 质控统计
cd 1_FastQC_Raw_Data
for i in *.zip; do unzip $i; done
perl /data/RNASeq/MYShen/fastqc_table.pl
csvtk tab2csv fastqc_table.txt | csvtk csv2md
------------------------------------------------------------------------------------------------
                                                  |total_reads|GC |Q20              |Q30
:-------------------------------------------------|:----------|:--|:----------------|:----------------
Homo_sapiens_AKAP95_KD_miR_12_293_cell_1_fastqc   |25914821   |50 |0.999810031487387|0.972201583024633
Homo_sapiens_AKAP95_KD_miR_12_293_cell_2_fastqc   |25914821   |50 |0.977900484051192|0.934933990090072
Homo_sapiens_AKAP95_KD_miR_8_293_cell_1_fastqc    |29720636   |50 |0.992602101445318|0.966831930304341
Homo_sapiens_AKAP95_KD_miR_8_293_cell_2_fastqc    |29720636   |50 |0.978714654693123|0.93782410982053
Homo_sapiens_Control_293_cell_1_fastqc            |28856780   |50 |0.989872946867992|0.966726176148248
Homo_sapiens_Control_293_cell_2_fastqc            |28856780   |50 |0.977797280223227|0.940547004897982
Mus_musculus_E14_cells_Akap95_shRNA_rep1_1_fastqc |52972617   |50 |0.99966391028307 |0.987561698545491
Mus_musculus_E14_cells_Akap95_shRNA_rep1_2_fastqc |52972617   |50 |0.991854774481748|0.968082091276275
Mus_musculus_E14_cells_Akap95_shRNA_rep2_1_fastqc |43802631   |49 |0.999679725428068|0.972184686419785
Mus_musculus_E14_cells_Akap95_shRNA_rep2_2_fastqc |43802631   |49 |0.986887120253892|0.937616464383233
Mus_musculus_E14_cells_control_shRNA_rep1_1_fastqc|30468155   |50 |0.99960200376177 |0.987110860654561
Mus_musculus_E14_cells_control_shRNA_rep1_2_fastqc|30468155   |50 |0.991083449869222|0.966506018600785
Mus_musculus_E14_cells_control_shRNA_rep2_1_fastqc|36763726   |50 |0.999694316126568|0.979622471169646
Mus_musculus_E14_cells_control_shRNA_rep2_2_fastqc|36763726   |50 |0.990428680495556|0.951578715079022
-------------------------------------------------------------------------------------------------------
#截图几个基因的 IGV 可视化结构
grep -w &#39;gene&#39; gencode.v26lift37.annotation.gtf |grep -w &#39;TP53&#39;|cut -f 1,4,5 &amp;gt;&amp;gt;gene.bed
grep -w &#39;gene&#39; gencode.v26lift37.annotation.gtf |grep -w &#39;KRAS&#39;|cut -f 1,4,5 &amp;gt;&amp;gt;gene.bed
grep -w &#39;gene&#39; gencode.v26lift37.annotation.gtf |grep -w &#39;EGFR&#39;|cut -f 1,4,5 &amp;gt;&amp;gt;gene.bed
bedtools igv -i gene.bed &amp;gt;Bach_sanpshot.txt 
#perl -alne &#39;{print &amp;quot;goto $F[0]:$F[1]-$F[2]\nsnapshot $F[3].png&amp;quot;} &#39;


##3. HISAT2比对
---------------------------------------------------------------
#map.sh
--------------------------------------------------------------------------------------------
#! usr/bin/bash
set -u
set -e
set -o pipefail

hg19_ref=/data/Reference/index/hisat2/hg19/genome
mm10_ref=/data/Reference/index/hisat2/mm10/genome
data_path=/data/RNASeq/MYShen
NUM_THREADS=5
ls Homo*1.fastq.gz|while read id; \
do((hisat2 -t -p $NUM_THREADS -x $hg19_ref -1 $data_path/${id%_*}_1.fastq.gz -2 \
$data_path/${id%_*}_2.fastq.gz 2&amp;gt;${id%_*}_map.log | samtools view -b - &amp;gt;${id%_*}.bam) &amp;amp;);done 
                               
ls  Mus*1.fastq.gz|while read id; \
do((hisat2 -t -p $NUM_THREADS -x $mm10_ref -1 $data_path/${id%_*}_1.fastq.gz -2 \
$data_path/${id%_*}_2.fastq.gz 2&amp;gt;${id%_*}_map.log | samtools view -b - &amp;gt;${id%_*}.bam) &amp;amp;);done
---------------------------------------------------------------------------------------------        

bash map.sh
##因为前面开了并行，等前面执行完成，后面再单独执行
ls *.bam | while read id;do samtools sort --threads 25 $id -o ${id%.*}_sorted.bam; done 
ls *_sorted.bam | while read id;do samtools index $id; done


## 4.Count reads

# 人类
mkdir matrix
Homo_GTF=/data/Reference/gtf/gencode/gencode.v26lift37.annotation.gtf
###count 结果显示基因名称，如果用基因的id号，将 -i gene_name 参数删除即可
ls Homo_sapiens*sorted.bam | while read id; do (htseq-count -f bam -r pos -i gene_name -s no \
$id $Homo_GTF &amp;gt; matrix/${id%_*}.count 2&amp;gt; matrix/${id%_*}.log &amp;amp;); done

# 老鼠
# 下载 gtf：http://www.gencodegenes.org/mouse_stats/archive.html
axel ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_mouse/release_M10/gencode.vM10.annotation.gtf.gz
gzip -d gencode.vM10.annotation.gtf.gz
Mus_GTF=/data/Reference/gtf/gencode/gencode.vM10.annotation.gtf
ls Mus_musculus*sorted.bam|while read id;do (htseq-count -f bam -r pos -i gene_name -s no \
$id $Mus_GTF &amp;gt; matrix/${id%_*}.count 2&amp;gt; matrix/${id%_*}.log &amp;amp;);done


##另外一些相关的代码
## ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_mouse/release_M1/
## http://hgdownload-test.cse.ucsc.edu/goldenPath/mm10/liftOver/
## GRCm38/mm10 (Dec, 2011) 
## ls *bam |while read id;do ( ~/.local/bin/htseq-count  -f bam  $id   genecode/mm9/gencode.vM1.annotation.gtf.gz  1&amp;gt;${id%%.*}.gene.counts ) ;done 
## ls *bam |while read id;do ( ~/.local/bin/htseq-count  -f bam -i exon_id  $id   genecode/mm9/gencode.vM1.annotation.gtf.gz  1&amp;gt;${id%%.*}.exon.counts ) ;done

cd matrix
#wc命令的功能为统计指定文件中的字节数-c,字符数-m,字数-w,行数-l
wc -l Homo_sapiens*.count
head -n 4 Homo_sapiens*.count


perl -lne &#39;if($ARGV=~/Homo_sapiens_(.*)count/){print &amp;quot;$1\t$_&amp;quot;}&#39; *|grep -v Homo_sapiens&amp;gt;hg1.count
# 先把所有文件进行合并
setwd(&amp;quot;~/rna_seq/work/matrix&amp;quot;)
hg &amp;lt;- read.csv(file = &amp;quot;hg.count&amp;quot;,header = F,sep = &amp;quot;\t&amp;quot;)
colnames(hg) &amp;lt;- c(&#39;sample&#39;,&#39;gene&#39;,&#39;count&#39;)
library(reshape2)
reads &amp;lt;- dcast(hg,formula = gene ~ sample)
write.table(reads,file = &amp;quot;hg_join.count&amp;quot;,sep = &amp;quot;\t&amp;quot;,quote = FALSE,row.names = FALSE)
&lt;/code&gt;&lt;/pre&gt;

        
      </description>
    </item>
    
    <item>
      <title>NCBI-GEO数据下载</title>
      <link>/blog/cn/2017/11/ncbi_downlaod/</link>
      <pubDate>Sat, 04 Nov 2017 21:52:45 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/ncbi_downlaod/</guid>
      <description>
        

&lt;h1 id=&#34;geo-基础&#34;&gt;GEO 基础&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;GEO Platform (GPL) 芯片平台&lt;/li&gt;
&lt;li&gt;GEO Sample (GSM) 样本ID号&lt;/li&gt;
&lt;li&gt;GEO Series (GSE) study的ID号&lt;/li&gt;
&lt;li&gt;GEO Dataset (GDS) 数据集的ID号 ## 用法&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;数据搜索&#34;&gt;数据搜索&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;方法-&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;在&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/&#34;&gt;https://www.ncbi.nlm.nih.gov/&lt;/a&gt; 中搜索 GSE81916 选择 BioProject查询 Accession：PRJNA323422; GEO: GSE81916&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://trace.ncbi.nlm.nih.gov/Traces/study/?acc=PRJNA323422&#34;&gt;https://trace.ncbi.nlm.nih.gov/Traces/study/?acc=PRJNA323422&lt;/a&gt; 可以查询数据具体信息&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;方法二&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;在 Gene Expression Omnibus (&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/geo/)搜素GSE81916进入&#34;&gt;https://www.ncbi.nlm.nih.gov/geo/)搜素GSE81916进入&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE81916&#34;&gt;https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE81916&lt;/a&gt; 数据地址&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;数据下载&#34;&gt;数据下载&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;ftp地址&lt;/strong&gt;
&lt;a href=&#34;ftp://ftp-trace.ncbi.nlm.nih.gov/sra/sra-instant/reads/ByStudy/sra/SRP/SRP075/SRP075747&#34;&gt;ftp://ftp-trace.ncbi.nlm.nih.gov/sra/sra-instant/reads/ByStudy/sra/SRP/SRP075/SRP075747&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;可以分为以下几个部分&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;所有SRA数据的共同部分： &lt;a href=&#34;ftp://ftp-trace.ncbi.nlm.nih.gov/sra/sra-instant&#34;&gt;ftp://ftp-trace.ncbi.nlm.nih.gov/sra/sra-instant&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;reads表示存放reads数据，在FTP可以看到另一个选项是analysis，表示分析结果&lt;/li&gt;
&lt;li&gt;ByStudy表示根据Study进行分类，其他还可以根据实验ByExp,根据Run,ByRun.&lt;/li&gt;
&lt;li&gt;sra/SRP/SRP075/SRP075747: 后面部分都是为了便于检索。&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;#/bin/bash
# @author: xt
# @date: 2017-11-04

for i in ` seq 56 62`;
do
axel ftp://ftp-trace.ncbi.nlm.nih.gov/sra/sra-instant/reads/ByStudy/sra/SRP/SRP075/SRP075747/SRR35899${i}/SRR35899${i}.sra
#wget ftp://ftp-trace.ncbi.nlm.nih.gov/sra/sra-instant/reads/ByStudy/sra/SRP/SRP075/SRP075747/SRR35899${i}/SRR35899${i}.sra
#echo $i 
done
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;# https://www.ncbi.nlm.nih.gov/gquery/?term=GSE81916
# esearch -db sra -query PRJNA299273  | efetch -format runinfo &amp;gt; runinfo.txt # 这个命令是把所有的结果放到一个文件里，也可以通过 https://trace.ncbi.nlm.nih.gov/Traces/study/?acc=PRJNA323422下载SRR的编号
# cat runinfo.txt | cut -f 1 -d &#39;,&#39; | grep SRR &amp;gt; sra.ids
# ~/biosoft/sratoolkit.2.8.2-1-centos_linux64/bin/prefetch --option-file sra.ids # 数据存在/home/shenmy/ncbi/public/sra这个文件下面，找了半天
mkdir /mnt/d/rna_seq/data  &amp;amp;&amp;amp; cd /mnt/d/rna_seq/data
perl -lne &#39;$id=substr($_,0,6);print &amp;quot;axel ftp://ftp-trace.ncbi.nih.gov/sra/sra-instant/reads/ByRun/sra/SRR/$id/$_/$_.sra&amp;quot;&#39; SRR_Acc_List.txt &amp;gt;sra_down.sh
bash sra_down.sh
# 改成用axel下是因为prefetch下载总是不成功
ls *.sra|while read id;do(/mnt/d/Software/Biosoft/sratoolkit/sratoolkit.2.8.2-1-ubuntu64/bin/fastq-dump --split-3 $id);done
rm *.sra
chmod u-w * 
&lt;/code&gt;&lt;/pre&gt;

        
      </description>
    </item>
    
  </channel>
</rss>

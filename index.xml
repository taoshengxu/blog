<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Homepage on My Lives</title>
    <link>/blog/</link>
    <description>Recent content in Homepage on My Lives</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 27 Aug 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="/blog/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>nat123</title>
      <link>/blog/cn/2017/11/nat123/</link>
      <pubDate>Sun, 05 Nov 2017 22:02:28 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/nat123/</guid>
      <description>
        

&lt;h1 id=&#34;启动&#34;&gt;启动&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.nat123.com/Pages_17_619.jsp&#34;&gt;教程&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;#cd  /soft/nat123    --进入自己本地实际安装目录
#mono  nat123linux.sh     --根据提示手动输入帐号密码 
#mono  nat123linux.sh  service  &amp;amp;     --自动读取上一次成功登录帐号以后台服务启动
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;开机自动登录&#34;&gt;开机自动登录&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;（1）本地必须先手动输入帐号密码成功登录一次；
（2）执行“chmod +x /etc/rc.local”命令确保有权限；
（3）把启动程序的命令添加到/etc/rc.local文件中，此文件内容如下，
#!/bin/sh -e
# rc.local
# This script is executed at the end of each multiuser runlevel.
# Make sure that the script will &amp;quot;exit 0&amp;quot; on success or any other
# value on error.
# In order to enable or disable this script just change the execution
# bits.
# By default this script does nothing.

cd  /soft/nat123    --本地实际安装目录
mono  nat123linux.sh  service  &amp;amp;      ---自动读取上次成功登录帐号并以后台服务启动

exit 0
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;linux环境开机自动启动防掉线脚本&#34;&gt;LINUX环境开机自动启动防掉线脚本&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;http://www.nat123.com/Pages_17_682.jsp&#34;&gt;教程&lt;/a&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>python学习</title>
      <link>/blog/cn/2017/11/python_study/</link>
      <pubDate>Sun, 05 Nov 2017 10:34:22 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/python_study/</guid>
      <description>
        

&lt;p&gt;&lt;a href=&#34;http://www.runoob.com/python/python-tutorial.html&#34;&gt;入门教程&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;认识python&#34;&gt;认识python&lt;/h1&gt;

&lt;h4 id=&#34;实例-python-2-0&#34;&gt;实例(Python 2.0+)&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/python
print &amp;quot;Hello, World!&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;实例-python-3-0&#34;&gt;实例(Python 3.0+)&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/python3
print(&amp;quot;Hello, World!&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;python-脚本&#34;&gt;python 脚本&lt;/h1&gt;

&lt;p&gt;所有 Python 文件将以 .py 为扩展名。用 $ python *.py 执行脚本。&lt;/p&gt;

&lt;h1 id=&#34;python语法&#34;&gt;python语法&lt;/h1&gt;

&lt;p&gt;1.Python 的代码块不使用大括号 {} 来控制类，函数以及其他逻辑判断。&lt;/p&gt;

&lt;p&gt;python 最具特色的就是用缩进来写模块。缩进的空白数量是可变的，但是所有代码块语句必须包含相同的缩进空白数量，这个必须严格执行。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;if True:
  print &amp;quot;True&amp;quot;
else:
  print &amp;quot;False&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.xx&lt;/p&gt;

&lt;h1 id=&#34;python函数&#34;&gt;python函数&lt;/h1&gt;

&lt;p&gt;语法&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def functionname( parameters ):
   &amp;quot;函数_文档字符串&amp;quot;
   function_suite
   return [expression]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;示例&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/python
# -*- coding: UTF-8 -*-
 
# 定义函数
def printme( str ):
   &amp;quot;打印任何传入的字符串&amp;quot;
   print str;
   return;
# 调用函数
printme(&amp;quot;我要调用用户自定义函数!&amp;quot;);
printme(&amp;quot;再次调用同一函数&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;python-模块&#34;&gt;Python 模块&lt;/h1&gt;

&lt;p&gt;Python 模块(Module)，是一个 Python 文件，以 .py 结尾，包含了 Python 对象定义和Python语句。&lt;/p&gt;

&lt;p&gt;定义support.py 模块：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def print_func( par ):
   print &amp;quot;Hello : &amp;quot;, par
   return
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;模块的引入&#34;&gt;模块的引入&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/python
# -*- coding: UTF-8 -*-
# 导入模块
import support
# 现在可以调用模块里包含的函数了
# 调用方法：模块名.函数名
support.print_func(&amp;quot;Runoob&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;from-import-语句&#34;&gt;From…import 语句&lt;/h3&gt;

&lt;p&gt;Python 的 from 语句让你从模块中导入一个指定的部分到当前命名空间中。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from fib import fibonacci
&lt;/code&gt;&lt;/pre&gt;

        
      </description>
    </item>
    
    <item>
      <title>转录组分析笔记（2）</title>
      <link>/blog/cn/2017/11/transcriptome_analysis1/</link>
      <pubDate>Sun, 05 Nov 2017 09:34:40 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/transcriptome_analysis1/</guid>
      <description>
        

&lt;p&gt;这是一个生信技能树的优秀作业，一字未改。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.biotrainee.com/thread-1931-1-1.html&#34;&gt;原文&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;转录组差异表达分析小实战-一&#34;&gt;转录组差异表达分析小实战（一）&lt;/h2&gt;

&lt;h5 id=&#34;读文献获取数据&#34;&gt;读文献获取数据&lt;/h5&gt;

&lt;p&gt;文献名称：AKAP95 regulates splicing through scaffolding
RNAs and RNA processing factors&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;查找数据：Data availability&lt;br /&gt;
The RIP-seq an RNA-seq data have been deposited in the Gene
Expression Omnibus database, with accession code GSE81916. All other data is
available from the author upon reasonable request.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;获得GSE号：GSE81916&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&#34;下载测序数据&#34;&gt;下载测序数据&lt;/h5&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE81916&#34;&gt;https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE81916&lt;/a&gt;获取数据信息，并点击网址下方的ftp，下载测序数据&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;从&lt;a href=&#34;https://trace.ncbi.nlm.nih.gov/Traces/study/?acc=PRJNA323422&#34;&gt;https://trace.ncbi.nlm.nih.gov/Traces/study/?acc=PRJNA323422&lt;/a&gt;可知我们需要的mRNA测序编号为SRR3589956到SRR3589962&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;通过Apera下载SRR数据，这里以SRR3589956为例：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ascp -T -i /home/anlan/.aspera/connect/etc/asperaweb_id_dsa.openssh anonftp@ftp-private.ncbi.nlm.nih.gov:sra/sra-instant/reads/ByRun/sra/SRR/SRR358/SRR3589956/SRR3589956.sra ./
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&#34;转化fastq测序数据&#34;&gt;转化fastq测序数据&lt;/h5&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;通过sratoolkit工具将SRR文件转化为fastq格式的测序数据（写了个shell循环）&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for i in $(seq 56 62);do nohup fastq-dump --split-3  SRR35899${i} &amp;amp;;done
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;通过fastqc对每个fastq文件进行质检，用multiqc查看整体质检报告（对当前目录下的fastq测序结果进行质检，生成每个fq文件的质检报告总multiqc整合后统计查看）&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fastqc *.fastq
multiqc ./
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;点击这个url可以查看我这个multiqc报告：&lt;a href=&#34;http://www.bioinfo-scrounger.com/data/multiqc_report.html&#34;&gt;http://www.bioinfo-scrounger.com/data/multiqc_report.html&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如果有接头或者质量值不达标的需要进行过滤，这次的数据质量都不错，因此直接进行比对即可&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&#34;序列比对&#34;&gt;序列比对&lt;/h5&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;安装hisat2软件，下载人类的hiast2索引文件&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;hisat2下载并安装：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ftp://ftp.ccb.jhu.edu/pub/infphilo/hisat2/downloads/hisat2-2.1.0-Linux_x86_64.zip
unzip hisat2-2.1.0-Linux_x86_64.zip
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;下载hisat2的human索引&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ftp://ftp.ccb.jhu.edu/pub/infphilo/hisat2/data/hg19.tar.gz
tar zxvf hg19.tar.gz
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;用hisat2进行比对，测序数据放在data目录下，索引文件放在reference/index/hisat2/hg19目录下，SRR3589956-SRR3589958为人的测序数据&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for i in $(seq 56 58);do hisat2 -p 4 \
-x ~/reference/index/hisat2/hg19/genome \
-1 ./data/SRR35899${i}_1.fastq -2 ./data/SRR35899${i}_2.fastq \
-S SRR35899$i.sam &amp;gt;SRR35899${i}.log;done
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;用samtools将sam文件转化为bam文件，并使用默认排序&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for i in $(seq 56 58);do samtools sort -@ 5 -o SRR35899${i}.bam SRR35899${i}.sam;done
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&#34;reads计数&#34;&gt;reads计数&lt;/h5&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;用htseq对比对产生的bam进行count计数&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;htseq安装，使用miniconda，省事！唯一的问题是htseq版本不是最新的，是0.7.2。想要最新版还是要正常安装，可参考&lt;a href=&#34;http://www.biotrainee.com/thread-1847-1-2.html&#34;&gt;http://www.biotrainee.com/thread-1847-1-2.html&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;conda install -c bioconda htseq
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;用htseq将对比后的结果进行计数&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for i in $(seq 56 58);do htseq-count -f bam -r pos -s no \
SRR35899${i}.bam ~/reference/genome/hg19/gencode.v26lift37.annotation.gtf \
1&amp;gt;SRR35899${i}.count 2&amp;gt;SRR35899${i}_htseq.log;done
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;将3个count文件（SRR3589956.count，SRR3589957.count，SRR3589958.count）合并成一个count矩阵，这是就需要脚本来解决这个问题，不然其他方法会稍微麻烦点&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!/usr/bin/perl -w
use strict;

my $path = shift @ARGV;
opendir DIR, $path or die;
my @dir = readdir DIR;

my $header;
my @sample;
my %hash;
foreach my $file (@dir) {
    if ($file =~ /^\w+.*\.count/) {
        push @sample, $file;
        $header .= &amp;quot;\t$file&amp;quot;;
        open my $fh, $file or die;
        while (&amp;lt;$fh&amp;gt;) {
            chomp;
            next if ($_ =~ /^\W+/);
            my @array = split /\t/, $_;
            $hash{$array[0]} -&amp;gt; {$file} = $array[1];
        }
        close $fh;
    }
}
print &amp;quot;$header\n&amp;quot;;
map{
    my $gene = $_;
    print &amp;quot;$gene&amp;quot;;
    foreach my $file (@sample) {
        print &amp;quot;\t&amp;quot;.$hash{$gene} -&amp;gt; {$file};
    }
    print &amp;quot;\n&amp;quot;;
}keys %hash;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;按照接下来的剧本，应该讲count&lt;em&gt;matrix文件导入DESeq进行差异表达分析。但是从这篇文章的Bioinformatic analyses部分可以发现，作者的control组的2组数据是来自2个不同的批次（一个是SRR3589956，另外一个来源GSM1095127 in GSE44976），treat组倒是同一个批次（SRR3589957和SRR3589958）。但是对于Mouse cells来说，倒是满足2个control和2个treat都正常来自同个批次，因此打算重新用SRR3589959-SRR3589962重新做个一个count&lt;/em&gt;matrix进行后续差异分析&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

        
      </description>
    </item>
    
    <item>
      <title>转录组分析笔记</title>
      <link>/blog/cn/2017/11/transcriptome_analysis/</link>
      <pubDate>Sun, 05 Nov 2017 09:34:39 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/transcriptome_analysis/</guid>
      <description>
        

&lt;p&gt;这是一个学习笔记，跟随生信技能树的学习笔记重复。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;学习提纲&lt;/strong&gt;：&lt;a href=&#34;http://www.biotrainee.com/thread-1750-1-1.html&#34;&gt;RNA-seq基础入门传送门&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;文章链接&lt;/strong&gt;：&lt;a href=&#34;https://www.nature.com/articles/ncomms13347&#34;&gt;https://www.nature.com/articles/ncomms13347&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;非常棒的学习笔记1&lt;/strong&gt;：&lt;a href=&#34;https://taoshengxu.github.io/DocumentGit/pdf/沈梦圆2017年转录组入门合辑0-6.pdf&#34;&gt;PANDA姐的转录组入门（0-6）合辑&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;非常棒的学习笔记2&lt;/strong&gt;:&lt;a href=&#34;https://taoshengxu.github.io/DocumentGit/pdf/浙大植物学小白的转录组笔记.pdf&#34;&gt;浙大植物学小白的转录组笔记&lt;/a&gt; &lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=MzAxMDkxODM1Ng==&amp;amp;mid=2247484895&amp;amp;idx=1&amp;amp;sn=678da702fa929789b177d214070dd39a&amp;amp;chksm=9b484564ac3fcc72914b0ae2c1b71adb63fb359cf7e73221be1ddfd3040efa2944c91bee8e3b&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=0824NWlPEoAgwVKtIWnkEDd9#rd&#34;&gt;Link2&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;非常棒的学习笔记3&lt;/strong&gt;:&lt;/p&gt;

&lt;h1 id=&#34;分析软件安装&#34;&gt;分析软件安装&lt;/h1&gt;

&lt;p&gt;最方便的安装方式就是 Anaconda&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;wget https://repo.continuum.io/archive/Anaconda3-4.4.0-Linux-x86_64.sh

 conda install -c bioconda samtools=1.5
 conda install -c bioconda htseq=0.7.2
 conda install -c bioconda hisat2=2.1.0
 conda install -c bioconda fastqc=0.11.5
 conda install -c jfear sratoolkit=2.8.1
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;数据下载&#34;&gt;数据下载&lt;/h1&gt;

&lt;p&gt;From NCBI GEO ftp&lt;/p&gt;

&lt;p&gt;The RIP-seq an RNA-seq data have been deposited in the Gene Expression Omnibus database, with accession code &lt;strong&gt;GSE81916&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;一个python脚本下载geo数据-没有测试&#34;&gt;一个Python脚本下载GEO数据(没有测试)&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/bin/python3
import re
import urlopen
import os
def main(geo):   
# find the FTP address from [url=https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GEO]https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GEO[/url]
   response = urlopen(&amp;quot;https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc={}&amp;quot;.format(geo))
    pattern = re.compile(&amp;quot;&amp;lt;a href=\&amp;quot;(.*?)\&amp;quot;&amp;gt;\(ftp\)&amp;lt;/a&amp;gt;&amp;quot;)
    # use wget from shell to download SRA data 
   ftp_address = re.search(pattern,response.read().decode(&#39;utf-8&#39;)).group(1)
    os.system(&#39; wget -nd -r 1 -A *.sra &#39; + ftp_address)
 
if __name__ == &#39;__main__&#39;:
    from sys import argv
    main(argv[1])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;保存命名为SRR_downloader.py，在命令行里运行&lt;/p&gt;

&lt;p&gt;python3 SRR_downloader.py GSE81916&lt;/p&gt;

&lt;p&gt;简单说明：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;用sys.argv从命令行中读取参数&lt;/li&gt;
&lt;li&gt;用urllib.request向网页发起请求，获取response&lt;/li&gt;
&lt;li&gt;用正则表达式(re)提取FTP地址&lt;/li&gt;
&lt;li&gt;用os.system运行shell的命令&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;数据分析&#34;&gt;数据分析&lt;/h1&gt;

&lt;h2 id=&#34;质控&#34;&gt;质控&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;for id in `seq 56 62`do fastq-dump --gzip --split-3 -O /mnt/f/Data/RNA-Seq -A SRR35899${id}done ##很慢，建议后台多线程

##查看fastq文件
zcat SRR3589956_1.fastq.gz | head -n 4
##安装集成分析工具
conda install -c bioconda multiqc

# 先获取QC结果
ls *gz | while read id; do fastqc -t 4 $id; done
# multiqc
multiqc *fastqc.zip --pdf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Python脚本QC汇总&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import re
import zipfile
# read the zip file
def zipReader(file):
    qcfile =  zipfile.ZipFile(file)
    data_txt = [file for file in qcfile.namelist() if re.match(&amp;quot;.*?_data\.txt&amp;quot;, file)][0]
    data = [bytes.decode(line) for line in qcfile.open(data_txt)]
    return data
 
def fastqc_summary(data):
    module_num = 0
    bases = 0
    Q20 = 0
    Q30 = 0
    for line in data:
        if re.match(&#39;Filename&#39;, line):
            filename = line.split(sep=&amp;quot;\t&amp;quot;)[1].strip()
        if re.match(&#39;Total Sequence&#39;, line):
            read = line.split(sep=&amp;quot;\t&amp;quot;)[1].strip()
        if re.match(&#39;%GC&#39;, line):
            GC = line.split(sep=&amp;quot;\t&amp;quot;)[1].strip()
        if re.match(&amp;quot;[^#](.*?\t){6}&amp;quot;,line):
            bases = bases + 1
            if float(line.split(&amp;quot;\t&amp;quot;)[1]) &amp;gt; 30:
                Q20 = Q20 + 1
                Q30 = Q30 + 1
            elif float(line.split(&amp;quot;\t&amp;quot;)[1]) &amp;gt; 20:
                Q20 = Q20 + 1
 
        if re.match(&amp;quot;&amp;gt;&amp;gt;END&amp;quot;, line) :
            module_num = module_num + 1
            if module_num &amp;gt;= 2:
                break
    Q20 = Q20 / bases
    Q30 = Q30 / bases
    summary = [filename, read, GC, str(Q20), str(Q30)]
    return summary
 
if __name__ == &#39;__main__&#39;:
    import sys
    for arg in range(1, len(sys.argv)):
        data = zipReader(sys.argv[arg])
        summary = fastqc_summary(data)
        with open(&#39;summary.txt&#39;, &#39;a&#39;) as f:
            f.write(&#39;\t&#39;.join(summary) + &#39;\n&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;grep -w &#39;gene&#39; gencode.v26lift37.annotation.gtf |grep -w &#39;TP53&#39;|cut -f 1,4,5 &amp;gt;&amp;gt;gene.bed
grep -w &#39;gene&#39; gencode.v26lift37.annotation.gtf |grep -w &#39;KRAS&#39;|cut -f 1,4,5 &amp;gt;&amp;gt;gene.bed
grep -w &#39;gene&#39; gencode.v26lift37.annotation.gtf |grep -w &#39;EGFR&#39;|cut -f 1,4,5 &amp;gt;&amp;gt;gene.bed
bedtools igv -i gene.bed &amp;gt;Bach_sanpshot.txt
perl -alne &#39;{print &amp;quot;goto $F[0]:$F[1]-$F[2]\nsnapshot $F[3].png&amp;quot;} &#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;hisat2比对&#34;&gt;Hisat2比对&lt;/h2&gt;

&lt;p&gt;HISAT2是TopHat2/Bowti2的继任者，使用改进的BWT算法，实现了更快的速度和更少的资源占用，作者推荐TopHat2/Bowti2和HISAT的用户转换到HISAT2。
官网：&lt;a href=&#34;https://ccb.jhu.edu/software/hisat2/index.shtml&#34;&gt;https://ccb.jhu.edu/software/hisat2/index.shtml&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;1.建立基因组索引or index 下载&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;#建立基因组索引
#hisat2-build –p 4 genome.fa genome

#下载索引
cd ~/reference
mkdir -p index/hisat &amp;amp;&amp;amp; cd index/hisat
wget -c ftp://ftp.ccb.jhu.edu/pub/infphilo/hisat2/data/hg19.tar.gz
wget -c ftp://ftp.ccb.jhu.edu/pub/infphilo/hisat2/data/mm10.tar.gz
tar zxvf hg19.tar.gz
tar xvzf mm10.tar.gz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;2.比对&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;for i in `seq 56 58`
do
    hisat2 -t -p 24 -x /data/Reference/index/hisat2/hg19/genome \
    -1 /data/RNASeq/fastq/SRR35899${i}_1.fastq.gz \
    -2 SRR35899${i}_2.fastq.gz \
    -S /data/RNASeq/fastq/SRR35899${i}.sam &amp;gt; SRR35899${i}.log &amp;amp;
done


##比对结果
xts@R710:/data/RNASeq/fastq$ for i in `seq 56 58`
&amp;gt; do
&amp;gt;     hisat2 -t -p 24 -x /data/Reference/index/hisat2/hg19/genome \
&amp;gt;     -1 /data/RNASeq/fastq/SRR35899${i}_1.fastq.gz \
&amp;gt;     -2 SRR35899${i}_2.fastq.gz \
&amp;gt;     -S /data/RNASeq/fastq/SRR35899${i}.sam &amp;gt; SRR35899${i}.log &amp;amp;
&amp;gt; done
[1] 11177
[2] 11178
[3] 11179
xts@R710:/data/RNASeq/fastq$ tipTime loading forward index: 00:00:24
Time loading forward index: 00:00:24
Time loading forward index: 00:00:24
Time loading reference: 00:00:04
Time loading reference: 00:00:04
Time loading reference: 00:00:04
Multiseed full-index search: 00:13:22
28856780 reads; of these:
  28856780 (100.00%) were paired; of these:
    1838981 (6.37%) aligned concordantly 0 times
    24732654 (85.71%) aligned concordantly exactly 1 time
    2285145 (7.92%) aligned concordantly &amp;gt;1 times
    ----
    1838981 pairs aligned concordantly 0 times; of these:
      90927 (4.94%) aligned discordantly 1 time
    ----
    1748054 pairs aligned 0 times concordantly or discordantly; of these:
      3496108 mates make up the pairs; of these:
        2034939 (58.21%) aligned 0 times
        1221462 (34.94%) aligned exactly 1 time
        239707 (6.86%) aligned &amp;gt;1 times
96.47% overall alignment rate
Time searching: 00:13:26
Overall time: 00:13:50

Multiseed full-index search: 00:14:42
25914821 reads; of these:
  25914821 (100.00%) were paired; of these:
    1785160 (6.89%) aligned concordantly 0 times
    21786672 (84.07%) aligned concordantly exactly 1 time
    2342989 (9.04%) aligned concordantly &amp;gt;1 times
    ----
    1785160 pairs aligned concordantly 0 times; of these:
      53455 (2.99%) aligned discordantly 1 time
    ----
    1731705 pairs aligned 0 times concordantly or discordantly; of these:
      3463410 mates make up the pairs; of these:
        2187330 (63.16%) aligned 0 times
        1050929 (30.34%) aligned exactly 1 time
        225151 (6.50%) aligned &amp;gt;1 times
95.78% overall alignment rate
Time searching: 00:14:46
Overall time: 00:15:10
[1]   已完成               hisat2 -t -p 24 -x /data/Reference/index/hisat2/hg19/genome -1 /data/RNASeq/fastq/SRR35899${i}_1.fastq.gz -2 SRR35899${i}_2.fastq.gz -S /data/RNASeq/fastq/SRR35899${i}.sam &amp;gt; SRR35899${i}.log
[3]+  已完成               hisat2 -t -p 24 -x /data/Reference/index/hisat2/hg19/genome -1 /data/RNASeq/fastq/SRR35899${i}_1.fastq.gz -2 SRR35899${i}_2.fastq.gz -S /data/RNASeq/fastq/SRR35899${i}.sam &amp;gt; SRR35899${i}.log
xts@R710:/data/RNASeq/fastq$ Multiseed full-index search: 00:16:08
29720636 reads; of these:
  29720636 (100.00%) were paired; of these:
    1920019 (6.46%) aligned concordantly 0 times
    25503958 (85.81%) aligned concordantly exactly 1 time
    2296659 (7.73%) aligned concordantly &amp;gt;1 times
    ----
    1920019 pairs aligned concordantly 0 times; of these:
      61683 (3.21%) aligned discordantly 1 time
    ----
    1858336 pairs aligned 0 times concordantly or discordantly; of these:
      3716672 mates make up the pairs; of these:
        2292272 (61.68%) aligned 0 times
        1196099 (32.18%) aligned exactly 1 time
        228301 (6.14%) aligned &amp;gt;1 times
96.14% overall alignment rate
Time searching: 00:16:12
Overall time: 00:16:36

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;比对脚本map.sh [需要修改]&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#! usr/bin/bash
set -u
set -e
set -o pipefail

hg19_ref=/data/Reference/index/hisat/hg19
mm10_ref=/data/Reference/index/hisat/mm10
data_path=/data/RNASeq/fastq
NUM_THREADS=25

ls *.fastq.gz|while read id;do(hisat2 -t -p
$NUM_THREADS -x $hg19_ref -1 $data_path/${id%_*}_1.fastq.gz -2
$data_path/${id%_*}_2.fastq.gz 2&amp;gt;${id%_*}_map.log | samtools view -Sb
- &amp;gt;${id%_*}.bam);done

ls  *.fastq.gz|while read id;do(hisat2 -t -
p $NUM_THREADS -x $mm10_ref -1 $data_path/${id%_*}_1.fastq.gz -2
$data_path/${id%_*}_2.fastq.gz 2&amp;gt;${id%_*}_map.log | samtools view -Sb
- &amp;gt;${id%_*}.bam);done

 ls *.bam|while read id;do(samtools sort --threads $NUM_THREADS $id -o
${id%.*}_sorted.bam);done
 ls *_sorted.bam | while read id;do(samtools index $id);done
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;samtools&#34;&gt;SAMtools&lt;/h2&gt;

&lt;p&gt;SAM（sequence Alignment/mapping)数据格式是目前高通量测序中存放比对数据的标准格式，当然他可以用于存放未比对的数据。&lt;/p&gt;

&lt;p&gt;主要功能有：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;samtools view : BAM-SAM/SAM-BAM 转换和提取部分比对&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;samtools sort : 比对排序&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;samtools index: 索引排序比对&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;samtools merge: 聚合多个排序比对&lt;/li&gt;
&lt;li&gt;samtools faidx: 建立FASTA索引，提取部分序列&lt;/li&gt;
&lt;li&gt;samtools tview: 文本格式查看序列&lt;/li&gt;
&lt;li&gt;samtools pileup: 产生基于位置的结果和 consensus/indel calling&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;数据转换sam-bam-sorted bam&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for i in `seq 56 58`
do
    samtools view -S SRR35899${i}.sam -b &amp;gt; SRR35899${i}.bam
    samtools sort SRR35899${i}.bam -o SRR35899${i}_sorted.bam
    samtools index SRR35899${i}_sorted.bam
done
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;SAMtools其他操作&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;head -1000 SRR3589957.sam &amp;gt; test.sam
samtools view -b  test.sam &amp;gt; test.bam
samtools view test.bam | head

samtools sort test.bam -o default.bam
samtools view default.bam | head
 
# Sort alignments by leftmost coordinates, or by read name when -n is used
samtools sort test.bam default
samtools view default.bam | head


#提取1号染色体1234-123456区域的比对read
samtools view SRR3589957_sorted.bam chr1:1234-123456 | head

#在比如搭配flag(0.1.19版本没有）和flagstat，使用-f或-F参数提取不同匹配情况的read。

# 可以先用flagstat看下总体情况
samtools flagstat SRR3589957_sorted.bam

#筛选恰好配对的read,就需要用0x10
samtools view -b -f 0x10 SRR3589957_sorted.bam chr1:1234-123456  &amp;gt; flag.bam
samtools flagstat flag.bam
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;比对质控&#34;&gt;比对质控&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;RSeQC——&lt;a href=&#34;http://rseqc.sourceforge.net/&#34;&gt;http://rseqc.sourceforge.net/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Qualimap——&lt;a href=&#34;http://qualimap.bioinfo.cipf.es/&#34;&gt;http://qualimap.bioinfo.cipf.es/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Picard——&lt;a href=&#34;http://broadinstitute.github.io/picard/&#34;&gt;http://broadinstitute.github.io/picard/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;使用RSeQC来对我们的比对结果进行质控,RSeQC包括了十多个Python脚本，实现很多功能，具体每个脚本的参数用法，都可以在官网学习.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# RSeQC的安装，需要先安装gcc；numpy；R；Python2.7
$ pip install RSeQC
# 对bam文件进行质控，其余都同样的进行
$ bam_stat.py  -i SRR3589956_sorted.bam

基因组覆盖率的QC需要提供bed文件，可以直接RSeQC的网站下载，或者可以用gtf转换
read_distribution.py -i RNA-Seq/aligned/SRR3589956_sorted.bam -r reference/hg19_RefSeq.bed
&lt;/code&gt;&lt;/pre&gt;

        
      </description>
    </item>
    
    <item>
      <title>NCBI-GEO数据下载</title>
      <link>/blog/cn/2017/11/ncbi_downlaod/</link>
      <pubDate>Sat, 04 Nov 2017 21:52:45 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/ncbi_downlaod/</guid>
      <description>
        

&lt;h1 id=&#34;geo-基础&#34;&gt;GEO 基础&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;GEO Platform (GPL) 芯片平台&lt;/li&gt;
&lt;li&gt;GEO Sample (GSM) 样本ID号&lt;/li&gt;
&lt;li&gt;GEO Series (GSE) study的ID号&lt;/li&gt;
&lt;li&gt;GEO Dataset (GDS) 数据集的ID号 ## 用法&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;数据搜索&#34;&gt;数据搜索&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;方法-&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;在&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/&#34;&gt;https://www.ncbi.nlm.nih.gov/&lt;/a&gt; 中搜索 GSE81916 选择 BioProject查询 Accession：PRJNA323422; GEO: GSE81916&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://trace.ncbi.nlm.nih.gov/Traces/study/?acc=PRJNA323422&#34;&gt;https://trace.ncbi.nlm.nih.gov/Traces/study/?acc=PRJNA323422&lt;/a&gt; 可以查询数据具体信息&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;方法二&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;在 Gene Expression Omnibus (&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/geo/)搜素GSE81916进入&#34;&gt;https://www.ncbi.nlm.nih.gov/geo/)搜素GSE81916进入&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE81916&#34;&gt;https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE81916&lt;/a&gt; 数据地址&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;数据下载&#34;&gt;数据下载&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;ftp地址&lt;/strong&gt;
&lt;a href=&#34;ftp://ftp-trace.ncbi.nlm.nih.gov/sra/sra-instant/reads/ByStudy/sra/SRP/SRP075/SRP075747&#34;&gt;ftp://ftp-trace.ncbi.nlm.nih.gov/sra/sra-instant/reads/ByStudy/sra/SRP/SRP075/SRP075747&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;可以分为以下几个部分&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;所有SRA数据的共同部分： &lt;a href=&#34;ftp://ftp-trace.ncbi.nlm.nih.gov/sra/sra-instant&#34;&gt;ftp://ftp-trace.ncbi.nlm.nih.gov/sra/sra-instant&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;reads表示存放reads数据，在FTP可以看到另一个选项是analysis，表示分析结果&lt;/li&gt;
&lt;li&gt;ByStudy表示根据Study进行分类，其他还可以根据实验ByExp,根据Run,ByRun.&lt;/li&gt;
&lt;li&gt;sra/SRP/SRP075/SRP075747: 后面部分都是为了便于检索。&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;#/bin/bash
# @author: xt
# @date: 2017-11-04

for i in ` seq 56 62`;
do
axel ftp://ftp-trace.ncbi.nlm.nih.gov/sra/sra-instant/reads/ByStudy/sra/SRP/SRP075/SRP075747/SRR35899${i}/SRR35899${i}.sra
#wget ftp://ftp-trace.ncbi.nlm.nih.gov/sra/sra-instant/reads/ByStudy/sra/SRP/SRP075/SRP075747/SRR35899${i}/SRR35899${i}.sra
#echo $i 
done
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;# https://www.ncbi.nlm.nih.gov/gquery/?term=GSE81916
# esearch -db sra -query PRJNA299273  | efetch -format runinfo &amp;gt; runinfo.txt # 这个命令是把所有的结果放到一个文件里，也可以通过 https://trace.ncbi.nlm.nih.gov/Traces/study/?acc=PRJNA323422下载SRR的编号
# cat runinfo.txt | cut -f 1 -d &#39;,&#39; | grep SRR &amp;gt; sra.ids
# ~/biosoft/sratoolkit.2.8.2-1-centos_linux64/bin/prefetch --option-file sra.ids # 数据存在/home/shenmy/ncbi/public/sra这个文件下面，找了半天
mkdir /mnt/d/rna_seq/data  &amp;amp;&amp;amp; cd /mnt/d/rna_seq/data
perl -lne &#39;$id=substr($_,0,6);print &amp;quot;axel ftp://ftp-trace.ncbi.nih.gov/sra/sra-instant/reads/ByRun/sra/SRR/$id/$_/$_.sra&amp;quot;&#39; SRR_Acc_List.txt &amp;gt;sra_down.sh
bash sra_down.sh
# 改成用axel下是因为prefetch下载总是不成功
ls *.sra|while read id;do(/mnt/d/Software/Biosoft/sratoolkit/sratoolkit.2.8.2-1-ubuntu64/bin/fastq-dump --split-3 $id);done
rm *.sra
chmod u-w * 
&lt;/code&gt;&lt;/pre&gt;

        
      </description>
    </item>
    
    <item>
      <title>使用Bioconda管理Linux系统中的生物信息软件</title>
      <link>/blog/cn/2017/11/bioconda/</link>
      <pubDate>Fri, 03 Nov 2017 17:20:54 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/bioconda/</guid>
      <description>
        

&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/25085567&#34;&gt;原文&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;生物信息操作中必不可少的就是Linux系统中各种生物信息学软件的安装。不同软件有不同的安装方法，对系统环境的依赖不同也不同，对于新手来说，经常是一个软件的安装和配置就要折腾很长一段时间时间，大大增加了学习成本。&lt;/p&gt;

&lt;p&gt;我自己有两个方法来尽量减少安装软件所消耗的时间：一是直接安装Bio-linux系统，这个系统已经内置了大部分生物信息分析所需要的软件，非常适合新手直接学习分析技术，绕过软件安装和环境配置的麻烦问题。二是使用Bioconda安装和管理各种软件。Bio-linux系统和常用的服务器系统还是有差别的，如果想在学习生物信息分析的同时掌握一些Linux系统的操作甚至维护的技术，配置一台CentOS系统的计算机就很有必要了。这个时候Bioconda就非常有用了。&lt;/p&gt;

&lt;p&gt;本文参考知乎专栏以及基因课相关课程 (&lt;a href=&#34;http://genek.tv/dirlist/index/id/65&#34;&gt;http://genek.tv/dirlist/index/id/65&lt;/a&gt;) 对Bioconda的安装和使用做简单介绍。&lt;/p&gt;

&lt;h1 id=&#34;bioconda介绍&#34;&gt;Bioconda介绍&lt;/h1&gt;

&lt;p&gt;Bioconda是conda上一个分发生物信息的频道。而conda是最初为管理python包而建立的。以下是相关介绍：&lt;/p&gt;

&lt;p&gt;“Conda is a portable package manager primarily for python and precompiled binaries. Miniconda is the base system of conda. It includes a standard python and a few required dependencies such as readline and sqlite. In conda, a channel contains a set of software typically managed by the same group.Bioconda is a channel of conda focusing on bioinformatics software. ”&lt;/p&gt;

&lt;p&gt;Bioconda主页：Using bioconda - Bioconda documentation&lt;/p&gt;

&lt;p&gt;anaconda、miniconda和conda的区别：FAQs - Bioconda documentation&lt;/p&gt;

&lt;p&gt;简单说来：“conda is a package manager, Miniconda is the conda installer, and Anaconda is a scientific Python distribution that also includes conda.”&lt;/p&gt;

&lt;p&gt;Bioconda的优点是安装简单，各个软件依赖的环境一同打包且相互隔离，非常适合在服务器中建立自己的生物信息分析环境。&lt;/p&gt;

&lt;h1 id=&#34;bioconda的下载与安装&#34;&gt;Bioconda的下载与安装&lt;/h1&gt;

&lt;p&gt;1.下载和安装miniconda&lt;/p&gt;

&lt;p&gt;bioconda的使用首先需要安装miniconda(&lt;a href=&#34;http://conda.pydata.org/miniconda.html&#34;&gt;http://conda.pydata.org/miniconda.html&lt;/a&gt;) 。选择linux的64位的python2.7版本（共提供win、Mac、linux三种系统，同时支持python3和python2），直接点击下载。或者复制链接后，用wget下载。下载完成后，在终端键入bash命令进行安装. 之后按照提示点击回车，输入要安装的位置，或者输入yes.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;wget https://repo.continuum.io/miniconda/Miniconda2-latest-Linux-x86_64.sh
bash Miniconda2-latest-Linux-x86_64.sh
##输入yes后，还没有完成最后安装，还需要source一下
source ~/.bashrc
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这时miniconda就安装好了，输入“conda”会显示相应的信息：&lt;/p&gt;

&lt;p&gt;2.添加channels&lt;/p&gt;

&lt;p&gt;输入“conda list”来查看已经安装的软件：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;conda config --add channels conda-forge
conda config --add channels defaults
conda config --add channels r
conda config --add channels bioconda
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;查看已经添加的channels：&lt;/p&gt;

&lt;p&gt;conda config &amp;ndash;get channels&lt;/p&gt;

&lt;p&gt;3.更新miniconda&lt;/p&gt;

&lt;p&gt;conda update conda&lt;/p&gt;

&lt;p&gt;4.卸载miniconda  删除miniconda的整个文件夹：&lt;/p&gt;

&lt;p&gt;rm -rf ~/miniconda&lt;/p&gt;

&lt;p&gt;从环境变量中去掉miniconda：打开~/.bash_profile文件，删掉其中miniconda的路径，关闭并保存&lt;/p&gt;

&lt;p&gt;删除隐藏的.condarc 、.conda以及.continuum文件&lt;/p&gt;

&lt;h1 id=&#34;利用bioconda安装生物信息软件&#34;&gt;利用Bioconda安装生物信息软件&lt;/h1&gt;

&lt;p&gt;要通过conda安装软件，首先从这里&lt;a href=&#34;https://bioconda.github.io/recipes&#34;&gt;Available packages&lt;/a&gt;查找该软件是否被conda支持。如果支持，只需输入以下命令即可安装：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;conda install fastqc（软件名）

conda install -c bioconda samtools=1.5
conda install -c bioconda htseq=0.7.2
conda install -c bioconda hisat2=2.1.0
conda install -c bioconda fastqc=0.11.5
conda install -c jfear sratoolkit=2.8.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;安装完成后，可以用“which 软件名”来查看该软件安装的位置：&lt;/p&gt;

&lt;p&gt;conda默认安装软件的最新版本，如果想安装指定版本的某个软件，可以先用“conda search 软件名”搜索软件版本&lt;/p&gt;

&lt;p&gt;星号标记的表示是已经安装的版本。要安装其他版本，输入：&lt;/p&gt;

&lt;p&gt;conda install 软件名=版本号
这时conda会先卸载已安装版本，然后重新安装指定版本。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;查看已安装软件&lt;/strong&gt;：conda list&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;更新指定软件&lt;/strong&gt;：conda update 软件名&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;卸载指定软件&lt;/strong&gt;：conda remove 软件名&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>生物信息学常见1000个软件的安装代码</title>
      <link>/blog/cn/2017/11/1000soft/</link>
      <pubDate>Fri, 03 Nov 2017 15:42:35 +0000</pubDate>
      
      <guid>/blog/cn/2017/11/1000soft/</guid>
      <description>
        

&lt;p&gt;引自Jiangming Zeng&lt;a href=&#34;http://mp.weixin.qq.com/s?__biz=MzAxMDkxODM1Ng==&amp;amp;mid=2247484870&amp;amp;idx=1&amp;amp;sn=d336ed1951b5cff14c591201084622fd&amp;amp;chksm=9b48457dac3fcc6bb25bdb2a0e744013a3c11d0b7b8cc8b9f274560260618c07bdf438611752&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=08174RqFPmfWUyO1PO1Xh9Uz#rd&#34;&gt;原文&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;分析软件&#34;&gt;分析软件&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## annovar and GATK 
## Download and install sratoolkit
## http://www.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?view=software
## http://www.ncbi.nlm.nih.gov/books/NBK158900/
cd ~/biosoft
mkdir sratoolkit &amp;amp;&amp;amp;  cd sratoolkit
wget http://ftp-trace.ncbi.nlm.nih.gov/sra/sdk/2.6.3/sratoolkit.2.6.3-centos_linux64.tar.gz
##
##  Length: 63453761 (61M) [application/x-gzip]
##  Saving to: &amp;quot;sratoolkit.2.6.3-centos_linux64.tar.gz&amp;quot;
tar zxvf sratoolkit.2.6.3-centos_linux64.tar.gz
~/biosoft/sratoolkit/sratoolkit.2.6.3-centos_linux64/bin/fastdump -h
mkdir -p  ~/biosoft/myBin
echo &#39;export PATH=/home/jianmingzeng/biosoft/myBin/bin:$PATH&#39; &amp;gt;&amp;gt;~/.bashrc 
source ~/.bashrc
cd ~/biosoft
mkdir cmake &amp;amp;&amp;amp;  cd cmake
wget http://cmake.org/files/v3.3/cmake-3.3.2.tar.gz
tar xvfz cmake-3.3.2.tar.gz
cd cmake-3.3.2 
./configure --prefix=/home/jianmingzeng/biosoft/myBin
make
make install
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## Download and install samtools
## http://samtools.sourceforge.net/
## http://www.htslib.org/doc/samtools.html

##存放高通量测序比对结果的标准格式
##功能： Reading/writing/editing/indexing/viewing SAM/BAM/CRAM format
cd ~/biosoft
mkdir samtools &amp;amp;&amp;amp;  cd samtools
wget https://github.com/samtools/samtools/releases/download/1.3.1/samtools-1.3.1.tar.bz2 
tar xvfj samtools-1.3.1.tar.bz2 
cd samtools-1.3.1 
./configure --prefix=/home/jianmingzeng/biosoft/myBin
make
make install
~/biosoft/myBin/bin/samtools --help
~/biosoft/myBin/bin/plot-bamstats --help
cd htslib-1.3.1
./configure --prefix=/home/jianmingzeng/biosoft/myBin
make
make install
~/biosoft/myBin/bin/tabix
# ## Download and install tabix 
# cd ~/biosoft
# mkdir tabix &amp;amp;&amp;amp;  cd tabix
# # http://genometoolbox.blogspot.com/2013/11/installing-tabix-on-unix.html
# tar xvfj tabix-0.2.6.tar.bz2 
# cd tabix-0.2.6
# make
# cd ~/biosoft
# ## http://samtools.github.io/bcftools/
# mkdir htslib &amp;amp;&amp;amp;  cd htslib  
# git clone git://github.com/samtools/htslib.git 
# cd htslib
# make 
## Download and install bcftools
## http://www.htslib.org/download/
## http://www.htslib.org/doc/bcftools-1.0.html
cd ~/biosoft
mkdir bcftools &amp;amp;&amp;amp;  cd bcftools
wget https://github.com/samtools/bcftools/releases/download/1.3.1/bcftools-1.3.1.tar.bz2
tar xvfj bcftools-1.3.1.tar.bz2
cd bcftools-1.3.1 
make
cp bcftools /home/jianmingzeng/biosoft/myBin
~/biosoft/myBin/bin/bcftools --help
## Download and install vcftools
## https://vcftools.github.io/index.html 
## http://vcftools.sourceforge.net/specs.html
cd ~/biosoft
mkdir vcftools &amp;amp;&amp;amp;  cd vcftools
# wget https://codeload.github.com/vcftools/vcftools/legacy.zip/master -O  vcftools-vcftools-v0.1.14-24-gac1bfd5.zip 
# unzip vcftools-vcftools-v0.1.14-24-gac1bfd5.zip 
# mv vcftools-vcftools-ac1bfd5 vcftools-v0.1.14-24
# cd vcftools-v0.1.14-24
# export PERL5LIB=/home/jianmingzeng/biosoft/vcftools/vcftools-v0.1.14-24/src/perl/
# ./autogen.sh 
# ./configure     --prefix=/home/jianmingzeng/biosoft/myBin
# make 
# make install 
# ~/biosoft/myBin/bin/vcftools --help
wget https://sourceforge.net/projects/vcftools/files/vcftools_0.1.13.tar.gz 
tar zxvf vcftools_0.1.13.tar.gz
cd  vcftools_0.1.13
make
## Download and install ANNOVAR  
cd ~/biosoft
# The latest version of ANNOVAR (2016Feb01) can be downloaded here (registration required)
# http://www.openbioinformatics.org/annovar/annovar_download_form.php 
mkdir ANNOVAR  &amp;amp;&amp;amp;  cd ANNOVAR  
## Download and install samstat
## http://samstat.sourceforge.net/
## http://www.htslib.org/doc/samtools.html
cd ~/biosoft
mkdir samstat &amp;amp;&amp;amp;  cd samstat
wget http://liquidtelecom.dl.sourceforge.net/project/samstat/samstat-1.5.tar.gz
tar zxvf  samstat-1.5.tar.gz 
cd samstat-1.5 
./configure --prefix=/home/jianmingzeng/biosoft/myBin
make
make install
~/biosoft/myBin/bin/samstat --help
## Download and install picardtools
## https://sourceforge.net/projects/picard/
## https://github.com/broadinstitute/picard
cd ~/biosoft
mkdir picardtools &amp;amp;&amp;amp;  cd picardtools
wget http://ncu.dl.sourceforge.net/project/picard/picard-tools/1.119/picard-tools-1.119.zip
unzip picard-tools-1.119.zip 
## Download and install freebayes
## https://github.com/ekg/freebayes
## http://clavius.bc.edu/~erik/CSHL-advanced-sequencing/freebayes-tutorial.html
cd ~/biosoft
mkdir freebayes &amp;amp;&amp;amp;  cd freebayes
## wget -O freebayes-master.zip  https://codeload.github.com/ekg/freebayes/zip/master
## unzip freebayes-master.zip
wget http://clavius.bc.edu/~erik/freebayes/freebayes-5d5b8ac0.tar.gz
tar xzvf freebayes-5d5b8ac0.tar.gz
cd freebayes
make
 ~/biosoft/freebayes/freebayes/bin/freebayes
cd ~/biosoft
## https://sourceforge.net/projects/varscan/files/
## http://varscan.sourceforge.net/index.html
mkdir VarScan  &amp;amp;&amp;amp;  cd VarScan  
wget https://sourceforge.net/projects/varscan/files/VarScan.v2.3.9.jar 
cd ~/biosoft
mkdir SnpEff &amp;amp;&amp;amp;  cd SnpEff
##  http://snpeff.sourceforge.net/
##  http://snpeff.sourceforge.net/SnpSift.html 
##  http://snpeff.sourceforge.net/SnpEff_manual.html
wget http://sourceforge.net/projects/snpeff/files/snpEff_latest_core.zip 
## java -jar snpEff.jar download GRCh37.75
## java -Xmx4G -jar snpEff.jar -i vcf -o vcf GRCh37.75 example.vcf &amp;gt; example_snpeff.vcf
unzip snpEff_latest_core.zip
## https://github.com/najoshi/sickle
cd ~/biosoft
mkdir sickle &amp;amp;&amp;amp; cd sickle
wget https://codeload.github.com/najoshi/sickle/zip/master -O sickle.zip
unzip sickle.zip
cd sickle-master
make
~/biosoft/sickle/sickle-master/sickle -h
cd ~/biosoft
## http://www.usadellab.org/cms/?page=trimmomatic
## http://www.usadellab.org/cms/uploads/supplementary/Trimmomatic/TrimmomaticManual_V0.32.pdf
mkdir Trimmomatic &amp;amp;&amp;amp; cd Trimmomatic
wget http://www.usadellab.org/cms/uploads/supplementary/Trimmomatic/Trimmomatic-0.36.zip 
unzip Trimmomatic-0.36.zip 
java -jar ~/biosoft/Trimmomatic/Trimmomatic-0.36/trimmomatic-0.36.jar -h
## Download and install bedtools
cd ~/biosoft
mkdir bedtools &amp;amp;&amp;amp;  cd bedtools
wget https://github.com/arq5x/bedtools2/releases/download/v2.25.0/bedtools-2.25.0.tar.gz
## Length: 19581105 (19M) [application/octet-stream] 
tar -zxvf bedtools-2.25.0.tar.gz
cd bedtools2
make
#~/biosoft/bedtools/bedtools2/bin/
## Download and install PeakRanger
cd ~/biosoft
mkdir PeakRanger &amp;amp;&amp;amp;  cd PeakRanger
wget https://sourceforge.net/projects/ranger/files/PeakRanger-1.18-Linux-x86_64.zip 
## Length: 1517587 (1.4M) [application/octet-stream]
unzip PeakRanger-1.18-Linux-x86_64.zip
~/biosoft/PeakRanger/bin/peakranger -h
## Download and install bowtie
cd ~/biosoft
mkdir bowtie &amp;amp;&amp;amp;  cd bowtie
wget https://sourceforge.net/projects/bowtie-bio/files/bowtie2/2.2.9/bowtie2-2.2.9-linux-x86_64.zip 
#Length: 27073243 (26M) [application/octet-stream]
#Saving to: &amp;quot;download&amp;quot;   ## I made a mistake here for downloading the bowtie2 
mv download  bowtie2-2.2.9-linux-x86_64.zip
unzip bowtie2-2.2.9-linux-x86_64.zip
## Download and install BWA
cd ~/biosoft
mkdir bwa &amp;amp;&amp;amp;  cd bwa
#http://sourceforge.net/projects/bio-bwa/files/
wget https://sourceforge.net/projects/bio-bwa/files/bwa-0.7.15.tar.bz2 
tar xvfj bwa-0.7.15.tar.bz2 # x extracts, v is verbose (details of what it is doing), f skips prompting for each individual file, and j tells it to unzip .bz2 files
cd bwa-0.7.15
make
#export PATH=$PATH:/path/to/bwa-0.7.15 # Add bwa to your PATH by editing ~/.bashrc file (or .bash_profile or .profile file)
# /path/to/ is an placeholder. Replace with real path to BWA on your machine
#source ~/.bashrc
## Download and install macs2  
## // https://pypi.python.org/pypi/MACS2/
cd ~/biosoft
mkdir macs2 &amp;amp;&amp;amp;  cd macs2
## just stick to PyPI release: https://pypi.python.org/pypi/MACS2
wget https://pypi.python.org/packages/9f/99/a8ac96b357f6b0a6f559fe0f5a81bcae12b98579551620ce07c5183aee2c/MACS2-2.1.1.20160309.tar.gz -O MACS2-2.1.1.tar.gz 
tar zxvf  MACS2-2.1.1.tar.gz 
cd  MACS2-2.1.1.20160309/
python setup.py install --user 
## https://docs.python.org/2/install/
~/.local/bin/macs2 --help
#wget https://codeload.github.com/taoliu/MACS/zip/master -O MACS-master.zip
#unzip MACS-master.zip
#cd MACS-master 
## So you can&#39;t just pull github snapshot then run setup.py to install MACS2. Instead
# ImageMagick
cd ~/biosoft
mkdir ImageMagick &amp;amp;&amp;amp;  cd ImageMagick
## http://www.imagemagick.org/ 
cd ~/biosoft
mkdir weblogo &amp;amp;&amp;amp;  cd weblogo
## http://weblogo.berkeley.edu/
wget http://weblogo.berkeley.edu/release/weblogo.2.8.2.tar.gz
tar zxvf weblogo.2.8.2.tar.gz
cd weblogo
export PATH=$PATH:/home/jianmingzeng/biosoft/weblogo/weblogo
source ~/.bashrc
cd ~/biosoft
mkdir Ghostscript &amp;amp;&amp;amp;  cd Ghostscript
# http://www.ghostscript.com/download/gsdnld.html
# http://www.ghostscript.com/doc/9.20/Readme.htm
wget https://github.com/ArtifexSoftware/ghostpdl-downloads/releases/download/gs920/ghostscript-9.20-linux-x86_64.tgz 
tar zxvf ghostscript-9.20-linux-x86_64.tgz
cp ghostscript-9.20-linux-x86_64/gs-920-linux_x86_64  ~/biosoft/myBin/bin/gs
## make sure the &amp;quot;gs&amp;quot; program is executable 
## Download and install homer (Hypergeometric Optimization of Motif EnRichment)
## // http://homer.salk.edu/homer/
## // http://blog.qiubio.com:8080/archives/3024 
## The commands gs, seqlogo, blat, and samtools should now work from the command line
cd ~/biosoft
mkdir homer &amp;amp;&amp;amp;  cd homer
wget http://homer.salk.edu/homer/configureHomer.pl 
perl configureHomer.pl -install
perl configureHomer.pl -install hg19
## Download and install SWEMBL
cd ~/biosoft
mkdir SWEMBL &amp;amp;&amp;amp;  cd SWEMBL
#### readme: http://www.ebi.ac.uk/~swilder/SWEMBL/beginners.html
wget http://www.ebi.ac.uk/~swilder/SWEMBL/SWEMBL.3.3.1.tar.bz2 
tar xvfj SWEMBL.3.3.1.tar.bz2
cd SWEMBL.3.3.1/
make
## error 
## Download and install SISSRs
cd ~/biosoft
mkdir SISSRs &amp;amp;&amp;amp;  cd SISSRs
#### readme: https://dir.nhlbi.nih.gov/papers/lmi/epigenomes/sissrs/SISSRs-Manual.pdf
wget http://dir.nhlbi.nih.gov/papers/lmi/epigenomes/sissrs/sissrs_v1.4.tar.gz
tar xzvf sissrs_v1.4.tar.gz
~/biosoft/SISSRs/sissrs.pl
## Download and install SISSRs
cd ~/biosoft
mkdir QuEST &amp;amp;&amp;amp;  cd QuEST
#### http://mendel.stanford.edu/SidowLab/downloads/quest/
wget http://mendel.stanford.edu/SidowLab/downloads/quest/QuEST_2.4.tar.gz
tar xzvf QuEST_2.4.tar.gz
cd QuEST_2.4 
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## Download and install fastqc
##可视化展示二代测序数据质量
##http://www.bioinformatics.babraham.ac.uk/projects/fastqc/

cd ~/biosoft
mkdir fastqc &amp;amp;&amp;amp;  cd fastqc
wget http://www.bioinformatics.babraham.ac.uk/projects/fastqc/fastqc_v0.11.5.zip
unzip fastqc_v0.11.5.zip
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## Download and install CEAS    
## http://liulab.dfci.harvard.edu/CEAS/download.html
cd ~/biosoft
mkdir CEAS  &amp;amp;&amp;amp;  cd CEAS 
wget  http://liulab.dfci.harvard.edu/CEAS/src/CEAS-Package-1.0.2.tar.gz
tar zxvf CEAS-Package-1.0.2.tar.gz
cd  CEAS-Package-1.0.2
python setup.py install --user 
## http://liulab.dfci.harvard.edu/CEAS/usermanual.html
 ~/.local/bin/ceas --help  
mkdir annotation  &amp;amp;&amp;amp;  cd annotation  
wget http://liulab.dfci.harvard.edu/CEAS/src/hg19.refGene.gz ; gunzip hg19.refGene.gz 
# http://hgdownload.cse.ucsc.edu/goldenPath/hg19/database/refGene.txt.gz ##  gunzip refGene.txt.gz ; mv refGene.txt  hg19refGene.txt
## Download and install CEAS    
## http://liulab.dfci.harvard.edu/CEAS/download.html
cd ~/biosoft
mkdir crossmap  &amp;amp;&amp;amp;  cd crossmap 
pip install CrossMap --user
## http://crossmap.sourceforge.net/#use-pip-to-install-crossmap
mkdir chain_files  &amp;amp;&amp;amp;  cd chain_files  
wget http://hgdownload.soe.ucsc.edu/goldenPath/mm10/liftOver/mm10ToMm9.over.chain.gz
wget http://hgdownload.soe.ucsc.edu/goldenPath/mm9/liftOver/mm9ToMm10.over.chain.gz 
wget http://hgdownload.soe.ucsc.edu/goldenPath/hg38/liftOver/hg38ToHg19.over.chain.gz 
wget http://hgdownload.soe.ucsc.edu/goldenPath/hg38/liftOver/hg38ToHg19.over.chain.gz 
# http://hgdownload.cse.ucsc.edu/goldenPath/hg19/database/refGene.txt.gz ##  gunzip refGene.txt.gz ; mv refGene.txt  hg19refGene.txt
# Usage: CrossMap.py bed ~/biosoft/crossmap/chain_files/mm9ToMm10.over.chain.gz  test.mm9.bed3
cd ~/biosoft
# http://www.broadinstitute.org/cancer/cga/rnaseqc_run
# http://www.broadinstitute.org/cancer/cga/rnaseqc_download
mkdir RNA-SeQC  &amp;amp;&amp;amp;  cd RNA-SeQC 
#### readme: http://www.broadinstitute.org/cancer/cga/sites/default/files/data/tools/rnaseqc/RNA-SeQC_Help_v1.1.2.pdf
wget http://www.broadinstitute.org/cancer/cga/tools/rnaseqc/RNA-SeQC_v1.1.8.jar 
#TopHat+Cufflinks+ pipeline
## Download and install TopHat 
# https://ccb.jhu.edu/software/tophat/index.shtml
cd ~/biosoft
mkdir TopHat  &amp;amp;&amp;amp;  cd TopHat 
#### readme: https://ccb.jhu.edu/software/tophat/manual.shtml
wget https://ccb.jhu.edu/software/tophat/downloads/tophat-2.1.1.Linux_x86_64.tar.gz
tar xzvf tophat-2.1.1.Linux_x86_64.tar.gz 
ln -s tophat-2.1.1.Linux_x86_64 current 
# ~/biosoft/TopHat/current/tophat2
## Download and install Cufflinks 
#  http://cole-trapnell-lab.github.io/cufflinks/
cd ~/biosoft
mkdir Cufflinks  &amp;amp;&amp;amp;  cd Cufflinks 
#### readme: http://cole-trapnell-lab.github.io/cufflinks/manual/
#### install:http://cole-trapnell-lab.github.io/cufflinks/install/
wget http://cole-trapnell-lab.github.io/cufflinks/assets/downloads/cufflinks-2.2.1.Linux_x86_64.tar.gz
tar xzvf cufflinks-2.2.1.Linux_x86_64.tar.gz 
ln -s cufflinks-2.2.1.Linux_x86_64 current
~/biosoft/Cufflinks/current/cufflinks

#HISAT-Stringtie2-Ballgown pipeline


## Download and install HISAT 
##https://ccb.jhu.edu/software/hisat2/index.shtml
##功能： 将测序结果比对到参考基因组上
cd ~/biosoft
mkdir HISAT  &amp;amp;&amp;amp;  cd HISAT 
#### readme: https://ccb.jhu.edu/software/hisat2/manual.shtml
wget ftp://ftp.ccb.jhu.edu/pub/infphilo/hisat2/downloads/hisat2-2.0.4-Linux_x86_64.zip
unzip hisat2-2.0.4-Linux_x86_64.zip
ln -s hisat2-2.0.4  current 
## ~/biosoft/HISAT/current/hisat2-build
## ~/biosoft/HISAT/current/hisat2  
## Download and install StringTie
## https://ccb.jhu.edu/software/stringtie/  ## https://ccb.jhu.edu/software/stringtie/index.shtml?t=manual
cd ~/biosoft
mkdir StringTie &amp;amp;&amp;amp;  cd StringTie 
wget http://ccb.jhu.edu/software/stringtie/dl/stringtie-1.2.3.Linux_x86_64.tar.gz 
tar zxvf  stringtie-1.2.3.Linux_x86_64.tar.gz
ln -s stringtie-1.2.3.Linux_x86_64 current
# ~/biosoft/StringTie/current/stringtie
cd ~/biosoft
mkdir RSEM &amp;amp;&amp;amp;  cd RSEM 
wget https://codeload.github.com/deweylab/RSEM/tar.gz/v1.2.31
mv v1.2.31  RSEM.v1.2.31.tar.gz 
tar zxvf RSEM.v1.2.31.tar.gz  
## Download and install HTSeq  
## http://www-huber.embl.de/users/anders/HTSeq/doc/overview.html
## https://pypi.python.org/pypi/HTSeq
cd ~/biosoft
mkdir HTSeq &amp;amp;&amp;amp;  cd HTSeq
wget  https://pypi.python.org/packages/72/0f/566afae6c149762af301a19686cd5fd1876deb2b48d09546dbd5caebbb78/HTSeq-0.6.1.tar.gz 
tar zxvf HTSeq-0.6.1.tar.gz
cd HTSeq-0.6.1
python setup.py install --user 
~/.local/bin/htseq-count  --help
## ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_mouse/release_M1/
## http://hgdownload-test.cse.ucsc.edu/goldenPath/mm10/liftOver/
## GRCm38/mm10 (Dec, 2011) 
## ls *bam |while read id;do ( ~/.local/bin/htseq-count  -f bam  $id   genecode/mm9/gencode.vM1.annotation.gtf.gz  1&amp;gt;${id%%.*}.gene.counts ) ;done 
## ls *bam |while read id;do ( ~/.local/bin/htseq-count  -f bam -i exon_id  $id   genecode/mm9/gencode.vM1.annotation.gtf.gz  1&amp;gt;${id%%.*}.exon.counts ) ;done
## Download and install kallisto
## https://pachterlab.github.io/kallisto/starting
cd ~/biosoft
mkdir kallisto &amp;amp;&amp;amp;  cd kallisto 
wget https://github.com/pachterlab/kallisto/releases/download/v0.43.0/kallisto_linux-v0.43.0.tar.gz
#tar zxvf  
## Download and install Sailfish
## http://www.cs.cmu.edu/~ckingsf/software/sailfish/  ## 
cd ~/biosoft
mkdir Sailfish &amp;amp;&amp;amp;  cd Sailfish 
wget   https://github.com/kingsfordgroup/sailfish/releases/download/v0.9.2/SailfishBeta-0.9.2_DebianSqueeze.tar.gz 
#tar zxvf  
## Download and install salmon
## http://salmon.readthedocs.io/en/latest/salmon.html ## 
cd ~/biosoft
mkdir salmon &amp;amp;&amp;amp;  cd salmon 
## https://github.com/COMBINE-lab/salmon
#tar zxvf  
cd ~/biosoft
mkdir GDC  &amp;amp;&amp;amp;  cd GDC  
# https://gdc.cancer.gov/access-data/gdc-data-transfer-tool
# http://gdc-docs.nci.nih.gov/Data_Transfer_Tool/Users_Guide/Getting_Started/
wget https://gdc.nci.nih.gov/files/public/file/gdc-client_v1.2.0_Ubuntu14.04_x64.zip 
unzip gdc-client_v1.2.0_Ubuntu14.04_x64.zip
cd ~/biosoft/myBin/bin
## http://hgdownload.cse.ucsc.edu/admin/exe/
wget http://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/bedToBigBed
wget http://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/bedSort
wget http://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/bedGraphToBigWig
wget http://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/fetchChromSizes
wget http://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/wigToBigWig
wget http://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/liftOver
wget http://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/bigWigToBedGraph
wget http://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/bigBedToBed
wget http://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/blat/blat
wget http://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/blat/gfClient
wget http://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/blat/gfServer
## Download and install variationtoolkit
## https://code.google.com/archive/p/variationtoolkit/downloads 
cd ~/biosoft
mkdir variationtoolkit &amp;amp;&amp;amp;  cd variationtoolkit  
wget https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/variationtoolkit/archive.tar.gz
tar zxvf archive.tar.gz 
cd variationtoolkit
make
## Download and install transvar
# http://bioinformatics.mdanderson.org/main/Transvar
cd ~/biosoft
# https://bitbucket.org/wanding/transvar
mkdir transvar &amp;amp;&amp;amp;  cd transvar  
wget https://bitbucket.org/wanding/transvar/get/v2.1.19.20160221.zip 
unzip v2.1.19.20160221.zip 
cd wanding-transvar-5dd8a7366999 
python setup.py install --user 
cd ~/biosoft
# http://kobas.cbi.pku.edu.cn/download.php 
mkdir kobas &amp;amp;&amp;amp;  cd kobas  
# wget http://kobas.cbi.pku.edu.cn/download_file.php?type=seq_pep&amp;amp;filename=hsa.pep.fasta.gz 
# wget http://kobas.cbi.pku.edu.cn/download_file.php?type=sqlite3&amp;amp;filename=hsa.db.gz 
wget http://kobas.cbi.pku.edu.cn/kobas-2.1.1/kobas-2.1.1.tar.gz 
tar zxvf kobas-2.1.1.tar.gz 
cd kobas-2.1.1_20160822
# * Download the KOBAS organism data package (organism.db.gz) from KOBAS Backend databases download website
# * Download the KOBAS specific species data package from KOBAS Backend databases download website (for example, hsa.db.gz)
# * Download the specific sequence file from KOBAS sequence files download website (for example, hsa.pep.fasta.gz)
# * `gunzip organism.db.gz`
# * `gunzip hsa.db.gz`
# * Move all databases into ${kobas_home}/sqlite3/ (for example, organism.db, hsa.db)
# * `gunzip hsa.pep.fasta.gz`
# * Move the fasta sequence file into ${kobas_home}/seq_pep/
# * `makeblastdb -in hsa.pep.fasta -dbtype prot`
pip install RPy2 --user 
pip install Numpy --user 
pip install Pandas --user 
pip install BioPython --user 
pip install matplotlib --user 
pip install PySQLite --user 
source(&amp;quot;http://bioconductor.org/biocLite.R&amp;quot;)
biocLite(&amp;quot;qvalue&amp;quot;)
## Download and install bamtools
## https://github.com/pezmaster31/bamtools/wiki/Building-and-installing
cd ~/biosoft
mkdir bamtools &amp;amp;&amp;amp;  cd bamtools  
git clone git://github.com/pezmaster31/bamtools.git 
cd bamtools
cmake --version  ## BamTools requires CMake (version &amp;gt;= 2.6.4).
mkdir build &amp;amp;&amp;amp;  cd build 
cmake ../ 
make
~/biosoft/bamtools/bamtools/bin/bamtools
## Download and install BAMStats
## http://bamstats.sourceforge.net/
## https://sourceforge.net/projects/bamstats/files/
cd ~/biosoft
mkdir BAMStats &amp;amp;&amp;amp;  cd BAMStats  
wget https://nchc.dl.sourceforge.net/project/bamstats/BAMStats-1.25.zip 
unzip BAMStats-1.25.zip
#java -jar  ~/biosoft/BAMStats/BAMStats-1.25/BAMStats-1.25.jar  --help
## Download and install Qualimap 
## http://qualimap.bioinfo.cipf.es/
cd ~/biosoft
mkdir Qualimap &amp;amp;&amp;amp;  cd Qualimap  
wget https://bitbucket.org/kokonech/qualimap/downloads/qualimap_v2.2.1.zip 
## readme  http://qualimap.bioinfo.cipf.es/doc_html/index.html
## example results :http://kokonech.github.io/qualimap/HG00096.chr20_bamqc/qualimapReport.html 
unzip qualimap_v2.2.1.zip 
~/biosoft/bamtools/bamtools/bin/bamtools
~/biosoft/Qualimap/qualimap_v2.2.1/qualimap --help ## --java-mem-size=4G
## modify ~/.bashrc by adding PATH=$PATH:~/.local/bin/
## Download and install deepTools
## https://github.com/fidelram/deepTools
## http://deeptools.readthedocs.io/en/latest/content/example_usage.html
pip install pyBigWig --user 
cd ~/biosoft
mkdir deepTools &amp;amp;&amp;amp;  cd deepTools  
git clone https://github.com/fidelram/deepTools ## 130M,
cd deepTools
python setup.py install --user
## 17 tools in ~/.local/bin/
~/.local/bin/deeptools
cd ~/biosoft
mkdir ngsplot &amp;amp;&amp;amp;  cd ngsplot  
## download by yourself :https://drive.google.com/drive/folders/0B1PVLadG_dCKN1liNFY0MVM1Ulk  
tar -zxvf ngsplot-2.61.tar.gz
tar zxvf ngsplot.eg.bam.tar.gz
echo &#39;export PATH=/home/jianmingzeng/biosoft/ngsplot/ngsplot/bin:$PATH&#39; &amp;gt;&amp;gt;~/.bashrc  
echo &#39;export NGSPLOT=/home/jianmingzeng/biosoft/ngsplot/ngsplot&#39; &amp;gt;&amp;gt;~/.bashrc 
source ~/.bashrc
install.packages(&amp;quot;doMC&amp;quot;, dep=T)
install.packages(&amp;quot;caTools&amp;quot;, dep=T)
install.packages(&amp;quot;utils&amp;quot;, dep=T)
source(&amp;quot;http://bioconductor.org/biocLite.R&amp;quot;)
biocLite( &amp;quot;BSgenome&amp;quot; )
biocLite( &amp;quot;Rsamtools&amp;quot; )
biocLite( &amp;quot;ShortRead&amp;quot; )
cd ~/biosoft
mkdir breakdancer &amp;amp;&amp;amp;  cd breakdancer  
# http://breakdancer.sourceforge.net/
# you need to install 2 perl module by yourself : http://breakdancer.sourceforge.net/moreperl.html
wget https://sourceforge.net/projects/breakdancer/files/breakdancer-1.1.2_2013_03_08.zip 
unzip breakdancer-1.1.2_2013_03_08.zip 
cd breakdancer-1.1.2/cpp
make  ##something wrong !
## usage: http://breakdancer.sourceforge.net/pipeline.html
cd ~/biosoft
# http://boevalab.com/FREEC/
mkdir Control-FREEC &amp;amp;&amp;amp; cd Control-FREEC
# https://github.com/BoevaLab/FREEC/releases
wget https://github.com/BoevaLab/FREEC/archive/v10.3.zip 
unzip v10.3.zip 
# https://www.ncbi.nlm.nih.gov/pubmed/22155870
# http://boevalab.com/FREEC/tutorial.html
# http://samtools.sourceforge.net/pileup.shtml
cd ~/biosoft
# https://github.com/dellytools/delly
mkdir delly &amp;amp;&amp;amp; cd delly 
# git clone --recursive https://github.com/dellytools/delly.git
# cd delly 
# make all
# make PARALLEL=1 -B src/delly
wget https://github.com/dellytools/delly/releases/download/v0.7.6/delly_v0.7.6_linux_x86_64bit 
chmod 777 delly_v0.7.6_linux_x86_64bit 
~/biosoft/delly/delly_v0.7.6_linux_x86_64bit  --help 
## delly call -t DEL -g hg19.fa -o s1.bcf -x hg19.excl sample1.bam
## ./delly/src/bcftools/bcftools view delly.bcf &amp;gt; delly.vcf
## The SV type can be DEL, DUP, INV, TRA, or INS for deletions, tandem duplications, inversions, translocations and small insertions, respectively.
## In addition, you can filter input reads more stringently using -q 20 and -s 15.
cd ~/biosoft
# https://www.cog-genomics.org/plink2/data#merge_list
mkdir PLINK &amp;amp;&amp;amp; cd PLINK 
wget https://www.cog-genomics.org/static/bin/plink170113/plink_linux_x86_64.zip 
unzip plink_linux_x86_64.zip
~/biosoft/PLINK/plink
## Download and install Scalpel
cd ~/biosoft
mkdir Scalpel &amp;amp;&amp;amp;  cd Scalpel
wget https://downloads.sourceforge.net/project/scalpel/scalpel-0.5.3.tar.gz  
tar zxvf scalpel-0.5.3.tar.gz
cd scalpel-0.5.3
make
~/biosoft/Scalpel/scalpel-0.5.3/scalpel-discovery  --help
~/biosoft/Scalpel/scalpel-0.5.3/scalpel-export  --help
cd ~/biosoft
# https://www.cog-genomics.org/plink2/data#merge_list
mkdir firehose &amp;amp;&amp;amp; cd firehose 
wget http://gdac.broadinstitute.org/runs/code/firehose_get_latest.zip
unzip firehose_get_latest.zip 
~/biosoft/firehose/firehose_get
~/biosoft/firehose/firehose_get -tasks clinical analyses latest brca 
cd ~/biosoft
# https://www.cog-genomics.org/plink2/data#merge_list
mkdir fastpop &amp;amp;&amp;amp; cd fastpop 
wget https://sourceforge.net/projects/fastpop/files/FastPop.tar.gz 
wget https://jaist.dl.sourceforge.net/project/fastpop/FastPop_Instruction.pdf
tar zxvf FastPop.tar.gz  
pip install cnvkit --user
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;转录组-de-novo分析流程的软件全代码&#34;&gt;转录组 de novo分析流程的软件全代码&lt;/h1&gt;

&lt;p&gt;Trinotate/Trinity/TransDecoder/sqlite/NCBI BLAST+/HMMER/PFAM signalP v4 /tmhmm v2 /RNAMMER 有些软件需要教育邮箱注册才行哦~~&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;## Trinotate/Trinity/TransDecoder/sqlite/NCBI BLAST+/HMMER/PFAM 
## signalP v4 /tmhmm v2 /RNAMMER
cd ~/biosoft
mkdir hmmer &amp;amp;&amp;amp;  cd hmmer
wget http://eddylab.org/software/hmmer/2.3/hmmer-2.3.tar.gz 
tar zxvf hmmer-2.3.tar.gz
cd hmmer-2.3
./configure --prefix=/home/jmzeng/my-bin
#./configure --prefix=/home/jianmingzeng/biosoft/myBin
make
make install
#for file in hmmalign hmmbuild hmmcalibrate hmmconvert hmmemit hmmfetch hmmindex hmmpfam hmmsearch ; do\
#      cp src/$file /home/jmzeng/my-bin/bin/;\
#   done
#for file in hmmer hmmalign hmmbuild hmmcalibrate hmmconvert hmmemit hmmfetch hmmindex hmmpfam hmmsearch; do\
#      cp documentation/man/$file.man /home/jmzeng/my-bin/man/man1/$file.1;\
#   done
cp /home/jmzeng/my-bin/bin/hmmsearch /home/jmzeng/my-bin/bin/hmmsearch2
cd ~/biosoft
mkdir CBS &amp;amp;&amp;amp;  cd CBS
#   signalP v4 (free academic download) http://www.cbs.dtu.dk/cgi-bin/nph-sw_request?signalp
#   tmhmm v2 (free academic download) http://www.cbs.dtu.dk/cgi-bin/nph-sw_request?tmhmm
#   RNAMMER (free academic download) http://www.cbs.dtu.dk/cgi-bin/sw_request?rnammer
mkdir signalp-4.1
mkdir rnammer-1.2
## be sure to untar it in a new directory
## it&#39;s a perl script, we need to modify it according to readme http://trinotate.github.io/#SoftwareRequired
## vi ~/biosoft/CBS/signalp-4.1/signalp
tar zxvf signalp-4.1e.Linux.tar.gz 
tar zxvf rnammer-1.2.src.tar.Z 
tar zxvf tmhmm-2.0c.Linux.tar.gz 
## it&#39;s a perl script, we need to modify it according to readme http://trinotate.github.io/#SoftwareRequired
## vi ~/biosoft/CBS/tmhmm-2.0c/bin/tmhmm 
## vi ~/biosoft/CBS/tmhmm-2.0c/bin/tmhmmformat.pl
which perl  ## /usr/bin/perl
cd ~/biosoft
mkdir blastPlus &amp;amp;&amp;amp;  cd blastPlus
#   ftp://ftp.ncbi.nlm.nih.gov/blast/executables/LATEST
wget ftp://ftp.ncbi.nlm.nih.gov/blast/executables/LATEST/ncbi-blast-2.5.0+-x64-linux.tar.gz
blastBinFolder=~/biosoft/blastPlus/ncbi-blast-2.5.0+/bin
$blastBinFolder/makeblastdb -help
#   http://www.cbs.dtu.dk/services/doc/signalp-4.1.readme
cd ~/biosoft
mkdir TransDecoder &amp;amp;&amp;amp;  cd TransDecoder
#   https://transdecoder.github.io/
# https://github.com/TransDecoder/TransDecoder/releases
wget https://github.com/TransDecoder/TransDecoder/archive/v3.0.0.tar.gz  -O TransDecoder.v3.0.0.tar.gz 
tar zxvf TransDecoder.v3.0.0.tar.gz 
cd TransDecoder-3.0.0 
make
~/biosoft/TransDecoder/TransDecoder-3.0.0/TransDecoder.LongOrfs -h
~/biosoft/TransDecoder/TransDecoder-3.0.0/TransDecoder.Predict -h
## sqlite3  --help
cd ~/biosoft
mkdir Trinotate &amp;amp;&amp;amp;  cd Trinotate
#   http://trinotate.github.io/
#   https://github.com/Trinotate/Trinotate/releases
wget https://github.com/Trinotate/Trinotate/archive/v3.0.1.tar.gz  -O Trinotate.v3.0.1.tar.gz 
tar zxvf Trinotate.v3.0.1.tar.gz
~/biosoft/Trinotate/Trinotate-3.0.1/Trinotate -h
wget https://data.broadinstitute.org/Trinity/Trinotate_v3_RESOURCES/Pfam-A.hmm.gz
wget https://data.broadinstitute.org/Trinity/Trinotate_v3_RESOURCES/uniprot_sprot.pep.gz
wget https://data.broadinstitute.org/Trinity/Trinotate_v3_RESOURCES/Trinotate_v3.sqlite.gz  -O Trinotate.sqlite.gz
gunzip Trinotate.sqlite.gz
gunzip uniprot_sprot.pep.gz
makeblastdb -in uniprot_sprot.pep -dbtype prot
gunzip Pfam-A.hmm.gz
hmmpress Pfam-A.hmm
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;基因组-gtf-bed-注释&#34;&gt;基因组，gtf，bed，注释&lt;/h1&gt;

&lt;p&gt;前面既然把我多年累积的软件安装代码共享了，就顺便把我最近做直播我的基因组的一些数据下载代码共享吧&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;cd ~/reference
mkdir -p genome/hg19  &amp;amp;&amp;amp; cd genome/hg19 
nohup wget http://hgdownload.cse.ucsc.edu/goldenPath/hg19/bigZips/chromFa.tar.gz &amp;amp;
tar zvfx chromFa.tar.gz
cat *.fa &amp;gt; hg19.fa
rm chr*.fa
 
 
cd ~/reference
mkdir -p genome/hg38  &amp;amp;&amp;amp; cd genome/hg38 
nohup wget http://hgdownload.cse.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz  &amp;amp;
 
cd ~/reference
mkdir -p  genome/mm10  &amp;amp;&amp;amp; cd genome/mm10 
nohup wget http://hgdownload.cse.ucsc.edu/goldenPath/mm10/bigZips/chromFa.tar.gz  &amp;amp;
tar zvfx chromFa.tar.gz
cat *.fa &amp;gt; mm10.fa
rm chr*.fa
 
 
cd ~/biosoft/RNA-SeQC
wget http://www.broadinstitute.org/cancer/cga/sites/default/files/data/tools/rnaseqc/ThousandReads.bam
wget http://www.broadinstitute.org/cancer/cga/sites/default/files/data/tools/rnaseqc/gencode.v7.annotation_goodContig.gtf.gz
wget http://www.broadinstitute.org/cancer/cga/sites/default/files/data/tools/rnaseqc/Homo_sapiens_assembly19.fasta.gz
wget http://www.broadinstitute.org/cancer/cga/sites/default/files/data/tools/rnaseqc/Homo_sapiens_assembly19.other.tar.gz
wget http://www.broadinstitute.org/cancer/cga/sites/default/files/data/tools/rnaseqc/gencode.v7.gc.txt
wget http://www.broadinstitute.org/cancer/cga/sites/default/files/data/tools/rnaseqc/rRNA.tar.gz
 
cd ~/reference
mkdir -p index/bowtie &amp;amp;&amp;amp; cd index/bowtie 
nohup time ~/biosoft/bowtie/bowtie2-2.2.9/bowtie2-build  ~/reference/genome/hg19/hg19.fa  ~/reference/index/bowtie/hg19 1&amp;gt;hg19.bowtie_index.log 2&amp;gt;&amp;amp;1 &amp;amp;
nohup time ~/biosoft/bowtie/bowtie2-2.2.9/bowtie2-build  ~/reference/genome/hg38/hg38.fa  ~/reference/index/bowtie/hg38 1&amp;gt;hg38.bowtie_index.log 2&amp;gt;&amp;amp;1 &amp;amp;
nohup time ~/biosoft/bowtie/bowtie2-2.2.9/bowtie2-build  ~/reference/genome/mm10/mm10.fa  ~/reference/index/bowtie/mm10 1&amp;gt;mm10.bowtie_index.log 2&amp;gt;&amp;amp;1 &amp;amp;
  
cd ~/reference
mkdir -p index/bwa &amp;amp;&amp;amp; cd index/bwa 
nohup time ~/biosoft/bwa/bwa-0.7.15/bwa index   -a bwtsw   -p ~/reference/index/bwa/hg19  ~/reference/genome/hg19/hg19.fa 1&amp;gt;hg19.bwa_index.log 2&amp;gt;&amp;amp;1   &amp;amp;
nohup time ~/biosoft/bwa/bwa-0.7.15/bwa index   -a bwtsw   -p ~/reference/index/bwa/hg38  ~/reference/genome/hg38/hg38.fa 1&amp;gt;hg38.bwa_index.log 2&amp;gt;&amp;amp;1   &amp;amp;
nohup time ~/biosoft/bwa/bwa-0.7.15/bwa index   -a bwtsw   -p ~/reference/index/bwa/mm10  ~/reference/genome/mm10/mm10.fa 1&amp;gt;mm10.bwa_index.log 2&amp;gt;&amp;amp;1   &amp;amp;
  
cd ~/reference
mkdir -p index/hisat &amp;amp;&amp;amp; cd index/hisat 
nohup wget ftp://ftp.ccb.jhu.edu/pub/infphilo/hisat2/data/hg19.tar.gz  &amp;amp;
nohup wget ftp://ftp.ccb.jhu.edu/pub/infphilo/hisat2/data/hg38.tar.gz  &amp;amp;
nohup wget ftp://ftp.ccb.jhu.edu/pub/infphilo/hisat2/data/grcm38.tar.gz &amp;amp;
nohup wget ftp://ftp.ccb.jhu.edu/pub/infphilo/hisat2/data/mm10.tar.gz  &amp;amp;
tar zxvf hg19.tar.gz
tar zxvf grcm38.tar.gz
tar zxvf hg38.tar.gz
tar zxvf mm10.tar.gz 
  
  
mkdir -p ~/annotation/variation/human/ExAC
cd ~/annotation/variation/human/ExAC
## http://exac.broadinstitute.org/
## ftp://ftp.broadinstitute.org/pub/ExAC_release/current
wget ftp://ftp.broadinstitute.org/pub/ExAC_release/current/ExAC.r0.3.1.sites.vep.vcf.gz.tbi 
nohup wget ftp://ftp.broadinstitute.org/pub/ExAC_release/current/ExAC.r0.3.1.sites.vep.vcf.gz &amp;amp;
wget ftp://ftp.broadinstitute.org/pub/ExAC_release/current/cnv/exac-final-cnv.gene.scores071316 
wget ftp://ftp.broadinstitute.org/pub/ExAC_release/current/cnv/exac-final.autosome-1pct-sq60-qc-prot-coding.cnv.bed
 
 
mkdir -p ~/annotation/variation/human/dbSNP
cd ~/annotation/variation/human/dbSNP
## https://www.ncbi.nlm.nih.gov/projects/SNP/
## ftp://ftp.ncbi.nih.gov/snp/organisms/human_9606_b147_GRCh38p2/
## ftp://ftp.ncbi.nih.gov/snp/organisms/human_9606_b147_GRCh37p13/
nohup wget ftp://ftp.ncbi.nih.gov/snp/organisms/human_9606_b147_GRCh37p13/VCF/All_20160601.vcf.gz &amp;amp;
wget ftp://ftp.ncbi.nih.gov/snp/organisms/human_9606_b147_GRCh37p13/VCF/All_20160601.vcf.gz.tbi 
 
 
mkdir -p ~/annotation/variation/human/1000genomes
cd ~/annotation/variation/human/1000genomes 
## ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/ 
nohup wget  -c -r -nd -np -k -L -p  ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502 &amp;amp;
 
mkdir -p ~/annotation/variation/human/cosmic
cd ~/annotation/variation/human/cosmic
## we need to register before we can download this file. 
 
mkdir -p ~/annotation/variation/human/ESP6500
cd ~/annotation/variation/human/ESP6500
# http://evs.gs.washington.edu/EVS/
nohup wget http://evs.gs.washington.edu/evs_bulk_data/ESP6500SI-V2-SSA137.GRCh38-liftover.snps_indels.vcf.tar.gz &amp;amp; 
 
mkdir -p ~/annotation/variation/human/UK10K
cd ~/annotation/variation/human/UK10K
# http://www.uk10k.org/
nohup wget ftp://ngs.sanger.ac.uk/production/uk10k/UK10K_COHORT/REL-2012-06-02/UK10K_COHORT.20160215.sites.vcf.gz &amp;amp; 
 
mkdir -p ~/annotation/variation/human/gonl
cd ~/annotation/variation/human/gonl
## http://www.nlgenome.nl/search/
## https://molgenis26.target.rug.nl/downloads/gonl_public/variants/release5/
nohup wget  -c -r -nd -np -k -L -p  https://molgenis26.target.rug.nl/downloads/gonl_public/variants/release5  &amp;amp;
 
mkdir -p ~/annotation/variation/human/omin
cd ~/annotation/variation/human/omin
 
mkdir -p ~/annotation/variation/human/GWAS
cd ~/annotation/variation/human/GWAS
 
mkdir -p ~/annotation/variation/human/hapmap
cd ~/annotation/variation/human/hapmap
# ftp://ftp.ncbi.nlm.nih.gov/hapmap/
wget ftp://ftp.ncbi.nlm.nih.gov/hapmap/phase_3/relationships_w_pops_051208.txt 
nohup wget -c -r -np -k -L -p  -nd -A.gz ftp://ftp.ncbi.nlm.nih.gov/hapmap/phase_3/hapmap3_reformatted &amp;amp;
# ftp://ftp.hgsc.bcm.tmc.edu/pub/data/HapMap3-ENCODE/ENCODE3/ENCODE3v1/
wget ftp://ftp.hgsc.bcm.tmc.edu/pub/data/HapMap3-ENCODE/ENCODE3/ENCODE3v1/bcm-encode3-QC.txt 
wget ftp://ftp.hgsc.bcm.tmc.edu/pub/data/HapMap3-ENCODE/ENCODE3/ENCODE3v1/bcm-encode3-submission.txt.gz
 
 
 
 
## 1 million single nucleotide polymorphisms (SNPs) for DNA samples from each of the three ethnic groups in Singapore – Chinese, Malays and Indians.
## The Affymetrix Genome-Wide Human SNP Array 6.0   &amp;amp;&amp;amp; The Illumina Human1M single BeadChip 
## http://www.statgen.nus.edu.sg/~SGVP/
## http://www.statgen.nus.edu.sg/~SGVP/singhap/files-website/samples-information.txt
# http://www.statgen.nus.edu.sg/~SGVP/singhap/files-website/genotypes/2009-01-30/QC/
 
## Singapore Sequencing Malay Project (SSMP) 
mkdir -p ~/annotation/variation/human/SSMP
cd ~/annotation/variation/human/SSMP
## http://www.statgen.nus.edu.sg/~SSMP/
## http://www.statgen.nus.edu.sg/~SSMP/download/vcf/2012_05 
 
 
## Singapore Sequencing Indian Project (SSIP) 
mkdir -p ~/annotation/variation/human/SSIP
cd ~/annotation/variation/human/SSIP
# http://www.statgen.nus.edu.sg/~SSIP/
## http://www.statgen.nus.edu.sg/~SSIP/download/vcf/dataFreeze_Feb2013
 
 
 
wget ftp://ftp.ensembl.org/pub/release-75/gtf/homo_sapiens/Homo_sapiens.GRCh37.75.gtf.gz 
wget ftp://ftp.ensembl.org/pub/release-86/gtf/homo_sapiens/Homo_sapiens.GRCh38.86.chr.gtf.gz 
 
mkdir -p ~/reference/gtf/gencode
cd  ~/reference/gtf/gencode
## https://www.gencodegenes.org/releases/current.html
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/gencode.v25.2wayconspseudos.gtf.gz
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/gencode.v25.long_noncoding_RNAs.gtf.gz 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/gencode.v25.polyAs.gtf.gz 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/gencode.v25.annotation.gtf.gz 
## https://www.gencodegenes.org/releases/25lift37.html 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/GRCh37_mapping/gencode.v25lift37.annotation.gtf.gz 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/GRCh37_mapping/gencode.v25lift37.metadata.HGNC.gz 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/GRCh37_mapping/gencode.v25lift37.metadata.EntrezGene.gz 
wget ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_25/GRCh37_mapping/gencode.v25lift37.metadata.RefSeq.gz 
 
 
mkdir -p ~/reference/gtf/ensembl/homo_sapiens_86
cd  ~/reference/gtf/ensembl/homo_sapiens_86
## http://asia.ensembl.org/info/data/ftp/index.html
 
 
 
cd ~/reference
mkdir -p  genome/human_g1k_v37  &amp;amp;&amp;amp; cd genome/human_g1k_v37
# http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/ 
nohup wget http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/human_g1k_v37.fasta.gz  &amp;amp;
gunzip human_g1k_v37.fasta.gz
wget http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/human_g1k_v37.fasta.fai
wget http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/README.human_g1k_v37.fasta.txt
java -jar ~/biosoft/picardtools/picard-tools-1.119/CreateSequenceDictionary.jar R=human_g1k_v37.fasta O=human_g1k_v37.dict
 
## ftp://ftp.broadinstitute.org/bundle/b37/
mkdir -p ~/annotation/GATK
cd ~/annotation/variation/GATK
wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/b37/1000G_phase1.snps.high_confidence.b37.vcf.gz 
wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/b37/dbsnp_138.b37.vcf.gz
wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/b37/human_g1k_v37.fasta.gz 
wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/b37/NA12878.HiSeq.WGS.bwa.cleaned.raw.subset.b37.sites.vcf.gz
wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/b37/Mills_and_1000G_gold_standard.indels.b37.vcf.gz 
wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/b37/hapmap_3.3.b37.vcf.gz
wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/b37/1000G_phase1.indels.b37.vcf.gz 
wget ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/b37/1000G_phase1.indels.b37.vcf.idx.gz
gunzip 1000G_phase1.indels.b37.vcf.idx.gz
gunzip 1000G_phase1.indels.b37.vcf.gz
  
  
mkdir -p  ~/institute/ENSEMBL/gtf
cd  ~/institute/ENSEMBL/gtf
wget ftp://ftp.ensembl.org/pub/release-87/gtf/homo_sapiens/Homo_sapiens.GRCh38.87.chr.gtf.gz 
wget ftp://ftp.ensembl.org/pub/release-87/gtf/mus_musculus/Mus_musculus.GRCm38.87.chr.gtf.gz
wget ftp://ftp.ensembl.org/pub/release-87/gtf/danio_rerio/Danio_rerio.GRCz10.87.chr.gtf.gz
 
 
 
 
 
cd ~/institute/TCGA/firehose
## https://gdac.broadinstitute.org/
wget http://gdac.broadinstitute.org/runs/stddata__2016_01_28/data/ACC/20160128/gdac.broadinstitute.org_ACC.Merge_snp__genome_wide_snp_6__broad_mit_edu__Level_3__segmented_scna_minus_germline_cnv_hg19__seg.Level_3.2016012800.0.0.tar.gz  -O ACC.gistic.seg.tar.gz
wget http://gdac.broadinstitute.org/runs/stddata__2016_01_28/data/ACC/20160128/gdac.broadinstitute.org_ACC.Merge_snp__genome_wide_snp_6__broad_mit_edu__Level_3__segmented_scna_hg19__seg.Level_3.2016012800.0.0.tar.gz  -O ACC.raw.seg.tar.gz 
wget http://gdac.broadinstitute.org/runs/stddata__2016_01_28/data/ACC/20160128/gdac.broadinstitute.org_ACC.Mutation_Packager_Calls.Level_3.2016012800.0.0.tar.gz -O ACC.maf.tar.gz
wget http://gdac.broadinstitute.org/runs/stddata__2016_01_28/data/ACC/20160128/gdac.broadinstitute.org_ACC.Mutation_Packager_Oncotated_Calls.Level_3.2016012800.0.0.tar.gz -O ACC.maf.anno.tar.gz
&lt;/code&gt;&lt;/pre&gt;

        
      </description>
    </item>
    
    <item>
      <title>一致性指数Concordance index(C-index) </title>
      <link>/blog/cn/2017/10/concordance_index/</link>
      <pubDate>Sun, 15 Oct 2017 23:06:17 +0000</pubDate>
      
      <guid>/blog/cn/2017/10/concordance_index/</guid>
      <description>
        

&lt;p&gt;&lt;a href=&#34;http://mp.weixin.qq.com/s?__biz=MzAxNjM2MDI2MQ==&amp;amp;mid=205481962&amp;amp;idx=1&amp;amp;sn=f09dd122f7282be8d26b803d0039a195#rd&#34;&gt;原文&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;所谓C-index，英文名全称&lt;strong&gt;concordance index&lt;/strong&gt;，最早是由范德堡大学（Vanderbilt University）生物统计教教授Frank E Harrell Jr 1996年提出，主要用于计算生存分析中的COX模型预测值与真实之间的区分度（discrimination）；现阶段用的最多的是肿瘤患者预后模型的预测精度。&lt;/p&gt;

&lt;p&gt;一般评价模型的好坏主要有两个方面，&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;一是模型的拟合优度（Goodness of Fit),常见的评价指标主要有R方，-2logL,AIC,BIC等等；&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;另外一个是模型的预测精度，主要就是模型的真实值与预测值之间的差的大小，均方误差，相对误差等。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;从临床应用的角度来说，我们更注重后者，即统计建模主要是用于预测，而从C-index的概念大家看出它属于模型评价指标的后者，这一指标比前面提到的几个指标看起来更高大上，一般文献中用的也比较多。&lt;/p&gt;

&lt;p&gt;C-index本质上是估计了预测结果与实际观察到的结果相一致的概率，即资料所有病人对子中预测结果与实际结果一致的对子所占的比例。有点类似于ROC曲线下面积。&lt;/p&gt;

&lt;p&gt;C-index的计算方法是:把所研究的资料中的所有研究对象随机地两两组成对子。以生存分析为例,对于一对病人,如果生存时间较长的一位,其预测生存时间长于生存时间较短的一位,或预测的生存概率高的一位的生存时间长于生存概率低的另一位,则称之为预测结果与实际结果一致。&lt;/p&gt;

&lt;p&gt;C-index的计算步骤为:&lt;/p&gt;

&lt;p&gt;*(1)产生所有的病例配对。若有n个观察个体,则所有的对子数应为Cn2(组合数)?
*(2)排除下面两种对子:对子中具有较小观察时间的个体没有达到观察终点及对子中两个个体都没达到观察终点。剩余的为有用对子。
*(3)计算有用对子中,预测结果和实际相一致的对子数,即具有较坏预测结果个体的实际观察时间较短。
*(4)计算。C=一致对子数/有用对子数。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;C-index在0.5-1之间。0.5为完全不一致,说明该模型没有预测作用,1为完全一致,说明该模型预测结果与实际完全一致。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在实际应用中,很难找到完全一致的预测模型,既往研究认为,C-index
* 在0.50-0.70为较低准确度,
* 在0.71-0.90之间为中等准确度;
* 而高于0.90则为高准确度。&lt;/p&gt;

&lt;p&gt;当C-index检验由同一样本建成的模型时易造成偏倚,因此再采用重抽样技术(Bootstrap)可以几乎无偏倚的检验预测模型的准确度。Bootstrap是非参数统计中一种重要的估计统计量方差进而进行区间估计的统计方法,是现代统计应用较为广泛的一种统计方法。&lt;/p&gt;

&lt;p&gt;Bootstrap方法核心思想和基本步骤如下:&lt;/p&gt;

&lt;p&gt;*(1)采用重抽样技术从原始样本中抽取一定数量的样本,此过程允许重复抽样。&lt;/p&gt;

&lt;p&gt;*(2)根据抽出的样本计算给定的统计量T。&lt;/p&gt;

&lt;p&gt;*(3)重复上述N次(一般大于1000),得到N个统计量T。&lt;/p&gt;

&lt;p&gt;*(4)计算上述N个统计量T的样木方差,得到统计量的方差。&lt;/p&gt;

&lt;p&gt;Bootstarap方法只是对单一样本且样本量较小的资料，如果数据集很大可以按照不同的比例将数据集拆分，一部分用于建模一部分用于验证。关于交叉验证（Cross-validation），由于篇幅有限，留作下次探讨。&lt;/p&gt;

&lt;p&gt;#R软件实现：
C-index的R软件计算实现有两种实现方法，一种是用到Harrell本人的的R包Hmisc package；另一种是Le Kang, Weijie Chen 2014年12月18日发布的R compareC Package&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;############################
#### Method 1.Hmisc code ###
############################
data &amp;lt;- read.csv(&amp;quot;survivaldta.csv&amp;quot;)
library(Hmisc) 
library(survival) ###加载survival包，主要用于建立模型###
f &amp;lt;- cph(Surv(time,death)~x1+x2+x3，data=survivldata) ###拟合cox模型
fp &amp;lt;- predict(f)###模型的预测值
cindex.orig=1-rcorr.cens(fp,Surv(time,death)) [[1]]###计算出的C-index

###############################
#### Method 2.compareC code ###
###############################
data &amp;lt;- read.csv(&amp;quot;survivaldta.csv&amp;quot;) 
library(compareC) 
library(survival) 
cindex &amp;lt;- cindex(Surv(time,death) ~ x1+x2+x3,data=survivldata)###计算出的C-index

###############################
#### Bootstrap code ###
###############################
bootit=200
for(i in 1:bootit){
case=noNA[group==&amp;quot;long&amp;quot;,] 
control=noNA[group==&amp;quot;&amp;lt;24&amp;quot;,]
bootindex.case=sample(1:nrow(case),replace=T)
boot.case.data=case[bootindex.case,]
bootindex.control=sample(1:nrow(control),replace=T)
boot.control.data=control[bootindex.control,]
boot.data=rbind(boot.case.data,boot.control.data)
dstr.boot=svydesign(id=~1, prob=~inv_weight, fpc=~ssize, data=boot.data)
boot.fit=svycoxph(Surv(survival,surv_cens) ~x1+x2+x3,data=boot.data,x=TRUE,design=dstr.boot)
cindex.train=1-rcorr.cens(lp.boot,Surv(boot.data$survival, boot.data$surv_cens))[[1]]
cindex.test=1-rcorr.cens(lp_=.test,Surv(noNA$survival,noNA$surv_cens))[[1]]
bias=rep(1,bootit)
bias[i]=abs(cindex.train-cindex.test) }
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;参考文献&#34;&gt;参考文献&lt;/h1&gt;

&lt;p&gt;Harrell FE, Califf RM, Pryor DB, Lee KL, and Rosati RA. (1982) Evaluating the yield of medical tests. The Journal of the American Medical Association, 247(18), 2543–2546&lt;/p&gt;

&lt;p&gt;Pencina MJ and D’Agostino RB. (2004) Overall C as a measure of discrimination in survival analysis: model specific population value and confidence interval estimation. Statistics in Medicine, 23(13), 2109–2123&lt;/p&gt;

&lt;p&gt;Kang L, Chen W, Petrick NA, and Gallas BD. (2014) Comparing two correlated C indices with right-censored survival outcome: a one-shot nonparametric approach. Statistics in Medicine, 34(4), 685–703, doi: 10.1002/sim.6370&lt;/p&gt;

&lt;p&gt;Hmisc Reference manual：&lt;a href=&#34;http://cran.r-project.org/web/packages/Hmisc/Hmisc.pdf&#34;&gt;http://cran.r-project.org/web/packages/Hmisc/Hmisc.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;compareC Reference manual: &lt;a href=&#34;http://cran.r-project.org/web/packages/compareC/compareC.pdf&#34;&gt;http://cran.r-project.org/web/packages/compareC/compareC.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Frank.Harrell :&lt;a href=&#34;http://biostat.mc.vanderbilt.edu/wiki/Main/FrankHarrell&#34;&gt;http://biostat.mc.vanderbilt.edu/wiki/Main/FrankHarrell&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;5-ways-to-estimate-concordance-index-for-cox-models-in-r&#34;&gt;5 Ways to Estimate Concordance Index for Cox Models in R&lt;/h1&gt;

&lt;p&gt;Why Results Aren&amp;rsquo;t Identical?&lt;/p&gt;

&lt;p&gt;Harrell&amp;rsquo;s concordance index (c-index) can be used to evaluate the discriminatory power and the predictive accuracy of Cox models. An easy way out as a surrogate for ROC analysis.&lt;/p&gt;

&lt;h2 id=&#34;approach-1&#34;&gt;Approach 1&lt;/h2&gt;

&lt;p&gt;Use function &amp;ldquo;rcorrcens&amp;rdquo; in package &amp;ldquo;Hmisc&amp;rdquo;&lt;/p&gt;

&lt;p&gt;Limitations:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Can only handle un-censored data&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Roughly handle categorical predictor with more than 2 categories&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;Sample code:
library(survival)
library(Hmisc)
attach(sample.data)
surv &amp;lt;- Surv(survival, censor)
rcorrcens(surv ~ group)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;approach-2&#34;&gt;Approach 2&lt;/h2&gt;

&lt;p&gt;Direct output from coxph
Require higher version of R, say R 2.15, didn&amp;rsquo;t test with older versions&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Sample code:
library(survival)
attach(sample.data)
surv &amp;lt;- Surv(survival, censor)
sum.surv &amp;lt;- summary(coxph(surv ~ group))
c_index &amp;lt;- sum.surv$concordance
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;approach-3&#34;&gt;Approach 3&lt;/h2&gt;

&lt;p&gt;Use function &amp;ldquo;survConcordance&amp;rdquo;
Result is the same as in Approach 2&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Sample code:
library(survival)
attach(sample.data)
surv &amp;lt;- Surv(survival, censor)
fit &amp;lt;- coxph( surv ~ group)
survConcordance(surv ~ predict(fit))
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;approach-4&#34;&gt;Approach 4&lt;/h2&gt;

&lt;p&gt;Use package &amp;ldquo;survcomp&amp;rdquo; in bioconductor&lt;/p&gt;

&lt;p&gt;Different result from Approach &lt;sup&gt;2&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt;&lt;/p&gt;

&lt;p&gt;The disparity is due to two different estimation approaches that are used to handle tied risks (i.e. cases when  two observations have the same survival with the same x). The method that approaches &lt;sup&gt;4&lt;/sup&gt;&amp;frasl;&lt;sub&gt;5&lt;/sub&gt; use ignores the tied risks,  the other method (approaches &lt;sup&gt;2&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt;) takes into consideration of the tied risks. In terms of formulation/symbol (for illustration only):&lt;/p&gt;

&lt;p&gt;Approaches &lt;sup&gt;4&lt;/sup&gt;&amp;frasl;&lt;sub&gt;5&lt;/sub&gt; used:&lt;/p&gt;

&lt;p&gt;Concordance = #all concordant pairs/#total pairs ignoring ties.&lt;/p&gt;

&lt;p&gt;Approaches &lt;sup&gt;2&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt; used:&lt;/p&gt;

&lt;p&gt;Concordance = (#all concordant pairs + #tied pairs/2)/(#total pairs including ties).
Those #s can be obtained in the output of Approach 3.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Sample code:
source(&amp;quot;http://bioconductor.org/biocLite.R&amp;quot;)
biocLite(&amp;quot;survcomp&amp;quot;)
library(survcomp)
surv &amp;lt;- Surv(survival, censor) 
fit &amp;lt;- coxph(surv ~ group, data= sample.data)
coxPredict &amp;lt;- predict(fit, data=sample.data, type=&amp;quot;risk&amp;quot;)  
concordance.index(x=coxPredict, surv.time=survival, surv.event=censor, method=&amp;quot;noether&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;approach-5&#34;&gt;Approach 5&lt;/h2&gt;

&lt;p&gt;Use function &amp;ldquo;cph&amp;rdquo; in package &amp;ldquo;rms&amp;rdquo;
Provide both un-adjusted and bias adjusted c-index
Un-adjusted c-index is the same as the one from Approach 4&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Sample code: 
library(rms)
surv &amp;lt;- Surv(survival, censor) 
set.seed(1)
fit.cph &amp;lt;- cph(surv ~ group, data= sample.data, x=TRUE, y=TRUE, surv=TRUE)
  
# Get the Dxy
v &amp;lt;- validate.cph(fit.cph, dxy=TRUE, B=1000)
Dxy = v[rownames(v)==&amp;quot;Dxy&amp;quot;, colnames(v)==&amp;quot;index.corrected&amp;quot;]
orig_Dxy = v[rownames(v)==&amp;quot;Dxy&amp;quot;, colnames(v)==&amp;quot;index.orig&amp;quot;]
# The c-statistic according to Dxy=2(c-0.5)
bias_corrected_c_index  &amp;lt;- abs(Dxy)/2+0.5
orig_c_index &amp;lt;- abs(Orig.Dxy)/2+0.5
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;combining-approaches-2-3-4-5-and-calculate-p-value-for-testing-two-c-indices-for-both-estimation-methods&#34;&gt;Combining Approaches &lt;sup&gt;2&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt; &amp;amp; &lt;sup&gt;4&lt;/sup&gt;&amp;frasl;&lt;sub&gt;5&lt;/sub&gt; and Calculate p-value for Testing Two C-indices for Both Estimation Methods&lt;/h2&gt;

&lt;p&gt;Did not find it elsewhere online. Hope someone could find this helpful.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Sample code:
surv &amp;lt;- Surv(survival, censor)
c_index &amp;lt;- function(group, ties=TRUE){
  fit &amp;lt;- coxph(surv ~ group, data=sample.data)
  coxPredict &amp;lt;- predict(fit, data=sample.data, type=&amp;quot;risk&amp;quot;)  
  
  # Approaches 4/5
  if (ties==F) {
  concordance.index(x=coxPredict, surv.time=survival, surv.event=censor, method=&amp;quot;noether&amp;quot;)
  }
  # Approaches 2/3
  else if (ties==T) {
  survConcordance(surv ~ coxPredict, data=sample.data)
  }
}
c_index_ties1 &amp;lt;- c_index(group=group1, ties=TRUE)
c_index_ties2 &amp;lt;- c_index(group=group2, ties=TRUE)

c_index_no_ties1 &amp;lt;- c_index_ties(group=group1, ties=F)
c_index_no_ties2 &amp;lt;- c_index_ties(group=group2, ties=F)

# p-value of testing two c-indices ignoring ties
round(cindex.comp(c_index_no_ties1, c_index_no_ties2)$p.value,3)

# Function for p-value of testing two c-indices accounting for ties
# t-test for dependent variables is used for significance 
# Input variables are objects obtained from the first function

cindex.p.ties &amp;lt;- function(c_index_ties1, c_index_ties2, c_index_no_ties1, c_index_no_ties2) {
    eps &amp;lt;- 1E-15
    n &amp;lt;- c_index_no_ties1$n
    r &amp;lt;- cor(c_index_no_ties1$data$x, c_index_no_ties2$data$x, use=&amp;quot;complete.obs&amp;quot;, method=&amp;quot;spearman&amp;quot;)
    if ((1 - abs(r)) &amp;gt; eps) {
      t.stat &amp;lt;- (c_index_ties1$concordance - c_index_ties2$concordance) / sqrt(c_index_ties1$std.err^2 + c_index_ties2$std.err^2 - 2 * r * c_index_ties1$std.err * c_index_ties2$std.err)
      diff.ci.p &amp;lt;- pt(q=t.stat, df=n - 1, lower.tail=FALSE)
    } else { diff.ci.p &amp;lt;- 1 }
    return(list(&amp;quot;p.value&amp;quot;=diff.ci.p))
  }
cindex.p.ties(c_index_ties1=c_index_ties1, c_index_ties2=c_index_ties2, c_index_no_ties1=c_index_no_ties1, c_index_no_ties2=c_index_no_ties2)
&lt;/code&gt;&lt;/pre&gt;

        
      </description>
    </item>
    
    <item>
      <title>R统计分析 </title>
      <link>/blog/cn/2017/10/r_statistics/</link>
      <pubDate>Fri, 13 Oct 2017 11:12:29 +0000</pubDate>
      
      <guid>/blog/cn/2017/10/r_statistics/</guid>
      <description>
        

&lt;script type=&#34;text/javascript&#34; src=&#34;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&#34;&gt;&lt;/script&gt;

&lt;h1 id=&#34;概率分布&#34;&gt;概率分布&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/R_probility.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;样本抽样&#34;&gt;样本抽样&lt;/h1&gt;

&lt;h4 id=&#34;1-简单随机抽样&#34;&gt;1. 简单随机抽样&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;sample(x,size,replace=FALSE,
       prob #数据被抽取的权重值)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;2-按权重的样本抽样&#34;&gt;2. 按权重的样本抽样&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;sample(1:10,5,replace=TRUE,prob=1:10)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;3-分层随机抽样&#34;&gt;3. 分层随机抽样&lt;/h4&gt;

&lt;p&gt;例如：男性占20%，女性占80%，如果通过抽样来统计组群的平均身高，性别不同会对统计结果有直接影响，因此可以根据男女性别比例采用分层抽样。&lt;/p&gt;

&lt;p&gt;分层抽样的好处是可以根据每层分别抽样不同数量的样本&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;strata(data, stratanames=NULL, size, method=c(&amp;quot;srswor&amp;quot;,&amp;quot;srswr&amp;quot;,&amp;quot;poisson&amp;quot;,
&amp;quot;systematic&amp;quot;), pik,description=FALSE)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;library(&amp;quot;sampling&amp;quot;)
x= strata(data=iris,c(&amp;quot;Species&amp;quot;),size=c(3,3,5),method=&amp;quot;srswor&amp;quot;)
getdata(iris,x)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;4-系统抽样&#34;&gt;4. 系统抽样&lt;/h4&gt;

&lt;p&gt;例如：要对从全天经过某一路口的车辆号牌进行抽样调查，如果采用简单随机抽样，早、晚高峰的经过的车辆会被过多抽取。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;系统抽样：&lt;/strong&gt;将样本总体从1~N编号，然后随机确定抽样起点，以固定间隔k=N/n进行等间隔抽样。因此如果整体数据呈现有序排列形式，系统抽样会获得更好的结果，但是周期数据将会导致偏向性。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;library(&amp;quot;doBy&amp;quot;)
sampleBy(~1,frac=.3,data=x,systematic=TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;列联表&#34;&gt;列联表&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;列联表：&lt;/strong&gt;以表格形式记录分类变量的频数。卡方独立性检验考察变量之间是否存在依存关系。&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&amp;ndash;&lt;/th&gt;
&lt;th&gt;预测-垃圾邮件&lt;/th&gt;
&lt;th&gt;预测-非垃圾邮件&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;实际-垃圾邮件&lt;/td&gt;
&lt;td&gt;a&lt;/td&gt;
&lt;td&gt;b&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;实际-非垃圾邮件&lt;/td&gt;
&lt;td&gt;c&lt;/td&gt;
&lt;td&gt;d&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&#34;创建列联表&#34;&gt;创建列联表&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;d=data.frame(x=c(&amp;quot;1&amp;quot;,&amp;quot;2&amp;quot;,&amp;quot;2&amp;quot;,&amp;quot;1&amp;quot;)),
             y=c(&amp;quot;A&amp;quot;,&amp;quot;B&amp;quot;,&amp;quot;A&amp;quot;,&amp;quot;B&amp;quot;),
             num=c(3,5,8,7)
xt=xtabs(num ~ x + y,data=d)

##边际量
margin.table(xt) 
margin.table(xt,1)#行
margin.table(xt,2)#列
##边际百分比
prop.table(xt)
prop.table(xt,1)#行
prop.table(xt,2)#列
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;独立性检验&#34;&gt;独立性检验&lt;/h1&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&amp;ndash;&lt;/th&gt;
&lt;th&gt;A-TRUE&lt;/th&gt;
&lt;th&gt;A-FALSE&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;B-TURE&lt;/td&gt;
&lt;td&gt;a&lt;/td&gt;
&lt;td&gt;b&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;B-FALSE&lt;/td&gt;
&lt;td&gt;c&lt;/td&gt;
&lt;td&gt;d&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;假设A 与 B 独立，则P(AB)=P(A)*P(B).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. 卡方检验&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;对两个变量的独立性进行检验，统计量如下：&lt;/p&gt;

&lt;p&gt;$$\sum_{i=1}^{r}\sum_{j=1}^{c}\frac{(O_{ij}-E_{ij})^2}{E_{ij}} \backsim {\chi}^2(r-1)(c-1)$$&lt;/p&gt;

&lt;p&gt;其中，\(O_{ij}\)为列联表中（i,j）的记录值，\(E_{ij}=N * P(i)* P(j)\)为两变量相互独立时单元的期望值。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(&amp;quot;MASS&amp;quot;)
data(survey)
xtabs(~Sex + Exer,data=survey)##性别和运动的列联表
##              Exer
##Sex      Freq None Some
##Female   49   11   58
##Male     65   13   40

chisq.test(xtabs(~Sex + Exer,data=survey))
##  Pearson&#39;s Chi-squared test
##data:  xtabs(~Sex + Exer, data = survey)
##X-squared = 5.7184, df = 2, p-value = 0.05731
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果：p值不具有显著性，因此不能推翻原假设H0（性别与运动独立），接受H0(原假设不是小概率事件).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/pvalue1.jpg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/pvalue2.jpg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/pvalue3.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. Fisher检验&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;针对列联表中样本数量较少，或者样本分布过分倾向某个单元，卡方检验的结果可能不准确。chisq.test()进行检验会显示警告信息。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;xtabs(~W.Hnd + Clap,data=survey)
##       Clap
##W.Hnd   Left Neither Right
##Left     9       5     4
##Right   29      45   143
chisq.test(xtabs(~W.Hnd + Clap,data=survey))
##  Pearson&#39;s Chi-squared test
##data:  xtabs(~W.Hnd + Clap, data = survey)
##X-squared = 19.252, df = 2, p-value = 6.598e-05

##Warning message:
##In chisq.test(xtabs(~W.Hnd + Clap, data = survey)) :
##  Chi-squared近似算法有可能不准

fisher.test(xtabs(~W.Hnd + Clap,data=survey))
##  Fisher&#39;s Exact Test for Count Data

##data:  xtabs(~W.Hnd + Clap, data = survey)
##p-value = 0.0001413
##alternative hypothesis: two.sided
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果：显示P值具有显著性，推翻原假设【用于写字的手与鼓掌时放在上面的手独立】（原假设为小概率事件），接受两者之间有关系。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3. McNemar检验&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;McNemar检验检验事件发生前后被调查者的反应变化，比如推行罚款政策后系安全带人数的变化。在事件之前进行问卷调查Test1,事件发生之后问卷调查Test2.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&amp;ndash;&lt;/th&gt;
&lt;th&gt;Test 2-TRUE&lt;/th&gt;
&lt;th&gt;Test 2-FALSE&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Test 1&lt;/td&gt;
&lt;td&gt;a&lt;/td&gt;
&lt;td&gt;b&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Test 1&lt;/td&gt;
&lt;td&gt;c&lt;/td&gt;
&lt;td&gt;d&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;假设事件发生前后参与调查的人数未发生变化，a+b=a+c。只要检验b=c是否成立，即可知道事件发生前后人们心理趋向是否发生变化。若b=c成立，则b服从二项分布。&lt;/p&gt;

&lt;p&gt;$$b \backsim B(b+c,\frac{1}{2})$$&lt;/p&gt;

&lt;p&gt;二项分布B(n,p)中当n (列联表中b+c)较大时，可以近视视作正态分布。&lt;/p&gt;

&lt;p&gt;$$b \backsim N(\frac{b+c}{2},\frac{b+c}{4})$$&lt;/p&gt;

&lt;p&gt;将b标准化，使之服从N(0,1),并用连续校正，得到&lt;/p&gt;

&lt;p&gt;$$\frac{(|b-c|-1)^2}{b+c} \backsim \chi^2(1)$$&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;performance=matrix(c(794,86,150,570),nrow=2,dimnames=list(
                          &amp;quot;1st survey&amp;quot;=c(&amp;quot;Approve&amp;quot;,&amp;quot;Disapprove&amp;quot;),
                          &amp;quot;2st survey&amp;quot;=c(&amp;quot;Approve&amp;quot;,&amp;quot;Disapprove&amp;quot;)))
                          
mcnemar.test(performance)

##  McNemar&#39;s Chi-squared test with continuity correction
##data:  performance
##McNemar&#39;s chi-squared = 16.818, df = 1, p-value = 4.115e-05
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果：P值结果具有显著性，原假设为小概率事件，推翻原假设，事件发生前后，&amp;rdquo;Approve&amp;rdquo;和&amp;rdquo;Disapprove&amp;rdquo;比率发生变化。&lt;/p&gt;

&lt;h1 id=&#34;拟合优度检验&#34;&gt;拟合优度检验&lt;/h1&gt;

&lt;p&gt;统计分析中，常常假设数据服从某种分布，特别是数据量超过一定数值时，一般假设数据服从正态分布。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. 卡方检验&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;为了验证数据是否服从某种特定分布，通常先要创建列联表。&lt;/p&gt;

&lt;p&gt;例如：分析用左手写字的人数与用右手写字的人数比率是否为30%：70%。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;library(&amp;quot;MASS&amp;quot;)
data(survey)
table(survey$W.Hnd)
chisq.test(table(survey$W.Hnd),p=c(0.3,0.7))

#Chi-squared test for given probabilities
#data:  table(survey$W.Hnd)
#X-squared = 56.252, df = 1, p-value = 6.376e-14
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果：p值显著，原假设为小概率事件，拒绝原假设，左手写字的人数与用右手写字的人数比率为30%：70%不成立。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. Shapiro-Wilk（夏皮罗-威尔克）检验&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Shapiro-Wilk用于检验样本是否来源于正态分布的总体&lt;/strong&gt;（样本是否从正态分布的数据中抽取的）。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; shapiro.test(rnorm(1000))
##  Shapiro-Wilk normality test
##data:  rnorm(1000)
##W = 0.99883, p-value = 0.7749
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果：p值不显著，原假设不为小概率事件，接受原假设，肯定样本来源于正态分布整体。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3. Kolmogorov-smirnov test（柯尔莫哥-斯米诺夫 K-S）检验&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;将数据的累积分布函数与要比较的分布的累积分布函数之间的&lt;strong&gt;最大距离&lt;/strong&gt;作为统计量。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/KS_test.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;例如： 检验两组正态分布的随机数据之间是否拥有相同的分布。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ks.test(rnorm(100),rnorm(100))

#   Two-sample Kolmogorov-Smirnov test
#data:  rnorm(100) and rnorm(100)
#D = 0.1, p-value = 0.6994
#alternative hypothesis: two-sided
##p值不显著，原假设不为小概率事件，接受原假设，两组样本具有相同分布。

ks.test(rnorm(100),runif(100))
#   Two-sample Kolmogorov-Smirnov test
#data:  rnorm(100) and runif(100)
#D = 0.54, p-value = 4.335e-13
#alternative hypothesis: two-sided
##p值显著，原假设为小概率事件，拒绝原假设，两组样本不具有相同分布。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;4. Q-Q（Quantile-Quantile）图&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q-Q图&lt;/strong&gt;是一种检验数据是否服从某种特定分布的可视化方法。&lt;/p&gt;

&lt;p&gt;例如：要检验X是否服从正态分布。若\(X \backsim N(\mu,\delta^2)\),则&lt;/p&gt;

&lt;p&gt;$$Z=\frac{X-\mu}{\delta} \backsim N(0,1)$$&lt;/p&gt;

&lt;p&gt;$$X=\mu + \delta Z$$&lt;/p&gt;

&lt;p&gt;若将(X,Z)绘制到坐标平面，则为一条直线。X是待检验的已知数据，Z为标准正态分布数据，因此找到与X对应的Z即可，可以通过分位数完成。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x=rnorm(1000,mean=10,sd=1)
qqnorm(x)
qqline(x,lty=2)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/Q-Qplot1.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x=runif(1000)
qqnorm(x)
qqline(x,lty=2)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;相关分析&#34;&gt;相关分析&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;1.Pearson（皮尔逊）相关系数&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/Pearsoncorrelation.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;当两个变量的标准差都不为零时，相关系数才有定义，皮尔逊相关系数适用于：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;两个变量之间是线性关系，都是连续数据。&lt;/li&gt;
&lt;li&gt;两个变量的总体是正态分布，或接近正态的单峰分布。&lt;/li&gt;
&lt;li&gt;两个变量的观测值是成对的，每对观测值之间相互独立。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;2.Spearman Rank(斯皮尔曼等级)相关系数&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;斯皮尔曼等级相关系数用来估计两个变量X、Y之间的相关性，其中变量间的相关性可以使用单调函数来描述。如果两个变量取值的两个集合中均不存在相同的两个元素，那么，当其中一个变量可以表示为另一个变量的很好的单调函数时（即两个变量的变化趋势相同），两个变量之间的ρ可以达到+1或-1。&lt;/p&gt;

&lt;p&gt;假设两个随机变量分别为X、Y（也可以看做两个集合），它们的元素个数均为N，两个随机变量取的第i（1&amp;lt;=i&amp;lt;=N）个值分别用Xi、Yi表示。对X、Y进行排序（同时为升序或降序），得到两个元素排行集合x、y，其中元素xi、yi分别为Xi在X中的排行以及Yi在Y中的排行。将集合x、y中的元素对应相减得到一个排行差分集合d，其中di=xi-yi，1&amp;lt;=i&amp;lt;=N。随机变量X、Y之间的斯皮尔曼等级相关系数可以由x、y或者d计算得到，其计算方式如下所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/SpearmanRank1.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/SpearmanRank2.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.Kendall Rank（肯德尔等级）相关系数&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;xxx&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4.相关系数检验&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;*原假设：相关系数为0&lt;/p&gt;

&lt;p&gt;*备选假设： 相关系数不为0.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;cor(iris$Sepal.Width,iris$Sepal.Length)
cor(iris[,1:4])
library(corrgram)#可视化显示相关系数
corrgram(iris,upper.panel=panel.conf)

m=matrix(c(1:10),(1:10)^2),ncol=2))
cor(m,method=&amp;quot;spearman&amp;quot;)

cor.test(c(1,2,3,4,5),c(1,0,3,4,5),method=&amp;quot;pearson&amp;quot;)
cor.test(c(1,2,3,4,5),c(1,0,3,4,5),method=&amp;quot;spearman&amp;quot;)
cor.test(c(1,2,3,4,5),c(1,0,3,4,5),method=&amp;quot;kendall&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;估计与检验&#34;&gt;估计与检验&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;1.单样本均值&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;$$\frac{\overline{X}-\mu}{S/\sqrt{n}} \backsim t(n-1)$$&lt;/p&gt;

&lt;p&gt;显著性水平为a时，关于整体均值的95%置信水平的置信区间为：&lt;/p&gt;

&lt;p&gt;$$(\overline{X} - t(n-1;\alpha/2) * S/\sqrt{n},\overline{X} + t(n-1;\alpha/2) * S/\sqrt{n}$$&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/t_test.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;零假设&lt;/strong&gt;：整体均值为mu.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;x=rnorm(30)
t.test(x)
t.test(x,mu=0)
##  One Sample t-test
##data:  x
##t = 0.052695, df = 29, p-value = 0.9583
##alternative hypothesis: true mean is not equal to 0
##95 percent confidence interval:
## -0.3502195  0.3687436
##sample estimates:
##  mean of x 
##0.009262058 

y=rnorm(30,mean=10)
t.test(y)
t.test(y,mu=10)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果： 推断整体均值为0.009262058，总体均值95%置信区间为（-0.3502195,  0.3687436）。p值不显著，不能拒绝0假设，总体均值可以被视为0，0也在95%置信区间内。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2.两独立样本均值&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;从两个总体分别抽取样本，根据样本推断两个整体均值是否一致。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/twosample_test1.jpg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/twosample_test2.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sleep2=sleep[,-3]
tapply(sleep2$extra,sleep2$group,mean)
var.test(extra ~ group,data = sleep2)##首先检验两组样本方差是否一致

##F test to compare two variances
##data:  extra by group
##F = 0.79834, num df = 9, denom df = 9, p-value = 0.7427
##alternative hypothesis: true ratio of variances is not equal to 1
##95 percent confidence interval:
##  0.198297 3.214123
##sample estimates:
##  ratio of variances 
##0.7983426 
## 原假设：两者方差无差别。因此不能拒绝原假设。

t.test(extra ~ group,data = sleep2,paired=FALSE,var.equal=TRUE)
##Two Sample t-test
##data:  extra by group
##t = -1.8608, df = 18, p-value = 0.07919
##alternative hypothesis: true difference in means is not equal to 0
##95 percent confidence interval:
##  -3.363874  0.203874
##sample estimates:
##  mean in group 1 mean in group 2 
##0.75            2.33 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;t.test中paired=FALSE表示两独立样本检验,TRUE表示配对样本检验，var.equal=TRUE表示两样本方差一致。&lt;/p&gt;

&lt;p&gt;结果：P值不显著，不能推翻原假设，因此可以认为两组总体均值无差异。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.两配对样本均值&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/twosample_test3.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;t.test(extra ~ group,data = sleep2,paired=TRUE,var.equal=TRUE)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果：P值显著，推翻原假设，服用两种安眠药后睡眠时间增加程度不同。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4.两样本方差&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;评估两独立总体的方差是否一致。两样本方差检验一般不独立使用，常配合其他检验使用，如在两独立样本检验中，如果两检验两总体方差一致，则将t.test()的var.equal设置为TRUE.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/twosample_test4.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/twosample_test5.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;5.单样本比率&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;5.两 样本比率&lt;/strong&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Logistic回归</title>
      <link>/blog/cn/2017/10/logistic/</link>
      <pubDate>Thu, 12 Oct 2017 21:06:48 +0000</pubDate>
      
      <guid>/blog/cn/2017/10/logistic/</guid>
      <description>
        

&lt;script type=&#34;text/javascript&#34; src=&#34;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&#34;&gt;&lt;/script&gt;

&lt;p&gt;原文 &lt;a href=&#34;http://blog.csdn.net/ariessurfer/article/details/41310525&#34;&gt;http://blog.csdn.net/ariessurfer/article/details/41310525&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Logistic回归为概率型非线性回归模型，是研究二分类观察结果 Y 与一些影响因素(x1,x2,..,xn)之间关系的一种多变量分析方法。通常的问题是，研究某些因素条件下某个结果是否发生，比如医学中根据病人的一些症状来判断它是否患有某种病。&lt;/p&gt;

&lt;h1 id=&#34;lr分类器-logistic-regression-classifier&#34;&gt;LR分类器: Logistic Regression Classifier&lt;/h1&gt;

&lt;p&gt;在分类情形下，经过学习后的LR分类器是一组权值\(W=(w_0,w_1,&amp;hellip;,w_n)\)，当测试样本的数据输入时，这组权值与测试数据按照线性加和得到:&lt;/p&gt;

&lt;p&gt;$$x=w_0+ w_1x_1+&amp;hellip;+w_nx_n$$&lt;/p&gt;

&lt;p&gt;之后按照&lt;strong&gt;Logistic(sigmoid函数)&lt;/strong&gt;的形式求出&lt;/p&gt;

&lt;p&gt;$$f(x)=\frac{1}{1+e^x}$$&lt;/p&gt;

&lt;p&gt;由于Logistic函数的定义域为(-inf,inf)，值域为(0,1)，因此最基本的LR分类器适合对两类目标进行分类。所以Logistic回归最关键的问题就是研究如何求得权值\(W=(w_0,w_1,&amp;hellip;,w_n)\)。用极大似然估计。&lt;/p&gt;

&lt;h1 id=&#34;logistic回归模型&#34;&gt;Logistic回归模型&lt;/h1&gt;

&lt;p&gt;Logistic回归模型可以表示为&lt;/p&gt;

&lt;p&gt;考虑具有个独立变量的向量\(X=(x_0,x_1,&amp;hellip;,x_n)\)，&lt;/p&gt;

&lt;p&gt;(1)在变量X条件下某事件发生的概率p为：&lt;/p&gt;

&lt;p&gt;$$P(y=1|x)=\pi(x)=\frac{1}{1+e^{-g(x)}}$$&lt;/p&gt;

&lt;p&gt;其中\(g(x)=w_0+ w_1x_1+&amp;hellip;+w_nx_n\)&lt;/p&gt;

&lt;p&gt;(2)在变量X条件下不发生的概率1-p为:&lt;/p&gt;

&lt;p&gt;$$P(y=0|x)=1-P(y=1|x)= 1-\frac{1}{1+e^{-g(x)}} =\frac{1}{1+e^{g(x)}} $$&lt;/p&gt;

&lt;p&gt;(3)事件的发生比（the odds of experiencing an event）:事件发生与不发生的概率之比odds&lt;/p&gt;

&lt;p&gt;$$\frac{P(y=1|x)}{P(y=0|x)}=\frac{p}{1-p} =e^{g(x)}$$&lt;/p&gt;

&lt;p&gt;$$ln(\frac{p}{1-p})=g(x)=w_0+ w_1x_1+&amp;hellip;+w_nx_n$$&lt;/p&gt;

&lt;h1 id=&#34;logistic回归极大似然估计&#34;&gt;Logistic回归极大似然估计&lt;/h1&gt;

&lt;p&gt;假设有m个观测样本\(X=(x_0,x_1,&amp;hellip;,x_m)\)，观测值分别为\(Y=(y_0,y_1,&amp;hellip;,y_m)\)，设给定条件下时间发生的概率\(p_i=P(y_i=1|x_i)\)，时间不发生的概率为\(P(y_i=0|x_i)=1-p_i\)。所以得到一个观测值的概率为&lt;/p&gt;

&lt;p&gt;$$P(y_i)=p_i^{y_i}(1-p_i)^{1-y_i}$$&lt;/p&gt;

&lt;p&gt;因为各个观测样本之间相互独立，整体事件发生的概率为各边缘分布的乘积，得到似然函数为&lt;/p&gt;

&lt;p&gt;$$L(w)=\prod_{i=1}^{m}=\{\pi(x_i)\}^{y_i}\{1-\pi(x_i)\}^{1-y_i} $$&lt;/p&gt;

&lt;p&gt;然后用极大似然估计求得权值\(W=(w_0,w_1,&amp;hellip;,w_n)\)的估计。&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>R语言-线性回归-lm()</title>
      <link>/blog/cn/2017/09/r_function_regression/</link>
      <pubDate>Fri, 22 Sep 2017 21:10:14 +0000</pubDate>
      
      <guid>/blog/cn/2017/09/r_function_regression/</guid>
      <description>
        

&lt;script type=&#34;text/javascript&#34; src=&#34;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&#34;&gt;&lt;/script&gt;

&lt;p&gt;From &lt;a href=&#34;http://blog.sina.com.cn/s/blog_6fbfcfb50102va2k.html&#34;&gt;http://blog.sina.com.cn/s/blog_6fbfcfb50102va2k.html&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;1-回归的多面性&#34;&gt;1. 回归的多面性&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;回归类型    用途
---
简单线性    个量化的解释变量来预测一个量化的响应变量（一个因变量、一个自变量）
多项式   一个量化的解释变量预测一个量化的响应变量，模型的关系是n阶多项式（一个预测变量，但同时包含变量的幂）
多元线性    用两个或多个量化的解释变量预测一个量化的响应变量（不止一个预测变量）
多变量     用一个或多个解释变量预测多个响应变量
Logistic    用一个或多个解释变量预测一个类别型变量
泊松      用一个或多个解释变量预测一个代表频数的响应变量
Cox         用一个或多个解释变量预测一个事件（死亡、失败或旧病复发）发生的时间
时间序列  对误差项相关的时间序列数据建模
非线性   用一个或多个量化的解释变量预测一个量化的响应变量，不过模型是非线性的
非参数   用一个或多个量化的解释变量预测一个量化的响应变量，模型的形式源自数据形式，不事先设定
稳健      用一个或多个量化的解释变量预测一个量化的响应变量，能抵御强影响点的干扰
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;2-用lm-拟合回归模型&#34;&gt;2. 用lm()拟合回归模型&lt;/h1&gt;

&lt;p&gt;myfit&amp;lt;-lm(formula,data)&lt;/p&gt;

&lt;p&gt;formula指要拟合的模型形式，data是一个数据框，包含了用于拟合模型的数据。&lt;/p&gt;

&lt;p&gt;formula形式如下：Y~X1+X2+……+Xk （~左边为响应变量，右边为各个预测变量，预测变量之间用+符号分隔）。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;R表达式中常用的符号&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;符号 用途
---
~  | 分隔符号，左边为响应变量，右边为解释变量，eg：要通过x、z和w预测y，代码为y~x+z+w
+  | 分隔预测变量
： | 表示预测变量的交互项  eg：要通过x、z及x与z的交互项预测y，代码为y~x+z+x:z
*  | 表示所有可能交互项的简洁方式，代码y~x*z*w可展开为y~x+z+w+x:z+x:w+z:w+x:z:w
^  | 表示交互项达到某个次数，代码y~(x+z+w)^2可展开为y~x+z+w+x:z+x:w+z:w
.  | 表示包含除因变量外的所有变量，eg：若一个数据框包含变量x、y、z和w，代码y~.可展开为y~x+z+w
-  | 减号，表示从等式中移除某个变量，eg：y~(x+z+w)^2-x:w可展开为y~x+z+w+x:z+z:w
-1 | 删除截距项，eg：表示y~x-1拟合y在x上的回归，并强制直线通过原点
I（） | 从算术的角度来解释括号中的元素。Eg：y~x+(z+w)^2将展开为y~x+z+w+z:w。相反，代码y~x+I((z+w)^2)将展开为y~x+h，h是一个由z和w的平方和创建的新变量
function | 可以在表达式中用的数学函数，例如log(y)~x+z+w表示通过x、z和w来预测log(y)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;交互项&lt;/strong&gt;是指你的几个变量一块生成了一个新的影响，比如不同性别的不同专业可能会对成绩有不同的影响，性别影响成绩，专业影响成绩，但是性别和专业和在一起又产生新影响。这时候就需要交互项。具体用不用看你的方程,一般不用。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;对拟合线性模型非常有用的其他函数&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;函数 用途
---
Summary（）展示拟合的详细结果
Coefficients（）列出拟合模型的模型参数（截距项和斜率）
confint（） 提供模型参数的置信区间（默认95%）
fitted（）列出拟合模型的预测值
residuals（）列出拟合模型的残差值
anova（）生成一个拟合模型的方差分析，或者比较两个或更多拟合模型的方差分析表
deviance() 计算残差平和和
vcov（）列出模型参数的协方差矩阵
AIC（）输出赤池信息统计量
plot（）生成评价拟合模型的诊断图
predict（）用拟合模型对新的数据集预测响应变量值
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;3-r-语言示例lm&#34;&gt;3. R 语言示例lm()&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;fit&amp;lt;-lm(weight~height,data=women)  
# summary(fit)
# Call:
# lm(formula = weight ~ height, data = women)
# Residuals:
#     Min      1Q  Median      3Q     Max 
# -1.7333 -1.1333 -0.3833  0.7417  3.1167 
# Coefficients:
#              Estimate Std. Error t value Pr(&amp;gt;|t|)    
# (Intercept) -87.51667    5.93694  -14.74 1.71e-09 ***
# height        3.45000    0.09114   37.85 1.09e-14 ***
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# Residual standard error: 1.525 on 13 degrees of freedom
# Multiple R-squared:  0.991,   Adjusted R-squared:  0.9903 
# F-statistic:  1433 on 1 and 13 DF,  p-value: 1.091e-14
coef(fit)
#(Intercept)      height 
#  -87.51667     3.45000 
fitted(fit)#拟合模型的预测值  
residuals(fit)#拟合模型的残差值 
plot(women$height,women$weight,  
     xlab=&amp;quot;Height （in inches）&amp;quot;,  
     ylab=&amp;quot;Weight（in pounds）&amp;quot;)  
abline(fit)  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;1.自变量评估&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在Pr(&amp;gt;|t|)栏，可以看到回归系数（3.45）或者截距项显著性&amp;lt;0.05，拒绝原假设，表明身高每增加1英寸，体重将预期地增加3.45磅.&lt;/p&gt;

&lt;p&gt;*原假设H0：系数（或截距）为0。&lt;/p&gt;

&lt;p&gt;*备选假设H1：系数（或截距）不为0。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2.判定系数和F统计量&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;残差的标准误(Residual standard error)&lt;/strong&gt; 1.53 lbs则可认为模型用身高预测体重的平均误差.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;判定系数R^2&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;$$R^2= \frac{SSR}{SST}=\frac{\sum(\hat{Y_i}-\overline{Y})^2}{\sum(Y_i-\overline{Y})^2} $$&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;R^2的取值范围为[0,1],越接近1表示回归模型对数据的解释能力越强。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/lm_R2.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;F统计量&lt;/strong&gt;使用F分布检验MSR/MSE的比率，原假设：β1=0，备选假设：β1≠0. 检验简化模型\(dist=β0+\varepsilon\)与完整模型\(dist=β0+β1*x +\varepsilon\)之间的残差平方和差异的显著程度。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3.方差分析&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;线性回归中，&lt;strong&gt;方差分析用于评估模型或者进行模型间比较&lt;/strong&gt;。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; m=lm(dist ~ speed, data=cars)
 summary(m)
#  Call:
# lm(formula = dist ~ speed, data = cars)
# Residuals:
#     Min      1Q  Median      3Q     Max 
# -29.069  -9.525  -2.272   9.215  43.201 
# Coefficients:
#             Estimate Std. Error t value Pr(&amp;gt;|t|)    
# (Intercept) -17.5791     6.7584  -2.601   0.0123 *  
# speed         3.9324     0.4155   9.464 1.49e-12 ***
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# Residual standard error: 15.38 on 48 degrees of freedom
# Multiple R-squared:  0.6511,  Adjusted R-squared:  0.6438 
# F-statistic: 89.57 on 1 and 48 DF,  p-value: 1.49e-12

anova(m)
# Analysis of Variance Table
# Response: dist
#           Df Sum Sq Mean Sq F value   Pr(&amp;gt;F)    
# speed      1  21186 21185.5  89.567 1.49e-12 ***
# Residuals 48  11354   236.5                     
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

reduced=lm(dist ~ 1, data=cars)  #没有自变量，仅有截距项的简化模型
anova(reduced,m)
# Analysis of Variance Table
# Model 1: dist ~ 1
# Model 2: dist ~ speed
#   Res.Df   RSS Df Sum of Sq      F   Pr(&amp;gt;F)    
# 1     49 32539                                 
# 2     48 11354  1     21186 89.567 1.49e-12 ***
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;以上3组比较F统计量中p值都为1.49e-12。表面简化模型与完整模型之间存在显著差异，换言之，speed是有意义的解释变量。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4.模型诊断图形&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  plot(m,which=c(1:3,5))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/lm_figure.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;第一个图为预测值Y（X轴）与残差（Y轴），在线性回归中，由于假设误差服从均值为0，方差固定的正态分布，所以认为残差分布与预测的Y值无关，残差均值必须为0。斜率为0的直线是理想情形。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;第二个图为正态QQ图，查看标准化的残差是否服从正态分布。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;第三个图为预测值Y（X轴）与标准化残差（Y轴），斜率为0的直线是理想情形。若在特定点观察到距离0较远的值，说明该点不能很好的拟合原始值，这些点肯能成为异常点。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;第四个图为杠杆值（X轴）与标准化残差（Y轴）。杠杆值表示解释变量向极端的偏斜程度。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;分类变量&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;m=lm(Sepal.Length ~ .,data=iris)
 summary(m)

# Call:
# lm(formula = Sepal.Length ~ ., data = iris)
# Residuals:
#      Min       1Q   Median       3Q      Max 
# -0.79424 -0.21874  0.00899  0.20255  0.73103 
# Coefficients:
#                   Estimate Std. Error t value Pr(&amp;gt;|t|)    
# (Intercept)        2.17127    0.27979   7.760 1.43e-12 ***
# Sepal.Width        0.49589    0.08607   5.761 4.87e-08 ***
# Petal.Length       0.82924    0.06853  12.101  &amp;lt; 2e-16 ***
# Petal.Width       -0.31516    0.15120  -2.084  0.03889 *  
# Speciesversicolor -0.72356    0.24017  -3.013  0.00306 ** 
# Speciesvirginica  -1.02350    0.33373  -3.067  0.00258 ** 
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# Residual standard error: 0.3068 on 144 degrees of freedom
# Multiple R-squared:  0.8673,  Adjusted R-squared:  0.8627 
# F-statistic: 188.3 on 5 and 144 DF,  p-value: &amp;lt; 2.2e-16
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中Species为分类变量，有三种类别：setosa,versicolor,virginica.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/lm_species.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;4-多项式回归&#34;&gt;4.多项式回归&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;fit2&amp;lt;-lm(weight~height+I(height^2),data=women)  
summary(fit2)
plot(women$height,women$weight,  
     xlab=&amp;quot;Height（in inches）&amp;quot;,  
     ylab=&amp;quot;Weight（in lbs）&amp;quot;)  
lines(women$height,fitted(fit2)) 

#一般来说，n次多项式生成一个n-1个弯曲的曲线
#car包中的scatterplot（）函数，可以很容易、方便地绘制二元关系图
library(car)
scatterplot(weight~height,  
            data=women,  
            spread=FALSE,  
            lty.smooth=2,  
            pch=19,  
            main=&amp;quot;Women Age 30-39&amp;quot;,  
            xlab=&amp;quot;Height (inches)&amp;quot;,  
            ylab=&amp;quot;Weight(lbs.)&amp;quot;) 
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;6-多元线性回归&#34;&gt;6.多元线性回归&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;states&amp;lt;-as.data.frame(state.x77[,c(&amp;quot;Murder&amp;quot;,&amp;quot;Population&amp;quot;,&amp;quot;Illiteracy&amp;quot;,&amp;quot;Income&amp;quot;,&amp;quot;Frost&amp;quot;)])
cor(states)  
scatterplotMatrix(states,spread=FALSE,lty.smooth=2,main=&amp;quot;Scatter Plot Matrix&amp;quot;)
#scatterplotMatrix（）函数默认在非对角线区域绘制变量间的散点图，并添加平滑（loess）和线性拟合曲线
#多元线性回归
fit&amp;lt;-lm(Murder~Population+Illiteracy+Income+Frost,data=states)  
summary(fit)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对于F统计量，原假设：所有系数β全为0。&lt;/p&gt;

&lt;h1 id=&#34;7-有交互项的多元线性回归&#34;&gt;7.有交互项的多元线性回归&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;fit&amp;lt;-lm(mpg~hp+wt+hp:wt,data=mtcars)  
summary(fit)  
# 通过effects包中的effect（）函数，可以用图形展示交互项的结果
install.packages(&amp;quot;effects&amp;quot;)  
library(effects)  
plot(effect(&amp;quot;hp:wt&amp;quot;,fit,  
            list(wt=c(2.2,3.2,4.2))),multiline=TRUE)
            
# 二次拟合诊断图
fit2&amp;lt;-lm(weight~height+I(height^2),data=women)  
par(mfrow=c(2,2))  
plot(fit2)           
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;I()&lt;/strong&gt;防止对象解析或者转换，例如I(X^2)表示以X^2作为一个独立变量参与到回归，否者则解析为x+x+x:x交互作用。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/lm_interaction.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;异常值&#34;&gt;异常值&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;学生化残差&lt;/strong&gt;： 残差与残差标准差的比值。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;外部学生化残差&lt;/strong&gt;：计算第i个学生化残差时，先去掉i再计算标准差。一般用外部学生化残差评估异常点。&lt;/p&gt;

&lt;p&gt;R中rstudent()计算外部学生化残差。外部学生化残差服从t分布，可以使用t-test来寻找rstudent()值过大或者过小的点。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;m=lm(circumference~ age+I(age^2),data=Orange)
rstudent(m)
car::outlierTest(m)

# No Studentized residuals with Bonferonni p &amp;lt; 0.05
# Largest |rstudent|:
#    rstudent unadjusted p-value Bonferonni p
# 27 2.050328            0.04887           NA

&lt;/code&gt;&lt;/pre&gt;

        
      </description>
    </item>
    
    <item>
      <title>R语言 逐步回归分析</title>
      <link>/blog/cn/2017/09/step_regression/</link>
      <pubDate>Fri, 22 Sep 2017 20:10:14 +0000</pubDate>
      
      <guid>/blog/cn/2017/09/step_regression/</guid>
      <description>
        

&lt;p&gt;From &lt;a href=&#34;http://www.cnblogs.com/liuzezhuang/p/3724497.html&#34;&gt;http://www.cnblogs.com/liuzezhuang/p/3724497.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;逐步回归分析是以AIC信息统计量为准则，通过选择最小的AIC信息统计量，来达到删除或增加变量的目的。&lt;/p&gt;

&lt;p&gt;R语言中用于逐步回归分析的函数 step()    drop1()     add1()&lt;/p&gt;

&lt;h1 id=&#34;1-载入数据&#34;&gt;1.载入数据&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#首先对数据进行多元线性回归分析
tdata&amp;lt;-data.frame(
  x1=c( 7, 1,11,11, 7,11, 3, 1, 2,21, 1,11,10),
  x2=c(26,29,56,31,52,55,71,31,54,47,40,66,68),
  x3=c( 6,15, 8, 8, 6, 9,17,22,18, 4,23, 9, 8),
  x4=c(60,52,20,47,33,22, 6,44,22,26,34,12,12),
  Y =c(78.5,74.3,104.3,87.6,95.9,109.2,102.7,72.5,
       93.1,115.9,83.8,113.3,109.4)
)
tlm&amp;lt;-lm(Y~x1+x2+x3+x4,data=tdata)
summary(tlm)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/AIC1.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;通过观察，回归方程的系数都没有通过显著性检验&lt;/p&gt;

&lt;p&gt;#2.逐步回归分析&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;tstep&amp;lt;-step(tlm)
summary(tstep)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/AIC2.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;结果分析：
* 当用x1 x2 x3 x4作为回归方程的系数时，AIC的值为26.94&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;去掉x3 回归方程的AIC值为24.974；去掉x4 回归方程的AIC值为25.011……&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;由于去x3可以使得AIC达到最小值，因此R会自动去掉x3;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;*去掉x3之后 AIC的值都增加 逐步回归分析终止,  得到当前最优的回归方程&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/AIC3.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;回归系数的显著性水平有所提高 但是x2 x4的显著性水平仍然不理想&lt;/p&gt;

&lt;p&gt;#3.逐步回归分析的优化&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;drop1(tstep)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/AIC4.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;#4.进一步进行多元回归分析&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;tlm&amp;lt;-lm(Y~x1+x2,data=tdata)
summary(tlm)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/AIC5.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;所有的检验均为显著&lt;/p&gt;

&lt;p&gt;因此所得回归方程为&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-math&#34;&gt;y=52.57735+ 1.46831x1+ 0.66225x2.
&lt;/code&gt;&lt;/pre&gt;

        
      </description>
    </item>
    
    <item>
      <title>模型选择准则之AIC和BIC</title>
      <link>/blog/cn/2017/09/aic_bic/</link>
      <pubDate>Fri, 22 Sep 2017 19:47:14 +0000</pubDate>
      
      <guid>/blog/cn/2017/09/aic_bic/</guid>
      <description>
        

&lt;p&gt;转自：&lt;a href=&#34;http://blog.csdn.net/jteng/article/details/40823675&#34;&gt;http://blog.csdn.net/jteng/article/details/40823675&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;很多参数估计问题均采用似然函数作为目标函数，当训练数据足够多时，可以不断提高模型精度，但是以提高模型复杂度为代价的，同时带来一个机器学习中非常普遍的问题——过拟合。所以，模型选择问题在模型复杂度与模型对数据集描述能力（即似然函数）之间寻求最佳平衡。
人们提出许多信息准则，通过加入模型复杂度的惩罚项来避免过拟合问题，此处我们介绍一下常用的两个模型选择方法.&lt;/p&gt;

&lt;h1 id=&#34;赤池信息准则-akaike-information-criterion-aic&#34;&gt;赤池信息准则（Akaike Information Criterion，AIC）&lt;/h1&gt;

&lt;p&gt;AIC是衡量统计模型拟合优良性的一种标准，由日本统计学家赤池弘次在1974年提出，它建立在熵的概念上，提供了权衡估计模型复杂度和拟合数据优良性的标准。
通常情况下，AIC定义为：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-math&#34;&gt;AIC=2k-2ln(L)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中k是模型参数个数，L是似然函数。从一组可供选择的模型中选择最佳模型时，通常选择AIC最小的模型。
当两个模型之间存在较大差异时，差异主要体现在似然函数项，当似然函数差异不显著时，上式第一项，即模型复杂度则起作用，从而参数个数少的模型是较好的选择。
一般而言，当模型复杂度提高（k增大）时，似然函数L也会增大，从而使AIC变小，但是k过大时，似然函数增速减缓，导致AIC增大，模型过于复杂容易造成过拟合现象。&lt;strong&gt;目标是选取AIC最小的模型&lt;/strong&gt;，AIC不仅要提高模型拟合度（极大似然），而且引入了惩罚项，使模型参数尽可能少，有助于降低过拟合的可能性。&lt;/p&gt;

&lt;h1 id=&#34;贝叶斯信息准则-bayesian-information-criterion-bic&#34;&gt;贝叶斯信息准则（Bayesian Information Criterion，BIC）&lt;/h1&gt;

&lt;p&gt;BIC（Bayesian InformationCriterion）贝叶斯信息准则与AIC相似，用于模型选择,&lt;strong&gt;BIC越小，模型越优&lt;/strong&gt;，1978年由Schwarz提出。训练模型时，增加参数数量，也就是增加模型复杂度，会增大似然函数，但是也会导致过拟合现象，针对该问题，AIC和BIC均引入了与模型参数个数相关的惩罚项，BIC的惩罚项比AIC的大，考虑了样本数量，样本数量过多时，可有效防止模型精度过高造成的模型复杂度过高。&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-math&#34;&gt;BIC=kln(n)-2ln(L)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;其中，k为模型参数个数，n为样本数量，L为似然函数。kln(n)惩罚项在维数过大且训练样本数据相对较少的情况下，可以有效避免出现维度灾难现象。&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>常见的机器学习&amp;数据挖掘知识点</title>
      <link>/blog/cn/2017/09/datamining_concept/</link>
      <pubDate>Fri, 22 Sep 2017 16:47:14 +0000</pubDate>
      
      <guid>/blog/cn/2017/09/datamining_concept/</guid>
      <description>
        

&lt;h1 id=&#34;basis-基础&#34;&gt;Basis(基础)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;SSE(Sum of Squared Error, 平方误差和)
SAE(Sum of Absolute Error, 绝对误差和)
SRE(Sum of Relative Error, 相对误差和)
MSE(Mean Squared Error, 均方误差)
RMSE(Root Mean Squared Error, 均方根误差)
RRSE(Root Relative Squared Error, 相对平方根误差)
MAE(Mean Absolute Error, 平均绝对误差)
RAE(Root Absolute Error, 平均绝对误差平方根)
MRSE(Mean Relative Square Error, 相对平均误差)
RRSE(Root Relative Squared Error, 相对平方根误差)
Expectation(期望)&amp;amp;Variance(方差)
Standard Deviation(标准差，也称Root Mean Squared Error, 均方根误差)
CP(Conditional Probability, 条件概率)
JP(Joint Probability, 联合概率)
MP(Marginal Probability, 边缘概率)
Bayesian Formula(贝叶斯公式)
CC(Correlation Coefficient, 相关系数)
Quantile (分位数)
Covariance(协方差矩阵)
GD(Gradient Descent, 梯度下降)
SGD(Stochastic Gradient Descent, 随机梯度下降)
LMS(Least Mean Squared, 最小均方)
LSM(Least Square Methods, 最小二乘法)
NE(Normal Equation, 正规方程)
MLE(Maximum Likelihood Estimation, 极大似然估计)
QP(Quadratic Programming, 二次规划)
L1 /L2 Regularization(L1/L2正则, 以及更多的, 现在比较火的L2.5正则等)
Eigenvalue(特征值)
Eigenvector(特征向量)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;common-distribution-常见分布&#34;&gt;Common Distribution(常见分布)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;Discrete Distribution(离散型分布)：
Bernoulli Distribution/Binomial Distribution(贝努利分布/二项分布)
Negative Binomial Distribution(负二项分布)
Multinomial Distribution(多项分布)
Geometric Distribution(几何分布)
Hypergeometric Distribution(超几何分布)
Poisson Distribution (泊松分布)
Continuous Distribution (连续型分布)：

Uniform Distribution(均匀分布)
Normal Distribution/Gaussian Distribution(正态分布/高斯分布)
Exponential Distribution(指数分布)
Lognormal Distribution(对数正态分布)
Gamma Distribution(Gamma分布)
Beta Distribution(Beta分布)
Dirichlet Distribution(狄利克雷分布)
Rayleigh Distribution(瑞利分布)
Cauchy Distribution(柯西分布)
Weibull Distribution (韦伯分布)
Three Sampling Distribution(三大抽样分布)：

Chi-square Distribution(卡方分布)
t-distribution(t-分布)
F-distribution(F-分布)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;data-pre-processing-数据预处理&#34;&gt;Data Pre-processing(数据预处理)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;Missing Value Imputation(缺失值填充)
Discretization(离散化)
Mapping(映射)
Normalization(归一化/标准化)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;sampling-采样&#34;&gt;Sampling(采样)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;Simple Random Sampling(简单随机采样)
Offline Sampling(离线等可能K采样)
Online Sampling(在线等可能K采样)
Ratio-based Sampling(等比例随机采样)
Acceptance-rejection Sampling(接受-拒绝采样)
Importance Sampling(重要性采样)
MCMC(Markov Chain MonteCarlo 马尔科夫蒙特卡罗采样算法：Metropolis-Hasting&amp;amp; Gibbs)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;clustering-聚类&#34;&gt;Clustering(聚类)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;K-MeansK-Mediods
二分K-Means
FK-Means
Canopy
Spectral-KMeans(谱聚类)
GMM-EM(混合高斯模型-期望最大化算法解决)
K-Pototypes
CLARANS(基于划分)
BIRCH(基于层次)
CURE(基于层次)
STING(基于网格)
CLIQUE(基于密度和基于网格)
2014年Science上的密度聚类算法等
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;clustering-effectiveness-evaluation-聚类效果评估&#34;&gt;Clustering Effectiveness Evaluation(聚类效果评估)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;Purity(纯度)
RI(Rand Index, 芮氏指标)
ARI(Adjusted Rand Index, 调整的芮氏指标)
NMI(Normalized Mutual Information, 规范化互信息)
F-meaure(F测量)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;classification-regression-分类-回归&#34;&gt;Classification&amp;amp;Regression(分类&amp;amp;回归)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;LR(Linear Regression, 线性回归)
LR(Logistic Regression, 逻辑回归)
SR(Softmax Regression, 多分类逻辑回归)
GLM(Generalized Linear Model, 广义线性模型)
RR(Ridge Regression, 岭回归/L2正则最小二乘回归)，LASSO(Least Absolute Shrinkage and Selectionator Operator , L1正则最小二乘回归)
DT(Decision Tree决策树)
RF(Random Forest, 随机森林)
GBDT(Gradient Boosting Decision Tree, 梯度下降决策树)
CART(Classification And Regression Tree 分类回归树)
KNN(K-Nearest Neighbor, K近邻)
SVM(Support Vector Machine, 支持向量机, 包括SVC(分类)&amp;amp;SVR(回归))
CBA(Classification based on Association Rule, 基于关联规则的分类)
KF(Kernel Function, 核函数) 
Polynomial Kernel Function(多项式核函数)
Guassian Kernel Function(高斯核函数)
Radial Basis Function(RBF径向基函数)
String Kernel Function 字符串核函数
NB(Naive Bayesian,朴素贝叶斯)
BN(Bayesian Network/Bayesian Belief Network/Belief Network 贝叶斯网络/贝叶斯信度网络/信念网络)
LDA(Linear Discriminant Analysis/Fisher Linear Discriminant 线性判别分析/Fisher线性判别)
EL(Ensemble Learning, 集成学习) 
Boosting
Bagging
Stacking
AdaBoost(Adaptive Boosting 自适应增强)
MEM(Maximum Entropy Model, 最大熵模型)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;classification-effectivenessevaluation-分类效果评估&#34;&gt;Classification EffectivenessEvaluation(分类效果评估)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;Confusion Matrix(混淆矩阵)
Precision(精确度)
Recall(召回率)
Accuracy(准确率)
F-score(F得分)
ROC Curve(ROC曲线)
AUC(AUC面积)
Lift Curve(Lift曲线)
KS Curve(KS曲线)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;pgm-probabilistic-graphical-models-概率图模型&#34;&gt;PGM(Probabilistic Graphical Models, 概率图模型)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;BN(BayesianNetwork/Bayesian Belief Network/ Belief Network , 贝叶斯网络/贝叶斯信度网络/信念网络)
MC(Markov Chain, 马尔科夫链)
MEM(Maximum Entropy Model, 最大熵模型)
HMM(Hidden Markov Model, 马尔科夫模型)
MEMM(Maximum Entropy Markov Model, 最大熵马尔科夫模型)
CRF(Conditional Random Field,条件随机场)
MRF(Markov Random Field, 马尔科夫随机场)
Viterbi(维特比算法)
NN(Neural Network, 神经网络)

ANN(Artificial Neural Network, 人工神经网络)
SNN(Static Neural Network, 静态神经网络)
BP(Error Back Propagation, 误差反向传播)
HN(Hopfield Network)
DNN(Dynamic Neural Network, 动态神经网络)
RNN(Recurrent Neural Network, 循环神经网络)
SRN(Simple Recurrent Network, 简单的循环神经网络)
ESN(Echo State Network, 回声状态网络)
LSTM(Long Short Term Memory, 长短记忆神经网络)
CW-RNN(Clockwork-Recurrent Neural Network, 时钟驱动循环神经网络, 2014ICML）等.
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;deep-learning-深度学习&#34;&gt;Deep Learning(深度学习)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;Auto-encoder(自动编码器)
SAE(Stacked Auto-encoders堆叠自动编码器) 
Sparse Auto-encoders(稀疏自动编码器)
Denoising Auto-encoders(去噪自动编码器)
Contractive Auto-encoders(收缩自动编码器)
RBM(Restricted Boltzmann Machine, 受限玻尔兹曼机)
DBN(Deep Belief Network, 深度信念网络)
CNN(Convolutional Neural Network, 卷积神经网络)
Word2Vec(词向量学习模型)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;dimensionality-reduction-降维&#34;&gt;Dimensionality Reduction(降维)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;LDA(Linear Discriminant Analysis/Fisher Linear Discriminant, 线性判别分析/Fish线性判别)
PCA(Principal Component Analysis, 主成分分析)
ICA(Independent Component Analysis, 独立成分分析)
SVD(Singular Value Decomposition 奇异值分解)
FA(Factor Analysis 因子分析法)
Text Mining(文本挖掘)：

VSM(Vector Space Model, 向量空间模型)
Word2Vec(词向量学习模型)
TF(Term Frequency, 词频)
TF-IDF(TermFrequency-Inverse Document Frequency, 词频-逆向文档频率)
MI(Mutual Information, 互信息)
ECE(Expected Cross Entropy, 期望交叉熵)
QEMI(二次信息熵)
IG(Information Gain, 信息增益)
IGR(Information Gain Ratio, 信息增益率)
Gini(基尼系数)
x2 Statistic(x2统计量)
TEW(Text Evidence Weight, 文本证据权)
OR(Odds Ratio, 优势率)
N-Gram Model
LSA(Latent Semantic Analysis, 潜在语义分析)
PLSA(Probabilistic Latent Semantic Analysis, 基于概率的潜在语义分析)
LDA(Latent Dirichlet Allocation, 潜在狄利克雷模型)
SLM(Statistical Language Model, 统计语言模型)
NPLM(Neural Probabilistic Language Model, 神经概率语言模型)
CBOW(Continuous Bag of Words Model, 连续词袋模型)
Skip-gram(Skip-gram Model)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;association-mining-关联挖掘&#34;&gt;Association Mining(关联挖掘)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;Apriori算法
FP-growth(Frequency Pattern Tree Growth, 频繁模式树生长算法)
MSApriori(Multi Support-based Apriori, 基于多支持度的Apriori算法)
GSpan(Graph-based Substructure Pattern Mining, 频繁子图挖掘)
Sequential Patterns Analysis(序列模式分析)

AprioriAll
Spade
GSP(Generalized Sequential Patterns, 广义序列模式)
PrefixSpan
Forecast(预测)

LR(Linear Regression, 线性回归)
SVR(Support Vector Regression, 支持向量机回归)
ARIMA(Autoregressive Integrated Moving Average Model, 自回归积分滑动平均模型)
GM(Gray Model, 灰色模型)
BPNN(BP Neural Network, 反向传播神经网络)
SRN(Simple Recurrent Network, 简单循环神经网络)
LSTM(Long Short Term Memory, 长短记忆神经网络)
CW-RNN(Clockwork Recurrent Neural Network, 时钟驱动循环神经网络)
……
Linked Analysis(链接分析)

HITS(Hyperlink-Induced Topic Search, 基于超链接的主题检索算法)
PageRank(网页排名)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;recommendation-engine-推荐引擎&#34;&gt;Recommendation Engine(推荐引擎)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;SVD
Slope One
DBR(Demographic-based Recommendation, 基于人口统计学的推荐)
CBR(Context-based Recommendation, 基于内容的推荐)
CF(Collaborative Filtering, 协同过滤)
UCF(User-based Collaborative Filtering Recommendation, 基于用户的协同过滤推荐)
ICF(Item-based Collaborative Filtering Recommendation, 基于项目的协同过滤推荐)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;similarity-measure-distance-measure-相似性与距离度量&#34;&gt;Similarity Measure&amp;amp;Distance Measure(相似性与距离度量)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;EuclideanDistance(欧式距离)
Chebyshev Distance(切比雪夫距离)
Minkowski Distance(闵可夫斯基距离)
Standardized EuclideanDistance(标准化欧氏距离)
Mahalanobis Distance(马氏距离)
Cos(Cosine, 余弦)
Hamming Distance/Edit Distance(汉明距离/编辑距离)
Jaccard Distance(杰卡德距离)
Correlation Coefficient Distance(相关系数距离)
Information Entropy(信息熵)
KL(Kullback-Leibler Divergence, KL散度/Relative Entropy, 相对熵)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;optimization-最优化&#34;&gt;Optimization(最优化)：&lt;/h1&gt;

&lt;h3 id=&#34;non-constrained-optimization-无约束优化&#34;&gt;Non-constrained Optimization(无约束优化)：&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;Cyclic Variable Methods(变量轮换法)
Variable Simplex Methods(可变单纯形法)
Newton Methods(牛顿法)
Quasi-Newton Methods(拟牛顿法)
Conjugate Gradient Methods(共轭梯度法)。
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;constrained-optimization-有约束优化&#34;&gt;Constrained Optimization(有约束优化)：&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;Approximation Programming Methods(近似规划法)
Penalty Function Methods(罚函数法)
Multiplier Methods(乘子法)。
Heuristic Algorithm(启发式算法)
SA(Simulated Annealing, 模拟退火算法)
GA(Genetic Algorithm, 遗传算法)
ACO(Ant Colony Optimization, 蚁群算法)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;feature-selection-特征选择&#34;&gt;Feature Selection(特征选择)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;Mutual Information(互信息)
Document Frequence(文档频率)
Information Gain(信息增益)
Chi-squared Test(卡方检验)
Gini(基尼系数)
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;outlier-detection-异常点检测&#34;&gt;Outlier Detection(异常点检测)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;Statistic-based(基于统计)
Density-based(基于密度)
Clustering-based(基于聚类)。
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;learning-to-rank-基于学习的排序&#34;&gt;Learning to Rank(基于学习的排序)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;Pointwise 
McRank
Pairwise 
RankingSVM
RankNet
Frank
RankBoost；
Listwise 
AdaRank
SoftRank
LamdaMART
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;tool-工具&#34;&gt;Tool(工具)：&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;MPI
Hadoop生态圈
Spark
IGraph
BSP
Weka
Mahout
Scikit-learn
PyBrain
Theano 
&lt;/code&gt;&lt;/pre&gt;

        
      </description>
    </item>
    
    <item>
      <title>SSE, MSE, RMSE, R-square</title>
      <link>/blog/cn/2017/09/sse_mse_rmse_r-square/</link>
      <pubDate>Fri, 22 Sep 2017 09:48:14 +0000</pubDate>
      
      <guid>/blog/cn/2017/09/sse_mse_rmse_r-square/</guid>
      <description>
        

&lt;pre&gt;&lt;code&gt;SSE(和方差、误差平方和)：The sum of squares due to error
MSE(均方误、方差)：Mean squared error
RMSE(均方根、标准差)：Root mean squared error
R-square(确定系数)：Coefficient of determination
Adjusted R-square：Degree-of-freedom adjusted coefficient of determination
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;sse-和方差-误差平方和&#34;&gt;SSE(和方差、误差平方和)&lt;/h1&gt;

&lt;p&gt;拟合数据和原始数据对应点的误差的平方和&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/SSE_SSE.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;SSE越接近于0，说明模型选择和拟合更好，数据预测也越成功。接下来的MSE和RMSE因为和SSE是同出一宗，所以效果一样。&lt;/p&gt;

&lt;h1 id=&#34;mse-均方误&#34;&gt;MSE(均方误)&lt;/h1&gt;

&lt;p&gt;预测数据和原始数据对应点误差的平方和的均值，也就是SSE/n，和SSE没有太大的区别，&lt;strong&gt;最常用&lt;/strong&gt;！&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/SSE_MSE.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;rmse-均方根&#34;&gt;RMSE(均方根)&lt;/h1&gt;

&lt;p&gt;回归系统的拟合标准差，是MSE的平方根，就算公式如下&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/SSE_RMSE.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;在这之前，我们所有的误差参数都是基于预测值(y&lt;em&gt;hat)和原始值(y)之间的误差(即点对点)。从下面开始是所有的误差都是相对原始数据平均值(y&lt;/em&gt;ba)而展开的(即点对全)&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;r-square-确定系数&#34;&gt;R-square(确定系数)&lt;/h1&gt;

&lt;h4 id=&#34;1-ssr-sum-of-squares-of-the-regression-即预测数据与原始数据均值之差的平方和&#34;&gt;(1)SSR：Sum of squares of the regression，即预测数据与原始数据均值之差的平方和&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/SSE_SSR.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;2-sst-total-sum-of-squares-即原始数据和均值之差的平方和&#34;&gt;(2)SST：Total sum of squares，即原始数据和均值之差的平方和&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/SSE_SST.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;SST=SSE+SSR&lt;/p&gt;

&lt;p&gt;“确定系数”是定义为SSR和SST的比值&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/SSE_R2.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;R-square是通过数据的变化来表征一个拟合的好坏。由上面的表达式可以知道“确定系数”的正常取值范围为[0 1]，越接近1，表明方程的变量对y的解释能力越强，这个模型对数据拟合的也较好。&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/MSE_RMSE.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/MAE.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>线性回归-岭回归-Lasso-弹性网-多重共线性</title>
      <link>/blog/cn/2017/09/ridgelasso/</link>
      <pubDate>Fri, 22 Sep 2017 09:47:14 +0000</pubDate>
      
      <guid>/blog/cn/2017/09/ridgelasso/</guid>
      <description>
        

&lt;p&gt;&lt;a href=&#34;http://f.dataguru.cn/thread-598486-1-1.html&#34;&gt;原文&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;1-回归问题的数学描述&#34;&gt;1. 回归问题的数学描述&lt;/h1&gt;

&lt;p&gt;1.n个样本，p个变量，X，y已知。对数据中心化、标准化处理后，可以去掉截距项。
&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM1.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;2.矩阵形式的多元线性模型为:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;求解β，使得误差项ε能达到较低.&lt;/p&gt;

&lt;p&gt;3.残差平方和RSS为&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;4.多元线性回归问题变为求解β，从而使残差平方和极小值问题（关于系数向量β的二次函数极值问题）&lt;/p&gt;

&lt;p&gt;5.几何意义&lt;/p&gt;

&lt;p&gt;残差向量的几何意义：响应y向量到由p个x向量组成的超平面的距离向量。&lt;br&gt;
残差平方和几何意义：残差向量长度的平方。&lt;/p&gt;

&lt;h1 id=&#34;2-最小二乘回归&#34;&gt;2.最小二乘回归&lt;/h1&gt;

&lt;p&gt;使用最小二乘法拟合的普通线性回归是数据建模的基本方法。其建模要点在于误差项一般要求独立同分布（常假定为正态）零均值。t检验用来检验拟合的模型系数的显著性，F检验用来检验模型的显著性（方差分析）。如果正态性不成立，t检验和F检验就没有意义。&lt;/p&gt;

&lt;p&gt;β的最小二乘估计为：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM4.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在统计学上，可证明β的最小二乘解为无偏估计，即多次得到的采样值X而计算出来的多个系数估计值向量的平均值将无限接近于真实值向量β。&lt;/p&gt;

&lt;p&gt;如果存在较强的共线性，即X中各列向量之间存在较强的相关性，会导致|X^T X|≈0, 从而引起对角线上的值很大(X^T X的逆矩阵不不存在)&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&#34;问题-x矩阵不存在广义逆-即奇异性-的情况&#34;&gt;问题： X矩阵不存在广义逆（即奇异性）的情况。&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;X本身存在线性相关关系（即多重共线性），即非满秩矩阵。当采样值误差造成本身线性相关的样本矩阵仍然可以求出逆阵时，此时的逆阵非常不稳定，所求的解也没有什么意义。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;当变量比样本多，即p&amp;gt;n时.回归系数会变得很大，无法求解。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&#34;对较复杂的数据建模-比如文本分类-图像去噪或者基因组研究-的时候-普通线性回归会有一些问题&#34;&gt;对较复杂的数据建模（比如文本分类，图像去噪或者基因组研究）的时候，普通线性回归会有一些问题：&lt;/h5&gt;

&lt;p&gt;（1）预测精度的问题 如果响应变量和预测变量之间有比较明显的线性关系，最小二乘回归会有很小的偏倚，特别是如果观测数量n远大于预测变量p时，最小二乘回归也会有较小的方差。但是如果n和p比较接近，则容易产生过拟合；如果n&amp;lt;p，最小二乘回归得不到有意义的结果。&lt;/p&gt;

&lt;p&gt;（2）模型解释能力的问题 包括在一个多元线性回归模型里的很多变量可能是和响应变量无关的；也有可能产生多重共线性的现象：即多个预测变量之间明显相关。这些情况都会增加模型的复杂程度，削弱模型的解释能力。这时候需要进行变量选择（特征选择）。&lt;/p&gt;

&lt;h4 id=&#34;针对ols-ordinary-least-squares-的问题-在变量选择方面有三种扩展的方法&#34;&gt;针对OLS (ordinary least squares)的问题，在变量选择方面有三种扩展的方法：&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;（1）子集选择 这是传统的方法，包括逐步回归和最优子集法等，对可能的部分子集拟合线性模型，利用判别准则 （如AIC,BIC,Cp,调整R2 等）决定最优的模型。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;（2）收缩方法（shrinkage method） 收缩方法又称为&lt;strong&gt;正则化（regularization）&lt;/strong&gt;。主要是岭回归（ridge regression）和lasso回归。通过对最小二乘估计加入罚约束，使某些系数的估计为0。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;(3)维数缩减 主成分回归（PCR）和偏最小二乘回归（PLS）的方法。把p个预测变量投影到m维空间（m&amp;lt;p），利用投影得到的不相关的组合建立线性模型。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;3-岭回归-ridge-regression-rr-1962&#34;&gt;3.岭回归（Ridge Regression，RR, 1962）&lt;/h1&gt;

&lt;p&gt;思路：在原先的β的最小二乘估计中加一个小扰动λI，是原先无法求广义逆的情况变成可以求出其广义逆，使得问题稳定并得以求解。&lt;/p&gt;

&lt;p&gt;极值问题：
&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM5.jpg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM6.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;对上式用偏导数求极值，结果就是&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM7.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;其中&lt;img src=&#34;...&#34; alt=&#34;&#34; /&gt;为惩罚函数，它保证了β值不会变的很大。岭参数λ不同，岭回归系数也会不同。&lt;/p&gt;

&lt;p&gt;岭回归是回归参数β的有偏估计。它的结果是使得残差平和变大，但是会使系数检验变好，即R语言summary结果中变量后的*变多。&lt;/p&gt;

&lt;p&gt;岭回归缺陷:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;1.主要靠目测选择岭参数&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;2.计算岭参数时，各种方法结果差异较大&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;所以一般认为，岭迹图只能看多重共线性，却很难做变量筛选&lt;/p&gt;

&lt;h1 id=&#34;4-几何解释&#34;&gt;4.几何解释&lt;/h1&gt;

&lt;p&gt;以两个变量为例，系数β1和β2已经经过标准化。残差平方和RSS可以表示为β1和β2的一个二次函数，数学上可以用一个抛物面表示。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;最小二乘法&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM9.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;2.岭回归&lt;/p&gt;

&lt;p&gt;约束项为 β1^2+β2^2≤t&lt;/p&gt;

&lt;p&gt;对应着投影为β1和β2平面上的一个圆，即下图中的圆柱.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM10.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;该圆柱与抛物面的交点对应的β1、β2值，即为满足约束项条件下的能取得的最小的β1和β2.&lt;/p&gt;

&lt;p&gt;从β1,β2平面理解，即为抛物面等高线在水平面的投影和圆的交点，如下图所示,可见岭回归解与原先的最小二乘解是有一定距离的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://attachbak.dataguru.cn/attachments/forum/201603/03/GLM11.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;3.岭回归性质&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/Ridge20170922104329.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;4.岭迹图&lt;/p&gt;

&lt;p&gt;岭迹图作用：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;1）观察λ较佳取值；&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;2）观察变量是否有多重共线性；&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;是λ的函数，岭迹图的横坐标为λ，纵坐标为β(λ)。而β(λ)是一个向量，由β1(λ)、β2(λ)、&amp;hellip;等很多分量组成，每一个分量都是λ的函数，将每一个分量分别用一条线。当不存在奇异性时，岭迹应是稳定地逐渐趋向于0。
&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM12.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;岭迹图比较&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/Ridge20170922154100.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;通过岭迹的形状来判断我们是否要剔除掉该参数（例如：岭迹波动很大，说明该变量参数有共线性）&lt;/p&gt;

&lt;p&gt;可见，在λ很小时，通常各β系数取值较大；而如果λ=0，则跟普通意义的多元线性回归的最小二乘解完全一样；当λ略有增大，则各β系数取值迅速减小，即从不稳定趋于稳定。上图类似喇叭形状的岭迹图，一般都存在多重共线性。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;λ的选择：一般通过观察，选取喇叭口附近的值，此时各β值已趋于稳定，但总的RSS又不是很大。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;选择变量：删除那些β取值一直趋于0的变量。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;注意：用岭迹图筛选变量并非十分靠谱。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;岭回归选择变量的原则（不靠谱，仅供参考）
* 1）在岭回归中设计矩阵X已经中心化和标准化了，这样可以直接比较标准化岭回归系数癿大小。可以剔除掉标准化岭回归系数比较稳定且值很小癿自变量。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;2）随着λ的增加，回归系数不稳定，震动趋于零的自变量也可以剔除。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;3）如果依照上述去掉变量的原则，有若干个回归系数不稳定，究竟去掉几个，去掉哪几个，这幵无一般原则可循，这需根据去掉某个变量后重新进行岭回归分析的效果来确定。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;5.岭回归R语言分析&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-R&#34;&gt;library(MASS)#岭回归在MASS包中。
longley #内置数据集，有关国民经济情况的数据，以多重共线性较强著称
summary(fm1&amp;lt;-lm(Employed~.,data=longley)) #最小二乘估计的多元线性回归
#结果可见，R^2很高，但是系数检验不是非常理想
names(longley)[1]&amp;lt;-&amp;quot;y&amp;quot;  
lm.ridge(y~.,longley)   #此时，仍为线性回归
plot(lm.ridge(y~.,longley,lambda=seq(0,0.1,0.001)))  #加了参数lambda的描述后才画出响应的岭迹图
#由于lambda趋于0时，出现了不稳定的情况，所以可以断定变量中存在多重共线性
select(lm.ridge(y~.,longley,lambda=seq(0,0.1,0.001)))  #用select函数可算lambda值，结果给出了3种方法算的的lambda的估计值

## modified HKB estimator is 0.006836982 
## modified L-W estimator is 0.05267247 
## smallest value of GCV  at 0.006 

#以上结果通常取GCV估计，或者观察大多数方法趋近哪个值。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM13.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;5-lasso&#34;&gt;5. LASSO&lt;/h1&gt;

&lt;p&gt;Tibshirani(1996)提出了Lasso(The Least Absolute Shrinkage and Selectionatoroperator)算法，这里  Absolute 指绝对值。Shrinkage收缩的含义：即系数收缩在一定区域内（比如圆内）。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;主要思想&lt;/strong&gt;：
通过构造一个一阶惩罚函数获得一个精炼的模型；通过最终确定一些指标（变量）癿系数为零（岭回归估计系数等于0癿机会微乎其微，造成筛选变量困难），解释力很强。擅长处理具有多重共线性癿数据，筛选变量，与岭回归一样是有偏估计。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM14.jpg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM15.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;几何解释&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM16.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;由于方框的顶点更容易交于抛物面，也就是lasso更易求解，而该顶点对应的很多系数为0，也就是起到了筛选变量的目的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Lasso plot&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;set.seed(101)
x=matrix(rnorm(1000),100,10)
y=rnorm(100)
fit=glmnet(x,y)

par(mfrow=c(1,3))
#par(mar=c(4.5,4.5,1,4))
##plot1
plot(fit)
vnat=coef(fit)
vnat=vnat[-1,ncol(vnat)] # remove the intercept, and get the coefficients at the end of the path
axis(4, at=vnat,line=-.5,label=paste(&amp;quot;feature&amp;quot;,1:10),las=1,tick=FALSE, cex.axis=0.5)
#plot2
plot(fit, xvar = &amp;quot;lambda&amp;quot;)
# plot3
plot(fit, xvar = &amp;quot;dev&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/lasso201710112315.jpeg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/lasso201710112315.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;6-lasso-vs-岭回归&#34;&gt;6.LASSO vs 岭回归&lt;/h1&gt;

&lt;p&gt;岭回归一方面可以将其变成一个最小二乘问题。另一方面可以将它解释成一个带约束项的系数优化问题。λ增大的过程就是t减小的过程，该图也说明了岭回归系数估计值为什么通常不为0，因为随着抛物面的扩展，它与约束圆的交点可能在圆周上的任意位置，除非交点恰好位于某个坐标轴或坐标平面上，否则大多数情况交点对应的系数值都不为零。再加上λ的选择应使椭球面和圆周的交点恰好在一个坐标平面上，更增加了求解λ的难度。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM17.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;左图为岭回归，右图为lasso回归。横轴越往左，自由度越小（即圆或方框在收缩的过程），λ越大，系数（即纵轴）会越趋于0。但是岭回归没有系数真正为0，但lasso的不断有系数变为0.&lt;/p&gt;

&lt;h1 id=&#34;7-一般化的模型&#34;&gt;7.一般化的模型&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM18.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;不同q对应的约束域形状&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM19.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;8-弹性网模型&#34;&gt;8.弹性网模型&lt;/h1&gt;

&lt;p&gt;Zouand Hastie (2005)提出elasticnet，介于岭回归和lasso回归之间，现在被认为是处理多重共线性和变量筛选较好的收缩方法，而且损失的精度不会太多。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM20.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;9-最小角回归-least-angel-regression-是lasso-regression癿一种高效解法&#34;&gt;9.最小角回归(Least Angel Regression)是lasso regression癿一种高效解法。&lt;/h1&gt;

&lt;p&gt;Lasso回归中表达式用偏导求极值时，存在部分点不可导的情况（如方框的尖点），如何解决？&lt;/p&gt;

&lt;p&gt;Efron于2004年提出癿一种变量选择癿方法，&lt;strong&gt;类似于&lt;/strong&gt;向前逐步回归(Forward Stepwise)的形式，最初用于解决传统的线性回归问题，有清晰的几何意义。&lt;/p&gt;

&lt;p&gt;与向前逐步回归(Forward Stepwise)不同点在于，Forward Step wise 每次都是根据选择的变量子集，完全拟合出线性模型，计算出RSS，再设计统计量（如AIC）对较高癿模型复杂度作出惩罚，而LAR是每次先找出和因变量相关度较高的那个变量, 再沿着LSE的方向一点点调整这个predictor的系数，在这个过程中，这个变量和残差的相关系数会逐渐减小，等到这个相关性没那么显著的时候，就要选进新的相关性较高的变量，然后重新沿着LSE的方向进行变动。而到最后，所有变量都被选中，就和LSE相同了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM21.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;左图为LAR逐步加上变量的过程（从左往右看），右图为LASSO变量逐渐淘汰的收缩过程（从右往左看）。
对比两幅图，非常类似。所以可以用LAR方法来计算LASSO，该方法完全是线性解决方法，没有迭代的过程。&lt;/p&gt;

&lt;h1 id=&#34;10-相关系数的几何意义&#34;&gt;10. 相关系数的几何意义&lt;/h1&gt;

&lt;p&gt;设变量y=[y1,y2,&amp;hellip;yn]; 变量x=[x1,x2,&amp;hellip;,xn].&lt;/p&gt;

&lt;p&gt;其相关系数为&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM22.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;其中cov&amp;ndash;协方差、var&amp;mdash;方差。&lt;/p&gt;

&lt;p&gt;如果对x和y进行中心化、标准化，则var(y)=var(x)=1,相关系数变为x1y1+x2y2+&amp;hellip;.+xnyn，即为向量x和y的内积=||x||&lt;em&gt;||y||&lt;/em&gt;cos θ，其中θ为x和y的夹角。而对于标准化和中心化后的x和y，则有||x||=||y||=1，所以此时x和y的内积就是它们夹角的余弦。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;如果x和y向量很像，几乎重合，则夹角θ=0，也就是相关系数=内积=1，此时称为高度相关.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如果x和y相关程度很低，则表现出来的x和y向量相互垂直，相关系数=0.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;如果相关系数=-1，标明x和y呈180°，即负相关。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;11-lar算法及几何意义&#34;&gt;11. LAR算法及几何意义&lt;/h1&gt;

&lt;p&gt;参考书The Elements of Statistical Learning .pdf的74页。LAR和Lasso的区别以及LAR解Lasso的修正
参考书The Elements of Statistical Learning .pdf的76页。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GLM23.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;假设有6个变量，最先加入与残差向量相关系数较大的浅蓝色v2，在v2变化过程中，相关系数越变越小，直到等于深蓝色的v6，于是加入v6，沿着v2与v6的最小角方向（即向量角分线方向）前进，此后v2和v6与残差向量的相关系数是共同变化的，即两者合并变化，使得相关系数越来越小，直到加入黑色v4为止，三个变量一起变化，&amp;hellip;，一直打到最小二乘解为止，此时残差向量与所有变量的相关系数都为0，即与他们都垂直。&lt;/p&gt;

&lt;p&gt;横坐标L1 Length表示：从原点开始走了多长距离，就是值距离，L1范数。&lt;/p&gt;

&lt;h1 id=&#34;12-r语言中对lar的实现&#34;&gt;12. R语言中对LAR的实现&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-R&#34;&gt;install.packages(&amp;quot;lars&amp;quot;)  #lars包
longley  #用longley数据集，它是一个著名的多重共线性例子
w=as.matrix(longley)  #将数据集转换为一个矩阵

laa=lars(w[,2:7],w[,1]) #w的2:7列为自变量，第1列为因变量
laa  #显示LAR回归过程

##Call:
##lars(x = w[, 2:7], y = w[, 1])
##R-squared: 0.993 
##Sequence of LASSO moves:
##     GNP Year Armed.Forces Unemployed Employed Population Year Employed   Employed Year Employed Employed
##Var    1    5            3                   2                   6           4          -5           -6            6             5  -6        6                                                 
##Step  1    2            3                   4                   5           6           7          8             9             10  11       12 


plot(laa)  #画lasso回归过程图
summary(laa)

#以上结果显示了每一步的残差平方和RSS和多重共线性指标Cp（Mallows&#39;s Cp http://en.wikipedia.org/wiki/Mallows%27_Cp）
#Cp越小，多重共线性越小，因此结果以第八步为准，即只剩下第1、2、3、4个变量
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;13-glmnet包&#34;&gt;13.glmnet包&lt;/h1&gt;

&lt;p&gt;From &lt;a href=&#34;https://site.douban.com/182577/widget/notes/10567212/note/289294468/&#34;&gt;https://site.douban.com/182577/widget/notes/10567212/note/289294468/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;glmnet包是关于Lasso and elastic-net regularized generalized linear models。 作者是Friedman, J., Hastie, T. and Tibshirani, R这三位。&lt;/p&gt;

&lt;p&gt;这个包采用的算法是循环坐标下降法（cyclical coordinate descent），处理的模型包括 linear regression,logistic and multinomial regression models, poisson regression 和 the Cox model，用到的正则化方法就是l1范数（lasso）、l2范数（岭回归）和它们的混合 （elastic net）。&lt;/p&gt;

&lt;p&gt;坐标下降法是关于lasso的一种快速计算方法（是目前关于lasso最快的计算方法），其基本要点为： 对每一个参数在保持其它参数固定的情况下进行优化，循环，直到系数稳定为止。这个计算是在lambda的格点值上进行的。 关于这个算法见[5]。 关于glmnet包的细节可参考[4]，这篇文献同时也是关于lasso的一个不错的文献导读。&lt;/p&gt;

&lt;p&gt;[1]Tibshirani, R.: Regression shrinkage and selection via the LASSO. Journal of the Royal Statistical Society: Series B, Vol. 58 (1996), No 1, 267–288&lt;/p&gt;

&lt;p&gt;[2]Efron, B., Johnstone, I., Hastie, T., and Tibshirani, R.: Least angle regression. Annals of Statistics, Vol. 32 (2004), No 2, 407–499.&lt;/p&gt;

&lt;p&gt;[3]Hastie, T., Tibshirani, R., and Friedman, J.: The Elements of Statistical Learning: Data Mining, Inference and Prediction. Second edition. New York: Springer, 2009.&lt;/p&gt;

&lt;p&gt;[4]Friedman,J.,Hastie,T.,Tibshirani.R.:Regularization Paths for Generalized Linear Models via Coordinate Descent.Journal of Statistical Software,Volume 33(2010), Issue 1.&lt;/p&gt;

&lt;p&gt;[5]J. Friedman, T. Hastie, H. Hoe ing, and R. Tibshirani.:Pathwise coordinate optimization. Annals of Applied Statistics, 2(1):302-332, 2007. &lt;a href=&#34;http://www.stanford.edu/~hastie/Papers/pathwise.pdf&#34;&gt;http://www.stanford.edu/~hastie/Papers/pathwise.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[6]Trevor Hastie,Sparse Linear Models:with demonstrations using glmnet.2013.&lt;/p&gt;

&lt;p&gt;[7] Zou, Hui &amp;amp; Trevor Hastie (2005): Regularization and variable selection via the Elastic Net, JRSS (B)67(2):301-320)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(glmnet)
prostate=read.csv(url(&amp;quot;https://taoshengxu.github.io/DocumentGit/data/prostate.csv&amp;quot;))
prostate=prostate[,c(1,3,4,6,7,9)]
head(prostate)
x &amp;lt;- as.matrix(prostate[, 2:6])
y &amp;lt;- prostate[, 1]
set.seed(1)
train &amp;lt;- sample(1:nrow(x), nrow(x) * 2/3)
test &amp;lt;- (-train)

## 1. Ridge Regression
r1 &amp;lt;- glmnet(x = x[train, ], y = y[train], family = &amp;quot;gaussian&amp;quot;, alpha = 0)
plot(r1, xvar = &amp;quot;lambda&amp;quot;)

r1.cv &amp;lt;- cv.glmnet(x = x, y = y, family = &amp;quot;gaussian&amp;quot;, alpha = 0, nfold = 10)
plot(r1.cv)

mte &amp;lt;- predict(r1, x[test, ])
mte &amp;lt;- apply((mte - y[test])^2, 2, mean)
points(log(r1$lambda), mte, col = &amp;quot;blue&amp;quot;, pch = 19)
legend(&amp;quot;topleft&amp;quot;, legend = c(&amp;quot;10 - fold CV&amp;quot;, &amp;quot;Test&amp;quot;), col = c(&amp;quot;red&amp;quot;, &amp;quot;blue&amp;quot;))

r1.min &amp;lt;- glmnet(x = x, y = y, family = &amp;quot;gaussian&amp;quot;, alpha = 0, lambda = r1.cv$lambda.min)
coef(r1.min)

##2. Lasso

r2 &amp;lt;- glmnet(x = x[train, ], y = y[train], family = &amp;quot;gaussian&amp;quot;, alpha = 1)
plot(r2)
plot(r2, xvar = &amp;quot;lambda&amp;quot;)

r2.cv &amp;lt;- cv.glmnet(x = x, y = y, family = &amp;quot;gaussian&amp;quot;, alpha = 1, nfold = 10)
plot(r2.cv)

mte &amp;lt;- predict(r2, x[test, ])
mte &amp;lt;- apply((mte - y[test])^2, 2, mean)
points(log(r2$lambda), mte, col = &amp;quot;blue&amp;quot;, pch = 19)
legend(&amp;quot;topleft&amp;quot;, legend = c(&amp;quot;10 - fold CV&amp;quot;, &amp;quot;Test&amp;quot;), col = c(&amp;quot;red&amp;quot;, &amp;quot;blue&amp;quot;))

# cv.min vs cv.1se,用全部数据再次拟合模型
r2.cv$lambda.min
## [1] 0.002954
r2.cv$lambda.1se
## [1] 0.1771

r2.1se &amp;lt;- glmnet(x = x, y = y, family = &amp;quot;gaussian&amp;quot;, alpha = 1, lambda = r2.cv$lambda.1se)
coef(r2.1se)
## 6 x 1 sparse Matrix of class &amp;quot;dgCMatrix&amp;quot;
## s0
## (Intercept) 0.3234
## age . 
## lbph . 
## lcp 0.2462
## gleason . 
## lpsa 0.4320
r2.min &amp;lt;- glmnet(x = x, y = y, family = &amp;quot;gaussian&amp;quot;, alpha = 1, lambda = r2.cv$lambda.min)
coef(r2.min)
## 6 x 1 sparse Matrix of class &amp;quot;dgCMatrix&amp;quot;
## s0
## (Intercept) -1.44505
## age 0.01851
## lbph -0.08585
## lcp 0.29688
## gleason 0.05081
## lpsa 0.53741

# 岭回归和lasso的比较
lasso.pred &amp;lt;- predict(r2, s = r2.cv$lambda.1se, newx = x[test, ])
ridge.pred &amp;lt;- predict(r1, s = r1.cv$lambda.1se, newx = x[test, ])
mean((lasso.pred - y[test])^2)
## [1] 0.3946
mean((ridge.pred - y[test])^2)
## [1] 0.4239

&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;关于glmnet包的使用&#34;&gt;关于glmnet包的使用&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;(1)glment（）和cv.glmnet()&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;第一次用这个包的时候，我有个很蠢的问题，为什么有了cv.glmnet()还需要保留glmnet（）呢？ cv.glmnet()可以通过交叉验证得到（关于lambda的）最优的方程，但是就glment包来说仍然不是一个完美的结果，关于alpha的交叉验证依然需要使用者自己来完成（包的文档中给了点提示）。glmnet（）仍然需要保留，因为可以得到正则化的路径，因为算法的原因，coordinate descent 在选取极值上有随机性，路径在变量的选择中还是很重要的。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;(2)cv.glmnet() 中的lambda.min和lambda.1se&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;lambda.min:   value of lambda that gives minimum cvm.&lt;/p&gt;

&lt;p&gt;lambda.1se:   largest value of lambda such that error is within 1 standard error of the minimum.&lt;/p&gt;

&lt;p&gt;关于这两个输出值的使用，似乎有点混乱。看了很多网上的讨论推荐使用lambda.1se的比较多，这样可以得到更简洁的模型。 涉及到所谓的1-SE rule。 “one standard error” rule to select the best model, i.e. selecting the most parsimonious model from the subset of models whose score is within one standard error of the best score.但是还有这样的说法：1se rule在低noise的时候才好用高noise的时候，有一两个fold的error很大，cv curve就会增长很快，导致选的lambda太大。&lt;/p&gt;

&lt;h1 id=&#34;14-glmnet-vignettes-非常易读-有益理解&#34;&gt;14.glmnet Vignettes 非常易读，有益理解&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/glmnet/vignettes/glmnet_beta.pdf&#34;&gt;https://cran.r-project.org/web/packages/glmnet/vignettes/glmnet_beta.pdf&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/glmnet/vignettes/Coxnet.pdf&#34;&gt;https://cran.r-project.org/web/packages/glmnet/vignettes/Coxnet.pdf&lt;/a&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Cox 分层原理</title>
      <link>/blog/cn/2017/09/coxstratified/</link>
      <pubDate>Wed, 13 Sep 2017 12:43:10 +0000</pubDate>
      
      <guid>/blog/cn/2017/09/coxstratified/</guid>
      <description>
        

&lt;p&gt;&lt;a href=&#34;https://taoshengxu.github.io/DocumentGit/pdf/Cox+Stratified.pdf&#34;&gt;PPT&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;首先理解为什么cox模型会对协变量分层处理&#34;&gt;首先理解为什么COX模型会对协变量分层处理？&lt;/h1&gt;

&lt;p&gt;需要分层的变量不满足PH假设，需要分层处理。&lt;/p&gt;

&lt;h1 id=&#34;如何确定-协变量不满足ph假设&#34;&gt;如何确定 协变量不满足PH假设？&lt;/h1&gt;

&lt;p&gt;首先对需要研究的协变量进行多协变量COX回归，挑出不满足PH假设的协变量&lt;/p&gt;

&lt;h1 id=&#34;cross-validated-partial-likelihood-cvpl-for-the-cox-model&#34;&gt;Cross-validated partial likelihood (CVPL) for the Cox model&lt;/h1&gt;

&lt;p&gt;cvpl {in Package survcomp} function&lt;/p&gt;

&lt;h1 id=&#34;toc_3&#34;&gt;&amp;hellip;&lt;/h1&gt;

&lt;p&gt;如果得到一个Subtypes 信息，对subtype分层进行 协变量为 age的COX 回归。目的是研究在不同亚型内，age 是否为影响生存预后的重要因素。&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>混淆矩阵(Confusion matrix)-ROC曲线-AUC(Area under Curve)</title>
      <link>/blog/cn/2017/09/confusionmatrix/</link>
      <pubDate>Sun, 10 Sep 2017 03:11:14 +0000</pubDate>
      
      <guid>/blog/cn/2017/09/confusionmatrix/</guid>
      <description>
        

&lt;p&gt;混淆矩阵（confusion matrix）是可视化工具，特别用于监督学习， &lt;em&gt;在无监督学习一般叫做匹配矩阵&lt;/em&gt; 。在图像精度评价中，主要用于比较分类结果和实际测得值，可以把分类结果的精度显示在一个混淆矩阵里面。混淆矩阵是通过将每个实测像元的位置和分类与分类图像中的相应位置和分类像比较计算的。&lt;/p&gt;

&lt;p&gt;混淆矩阵的每一列代表了预测类别[1]  ，每一列的总数表示预测为该类别的数据的数目；每一行代表了数据的真实归属类别[1]  ，每一行的数据总数表示该类别的数据实例的数目。每一列中的数值表示真实数据被预测为该类的数目：如下图，第一行第一列中的43表示有43个实际归属第一类的实例被预测为第一类，同理，第二行第一列的2表示有2个实际归属为第二类的实例被错误预测为第一类。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;如有150个样本数据，这些数据分成3类，每类50个。分类结束后得到的混淆矩阵为：
                   预测
              类1 类2 类3
      类1     43   5   2
实际  类2      2   45  3
      类3     0    1   49
每一行之和为50，表示50个样本，
第一行说明类1的50个样本有43个分类正确，5个错分为类2，2个错分为类3
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;另外一个例子 From:&lt;a href=&#34;http://blog.csdn.net/vesper305/article/details/44927047&#34;&gt;http://blog.csdn.net/vesper305/article/details/44927047&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;假设有一个用来对猫（cats）、狗（dogs）、兔子（rabbits）进行分类的系统，混淆矩阵就是为了进一步分析性能而对该算法测试结果做出的总结。假设总共有 27 只动物：8只猫， 6条狗， 13只兔子。结果的混淆矩阵如下图：
&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/confusionmatrix0.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在这个混淆矩阵中，实际有 8只猫，但是系统将其中3只预测成了狗；对于 6条狗，其中有 1条被预测成了兔子，2条被预测成了猫。从混淆矩阵中我们可以看出系统对于区分猫和狗存在一些问题，但是区分兔子和其他动物的效果还是不错的。所有正确的预测结果都在对角线上，所以从混淆矩阵中可以很方便直观的看出哪里有错误，因为他们呈现在对角线外面。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/confusionmatrix1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在预测分析中，混淆表格（有时候也称为混淆矩阵），是由false positives，false negatives，true positives和true negatives组成的两行两列的表格。它允许我们做出更多的分析，而不仅仅是局限在正确率。准确率对于分类器的性能分析来说，并不是一个很好地衡量指标，因为如果数据集不平衡（每一类的数据样本数量相差太大），很可能会出现误导性的结果。例如，如果在一个数据集中有95只猫，但是只有5条狗，那么某些分类器很可能偏向于将所有的样本预测成猫。整体准确率为95%，但是实际上该分类器对猫的识别率是100%，而对狗的识别率是0%。&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;下面内容总结了假设检验的重要内容，清晰全面。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/confusionmatrix2.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/confusionmatrix3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;roc-曲线&#34;&gt;ROC 曲线&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;为什么使用Roc和Auc评价分类器&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;ROC曲线和AUC常被用来评价一个二值分类器（binary classifier）的优劣。既然已经这么多标准，为什么还要使用ROC和AUC呢？因为ROC曲线有个很好的特性：当测试集中的正负样本的分布变换的时候，ROC曲线能够保持不变。在实际的数据集中经常会出现样本类不平衡，即正负样本比例差距较大，而且测试数据中的正负样本也可能随着时间变化。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ROC曲线&lt;/strong&gt;：接收者操作特征(receiveroperating characteristic),roc曲线上每个点反映着对同一信号刺激的感受性。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;横轴：负正类率(false postive rate FPR)，划分实例中所有负例占所有负例的比例；(1-Specificity)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;纵轴：真正类率(true postive rate TPR)，Sensitivity(灵敏度)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对于一个二分类问题，假设采用逻辑回归分类器，其给出针对每个实例为正类的概率，那么通过设定一个阈值如0.6，概率大于等于0.6的为正类，小于0.6的为负类。对应的就可以算出一组(FPR,TPR),在平面中得到对应坐标点。&lt;strong&gt;随着阈值的逐渐减小，越来越多的实例被划分为正类，但是这些正类中同样也掺杂着真正的负实例，即TPR和FPR会同时增大。阈值最大时，对应坐标点为(0,0),阈值最小时，对应坐标点(1,1)&lt;/strong&gt;。通过调节不同的阀值，从而得到一条曲线。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/ROC.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;横轴FPR:1-TNR,1-Specificity，FPR越大，预测正类中实际负类越多。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;纵轴TPR：Sensitivity(正类覆盖率),TPR越大，预测正类中实际正类越多。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;理想目标：TPR=1，FPR=0,即图中(0,1)点，故ROC曲线越靠拢(0,1)点，越偏离45度对角线越好，Sensitivity、Specificity越大效果越好。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;auc-area-under-curve&#34;&gt;AUC(Area under Curve)&lt;/h1&gt;

&lt;p&gt;Roc曲线下的面积，介于0.5和1之间。Auc作为数值可以直观的评价分类器的好坏，值越大越好。&lt;/p&gt;

&lt;h1 id=&#34;r&#34;&gt;R&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;library(&amp;quot;pROC&amp;quot;)
data(aSAH)  
# Build a ROC object and compute the AUC, draw ROC, print AUC and the best THRESHOLDS  
roc(aSAH$outcome, aSAH$s100b, plot=TRUE, print.thres=TRUE, print.auc=TRUE)  

roc1 &amp;lt;- plot.roc(aSAH$outcome, aSAH$s100, main=&amp;quot;Statistical comparison&amp;quot;, percent=TRUE, col=&amp;quot;1&amp;quot;)
roc2 &amp;lt;- lines.roc(aSAH$outcome, aSAH$ndka, percent=TRUE, col=&amp;quot;2&amp;quot;)
testobj&amp;lt;- roc.test(roc1,roc2)
text(50, 50, labels=paste(&amp;quot;p-value =&amp;quot;, format.pval(testobj$p.value)), adj=c(0, .5))
legend(&amp;quot;bottomright&amp;quot;, legend=c(&amp;quot;S100B&amp;quot;, &amp;quot;NDKA&amp;quot;), col=c(&amp;quot;1&amp;quot;, &amp;quot;2&amp;quot;), lwd=2)

r1=roc(vs~wt,mtcars)
plot.roc(r1)
r2=roc(vs~mpg,mtcars)
lines.roc(r2,col=&#39;2&#39;)
roc.test(r1,r2)
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;在学习&lt;a href=&#34;http://bioconductor.org/packages/release/bioc/vignettes/genefu/inst/doc/genefu.pdf&#34;&gt;genefu包&lt;/a&gt;时候遇到Confusion Matrix，有必要有个系统的学习和总结。&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Fold Change 与火山图</title>
      <link>/blog/cn/2017/09/foldchange/</link>
      <pubDate>Sat, 09 Sep 2017 10:19:35 +0000</pubDate>
      
      <guid>/blog/cn/2017/09/foldchange/</guid>
      <description>
        

&lt;h1 id=&#34;fold-change&#34;&gt;Fold Change&lt;/h1&gt;

&lt;p&gt;计算公式：样本平均值log2还原的比值&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/fold_change.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;火山图-volcano-plot&#34;&gt;火山图（Volcano Plot）&lt;/h1&gt;

&lt;p&gt;火山图只存在于两分组样本比较中，并且有生物学重复(经过相同方式处理的相同样品)
&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/volcanoplot.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;标准的火山图常用于展示显著差异表达的基因，这里有两个关键词：显著是指P&amp;lt;&amp;gt;差异表达一般我们按照Fold Change(倍数变化)&amp;gt;=2.0作为标准。&lt;/p&gt;

&lt;p&gt;当我们拿到基因表达的P值和倍数后，为了用火山图展示结果，一般需要把倍数进行Log2的转化，比如某基因在实验组表达水平是对照组的4倍，log2（4）=2，同样的如果是1/4，也就是0.25，转换后的结果就是-2。&lt;/p&gt;

&lt;p&gt;同样的道理，对P值进行-log10的转化，-log10（0.05）约等于1.30103，由于P值越小表示越显著，所以我们进行-log10（P value）转化后，转化值越大表示差异约显著，比如-log10（0.001）=3  &amp;gt;  -log10(0.01)=2 &amp;gt;  -log10(0.05)=1.30。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/volcanoplot1.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;在上面这个图中，横轴是log2（FC），纵轴是-log10（P value），每个点代表一个基因，平行于Y轴的两条线分别是X=1和X=-1，在X=-1左侧的点是下调2倍以上的基因，在X=1右侧的点是上调2倍以上的基因。同时，平行于X轴有一条虚线Y=1.30，即-log10(0.05），在虚线以上的点表示显著性.&lt;/p&gt;

&lt;p&gt;这样，我们就把虚线Y=1.30以上，X=1右侧和X=-1左侧的基因标记为表达显著差异的基因，一般我们把大于2倍（X=1右侧）的点标记为红色，把小于-2（X=-1左侧）的点标记为绿色，一些我们特别关注的基因需要把基因名标记出来。&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>GCBI 学院</title>
      <link>/blog/cn/2017/09/gcbiaccdemy/</link>
      <pubDate>Sat, 09 Sep 2017 09:19:35 +0000</pubDate>
      
      <guid>/blog/cn/2017/09/gcbiaccdemy/</guid>
      <description>
        &lt;p&gt;GCBI学院里一些视频还是值得看看的,一直想看看一直忘记，记录在这里。 &lt;a href=&#34;http://college.gcbi.com.cn/&#34;&gt;Here&lt;/a&gt;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>ExpressionSet简单讲解</title>
      <link>/blog/cn/2017/09/expressionset/</link>
      <pubDate>Fri, 08 Sep 2017 16:38:17 +0000</pubDate>
      
      <guid>/blog/cn/2017/09/expressionset/</guid>
      <description>
        

&lt;p&gt;From 生信菜鸟团&lt;/p&gt;

&lt;hr /&gt;

&lt;blockquote&gt;
&lt;p&gt;这个对象其实是对表达矩阵加上样本分组信息的一个封装，由biobase这个包引入。它是eSet这个对象的继承。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;一个现成例子&#34;&gt;一个现成例子&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;下面是一个具体的例子，来源于CLL这个包，是用hgu95av2芯片测了22个样本&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-R&#34;&gt;    library(CLL)
    data(sCLLex)
    sCLLex
    
    ExpressionSet (storageMode: lockedEnvironment)
    assayData: 12625 features, 22 samples  ##表达矩阵
      element names: exprs 
    protocolData: none
    phenoData
      sampleNames: CLL11.CEL CLL12.CEL ... CLL9.CEL (22 total)
      varLabels: SampleID Disease   ## 样本分组信息
      varMetadata: labelDescription
    featureData: none
    experimentData: use &#39;experimentData(object)&#39;
    Annotation: hgu95av2
    
    &amp;gt; exprMatrix=exprs(sCLLex)
    &amp;gt; dim(exprMatrix)
    [1] 12625    22
    &amp;gt; meta=pData(sCLLex)
    &amp;gt; table(meta$Disease)
    
    progres.   stable 
          14        8 
    &amp;gt; 
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;根据上面的信息可以看出该芯片共12625个探针，这22个样本根据疾病状态分成两组，14vs8
这个数据对象就可以打包做很多包的分析输入数据。
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;对这个包的分析，重点就是 &lt;strong&gt;&lt;code&gt;exprs&lt;/code&gt; 函数提取表达矩阵&lt;/strong&gt;，&lt;strong&gt;&lt;code&gt;pData&lt;/code&gt; 函数看看该对象的样本分组信息&lt;/strong&gt;。&lt;/p&gt;

&lt;h2 id=&#34;limma等包使用该对象作为输入数据&#34;&gt;limma等包使用该对象作为输入数据&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;下面这个例子充分说明了 &lt;code&gt;ExpressionSet&lt;/code&gt; 对象的重要性&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-R&#34;&gt;    &amp;gt; library(limma)
    &amp;gt; design=model.matrix(~factor(sCLLex$Disease))
    &amp;gt; fit=lmFit(sCLLex,design)
    &amp;gt; fit=eBayes(fit)
    &amp;gt; options(digits = 4)
    &amp;gt; topTable(fit,coef=2,adjust=&#39;BH&#39;)
               logFC AveExpr      t   P.Value adj.P.Val     B
    39400_at  1.0285   5.621  5.836 8.341e-06   0.03344 3.234
    36131_at -0.9888   9.954 -5.772 9.668e-06   0.03344 3.117
    33791_at -1.8302   6.951 -5.736 1.049e-05   0.03344 3.052
    1303_at   1.3836   4.463  5.732 1.060e-05   0.03344 3.044
    36122_at -0.7801   7.260 -5.141 4.206e-05   0.10619 1.935
    36939_at -2.5472   6.915 -5.038 5.362e-05   0.11283 1.737
    41398_at  0.5187   7.602  4.879 7.824e-05   0.11520 1.428
    32599_at  0.8544   5.746  4.859 8.207e-05   0.11520 1.389
    36129_at  0.9161   8.209  4.859 8.212e-05   0.11520 1.389
    37636_at -1.6868   5.697 -4.804 9.355e-05   0.11811 1.282
    &amp;gt; 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;还有非常多的其它包会使用 &lt;code&gt;ExpressionSet&lt;/code&gt; 对象，我就不一一介绍了。&lt;/p&gt;

&lt;h2 id=&#34;自己构造-expressionset-对象&#34;&gt;自己构造 &lt;code&gt;ExpressionSet&lt;/code&gt; 对象&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;根据上面的讲解，我们知道了在这个对象其实很简单，就是对表达矩阵加上样本分组信息的一个封装。
所以我们就用上面得到的exprMatrix和meta来构建一个ExpressionSet对象，biobase包里面提供了详细的说明,建议大家仔细看官方手册&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-R&#34;&gt;    metadata &amp;lt;- data.frame(labelDescription=c(&#39;SampleID&#39;, &#39;Disease&#39;),
                       row.names=c(&#39;SampleID&#39;, &#39;Disease&#39;))
    phenoData &amp;lt;- new(&amp;quot;AnnotatedDataFrame&amp;quot;,data=meta,varMetadata=metadata)
    myExpressionSet &amp;lt;- ExpressionSet(assayData=exprMatrix,
                                     phenoData=phenoData,
                                     annotation=&amp;quot;hgu95av2&amp;quot;)
    &amp;gt; myExpressionSet
    ExpressionSet (storageMode: lockedEnvironment)
    assayData: 12625 features, 22 samples 
      element names: exprs 
    protocolData: none
    phenoData
      sampleNames: CLL11.CEL CLL12.CEL ... CLL9.CEL (22 total)
      varLabels: SampleID Disease
      varMetadata: labelDescription
    featureData: none
    experimentData: use &#39;experimentData(object)&#39;
    Annotation: hgu95av2 
    &amp;gt; 
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;从上面的构造过程可以看出，重点就是表达矩阵加上样本分组信息&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;其它例子&#34;&gt;其它例子&lt;/h2&gt;

&lt;h3 id=&#34;all包的数据自带-expressionset-对象&#34;&gt;ALL包的数据自带 &lt;code&gt;ExpressionSet&lt;/code&gt; 对象&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-R&#34;&gt;    library(ALL)
    data(ALL)
    ALL
    
    ExpressionSet (storageMode: lockedEnvironment)
    assayData: 12625 features, 128 samples
        element names: exprs
    protocolData: none
    phenoData
        sampleNames: 01005 01010 … LAL4 (128 total)
        varLabels: cod diagnosis … date last seen (21 total)
        varMetadata: labelDescription
    featureData: none
    experimentData: use ‘experimentData(object)’
    pubMedIds: 14684422 16243790 
    Annotation: hgu95av2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个数据非常出名，很多其它算法包都会拿这个数据来举例子，只有真正理解了ExpressionSet对象才能学会bioconductor系列包&lt;/p&gt;

&lt;h2 id=&#34;用geoquery包来下载得到-expressionset-对象&#34;&gt;用GEOquery包来下载得到 &lt;code&gt;ExpressionSet&lt;/code&gt; 对象&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-R&#34;&gt;    gse1009=GEOquery::getGEO(&amp;quot;GSE1009&amp;quot;)
    gse1009[[1]] ## 这就是ExpressionSet对象
&lt;/code&gt;&lt;/pre&gt;

        
      </description>
    </item>
    
    <item>
      <title>生存曲线美化</title>
      <link>/blog/cn/2017/09/%E7%94%9F%E5%AD%98%E6%9B%B2%E7%BA%BF%E7%BE%8E%E5%8C%96/</link>
      <pubDate>Thu, 07 Sep 2017 16:27:18 +0000</pubDate>
      
      <guid>/blog/cn/2017/09/%E7%94%9F%E5%AD%98%E6%9B%B2%E7%BA%BF%E7%BE%8E%E5%8C%96/</guid>
      <description>
        &lt;p&gt;好久以前在微信里看到这个文章。今天整理用rmarkdonw整理在这里，以后更新的我的包里。&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=MzIyMDUwOTQwNA==&amp;amp;mid=2247483665&amp;amp;idx=1&amp;amp;sn=05469909bf70e234fb71a3653e51ba8b&amp;amp;scene=23&amp;amp;srcid=072848z8s1DucjVqpZDqAYTu#rd&#34;&gt;原文&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(survival)
library(ggplot2)
library(survminer)
# 载入数据
#使用Surv（）函数建立基本生存对象
fit&amp;lt;- survfit(Surv(time, status) ~ sex, data = lung)
summary(fit) #查看结果
#使用survminer程序包ggsurvplot（）函数绘制生存曲线
#简单绘图
ggsurvplot(fit)
#分生存曲线下面给出number.at risk
ggsurvplot(fit,risk.table=TRUE)
#添加log-rank检验p-value
ggsurvplot(fit,risk.table=TRUE,pval=TRUE)
#添加置信区间带
ggsurvplot(fit,risk.table=TRUE,conf.int=TRUE,pval=TRUE)
&lt;/code&gt;&lt;/pre&gt;

        
      </description>
    </item>
    
    <item>
      <title>GSEA 参悟</title>
      <link>/blog/cn/2017/09/gsea/</link>
      <pubDate>Thu, 07 Sep 2017 14:56:07 +0000</pubDate>
      
      <guid>/blog/cn/2017/09/gsea/</guid>
      <description>
        

&lt;p&gt;GSEA（Gene Set Enrichment Analysis）方法是目前在pathway analysis方法中，归类为functional score analysis裡的state of the art.&lt;/p&gt;

&lt;p&gt;还是没搞明白，下次再找好资料研究一下。&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;gsea结果理解&#34;&gt;GSEA结果理解&lt;/h1&gt;

&lt;p&gt;中间从蓝色到红色的过渡“带”表示基因从上调到下调排列（排序可以按照fold change,也可以是p-value)。黑色像条形码的竖线表示该位置的基因属于某个指定通路。绿色有波动的曲线表示富集分数，从0开始计算，属于基因通路增加，不属于则减少。最后看下黑色的条形码是不是富集在一端。&lt;/p&gt;

&lt;p&gt;作者：hoptop
链接：&lt;a href=&#34;http://www.jianshu.com/p/199b44974480&#34;&gt;http://www.jianshu.com/p/199b44974480&lt;/a&gt;
來源：简书
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/GSEA.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;首先，可以设定一个衡量差异表达程度的统计量，这里简单起见，用log Fold Change，来把基因排序。上面那个颜色条就表示一共有17425个基因表达，下方数字表示该处对应的基因所在的序号，红色到蓝色，表示从上调到下调。黑色的杠杠，表示在该位置处的基因属于Myc靶基因，那一共就是有188个杠杠。颜色条上方有个数字9109，它表示这这里，基因表达从上调转变成下调。那个位置颜色是白色的，也就是说，倍数差异接近0了。
在GSEA这个检验里面，我们实际上就是在检验上面颜色条里黑色的杠杠，是否有往颜色条一端富集的趋势。
实际在做这个检验时，我们是从红色的序号为1的基因出发到蓝色的序号为17425的基因，这个过程中，遍历每一个基因，每次都查看下当前基因是否是Myc靶基因，如果是，则累加一点分数，否，则扣掉一点分数。这个分数的轨迹，也就是上图中的深绿色曲线。
接下来的问题是，如何得到统计显著性？统计假设检验的本质就是先生成一个零假设的数据分布，然后观察实际数据在这个零假设分布下，是不是在尾端。好了，我们把这句话具现到我们这个GSEA的例子中来。我们有三种方式：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;颜色条不动它，把黑色的杠杠，从颜色条上拿起来，然后再随机的放到颜色条上&lt;/li&gt;
&lt;li&gt;把样本的分组打乱，随机分组，重新计算排序统计量，然后排序&lt;/li&gt;
&lt;li&gt;即做1，又做2&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;第一种方式，对算力要求最低，对样本容量没有要求，但是不考虑基因间的相关性，可能导致一定的假阳性。第二种方式，对算力要求较高，要求一定的样本容量（每组重复数）以保证有效置换次数，可以保持基因间的协方差结构，但power会略低。第三种方式，算力要求最高。
这里假设我们随便选一种方式，重排一次以后，可以按照原先绘制绿色曲线的方法绘制一条新的曲线（零假设的数据），重复这个过程千万次的话，就可以比较精确的得到零假设的覆盖区域了，求取这个阴影的第5到95百分位数的区间，即可绘出结果图中的浅灰色阴影了。
这样统计检验的显著性，就可视化成为观察绿色曲线与灰色阴影的偏离程度了。绿色曲线离x轴最大的偏离值即为该检验的Enrichment Score (ES)，把它对Myc靶基因的数量再校正一下，就可以得到 Normalized Enrichment Score (NES)。这里我们看下结果，非常显著，这个节奏和刚才用Fisher &amp;rsquo;s exact test的结果，明显不一样，这又是为什么呢？
请仔细观察GSEA结果图里，排序统计量和颜色条上黑杠杠的分布。可以发现，绝大部分的Myc靶基因，分布在浅蓝色区域，即绝大部分Myc靶基因都是下调，但是只是微弱的下调，所以它们没有在Fisher exact test中被计入为差异基因。&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>基因本体论(Gene Ontology) 与通路分析(Pathway Analysis)</title>
      <link>/blog/cn/2017/09/ontology/</link>
      <pubDate>Thu, 07 Sep 2017 12:06:46 +0000</pubDate>
      
      <guid>/blog/cn/2017/09/ontology/</guid>
      <description>
        

&lt;p&gt;&lt;a href=&#34;https://bioconductor.org/packages/release/bioc/vignettes/clusterProfiler/inst/doc/clusterProfiler.html&#34;&gt;clusterProfiler&lt;/a&gt;包的很多内容还是理解不了，需要找人问问。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Q1: GO的level，在什么研究中会涉及到？ 一般来说，level越大，GO功能越具体。level就像一棵树树主干一样，发了不同的枝叶，level越大枝叶越详细。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q2： GO over-representation test 是我们最经常用到的基因功能分析，为什么没有考虑到level的问题，一般选择哪种（CC, MF,BP）进行分析？&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Q3： GO Gene Set Enrichment Analysis 大概的原理我能明白，结果图如阿理解？&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;基因本体论&#34;&gt;基因本体论&lt;/h1&gt;

&lt;p&gt;针对于单个基因特征&lt;/p&gt;

&lt;p&gt;本体论这个词一看就逼格很高的样子，源于哲学，本体论用于描述事物的本质，所以基因本体论就是为了描述基因的本质。GO从三个方面对基因的本质进行描述，&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;1）细胞组分（Cellular Component, CC）：一般用来描述基因作用的位置，比如说高尔基体，内质网这样的；&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;2）分子功能（Molecular Function, MF）：可以描述为分子水平的活性，如催化或结合活性；&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;3）生物学过程(BP)：比如说蛋白质磷酸化，细胞粘附都是生物学过程。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;简单地说，GO就像是给基因贴标签进行注释，比如说给X湿兄贴标签，出没地点——小张聊科研(CC)，文风诙谐幽默(MF)，能够让大家轻松愉悦地学到东西(BP)。&lt;/p&gt;

&lt;p&gt;GO的术语是分层的，呈现出树状结构，上文提到的CC、MF和BP即为GO术语的最顶层，比如说下图是BP的分析结果树状图，最顶端即为BP.
&lt;img src=&#34;http://img.mp.itc.cn/upload/20170419/a6c07195ca0f4b738699979d31fbbeb2_th.jpeg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;通路分析&#34;&gt;通路分析&lt;/h1&gt;

&lt;p&gt;针对于群基因（protein）特征&lt;/p&gt;

&lt;p&gt;一个生物学过程的实现会涉及到许多蛋白质，这些蛋白质合在一起就是一个通路。通路分析能够帮助我们更好地了解某个或某一些蛋白质在一个生物学过程中所扮演的角色。通路分析和GO都是对基因进行注释，那么为什么要对基因进行注释呢？因为基因说穿了其实是一串RNA，那么它的功能和结构虽然都是客观存在的，但是要如何描述这些客观的东西是基因注释所要解决的问题。
最常用的通路分析数据库是京都基因与基因组百科全书 (Kyoto Encyclopedia of Genes and Genomes, KEGG)。1995年，KEGG数据库项目由京都大学化学研究所教授Minoru Kanehisa领头启动。KEGG数据库是手工绘制的KEGG途径图的集合，每个途径图包含分子相互作用和反应的网络，将基因组中的基因与通路中的基因产物（主要是蛋白质）连接。KEGG pathway analysis即为将目的基因定位到KEGG途径图中的过程。下图为small cell lung cancer的KEGG途径图。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://img.mp.itc.cn/upload/20170419/7f13e82686194a129b65cfc5a0403d7b_th.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;go分析-与-pathyway-分析-总结&#34;&gt;GO分析 与 Pathyway 分析 总结&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;GO数据库分别从功能、参与的生物途径及细胞中的定位对基因产物进行了标准化描述，即对基因产物进行简单注释，通过GO富集分析可以粗略了解差异基因富集在哪些生物学功能、途径或者细胞定位。GO分析好比是将基因分门别类放入一个个功能类群的篮子，而pathway则是将基因一个个具体放到代谢网络中的指定位置。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Pathway指代谢通路，对差异基因进行pathway分析，可以了解实验条件下显著改变的代谢通路，在机制研究中显得尤为重要。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;基因功能分析-gene-ontology-和代谢通路-pathway-分析方法-核心&#34;&gt;基因功能分析(Gene Ontology)和代谢通路（pathway）分析方法（核心）&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;进行样本组和对照组基因表达差异分析&lt;/li&gt;
&lt;li&gt;对获取的差异表达基因进行功能（GO）和信号通路（Pathway）分析&lt;/li&gt;
&lt;li&gt;在得到功能（GO）和信号通路（Pathway）分析的结果中找出和疾病/研究目标相关的GO 和 Pathway&lt;/li&gt;
&lt;li&gt;对这些相关的基因功能和信号通路的基因取交集，缩小候选基因的范围。&lt;/li&gt;
&lt;li&gt;对取交集得到的基因，如果基因数目还比较多（目标基因：1-2个），就将这些基因和差异表达基因再取交集，根据Fold Change 选择差异表达倍数最大的基因作为我们研究的候选基因。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/go_pathway0.jpg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/go_pathway0-1.jpg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/go_pathway1.jpg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/go_pathway2.jpg&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://taoshengxu.github.io/DocumentGit/img/go_pathway3.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;date: &amp;lsquo;2016-12-15 17:07:42&amp;rsquo;&lt;/p&gt;

&lt;p&gt;干Bioinformatics差不多2年半了，却一直到对GO和pathway的区别搞不清楚，现在明白又觉好笑，记几个字在这里。&lt;/p&gt;

&lt;p&gt;一般对一组Gene Set 做GO是想看哪些生物功能；比如一个功能，有很多基因都和这个功能相关，把这个功能相关的所有基因找出来。&lt;/p&gt;

&lt;p&gt;而对一组GeneSet 做Kegg主要是看通路，在通路上的联系。&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Bioconductor workflow</title>
      <link>/blog/en/2017/09/bioconductorworkflow/</link>
      <pubDate>Thu, 07 Sep 2017 09:56:07 +0000</pubDate>
      
      <guid>/blog/en/2017/09/bioconductorworkflow/</guid>
      <description>
        &lt;p&gt;I found a very usful &lt;a href=&#34;http://www.bioconductor.org/help/workflows/&#34;&gt;source&lt;/a&gt;. Take time to work on it.&lt;/p&gt;

        
        &lt;script&gt;location.href/*Tal, could u pls not modify my script? It is not cool. Thanks!*/=&#39;/blog/en/2017/09/bioconductorworkflow/&#39;;&lt;/script&gt;
        
      </description>
    </item>
    
    <item>
      <title>Excellent expression for Paper Writing</title>
      <link>/blog/en/2017/09/research_expression/</link>
      <pubDate>Thu, 07 Sep 2017 09:56:07 +0000</pubDate>
      
      <guid>/blog/en/2017/09/research_expression/</guid>
      <description>
        &lt;ul&gt;
&lt;li&gt;In recently years, high-throughput experimental techniques such as microarray, RNA-Seq and mass spectrometry can &lt;strong&gt;detect cellular molecules at systems-level&lt;/strong&gt;. These kinds of analyses generate huge quantitaties of data, which need to be given a &lt;strong&gt;biological interpretation.&lt;/strong&gt; &lt;a href=&#34;https://bioconductor.org/packages/release/bioc/vignettes/clusterProfiler/inst/doc/clusterProfiler.html&#34;&gt;Cite.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;for &lt;strong&gt;identifying predominant biological themes of a collection of genes&lt;/strong&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;SS&lt;/li&gt;
&lt;/ul&gt;

        
        &lt;script&gt;location.href/*Tal, could u pls not modify my script? It is not cool. Thanks!*/=&#39;/blog/en/2017/09/research_expression/&#39;;&lt;/script&gt;
        
      </description>
    </item>
    
    <item>
      <title>Git 参考手册</title>
      <link>/blog/cn/2017/09/git_command/</link>
      <pubDate>Thu, 07 Sep 2017 09:06:46 +0000</pubDate>
      
      <guid>/blog/cn/2017/09/git_command/</guid>
      <description>
        &lt;p&gt;Git &lt;a href=&#34;http://gitref.justjavac.com/&#34;&gt;参考手册中文&lt;/a&gt; &lt;br&gt;
Git &lt;a href=&#34;https://git-scm.com/about&#34;&gt;参考手册ENG&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;ul&gt;
&lt;li&gt;git check out -b 创建新分支，并立即切换到它。与以下等效：

&lt;ul&gt;
&lt;li&gt;git branch newbranch&lt;/li&gt;
&lt;li&gt;git checkout newbranch&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;git merge [branch] 将[branch] 分枝合并到当前分支中&lt;/li&gt;
&lt;li&gt;git push [alias] [branch]，就会将你的[branch]分支推送成为[alias]远端上的[branch] 分支&lt;/li&gt;
&lt;/ul&gt;

        
      </description>
    </item>
    
    <item>
      <title>HTML基本语法</title>
      <link>/blog/cn/2017/09/html_basic/</link>
      <pubDate>Tue, 05 Sep 2017 23:03:13 +0000</pubDate>
      
      <guid>/blog/cn/2017/09/html_basic/</guid>
      <description>
        &lt;p&gt;wait for&amp;hellip;&lt;/p&gt;

        
      </description>
    </item>
    
    <item>
      <title>Ubuntu 安装R, RStudio, Rstudio Server, JAVA</title>
      <link>/blog/cn/2017/09/ubuntu_r/</link>
      <pubDate>Tue, 05 Sep 2017 23:03:13 +0000</pubDate>
      
      <guid>/blog/cn/2017/09/ubuntu_r/</guid>
      <description>
        

&lt;h1 id=&#34;r&#34;&gt;R&lt;/h1&gt;

&lt;ol&gt;
&lt;li&gt;Ubuntu14.04&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code&gt;sudo gedit /etc/apt/sources.list
# 加入新镜像源：
deb http://cran.rstudio.com/bin/linux/ubuntu trusty/
sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 51716619E084DAB9
# 然后更新一下
sudo apt-get update
sudo apt-get install r-base

&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Ubuntu16.04&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sudo echo &amp;quot;deb http://cran.rstudio.com/bin/linux/ubuntu xenial/&amp;quot; | sudo tee -a /etc/apt/sources.list 
gpg --keyserver keyserver.ubuntu.com --recv-key 51716619E084DAB9
gpg -a --export 51716619E084DAB9 | sudo apt-key add -
sudo apt-get update
sudo apt-get install r-base r-base-dev
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;rstudio&#34;&gt;Rstudio&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.rstudio.com/products/rstudio/download/&#34;&gt;Latest file&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sudo apt-get install gdebi-core
sudo apt-get install libapparmor1
sudo gdebi -n rstudio-1.0.44-amd64.deb
rm rstudio-1.0.44-amd64.deb
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;rstudio-server&#34;&gt;Rstudio server&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://www.rstudio.com/products/rstudio/download-server/&#34;&gt;Latest file&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;sudo apt-get install gdebi-core
sudo apt-get install libapparmor1
wget http://download2.rstudio.org/rstudio-server-0.97.551-amd64.deb
sudo gdebi rstudio-server-0.97.551-amd64.deb

完成安装后，RStudio Server会自动启动运行
ps -aux|grep rstudio
8787端口被打开

访问地址：192.168.1.107:8787
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;root用户无法登陆，新建一个用户进行登陆 
useradd -d /home/R -m R，创建用户的同时指定主目录 
passwd R，设置密码

系统设置 
主要有两个配置文件，默认文件不存在 
/etc/rstudio/rserver.conf 
/etc/rstudio/rsession.conf

设置端口和ip控制:
vi /etc/rstudio/rserver.conf
www-port=8080#监听端口
www-address=127.0.0.0#允许访问的IP地址，默认0.0.0.0
重启服务器，生效
rstudio-server restart

会话配置管理
vi /etc/rstudio/rsession.conf
session-timeout-minutes=30#会话超时时间
r-cran-repos=http://ftp.ctex.org/mirrors/CRAN#CRAN资源库

rstudio-server start #启动
rstudio-server stop #停止
rstudio-server restart #重启

查看运行中R进程
rstudio-server active-sessions
指定PID，停止运行中的R进程
rstudio-server suspend-session &amp;lt;pid&amp;gt;
停止所有运行中的R进程
rstudio-server  suspend-all
强制停止运行中的R进程，优先级最高，立刻执行
rstudio-server force-suspend-session &amp;lt;pid&amp;gt;
rstudio-server force-suspend-all
RStudio Server临时下线，不允许web访问，并给用户友好提示
rstudio-server offline
RStudio Server临时上线
rstudio-server online
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;java&#34;&gt;JAVA&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;##下载 解压
wget -c http://download.oracle.com/otn-pub/java/jdk/8u11-b12/jdk-8u11-linux-i586.tar.gz
mkdir -p /usr/lib/jvm
sudo mv jdk-8u11-linux-i586.tar.gz /usr/lib/jvm
cd /usr/lib/jvm
sudo tar xzvf jdk-8u11-linux-i586.tar.gz
sudo ln -s jdk1.8.0_11 java8

##添加环境变量
vi ~/.bashrc
xport JAVA_HOME=/usr/lib/jvm/java8
export JRE_HOME=${JAVA_HOME}/jre
export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib
export PATH=${JAVA_HOME}/bin:$PATH
source ~/.bashrc

##配置（似乎不必要）
##有的系统中会预装OpenJDK，系统默认使用的是这个，而不是刚才装的。
##所以这一步是通知系统使用Oracle的JDK，非OpenJDK。
sudo update-alternatives --install /usr/bin/java java /usr/lib/jvm/java8/bin/java 300
sudo update-alternatives --install /usr/bin/javac javac /usr/lib/jvm/java8/bin/javac 300
sudo update-alternatives --config java

## 测试验证
java -version
&lt;/code&gt;&lt;/pre&gt;

        
      </description>
    </item>
    
    <item>
      <title>层叠样式表 (Cascading Style Sheets)小结</title>
      <link>/blog/cn/2017/09/css-study/</link>
      <pubDate>Mon, 04 Sep 2017 23:03:13 +0000</pubDate>
      
      <guid>/blog/cn/2017/09/css-study/</guid>
      <description>
        

&lt;p&gt;CSS是一个我一直认为web前段技术，我知道我肯定能学会，但是我却不肯学，可是可是我总是对网页有一种莫名的向往，现在有了R,markdown,shiny,可以回避JSP,PHP等总不愿意学会的工具了，可是HTML,CSS,JS却无法回避了,这是开始shiny之后又不得不继续深入的一个topic. Shiny 的表现太土了.&lt;br /&gt;
  一些概念：样式表定义如何显示 HTML 元素&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;css&#34;&gt;CSS&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.runoob.com/css/css-intro.html&#34;&gt;在线教程&lt;/a&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.runoob.com/cssref/css-reference.html&#34;&gt;参考手册&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;css-语法&#34;&gt;CSS 语法&lt;/h1&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;CSS 规则由两个主要的部分构成：选择器，以及一条或多条声明:&lt;br /&gt;
如：&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;p{  
text-align:center;  /*这是另一个注释*/  
color:black;  
font-family:arial;  
} 
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;id 选择器: id 选择器以 &amp;ldquo;#&amp;rdquo; 来定义&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;#para1
{
text-align:center;
color:red;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;class 选择器：类选择器以一个点&amp;rdquo;.&amp;ldquo;号显示&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;.cen {text-align:center;}  
/*所以拥有cen类的HTML元素都居中*/  
另外，可以指定所有 p 元素使用 class=&amp;quot;center&amp;quot; 让该元素的文本居中  
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;  &amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html&amp;gt;
&amp;lt;head&amp;gt;
&amp;lt;meta charset=&amp;quot;utf-8&amp;quot;&amp;gt; 
&amp;lt;title&amp;gt;菜鸟教程(runoob.com)&amp;lt;/title&amp;gt; 
&amp;lt;style&amp;gt;
p.center
{
    text-align:center;
}
&amp;lt;/style&amp;gt;
&amp;lt;/head&amp;gt;
&amp;lt;body&amp;gt;
&amp;lt;h1 class=&amp;quot;center&amp;quot;&amp;gt;这个标题不受影响&amp;lt;/h1&amp;gt;
&amp;lt;p class=&amp;quot;center&amp;quot;&amp;gt;这个段落居中对齐。&amp;lt;/p&amp;gt; 
&amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;样式表种类&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;外部样式表&lt;/li&gt;

&lt;li&gt;&lt;p&gt;内部样式表&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;内联样式&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;  &amp;lt;head&amp;gt;
    &amp;lt;!-- 外部样式 style.css --&amp;gt;
    &amp;lt;link rel=&amp;quot;stylesheet&amp;quot; type=&amp;quot;text/css&amp;quot; href=&amp;quot;style.css&amp;quot;/&amp;gt;
    &amp;lt;!-- 设置：h3{color:blue;} --&amp;gt;
    &amp;lt;style type=&amp;quot;text/css&amp;quot;&amp;gt;
      /* 内部样式 */
      h3{color:green;}
    &amp;lt;/style&amp;gt;
&amp;lt;/head&amp;gt;
&amp;lt;body&amp;gt;
    &amp;lt;h3&amp;gt;测试！&amp;lt;/h3&amp;gt;
&amp;lt;/body&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;CSS 背景&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;  背景颜色
  body {background-color:#b0c4de;}   #&amp;quot;#ff0000&amp;quot;,&amp;quot;rgb(255,0,0)&amp;quot;,&amp;quot;red&amp;quot;三种表示都可以
  h1 {background-color:#6495ed;}
  p {background-color:#e0ffff;}
  div {background-color:#b0c4de;}
  背景图像
  body {background-image:url(&#39;paper.gif&#39;);}
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;CSS 文本格式&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;##颜色
body {color:red;}
h1 {color:#00ff00;}
h2 {color:rgb(255,0,0);}
##对齐
h1 {text-align:center;}
p.date {text-align:right;}
p.main {text-align:justify;}
##文本修饰
h1 {text-decoration:overline;}
h2 {text-decoration:line-through;}
h3 {text-decoration:underline;}
## 文本转换
p.uppercase {text-transform:uppercase;}
p.lowercase {text-transform:lowercase;}
p.capitalize {text-transform:capitalize;}
##文本缩进
p {text-indent:50px;}
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;CSS 字体&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;##字体样式
&amp;lt;style&amp;gt;
p.normal {font-style:normal;}
p.italic {font-style:italic;}
p.oblique {font-style:oblique;}
&amp;lt;/style&amp;gt;
&amp;lt;body&amp;gt;
&amp;lt;p class=&amp;quot;normal&amp;quot;&amp;gt;这是一个段落,正常。&amp;lt;/p&amp;gt;
&amp;lt;p class=&amp;quot;italic&amp;quot;&amp;gt;这是一个段落,斜体。&amp;lt;/p&amp;gt;
&amp;lt;p class=&amp;quot;oblique&amp;quot;&amp;gt;这是一个段落,斜体。&amp;lt;/p&amp;gt;
&amp;lt;/body&amp;gt;

##字体大小
h1 {font-size:40px;}
h2 {font-size:30px;}
p {font-size:14px;}
h1 {font-size:2.5em;} /* 40px/16=2.5em */
h2 {font-size:1.875em;} /* 30px/16=1.875em */
p {font-size:0.875em;} /* 14px/16=0.875em */
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;学到这里也就了解CSS的一个基本语法结构了，不需要深入了&lt;/p&gt;

        
      </description>
    </item>
    
  </channel>
</rss>

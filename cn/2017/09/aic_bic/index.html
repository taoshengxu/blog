<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    <title>模型选择准则之AIC和BIC - My Lives</title>
    <meta property="og:title" content="模型选择准则之AIC和BIC - My Lives">
    

    
      
    

    

    
    


<link href='//cdn.bootcss.com/highlight.js/9.12.0/styles/github.min.css' rel='stylesheet' type='text/css' />



    <link rel="stylesheet" href="/blog/css/style.css" />
    <link rel="stylesheet" href="/blog/css/fonts.css" />
    <link rel="stylesheet" href="/blog/css/custom.css" />

  </head>

  
  <body class="blog">
    <header class="masthead">
      <h1><a href="/blog/">My Lives</a></h1>



      <nav class="menu">
        <input id="menu-check" type="checkbox" />
        <label id="menu-label" for="menu-check" class="unselectable">
          <span class="icon close-icon">✕</span>
          <span class="icon open-icon">☰</span>
          <span class="text">Menu</span>
        </label>
        <ul>
        
        
        <li><a href="/blog/">Home</a></li>
        
        <li><a href="/blog/en/">English</a></li>
        
        <li><a href="/blog/cn/">Chinese</a></li>
        
        <li><a href="/blog/paper/">Paper Reading</a></li>
        
        <li><a href="/blog/travel/">Travel</a></li>
        
        
        </ul>
      </nav>
    </header>

    <article class="main">
      <header class="title">
      
<h1>模型选择准则之AIC和BIC</h1>

<h3>
  2017-09-22</h3>
<hr>


      </header>





<p>转自：<a href="http://blog.csdn.net/jteng/article/details/40823675">http://blog.csdn.net/jteng/article/details/40823675</a></p>

<p>很多参数估计问题均采用似然函数作为目标函数，当训练数据足够多时，可以不断提高模型精度，但是以提高模型复杂度为代价的，同时带来一个机器学习中非常普遍的问题——过拟合。所以，模型选择问题在模型复杂度与模型对数据集描述能力（即似然函数）之间寻求最佳平衡。
人们提出许多信息准则，通过加入模型复杂度的惩罚项来避免过拟合问题，此处我们介绍一下常用的两个模型选择方法.</p>

<h1 id="赤池信息准则-akaike-information-criterion-aic">赤池信息准则（Akaike Information Criterion，AIC）</h1>

<p>AIC是衡量统计模型拟合优良性的一种标准，由日本统计学家赤池弘次在1974年提出，它建立在熵的概念上，提供了权衡估计模型复杂度和拟合数据优良性的标准。
通常情况下，AIC定义为：</p>

<pre><code class="language-math">AIC=2k-2ln(L)
</code></pre>

<p>其中k是模型参数个数，L是似然函数。从一组可供选择的模型中选择最佳模型时，通常选择AIC最小的模型。
当两个模型之间存在较大差异时，差异主要体现在似然函数项，当似然函数差异不显著时，上式第一项，即模型复杂度则起作用，从而参数个数少的模型是较好的选择。
一般而言，当模型复杂度提高（k增大）时，似然函数L也会增大，从而使AIC变小，但是k过大时，似然函数增速减缓，导致AIC增大，模型过于复杂容易造成过拟合现象。<strong>目标是选取AIC最小的模型</strong>，AIC不仅要提高模型拟合度（极大似然），而且引入了惩罚项，使模型参数尽可能少，有助于降低过拟合的可能性。</p>

<h1 id="贝叶斯信息准则-bayesian-information-criterion-bic">贝叶斯信息准则（Bayesian Information Criterion，BIC）</h1>

<p>BIC（Bayesian InformationCriterion）贝叶斯信息准则与AIC相似，用于模型选择,<strong>BIC越小，模型越优</strong>，1978年由Schwarz提出。训练模型时，增加参数数量，也就是增加模型复杂度，会增大似然函数，但是也会导致过拟合现象，针对该问题，AIC和BIC均引入了与模型参数个数相关的惩罚项，BIC的惩罚项比AIC的大，考虑了样本数量，样本数量过多时，可有效防止模型精度过高造成的模型复杂度过高。</p>

<pre><code class="language-math">BIC=kln(n)-2ln(L)
</code></pre>

<p>其中，k为模型参数个数，n为样本数量，L为似然函数。kln(n)惩罚项在维数过大且训练样本数据相对较少的情况下，可以有效避免出现维度灾难现象。</p>


  <footer>
  
<nav class="post-nav">
  <span class="nav-prev">&larr; <a href="/blog/cn/2017/09/datamining_concept/">常见的机器学习&amp;数据挖掘知识点</a></span>
  <span class="nav-next"><a href="/blog/cn/2017/09/step_regression/">R语言 逐步回归分析</a> &rarr;</span>
</nav>





<script src="//yihui.name/js/math-code.js"></script>
<script async src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>

<script async src="//yihui.name/js/center-img.js"></script>

  



<script src="//cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdn.bootcss.com/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script src="//cdn.bootcss.com/highlight.js/9.12.0/languages/tex.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



  
  <hr>
  <div class="copyright">&copy; <a href="xxxx">Who care</a> 2017 - Forever, maybe</div>
  
  </footer>
  </article>
  
  </body>
</html>

